{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90aa7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3849, 1, 264), (3849, 1, 264), (3849,), (3849,), (3849, 34716)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "basis_file = '/home/anton/Documents/Tulane/Research/PNC_Good/AngleBasis1.pkl'\n",
    "demodir = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/PNC/'\n",
    "\n",
    "basis = pickle.load(open(basis_file, 'rb'))\n",
    "\n",
    "pnc_thetas = []\n",
    "pnc_jitter = []\n",
    "pnc_sex = []\n",
    "pnc_race = []\n",
    "pnc_fc = []\n",
    "\n",
    "demo = pickle.load(open(f'{demodir}/demographics.pkl', 'rb'))\n",
    "pnc_subs = []\n",
    "pnc_tasks = []\n",
    "\n",
    "for subtask in basis:\n",
    "    m = re.search('([^-]+)-(.*)', subtask)\n",
    "    sub = m.group(1)\n",
    "    task = m.group(2)\n",
    "    if sub not in demo['Race'] or demo['Race'][sub] not in ['AA', 'EA']:\n",
    "        continue\n",
    "    s = demo['Sex'][sub] == 'M'\n",
    "    r = demo['Race'][sub]\n",
    "    pnc_subs.append(sub)\n",
    "    pnc_tasks.append(task)\n",
    "    pnc_sex.append(s)\n",
    "    pnc_race.append(r == 'AA')\n",
    "    pnc_thetas.append(basis[subtask]['thetas'])\n",
    "    pnc_jitter.append(basis[subtask]['jitter'])\n",
    "    p = np.load(f'{demodir}/fc/{sub}_task-{task}_fc.npy')\n",
    "    pnc_fc.append(p)\n",
    "    \n",
    "pnc_thetas = np.stack(pnc_thetas)\n",
    "pnc_jitter = np.stack(pnc_jitter)\n",
    "pnc_sex = np.array(pnc_sex).astype('int')\n",
    "pnc_race = np.array(pnc_race).astype('int')\n",
    "pnc_fc = np.stack(pnc_fc)\n",
    "\n",
    "print([a.shape for a in [pnc_thetas, pnc_jitter, pnc_sex, pnc_race, pnc_fc]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "219bb62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1165, 1, 264), (1165, 1, 264), (1165, 34716), (1165,), (1165,)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "basis_file = '/home/anton/Documents/Tulane/Research/BSNIP/AngleBasis1.pkl'\n",
    "demodir = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/BSNIP/'\n",
    "\n",
    "basis = pickle.load(open(basis_file, 'rb'))\n",
    "\n",
    "bsnip_thetas = []\n",
    "bsnip_jitter = []\n",
    "bsnip_fc = []\n",
    "bsnip_race = []\n",
    "bsnip_sex = []\n",
    "\n",
    "demo = pickle.load(open(f'{demodir}/demographics.pkl', 'rb'))\n",
    "bsnip_subs = []\n",
    "\n",
    "for subtask in basis:\n",
    "    m = re.search('([^-]+)', subtask)\n",
    "    sub = m.group(1)\n",
    "    s = demo['sex'][sub] == 's1.0' # Male\n",
    "    r = demo['Race'][sub]\n",
    "    if r not in ['AA', 'CA']:\n",
    "        continue\n",
    "    bsnip_sex.append(s)\n",
    "    bsnip_race.append(r == 'AA')\n",
    "    bsnip_subs.append(sub)\n",
    "    bsnip_thetas.append(basis[subtask]['thetas'])\n",
    "    bsnip_jitter.append(basis[subtask]['jitter'])\n",
    "    p = np.load(f'{demodir}/fc/{sub}_task-unk_fc.npy')\n",
    "    bsnip_fc.append(p)\n",
    "    \n",
    "bsnip_thetas = np.stack(bsnip_thetas)\n",
    "bsnip_jitter = np.stack(bsnip_jitter)\n",
    "bsnip_fc = np.stack(bsnip_fc)\n",
    "bsnip_sex = np.array(bsnip_sex).astype('int')\n",
    "bsnip_race = np.array(bsnip_race).astype('int')\n",
    "\n",
    "print([a.shape for a in [bsnip_thetas, bsnip_jitter, bsnip_fc, bsnip_sex, bsnip_race]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ce892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def tops(thetas, jitter):\n",
    "    t0 = np.expand_dims(thetas, 2)\n",
    "    t1 = np.expand_dims(thetas, 3)\n",
    "    j0 = np.expand_dims(jitter, 2)\n",
    "    j1 = np.expand_dims(jitter, 3)\n",
    "    ps = np.cos(t0-t1)*(j0*j1)\n",
    "    a,b = np.triu_indices(264, 1)\n",
    "    ps = ps[:,:,a,b]\n",
    "    return ps\n",
    "\n",
    "def tops2(thetas, jitter, fc):\n",
    "    paps = []\n",
    "    pres = []\n",
    "\n",
    "    for i in range(0,fc.shape[0],500):\n",
    "        ps = tops(thetas[i:i+500], jitter[i:i+500])\n",
    "        aps = np.mean(ps, axis=1)\n",
    "        res = fc[i:i+500] - aps\n",
    "        paps.append(aps)\n",
    "        pres.append(res)\n",
    "        print(f'Done {i}')\n",
    "\n",
    "    aps = np.concatenate(paps)\n",
    "    res = np.concatenate(pres)\n",
    "    \n",
    "    return aps, res\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47bd75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "Done 1500\n",
      "Done 2000\n",
      "Done 2500\n",
      "Done 3000\n",
      "Done 3500\n",
      "(3849, 34716)\n",
      "(3849, 34716)\n",
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "(1165, 34716)\n",
      "(1165, 34716)\n"
     ]
    }
   ],
   "source": [
    "# AB20\n",
    "\n",
    "pnc_ab20, pnc_res20 = tops2(pnc_thetas, pnc_jitter, pnc_fc)\n",
    "\n",
    "print(pnc_ab20.shape)\n",
    "print(pnc_res20.shape)\n",
    "\n",
    "bsnip_ab20, bsnip_res20 = tops2(bsnip_thetas, bsnip_jitter, bsnip_fc)\n",
    "\n",
    "print(bsnip_ab20.shape)\n",
    "print(bsnip_res20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1cbd5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "Done 1500\n",
      "Done 2000\n",
      "Done 2500\n",
      "Done 3000\n",
      "Done 3500\n",
      "(3849, 34716)\n",
      "(3849, 34716)\n",
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "(1165, 34716)\n",
      "(1165, 34716)\n"
     ]
    }
   ],
   "source": [
    "# AB1\n",
    "\n",
    "pnc_ab1, pnc_res1 = tops2(pnc_thetas, pnc_jitter, pnc_fc)\n",
    "\n",
    "print(pnc_ab1.shape)\n",
    "print(pnc_res1.shape)\n",
    "\n",
    "bsnip_ab1, bsnip_res1 = tops2(bsnip_thetas, bsnip_jitter, bsnip_fc)\n",
    "\n",
    "print(bsnip_ab1.shape)\n",
    "print(bsnip_res1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0321a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tonp(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def totorch(x):\n",
    "    return torch.from_numpy(x).float().cuda()\n",
    "\n",
    "def totorchidcs(x):\n",
    "    return torch.from_numpy(x).long().cuda() #F.one_hot(torch.from_numpy(x)).float().cuda()\n",
    "\n",
    "def rmse(yt, yhat):\n",
    "    return torch.mean((yt-yhat)**2)**0.5\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Linear(34716,100).float().cuda()\n",
    "        self.l2 = nn.Linear(100,2).float().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "def fit_mlp(xtr, ytr, verbose=False):\n",
    "    xtr = totorch(xtr)\n",
    "    ytr = totorchidcs(ytr)\n",
    "    \n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    mlp = MLP()\n",
    "    optim = torch.optim.Adam(mlp.parameters(), lr=5e-4, weight_decay=5e-4)\n",
    "\n",
    "    nepochs = 1000\n",
    "    pperiod = 100\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        yhat = mlp(xtr)\n",
    "        loss = ce(yhat, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if verbose:\n",
    "            if epoch % pperiod == 0 or epoch == nepochs-1:\n",
    "                print(f'{epoch} {float(loss)}')\n",
    "\n",
    "    if verbose:\n",
    "        print('Complete')\n",
    "    \n",
    "    return mlp\n",
    "    \n",
    "def predict_help(model, xt):\n",
    "    xt = totorch(xt)\n",
    "    with torch.no_grad():\n",
    "        yhat = model(xt)\n",
    "        return tonp(yhat)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e77633f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7213427851534008\n",
      "0.7166706647916093\n",
      "0.7198197973789989\n",
      "0.7073134279056847\n",
      "0.7261364737837623\n",
      "0.7514142802914823\n",
      "---\n",
      "0.7028198693993986\n",
      "0.7200984026091962\n",
      "0.7167884425128297\n",
      "0.6952592165805039\n",
      "0.7264318657236507\n",
      "0.7376721923821912\n",
      "---\n",
      "0.6836154673826107\n",
      "0.7084683264570999\n",
      "0.7228998878539491\n",
      "0.7104243842661961\n",
      "0.7264963050285942\n",
      "0.751885661929746\n",
      "---\n",
      "0.716242468317793\n",
      "0.7099900958412824\n",
      "0.7166663327374954\n",
      "0.7147155546193504\n",
      "0.7261929258639334\n",
      "0.7575632249760247\n",
      "---\n",
      "0.6975952767613997\n",
      "0.7172200234039223\n",
      "0.7117345598822548\n",
      "0.7013083886437368\n",
      "0.7264334902439433\n",
      "0.7477203918992754\n",
      "---\n",
      "0.6837825222193763\n",
      "0.6974477161681465\n",
      "0.7204105812587758\n",
      "0.6833487753012266\n",
      "0.7262593958192428\n",
      "0.7366823180171755\n",
      "---\n",
      "0.700488818156072\n",
      "0.7117280618010839\n",
      "0.7100169004261117\n",
      "0.7147843259784079\n",
      "0.7260365657857615\n",
      "0.7550810933454776\n",
      "---\n",
      "0.7159932398295553\n",
      "0.719763751428901\n",
      "0.7180607126553921\n",
      "0.685901167434433\n",
      "0.7267776177926126\n",
      "0.7322416917970931\n",
      "---\n",
      "0.7188693176310812\n",
      "0.7202261982055549\n",
      "0.7195452534495335\n",
      "0.693041746380975\n",
      "0.7209642719252027\n",
      "0.7362236617878712\n",
      "---\n",
      "0.7179321047988871\n",
      "0.7235510497379378\n",
      "0.7215951273055328\n",
      "0.6742168052292226\n",
      "0.725792346235093\n",
      "0.7234755095443275\n",
      "---\n",
      "0.7101923080047156 0.011766088075789516\n",
      "0.7177537595460873 0.003925222478483088\n",
      "0.6980313792339736 0.013311426964141226\n",
      "0.7257521258201798 0.001616699102405181\n",
      "0.7429960025970664 0.01068289146684681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cat(x, **kwargs):\n",
    "    return np.concatenate(x, **kwargs)\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def predict(xtr, xt, ytr, yt, lst):\n",
    "    reg = fit_mlp(xtr, ytr)\n",
    "    p = predict_help(reg, xt)\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "    return p\n",
    "    \n",
    "def get_res(fctr, fct, abtr, abt):\n",
    "    return fctr-abtr, fct-abt\n",
    "\n",
    "def combine(yt, p0, p1, lst):\n",
    "    p = (p0+p1)/2\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "\n",
    "rfc = []\n",
    "rfc2 = []\n",
    "rfc_ens = []\n",
    "\n",
    "rab20 = []\n",
    "rres1 = []\n",
    "rbest = []\n",
    "\n",
    "x1a = bsnip_fc\n",
    "x1b = pnc_fc\n",
    "x2a = bsnip_ab20\n",
    "x2b = pnc_ab20\n",
    "x3a = bsnip_res1\n",
    "x3b = pnc_res1\n",
    "ya = bsnip_sex\n",
    "yb = pnc_sex\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    p1 = predict(x1a, x1b, ya, yb, rfc)\n",
    "    p2 = predict(x1a, x1b, ya, yb, rfc)\n",
    "    combine(yb, p1, p2, rfc_ens)\n",
    "    \n",
    "    p1 = predict(x2a, x2b, ya, yb, rab20)\n",
    "    p2 = predict(x3a, x3b, ya, yb, rres1)\n",
    "    combine(yb, p1, p2, rbest)\n",
    "    \n",
    "    print('---')\n",
    "    \n",
    "print(np.mean(rfc), np.std(rfc))\n",
    "print(np.mean(rfc_ens), np.std(rfc_ens))\n",
    "print(np.mean(rab20), np.std(rab20))\n",
    "print(np.mean(rres1), np.std(rres1))\n",
    "print(np.mean(rbest), np.std(rbest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96765470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
