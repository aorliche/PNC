{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a452c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3849, 20, 264), (3849, 20, 264), (3849,), (3849,), (3849,), (3849, 34716)]\n",
      "0.5263704858404781\n",
      "0.5188360613146272\n",
      "14.398285268901013\n"
     ]
    }
   ],
   "source": [
    "# PNC\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "basis_file = '/home/anton/Documents/Tulane/Research/PNC_Good/AngleBasisLong20.pkl'\n",
    "demodir = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/PNC/'\n",
    "\n",
    "basis = pickle.load(open(basis_file, 'rb'))\n",
    "\n",
    "thetas = []\n",
    "jitter = []\n",
    "age = []\n",
    "sex = []\n",
    "race = []\n",
    "fc = []\n",
    "\n",
    "demo = pickle.load(open(f'{demodir}/demographics.pkl', 'rb'))\n",
    "\n",
    "for subtask in basis:\n",
    "    m = re.search('([^-]+)-(.+)', subtask)\n",
    "    sub = m.group(1)\n",
    "    task = m.group(2)\n",
    "    if sub not in demo['Race'] or demo['Race'][sub] not in ['AA', 'EA']:\n",
    "        continue\n",
    "    a = demo['age_at_cnb'][sub]\n",
    "    s = demo['Sex'][sub] == 'M'\n",
    "    r = demo['Race'][sub] == 'AA'\n",
    "    age.append(a)\n",
    "    sex.append(s)\n",
    "    race.append(r)\n",
    "    thetas.append(basis[subtask]['thetas'])\n",
    "    jitter.append(basis[subtask]['jitter'])\n",
    "    p = np.load(f'{demodir}/fc/{sub}_task-{task}_fc.npy')\n",
    "    fc.append(p)\n",
    "    \n",
    "thetas = np.stack(thetas)\n",
    "jitter = np.stack(jitter)\n",
    "age = np.array(age).astype('int')\n",
    "sex = np.array(sex).astype('int')\n",
    "race = np.array(race).astype('int')\n",
    "fc = np.stack(fc)\n",
    "\n",
    "print([a.shape for a in [thetas, jitter, sex, race, age, fc]])\n",
    "print(np.mean(1-sex))\n",
    "print(np.mean(1-race))\n",
    "print(np.mean(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a4211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "Done 1500\n",
      "Done 2000\n",
      "Done 2500\n",
      "Done 3000\n",
      "Done 3500\n",
      "(349, 20, 34716)\n",
      "(3849, 34716)\n",
      "(3849, 34716)\n"
     ]
    }
   ],
   "source": [
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def tops(thetas, jitter):\n",
    "    t0 = np.expand_dims(thetas, 2)\n",
    "    t1 = np.expand_dims(thetas, 3)\n",
    "    j0 = np.expand_dims(jitter, 2)\n",
    "    j1 = np.expand_dims(jitter, 3)\n",
    "    ps = np.cos(t0-t1)*(j0*j1)\n",
    "    a,b = np.triu_indices(264, 1)\n",
    "    ps = ps[:,:,a,b]\n",
    "    return ps\n",
    "\n",
    "paps = []\n",
    "pres = []\n",
    "\n",
    "for i in range(0,fc.shape[0],500):\n",
    "    ps = tops(thetas[i:i+500], jitter[i:i+500])\n",
    "    aps = np.mean(ps, axis=1)\n",
    "    res = fc[i:i+500] - aps\n",
    "    paps.append(aps)\n",
    "    pres.append(res)\n",
    "    print(f'Done {i}')\n",
    "    \n",
    "aps = np.concatenate(paps)\n",
    "res = np.concatenate(pres)\n",
    "\n",
    "print(ps.shape)\n",
    "print(aps.shape)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb14598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "aps20 = aps\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b40f7b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tonp(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def totorch(x):\n",
    "    return torch.from_numpy(x).float().cuda()\n",
    "\n",
    "def totorchidcs(x):\n",
    "    return torch.from_numpy(x).long().cuda() #F.one_hot(torch.from_numpy(x)).float().cuda()\n",
    "\n",
    "def rmse(yt, yhat):\n",
    "    return torch.mean((yt-yhat)**2)**0.5\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Linear(34716,100).float().cuda()\n",
    "        self.l2 = nn.Linear(100,2).float().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "def fit_mlp(xtr, ytr, verbose=False):\n",
    "    xtr = totorch(xtr)\n",
    "    ytr = totorchidcs(ytr)\n",
    "    \n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    mlp = MLP()\n",
    "    optim = torch.optim.Adam(mlp.parameters(), lr=5e-4, weight_decay=5e-4)\n",
    "\n",
    "    nepochs = 1000\n",
    "    pperiod = 100\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        yhat = mlp(xtr)\n",
    "        loss = ce(yhat, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if verbose:\n",
    "            if epoch % pperiod == 0 or epoch == nepochs-1:\n",
    "                print(f'{epoch} {float(loss)}')\n",
    "\n",
    "    if verbose:\n",
    "        print('Complete')\n",
    "    \n",
    "    return mlp\n",
    "    \n",
    "def predict_help(model, xt):\n",
    "    xt = totorch(xt)\n",
    "    with torch.no_grad():\n",
    "        yhat = model(xt)\n",
    "        return tonp(yhat)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0af365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9277794689666836\n",
      "0.8017791307289024\n",
      "0.8673769660071029\n",
      "0.7998308811094199\n",
      "0.9158599695585998\n",
      "0.9300186030779638\n",
      "0.9283341789277861\n",
      "0.9525114155251142\n",
      "0.9509216979536615\n",
      "0.9468831388466094\n",
      "0.9434737020125148\n",
      "0.9345577541011332\n",
      "0.9046034162015897\n",
      "0.9504346355487908\n",
      "0.9505766954168781\n",
      "0.9101978691019785\n",
      "0.9645729748012853\n",
      "0.965499746321664\n",
      "0.9563064434297309\n",
      "0.9641332656857772\n",
      "---\n",
      "0.9434601725012683\n",
      "0.7924978860138677\n",
      "0.8540842212075089\n",
      "0.8366852697446305\n",
      "0.9284965330627432\n",
      "0.9323930323017081\n",
      "0.9359512937595129\n",
      "0.9603450025367833\n",
      "0.958532048029765\n",
      "0.9558532048029764\n",
      "0.955900558092339\n",
      "0.9330559783527821\n",
      "0.9294503636056147\n",
      "0.9545881955014375\n",
      "0.9583832234060544\n",
      "0.9498393370539491\n",
      "0.9660679857940132\n",
      "0.9578149839337055\n",
      "0.9627059022492812\n",
      "0.9684018264840182\n",
      "---\n",
      "0.9348689328598005\n",
      "0.8014950109927279\n",
      "0.8754473194655843\n",
      "0.8974598342634871\n",
      "0.9150008455944529\n",
      "0.9284085912396414\n",
      "0.9031692880094706\n",
      "0.9488584474885845\n",
      "0.9542093691865382\n",
      "0.9487705056654828\n",
      "0.9414375105699306\n",
      "0.9188905800777946\n",
      "0.9182411635379673\n",
      "0.9456181295450702\n",
      "0.9567123287671232\n",
      "0.9520581768983596\n",
      "0.9544258413664808\n",
      "0.9569829189920515\n",
      "0.9507255200405886\n",
      "0.9587417554540841\n",
      "---\n",
      "0.9446913580246913\n",
      "0.8062506341958396\n",
      "0.8845594452900389\n",
      "0.9110569930661254\n",
      "0.93039066463724\n",
      "0.9390698461018095\n",
      "0.9363368848300355\n",
      "0.9511787586673432\n",
      "0.9471740233384068\n",
      "0.9387519025875191\n",
      "0.9332318619989852\n",
      "0.9170167427701675\n",
      "0.9121393539658379\n",
      "0.9364721799424995\n",
      "0.9555555555555555\n",
      "0.9601894131574497\n",
      "0.9596414679519703\n",
      "0.9633485540334855\n",
      "0.9599729409775072\n",
      "0.9633417892778622\n",
      "---\n",
      "0.9536073059360731\n",
      "0.7602705902249282\n",
      "0.8912971418907493\n",
      "0.7926737696600711\n",
      "0.9403822086927109\n",
      "0.9108066971080669\n",
      "0.9457060713681719\n",
      "0.9584238119397936\n",
      "0.957104684593269\n",
      "0.9513952308472856\n",
      "0.9391104346355488\n",
      "0.9314865550481989\n",
      "0.9100084559445291\n",
      "0.9542026044309149\n",
      "0.9718518518518519\n",
      "0.9529240656181296\n",
      "0.9704515474378488\n",
      "0.9564755623203112\n",
      "0.97039066463724\n",
      "0.9749298156604094\n",
      "---\n",
      "0.9477760865888719\n",
      "0.8295755115846439\n",
      "0.8839912058176899\n",
      "0.9228344326061222\n",
      "0.9242956198207339\n",
      "0.9002739726027397\n",
      "0.9468899036022322\n",
      "0.9519634703196347\n",
      "0.9510637578217488\n",
      "0.9401454422458988\n",
      "0.9374327752409946\n",
      "0.9289430069338744\n",
      "0.9189852866565196\n",
      "0.9545273127008287\n",
      "0.9598917639100287\n",
      "0.9646676813800101\n",
      "0.9581261626923727\n",
      "0.931987146964316\n",
      "0.9654118044985626\n",
      "0.9680771182141045\n",
      "---\n",
      "0.9424386944021648\n",
      "0.8050668019617792\n",
      "0.8791882293252157\n",
      "0.9013766277693218\n",
      "0.9292541856925419\n",
      "0.9332183324877389\n",
      "0.9297209538305429\n",
      "0.9563537967190935\n",
      "0.943683409436834\n",
      "0.9369389480805006\n",
      "0.932954507018434\n",
      "0.9211364789446982\n",
      "0.9170438017926603\n",
      "0.9421748689328598\n",
      "0.9503669879925588\n",
      "0.9573955690850668\n",
      "0.9608997124978861\n",
      "0.9532487738880433\n",
      "0.9580585151361407\n",
      "0.9646473871131406\n",
      "---\n",
      "0.9477693218332488\n",
      "0.7985455775410114\n",
      "0.8683510908168443\n",
      "0.9162590901403688\n",
      "0.9352342296634535\n",
      "0.9345036360561474\n",
      "0.9430272281413834\n",
      "0.9606088280060883\n",
      "0.9552443767968882\n",
      "0.9476746152545239\n",
      "0.9386639607644173\n",
      "0.9295721292068324\n",
      "0.9183967529173008\n",
      "0.950705225773719\n",
      "0.9525114155251142\n",
      "0.9656147471672586\n",
      "0.9712430238457634\n",
      "0.9655065110772874\n",
      "0.9682800608828006\n",
      "0.9736039235582614\n",
      "---\n",
      "0.9420733975985118\n",
      "0.8192322002367665\n",
      "0.8838017926602403\n",
      "0.9000372061559276\n",
      "0.9168543886352105\n",
      "0.93315744968713\n",
      "0.9203517672924065\n",
      "0.945746659901911\n",
      "0.9409233891425673\n",
      "0.9472957889396245\n",
      "0.9355251141552511\n",
      "0.9220023676644681\n",
      "0.9061728395061728\n",
      "0.9429663453407746\n",
      "0.9499475731439202\n",
      "0.9617926602401489\n",
      "0.9608117706747844\n",
      "0.9573076272619652\n",
      "0.9534990698461019\n",
      "0.9598511753762895\n",
      "---\n",
      "0.9542837814983934\n",
      "0.7916252325384746\n",
      "0.8142533400980888\n",
      "0.9100355149670217\n",
      "0.9416133942161339\n",
      "0.9470319634703196\n",
      "0.8582445459157788\n",
      "0.9674074074074075\n",
      "0.9576188060206324\n",
      "0.9504481650600373\n",
      "0.9292135971588026\n",
      "0.9194114662607813\n",
      "0.917037037037037\n",
      "0.9563943852528327\n",
      "0.9442651784204297\n",
      "0.9637273803483849\n",
      "0.9684085912396415\n",
      "0.9644715034669372\n",
      "0.9329342127515644\n",
      "0.9661626923727381\n",
      "---\n",
      "0.9438748520209707 0.0076142456083992454\n",
      "0.9661890749196684 0.005001838944883086\n",
      "0.8006338576018941 0.017371452791562998\n",
      "0.8702350752579063 0.021297733630775615\n",
      "0.8788249619482496 0.047005097289453804\n",
      "0.927738203957382 0.009231102562339798\n",
      "0.9288882124133264 0.012887506252486764\n",
      "0.9247732115677321 0.025433663805884164\n",
      "0.9553397598511753 0.006162232300202971\n",
      "0.9516475562320311 0.005758887795436483\n",
      "0.9464156942330458 0.00571055848239683\n",
      "0.9386944021647219 0.0070064231684471324\n",
      "0.925607305936073 0.006223262994104282\n",
      "0.9152078471165229 0.006882875531354954\n",
      "0.9488083882969729 0.006320543412035273\n",
      "0.9550062573989514 0.007145541782826241\n",
      "0.9538406900050737 0.01547417295643208\n",
      "0.9634649078302047 0.005293401866972088\n",
      "0.9572643328259767 0.009385008665405016\n",
      "0.9578285134449518 0.010218750817581793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cat(x, **kwargs):\n",
    "    return np.concatenate(x, **kwargs)\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def predict(xtr, xt, ytr, yt, lst):\n",
    "    reg = fit_mlp(xtr, ytr)\n",
    "    p = predict_help(reg, xt)\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "    return p\n",
    "    \n",
    "def get_res(fctr, fct, abtr, abt):\n",
    "    return fctr-abtr, fct-abt\n",
    "\n",
    "def combine(yt, p0, p1, lst):\n",
    "    p = (p0+p1)/2\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "\n",
    "rfc = []\n",
    "\n",
    "rab1 = []\n",
    "rab3 = []\n",
    "rab5 = []\n",
    "rab10 = []\n",
    "rab15 = []\n",
    "rab20 = []\n",
    "\n",
    "rres1 = []\n",
    "rres3 = []\n",
    "rres5 = []\n",
    "rres10 = []\n",
    "rres15 = []\n",
    "rres20 = []\n",
    "\n",
    "rens1 = []\n",
    "rens3 = []\n",
    "rens5 = []\n",
    "rens10 = []\n",
    "rens15 = []\n",
    "rens20 = []\n",
    "\n",
    "rbest = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    x0tr, x0t, x1tr, x1t, x2tr, x2t, x3tr, x3t, x4tr, x4t, x5tr, x5t, x6tr, x6t, ytr, yt = train_test_split(\n",
    "        fc, aps1, aps3, aps5, aps10, aps15, aps20, sex, stratify=sex, train_size=0.8)\n",
    "    \n",
    "    x1atr, x1at = get_res(x0tr, x0t, x1tr, x1t)\n",
    "    x2atr, x2at = get_res(x0tr, x0t, x2tr, x2t)\n",
    "    x3atr, x3at = get_res(x0tr, x0t, x3tr, x3t)\n",
    "    x4atr, x4at = get_res(x0tr, x0t, x4tr, x4t)\n",
    "    x5atr, x5at = get_res(x0tr, x0t, x5tr, x5t)\n",
    "    x6atr, x6at = get_res(x0tr, x0t, x6tr, x6t)\n",
    "\n",
    "    predict(x0tr, x0t, ytr, yt, rfc)\n",
    "    \n",
    "    p1 = predict(x1tr, x1t, ytr, yt, rab1)\n",
    "    p2 = predict(x2tr, x2t, ytr, yt, rab3)\n",
    "    p3 = predict(x3tr, x3t, ytr, yt, rab5)\n",
    "    p4 = predict(x4tr, x4t, ytr, yt, rab10)\n",
    "    p5 = predict(x5tr, x5t, ytr, yt, rab15)\n",
    "    p6 = predict(x6tr, x6t, ytr, yt, rab20)\n",
    "    \n",
    "    p1a = predict(x1atr, x1at, ytr, yt, rres1)\n",
    "    p2a = predict(x2atr, x2at, ytr, yt, rres3)\n",
    "    p3a = predict(x3atr, x3at, ytr, yt, rres5)\n",
    "    p4a = predict(x4atr, x4at, ytr, yt, rres10)\n",
    "    p5a = predict(x5atr, x5at, ytr, yt, rres15)\n",
    "    p6a = predict(x6atr, x6at, ytr, yt, rres20)\n",
    "    \n",
    "    combine(yt, p1, p1a, rens1)\n",
    "    combine(yt, p2, p2a, rens3)\n",
    "    combine(yt, p3, p3a, rens5)\n",
    "    combine(yt, p4, p4a, rens10)\n",
    "    combine(yt, p5, p5a, rens15)\n",
    "    combine(yt, p6, p6a, rens20)\n",
    "\n",
    "    combine(yt, p6, p1a, rbest)\n",
    "    \n",
    "    print('---')\n",
    "    \n",
    "print(np.mean(rfc), np.std(rfc))\n",
    "print(np.mean(rbest), np.std(rbest))\n",
    "\n",
    "print(np.mean(rab1), np.std(rab1))\n",
    "print(np.mean(rab3), np.std(rab3))\n",
    "print(np.mean(rab5), np.std(rab5))\n",
    "print(np.mean(rab10), np.std(rab10))\n",
    "print(np.mean(rab15), np.std(rab15))\n",
    "print(np.mean(rab20), np.std(rab20))\n",
    "\n",
    "print(np.mean(rres1), np.std(rres1))\n",
    "print(np.mean(rres3), np.std(rres3))\n",
    "print(np.mean(rres5), np.std(rres5))\n",
    "print(np.mean(rres10), np.std(rres10))\n",
    "print(np.mean(rres15), np.std(rres15))\n",
    "print(np.mean(rres20), np.std(rres20))\n",
    "\n",
    "print(np.mean(rens1), np.std(rens1))\n",
    "print(np.mean(rens3), np.std(rens3))\n",
    "print(np.mean(rens5), np.std(rens5))\n",
    "print(np.mean(rens10), np.std(rens10))\n",
    "print(np.mean(rens15), np.std(rens15))\n",
    "print(np.mean(rens20), np.std(rens20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87704c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
