{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88faa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3849, 1, 264), (3849, 1, 264), (3849,), (3849,), (3849,), (3849, 34716)]\n",
      "0.5263704858404781\n",
      "0.5188360613146272\n",
      "14.398285268901013\n"
     ]
    }
   ],
   "source": [
    "# PNC\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "basis_file = '/home/anton/Documents/Tulane/Research/PNC_Good/AngleBasis1.pkl'\n",
    "demodir = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/PNC/'\n",
    "\n",
    "basis = pickle.load(open(basis_file, 'rb'))\n",
    "\n",
    "thetas = []\n",
    "jitter = []\n",
    "age = []\n",
    "sex = []\n",
    "race = []\n",
    "fc = []\n",
    "\n",
    "demo = pickle.load(open(f'{demodir}/demographics.pkl', 'rb'))\n",
    "\n",
    "for subtask in basis:\n",
    "    m = re.search('([^-]+)-(.+)', subtask)\n",
    "    sub = m.group(1)\n",
    "    task = m.group(2)\n",
    "    if sub not in demo['Race'] or demo['Race'][sub] not in ['AA', 'EA']:\n",
    "        continue\n",
    "    a = demo['age_at_cnb'][sub]\n",
    "    s = demo['Sex'][sub] == 'M'\n",
    "    r = demo['Race'][sub] == 'AA'\n",
    "    age.append(a)\n",
    "    sex.append(s)\n",
    "    race.append(r)\n",
    "    thetas.append(basis[subtask]['thetas'])\n",
    "    jitter.append(basis[subtask]['jitter'])\n",
    "    p = np.load(f'{demodir}/fc/{sub}_task-{task}_fc.npy')\n",
    "    fc.append(p)\n",
    "    \n",
    "thetas = np.stack(thetas)\n",
    "jitter = np.stack(jitter)\n",
    "age = np.array(age).astype('int')\n",
    "sex = np.array(sex).astype('int')\n",
    "race = np.array(race).astype('int')\n",
    "fc = np.stack(fc)\n",
    "\n",
    "print([a.shape for a in [thetas, jitter, sex, race, age, fc]])\n",
    "print(np.mean(1-sex))\n",
    "print(np.mean(1-race))\n",
    "print(np.mean(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46647241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "Done 1500\n",
      "Done 2000\n",
      "Done 2500\n",
      "Done 3000\n",
      "Done 3500\n",
      "(349, 1, 34716)\n",
      "(3849, 34716)\n",
      "(3849, 34716)\n"
     ]
    }
   ],
   "source": [
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def tops(thetas, jitter):\n",
    "    t0 = np.expand_dims(thetas, 2)\n",
    "    t1 = np.expand_dims(thetas, 3)\n",
    "    j0 = np.expand_dims(jitter, 2)\n",
    "    j1 = np.expand_dims(jitter, 3)\n",
    "    ps = np.cos(t0-t1)*(j0*j1)\n",
    "    a,b = np.triu_indices(264, 1)\n",
    "    ps = ps[:,:,a,b]\n",
    "    return ps\n",
    "\n",
    "paps = []\n",
    "pres = []\n",
    "\n",
    "for i in range(0,3849,500):\n",
    "    ps = tops(thetas[i:i+500], jitter[i:i+500])\n",
    "    aps = np.mean(ps, axis=1)\n",
    "    res = fc[i:i+500] - aps\n",
    "    paps.append(aps)\n",
    "    pres.append(res)\n",
    "    print(f'Done {i}')\n",
    "    \n",
    "aps = np.concatenate(paps)\n",
    "res = np.concatenate(pres)\n",
    "\n",
    "print(ps.shape)\n",
    "print(aps.shape)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747895bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "aps1 = aps\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe55f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tonp(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def totorch(x):\n",
    "    return torch.from_numpy(x).float().cuda()\n",
    "\n",
    "def totorchidcs(x):\n",
    "    return torch.from_numpy(x).long().cuda() #F.one_hot(torch.from_numpy(x)).float().cuda()\n",
    "\n",
    "def rmse(yt, yhat):\n",
    "    return torch.mean((yt-yhat)**2)**0.5\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Linear(34716,100).float().cuda()\n",
    "        self.l2 = nn.Linear(100,2).float().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "def fit_mlp(xtr, ytr):\n",
    "    xtr = totorch(xtr)\n",
    "    ytr = totorchidcs(ytr)\n",
    "    \n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    mlp = MLP()\n",
    "    optim = torch.optim.Adam(mlp.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "    nepochs = 1000\n",
    "    pperiod = 100\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        yhat = mlp(xtr)\n",
    "        loss = ce(yhat, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "#         if epoch % pperiod == 0 or epoch == nepochs-1:\n",
    "#             print(f'{epoch} {float(loss)}')\n",
    "\n",
    "#     print('Complete')\n",
    "    \n",
    "    return mlp\n",
    "\n",
    "class BrainNetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainNetCNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(264,10,5).float().cuda()\n",
    "        self.cnn2 = nn.Conv1d(10,10,5).float().cuda()\n",
    "        self.pool = nn.AvgPool1d(200,ceil_mode=True).float().cuda()\n",
    "        self.l1 = nn.Linear(10,2).float().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.cnn1(x))\n",
    "        x = F.relu(self.cnn2(x))\n",
    "        x = self.pool(x).squeeze()\n",
    "        x = self.l1(x)\n",
    "        return x\n",
    "      \n",
    "def fit_cnn(xtr, ytr):\n",
    "    xtr = totorch(xtr)\n",
    "    ytr = totorchidcs(ytr)\n",
    "    \n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    bnc = BrainNetCNN()\n",
    "    optim = torch.optim.Adam(bnc.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "    nepochs = 1000\n",
    "    pperiod = 100\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        yhat = bnc(xtr)\n",
    "        loss = ce(yhat, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "#         if epoch % pperiod == 0 or epoch == nepochs-1:\n",
    "#             print(f'{epoch} {float(loss)}')\n",
    "\n",
    "#     print('Complete')\n",
    "    \n",
    "    return bnc\n",
    "    \n",
    "def predict_help(model, xt):\n",
    "    xt = totorch(xt)\n",
    "    with torch.no_grad():\n",
    "        yhat = model(xt)\n",
    "        return tonp(yhat)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d80d75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577608658887198\n",
      "0.8117774395399966\n",
      "0.9068560798241163\n",
      "0.9569220361914426\n",
      "0.9252359208523592\n",
      "0.9658785726365635\n",
      "---\n",
      "0.8150076103500761\n",
      "0.7846101809572129\n",
      "0.9424792829359039\n",
      "0.9686656519533232\n",
      "0.9199594114662608\n",
      "0.9766480635887028\n",
      "---\n",
      "0.9487096228648739\n",
      "0.6993066125486216\n",
      "0.9028310502283106\n",
      "0.9513478775579233\n",
      "0.9159884999154405\n",
      "0.9633891425672247\n",
      "---\n",
      "0.947911381701336\n",
      "0.8195569085066802\n",
      "0.9402266193133774\n",
      "0.9541011330965669\n",
      "0.9178893962455605\n",
      "0.9659868087265346\n",
      "---\n",
      "0.8222695755115845\n",
      "0.792673769660071\n",
      "0.9242279722645019\n",
      "0.9520446473871131\n",
      "0.9245594452900389\n",
      "0.9612108912565533\n",
      "---\n",
      "0.898331811263318 0.06520162023390498\n",
      "0.9666226957551158 0.0053143121074506776\n",
      "0.7815849822425165 0.04302393476894367\n",
      "0.923324200913242 0.01639874357946309\n",
      "0.9566162692372739 0.006328707676963734\n",
      "0.920726534753932 0.0036362775842176285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cat(x, **kwargs):\n",
    "    return np.concatenate(x, **kwargs)\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def predict(xtr, xt, ytr, yt, lst):\n",
    "    reg = fit_mlp(xtr, ytr)\n",
    "    p = predict_help(reg, xt)\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "    return p\n",
    "    \n",
    "def get_res(fctr, fct, abtr, abt):\n",
    "    return fctr-abtr, fct-abt\n",
    "\n",
    "def combine(yt, p0, p1, lst):\n",
    "    p = (p0+p1)/2\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "\n",
    "rfc = []\n",
    "\n",
    "rab1 = []\n",
    "rab20 = []\n",
    "\n",
    "rres1 = []\n",
    "rres20 = []\n",
    "\n",
    "rbest = []\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    x0tr, x0t, x1tr, x1t, x2tr, x2t, ytr, yt = train_test_split(\n",
    "        fc, aps1, aps20, sex, stratify=sex, train_size=0.8)\n",
    "    \n",
    "#     mu = np.mean(ytr)\n",
    "#     ytr = ytr-mu\n",
    "#     yt = yt-mu\n",
    "    \n",
    "    x1atr, x1at = get_res(x0tr, x0t, x1tr, x1t)\n",
    "    x2atr, x2at = get_res(x0tr, x0t, x2tr, x2t)\n",
    "\n",
    "    predict(x0tr, x0t, ytr, yt, rfc)\n",
    "    \n",
    "    p1 = predict(x1tr, x1t, ytr, yt, rab1)\n",
    "    p2 = predict(x2tr, x2t, ytr, yt, rab20)\n",
    "    \n",
    "    p1a = predict(x1atr, x1at, ytr, yt, rres1)\n",
    "    p2a = predict(x2atr, x2at, ytr, yt, rres20)\n",
    "\n",
    "    combine(yt, p2, p1a, rbest)\n",
    "    \n",
    "    print('---')\n",
    "    \n",
    "print(np.mean(rfc), np.std(rfc))\n",
    "print(np.mean(rbest), np.std(rbest))\n",
    "\n",
    "print(np.mean(rab1), np.std(rab1))\n",
    "print(np.mean(rab20), np.std(rab20))\n",
    "\n",
    "print(np.mean(rres1), np.std(rres1))\n",
    "print(np.mean(rres20), np.std(rres20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0618e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
