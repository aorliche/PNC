{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddfff3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3849, 20, 264), (3849, 20, 264), (3849,), (3849,), (3849,), (3849, 34716)]\n",
      "0.5263704858404781\n",
      "0.5188360613146272\n",
      "14.398285268901013\n"
     ]
    }
   ],
   "source": [
    "# PNC\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "basis_file = '/home/anton/Documents/Tulane/Research/PNC_Good/AngleBasisNoJit20.pkl'\n",
    "demodir = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/PNC/'\n",
    "\n",
    "basis = pickle.load(open(basis_file, 'rb'))\n",
    "\n",
    "thetas = []\n",
    "jitter = []\n",
    "age = []\n",
    "sex = []\n",
    "race = []\n",
    "fc = []\n",
    "\n",
    "demo = pickle.load(open(f'{demodir}/demographics.pkl', 'rb'))\n",
    "\n",
    "for subtask in basis:\n",
    "    m = re.search('([^-]+)-(.+)', subtask)\n",
    "    sub = m.group(1)\n",
    "    task = m.group(2)\n",
    "    if sub not in demo['Race'] or demo['Race'][sub] not in ['AA', 'EA']:\n",
    "        continue\n",
    "    a = demo['age_at_cnb'][sub]\n",
    "    s = demo['Sex'][sub] == 'M'\n",
    "    r = demo['Race'][sub] == 'AA'\n",
    "    age.append(a)\n",
    "    sex.append(s)\n",
    "    race.append(r)\n",
    "    thetas.append(basis[subtask]['thetas'])\n",
    "    jitter.append(basis[subtask]['jitter'])\n",
    "    p = np.load(f'{demodir}/fc/{sub}_task-{task}_fc.npy')\n",
    "    fc.append(p)\n",
    "    \n",
    "thetas = np.stack(thetas)\n",
    "jitter = np.stack(jitter)\n",
    "age = np.array(age).astype('int')\n",
    "sex = np.array(sex).astype('int')\n",
    "race = np.array(race).astype('int')\n",
    "fc = np.stack(fc)\n",
    "\n",
    "print([a.shape for a in [thetas, jitter, sex, race, age, fc]])\n",
    "print(np.mean(1-sex))\n",
    "print(np.mean(1-race))\n",
    "print(np.mean(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254dd436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done eigs\n",
      "Done 20\n",
      "Done 15\n",
      "Done 10\n",
      "Done 5\n",
      "Done 3\n",
      "Done 1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mat2vec(mat):\n",
    "    a,b = np.triu_indices(264,1)\n",
    "    return mat[:,a,b]\n",
    "\n",
    "a,b = np.triu_indices(264,1)\n",
    "X = np.ones((fc.shape[0],264,264))\n",
    "X[:,a,b] = fc\n",
    "X[:,b,a] = fc\n",
    "w, v = np.linalg.eig(X)\n",
    "print('Done eigs')\n",
    "\n",
    "w[:,20:] = 0\n",
    "aps20 = np.real(np.einsum('nab,nb,ncb->nac',v,w,v))\n",
    "aps20 = mat2vec(aps20)\n",
    "print('Done 20')\n",
    "\n",
    "w[:,15:] = 0\n",
    "aps15 = np.real(np.einsum('nab,nb,ncb->nac',v,w,v))\n",
    "aps15 = mat2vec(aps15)\n",
    "print('Done 15')\n",
    "\n",
    "w[:,10:] = 0\n",
    "aps10 = np.real(np.einsum('nab,nb,ncb->nac',v,w,v))\n",
    "aps10 = mat2vec(aps10)\n",
    "print('Done 10')\n",
    "\n",
    "w[:,5:] = 0\n",
    "aps5 = np.real(np.einsum('nab,nb,ncb->nac',v,w,v))\n",
    "aps5 = mat2vec(aps5)\n",
    "print('Done 5')\n",
    "\n",
    "w[:,3:] = 0\n",
    "aps3 = np.real(np.einsum('nab,nb,ncb->nac',v,w,v))\n",
    "aps3 = mat2vec(aps3)\n",
    "print('Done 3')\n",
    "\n",
    "w[:,1:] = 0\n",
    "aps1 = np.real(np.einsum('nab,nb,ncb->nac',v,w,v))\n",
    "aps1 = mat2vec(aps1)\n",
    "print('Done 1')\n",
    "\n",
    "w = None\n",
    "v = None\n",
    "X = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91fe1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "Done 1500\n",
      "Done 2000\n",
      "Done 2500\n",
      "Done 3000\n",
      "Done 3500\n",
      "(349, 20, 34716)\n",
      "(3849, 34716)\n",
      "(3849, 34716)\n"
     ]
    }
   ],
   "source": [
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def tops(thetas, jitter):\n",
    "    t0 = np.expand_dims(thetas, 2)\n",
    "    t1 = np.expand_dims(thetas, 3)\n",
    "#     j0 = np.expand_dims(jitter, 2)\n",
    "#     j1 = np.expand_dims(jitter, 3)\n",
    "    ps = np.cos(t0-t1)#*(j0*j1)\n",
    "    a,b = np.triu_indices(264, 1)\n",
    "    ps = ps[:,:,a,b]\n",
    "    return ps\n",
    "\n",
    "paps = []\n",
    "pres = []\n",
    "\n",
    "for i in range(0,3849,500):\n",
    "    ps = tops(thetas[i:i+500], jitter[i:i+500])\n",
    "    aps = np.mean(ps, axis=1)\n",
    "    res = fc[i:i+500] - aps\n",
    "    paps.append(aps)\n",
    "    pres.append(res)\n",
    "    print(f'Done {i}')\n",
    "    \n",
    "aps = np.concatenate(paps)\n",
    "res = np.concatenate(pres)\n",
    "\n",
    "print(ps.shape)\n",
    "print(aps.shape)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8c26259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "aps20 = aps\n",
    "res20 = res\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c53609ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/anton/Documents/Tulane/Research/code/AngleBasis', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/anton/.local/lib/python3.10/site-packages', '/usr/lib/python3.10/site-packages', '../../LatentSimilarity/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "pth = '../../LatentSimilarity/'\n",
    "\n",
    "if pth not in sys.path:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16344e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paps = None\n",
    "pres = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b909015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0tr, x0t, x1tr, x1t, x2tr, x2t, x3tr, x3t, x4tr, x4t, x5tr, x5t, x6tr, x6t, ytr, yt = 16*[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132139e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'latsim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ridge, LogisticRegression\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlatsim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LatSimClf\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      6\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'latsim'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from latsim import LatSimClf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def cat(x, **kwargs):\n",
    "    return np.concatenate(x, **kwargs)\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def predict(xtr, xt, ytr, yt, lst):\n",
    "#     reg = LogisticRegression(C=1,max_iter=100).fit(xtr, ytr) \n",
    "    reg = LatSimClf(nepochs=1000).fit(xtr, ytr) \n",
    "#     reg = Ridge(alpha=1,max_iter=1000).fit(xtr, ytr)\n",
    "    yhat = reg.predict(xt)\n",
    "    p = reg.predict_proba(xt)\n",
    "#     acc = rmse(yt, yhat)\n",
    "#     acc = np.mean(yt == yhat)\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "    return p\n",
    "    \n",
    "def get_res(fctr, fct, abtr, abt):\n",
    "    return fctr-abtr, fct-abt\n",
    "\n",
    "def combine(yt, p0, p1, lst):\n",
    "    p = (p0+p1)/2\n",
    "#     acc = np.mean(yt == np.argmax(p, axis=1))\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "#     acc = rmse(yt, p)\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "\n",
    "rfc = []\n",
    "\n",
    "rab1 = []\n",
    "rab3 = []\n",
    "rab5 = []\n",
    "rab10 = []\n",
    "rab15 = []\n",
    "rab20 = []\n",
    "\n",
    "rres1 = []\n",
    "rres3 = []\n",
    "rres5 = []\n",
    "rres10 = []\n",
    "rres15 = []\n",
    "rres20 = []\n",
    "\n",
    "rens1 = []\n",
    "rens3 = []\n",
    "rens5 = []\n",
    "rens10 = []\n",
    "rens15 = []\n",
    "rens20 = []\n",
    "\n",
    "rbest = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "#     xtr, xt, ytr, yt = train_test_split(fc, sex, stratify=sex, train_size=0.8)\n",
    "    \n",
    "#     p1 = predict(xtr, xt, ytr, yt, rfc)\n",
    "#     p2 = predict(xtr, xt, ytr, yt, rfc)\n",
    "    \n",
    "#     combine(yt, p1, p2, rbest)\n",
    "\n",
    "    x0tr, x0t, x1tr, x1t, x2tr, x2t, x3tr, x3t, x4tr, x4t, x5tr, x5t, x6tr, x6t, ytr, yt = train_test_split(\n",
    "        fc, aps1, aps3, aps5, aps10, aps15, aps20, sex, stratify=sex, train_size=0.8)\n",
    "    \n",
    "#     mu = np.mean(ytr)\n",
    "#     ytr = ytr-mu\n",
    "#     yt = yt-mu\n",
    "    \n",
    "    x1atr, x1at = get_res(x0tr, x0t, x1tr, x1t)\n",
    "    x2atr, x2at = get_res(x0tr, x0t, x2tr, x2t)\n",
    "    x3atr, x3at = get_res(x0tr, x0t, x3tr, x3t)\n",
    "    x4atr, x4at = get_res(x0tr, x0t, x4tr, x4t)\n",
    "    x5atr, x5at = get_res(x0tr, x0t, x5tr, x5t)\n",
    "    x6atr, x6at = get_res(x0tr, x0t, x6tr, x6t)\n",
    "\n",
    "    predict(x0tr, x0t, ytr, yt, rfc)\n",
    "    \n",
    "    p1 = predict(x1tr, x1t, ytr, yt, rab1)\n",
    "    p2 = predict(x2tr, x2t, ytr, yt, rab3)\n",
    "    p3 = predict(x3tr, x3t, ytr, yt, rab5)\n",
    "    p4 = predict(x4tr, x4t, ytr, yt, rab10)\n",
    "    p5 = predict(x5tr, x5t, ytr, yt, rab15)\n",
    "    p6 = predict(x6tr, x6t, ytr, yt, rab20)\n",
    "    \n",
    "    p1a = predict(x1atr, x1at, ytr, yt, rres1)\n",
    "    p2a = predict(x2atr, x2at, ytr, yt, rres3)\n",
    "    p3a = predict(x3atr, x3at, ytr, yt, rres5)\n",
    "    p4a = predict(x4atr, x4at, ytr, yt, rres10)\n",
    "    p5a = predict(x5atr, x5at, ytr, yt, rres15)\n",
    "    p6a = predict(x6atr, x6at, ytr, yt, rres20)\n",
    "    \n",
    "    combine(yt, p1, p1a, rens1)\n",
    "    combine(yt, p2, p2a, rens3)\n",
    "    combine(yt, p3, p3a, rens5)\n",
    "    combine(yt, p4, p4a, rens10)\n",
    "    combine(yt, p5, p5a, rens15)\n",
    "    combine(yt, p6, p6a, rens20)\n",
    "\n",
    "    combine(yt, p6, p1a, rbest)\n",
    "    \n",
    "    print('---')\n",
    "    \n",
    "print(np.mean(rfc), np.std(rfc))\n",
    "print(np.mean(rbest), np.std(rbest))\n",
    "\n",
    "print(np.mean(rab1), np.std(rab1))\n",
    "print(np.mean(rab3), np.std(rab3))\n",
    "print(np.mean(rab5), np.std(rab5))\n",
    "print(np.mean(rab10), np.std(rab10))\n",
    "print(np.mean(rab15), np.std(rab15))\n",
    "print(np.mean(rab20), np.std(rab20))\n",
    "\n",
    "print(np.mean(rres1), np.std(rres1))\n",
    "print(np.mean(rres3), np.std(rres3))\n",
    "print(np.mean(rres5), np.std(rres5))\n",
    "print(np.mean(rres10), np.std(rres10))\n",
    "print(np.mean(rres15), np.std(rres15))\n",
    "print(np.mean(rres20), np.std(rres20))\n",
    "\n",
    "print(np.mean(rens1), np.std(rens1))\n",
    "print(np.mean(rens3), np.std(rens3))\n",
    "print(np.mean(rens5), np.std(rens5))\n",
    "print(np.mean(rens10), np.std(rens10))\n",
    "print(np.mean(rens15), np.std(rens15))\n",
    "print(np.mean(rens20), np.std(rens20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb4c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
