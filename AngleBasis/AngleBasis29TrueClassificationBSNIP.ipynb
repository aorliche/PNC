{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a452c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(441, 1, 264), (441, 1, 264), (441,), (441,), (441,), (441,), (441, 34716)]\n",
      "0.4580498866213152\n",
      "0.6439909297052154\n",
      "0.5487528344671202\n",
      "36.54875283446712\n"
     ]
    }
   ],
   "source": [
    "# BSNIP\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "basis_file = '/home/anton/Documents/Tulane/Research/BSNIP/AngleBasis1.pkl'\n",
    "demodir = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/BSNIP/'\n",
    "\n",
    "basis = pickle.load(open(basis_file, 'rb'))\n",
    "\n",
    "thetas = []\n",
    "jitter = []\n",
    "age = []\n",
    "sex = []\n",
    "race = []\n",
    "sz = []\n",
    "fc = []\n",
    "\n",
    "demo = pickle.load(open(f'{demodir}/demographics.pkl', 'rb'))\n",
    "\n",
    "for subtask in basis:\n",
    "    m = re.search('([^-]+)', subtask)\n",
    "    sub = m.group(1)\n",
    "    a = demo['Age_cal'][sub]\n",
    "    s = demo['sex'][sub] == 's1.0'\n",
    "    r = demo['Race'][sub] == 'AA'\n",
    "    z = demo['DXGROUP_2'][sub] == 'SZP'\n",
    "    if demo['DXGROUP_2'][sub] not in ['SZP', 'NC']:\n",
    "        continue\n",
    "    age.append(a)\n",
    "    sz.append(z)\n",
    "    sex.append(s)\n",
    "    race.append(r)\n",
    "    thetas.append(basis[subtask]['thetas'])\n",
    "    jitter.append(basis[subtask]['jitter'])\n",
    "    p = np.load(f'{demodir}/fc/{sub}_task-unk_fc.npy')\n",
    "    fc.append(p)\n",
    "    \n",
    "thetas = np.stack(thetas)\n",
    "jitter = np.stack(jitter)\n",
    "age = np.array(age).astype('int')\n",
    "sex = np.array(sex).astype('int')\n",
    "race = np.array(race).astype('int')\n",
    "sz = np.array(sz).astype('int')\n",
    "fc = np.stack(fc)\n",
    "\n",
    "print([a.shape for a in [thetas, jitter, sex, race, sz, age, fc]])\n",
    "print(np.mean(1-sex))\n",
    "print(np.mean(1-race))\n",
    "print(np.mean(1-sz))\n",
    "print(np.mean(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a4211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "(441, 1, 34716)\n",
      "(441, 34716)\n",
      "(441, 34716)\n"
     ]
    }
   ],
   "source": [
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def tops(thetas, jitter):\n",
    "    t0 = np.expand_dims(thetas, 2)\n",
    "    t1 = np.expand_dims(thetas, 3)\n",
    "    j0 = np.expand_dims(jitter, 2)\n",
    "    j1 = np.expand_dims(jitter, 3)\n",
    "    ps = np.cos(t0-t1)*(j0*j1)\n",
    "    a,b = np.triu_indices(264, 1)\n",
    "    ps = ps[:,:,a,b]\n",
    "    return ps\n",
    "\n",
    "paps = []\n",
    "pres = []\n",
    "\n",
    "for i in range(0,fc.shape[0],500):\n",
    "    ps = tops(thetas[i:i+500], jitter[i:i+500])\n",
    "    aps = np.mean(ps, axis=1)\n",
    "    res = fc[i:i+500] - aps\n",
    "    paps.append(aps)\n",
    "    pres.append(res)\n",
    "    print(f'Done {i}')\n",
    "    \n",
    "aps = np.concatenate(paps)\n",
    "res = np.concatenate(pres)\n",
    "\n",
    "print(ps.shape)\n",
    "print(aps.shape)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bb14598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "aps1 = aps\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b40f7b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tonp(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "def totorch(x):\n",
    "    return torch.from_numpy(x).float().cuda()\n",
    "\n",
    "def totorchidcs(x):\n",
    "    return torch.from_numpy(x).long().cuda() #F.one_hot(torch.from_numpy(x)).float().cuda()\n",
    "\n",
    "def rmse(yt, yhat):\n",
    "    return torch.mean((yt-yhat)**2)**0.5\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Linear(34716,100).float().cuda()\n",
    "        self.l2 = nn.Linear(100,2).float().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x\n",
    "    \n",
    "def fit_mlp(xtr, ytr, verbose=False):\n",
    "    xtr = totorch(xtr)\n",
    "    ytr = totorchidcs(ytr)\n",
    "    \n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    mlp = MLP()\n",
    "    optim = torch.optim.Adam(mlp.parameters(), lr=2e-4, weight_decay=2e-4)\n",
    "\n",
    "    nepochs = 2000\n",
    "    pperiod = 100\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        yhat = mlp(xtr)\n",
    "        loss = ce(yhat, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if verbose:\n",
    "            if epoch % pperiod == 0 or epoch == nepochs-1:\n",
    "                print(f'{epoch} {float(loss)}')\n",
    "\n",
    "    if verbose:\n",
    "        print('Complete')\n",
    "    \n",
    "    return mlp\n",
    "    \n",
    "def predict_help(model, xt):\n",
    "    xt = totorch(xt)\n",
    "    with torch.no_grad():\n",
    "        yhat = model(xt)\n",
    "        return tonp(yhat)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0af365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8959183673469387\n",
      "0.8326530612244898\n",
      "0.8806122448979592\n",
      "0.8642857142857143\n",
      "0.8857142857142857\n",
      "0.888265306122449\n",
      "0.8877551020408164\n",
      "0.8255102040816327\n",
      "0.801530612244898\n",
      "0.7698979591836734\n",
      "0.7117346938775511\n",
      "0.6566326530612245\n",
      "0.7316326530612244\n",
      "0.8673469387755102\n",
      "0.8943877551020408\n",
      "0.8678571428571429\n",
      "0.8806122448979592\n",
      "0.8826530612244898\n",
      "0.8775510204081632\n",
      "0.8938775510204082\n",
      "---\n",
      "0.810204081632653\n",
      "0.7540816326530612\n",
      "0.7872448979591837\n",
      "0.7806122448979592\n",
      "0.7959183673469388\n",
      "0.8096938775510204\n",
      "0.7908163265306122\n",
      "0.7520408163265306\n",
      "0.7198979591836736\n",
      "0.7591836734693879\n",
      "0.745408163265306\n",
      "0.7352040816326532\n",
      "0.7510204081632653\n",
      "0.8107142857142857\n",
      "0.8290816326530612\n",
      "0.8153061224489796\n",
      "0.8244897959183674\n",
      "0.8285714285714286\n",
      "0.8209183673469388\n",
      "0.810204081632653\n",
      "---\n",
      "0.8112244897959184\n",
      "0.7234693877551021\n",
      "0.801530612244898\n",
      "0.7908163265306123\n",
      "0.801530612244898\n",
      "0.8081632653061225\n",
      "0.8045918367346939\n",
      "0.8311224489795918\n",
      "0.7698979591836734\n",
      "0.7357142857142859\n",
      "0.7341836734693877\n",
      "0.6948979591836735\n",
      "0.7122448979591837\n",
      "0.8122448979591836\n",
      "0.8362244897959183\n",
      "0.8056122448979592\n",
      "0.8153061224489796\n",
      "0.8183673469387756\n",
      "0.8076530612244898\n",
      "0.8566326530612245\n",
      "---\n",
      "0.8066326530612244\n",
      "0.7867346938775511\n",
      "0.7821428571428571\n",
      "0.7780612244897959\n",
      "0.8076530612244898\n",
      "0.7979591836734694\n",
      "0.798469387755102\n",
      "0.7841836734693878\n",
      "0.8091836734693877\n",
      "0.8372448979591837\n",
      "0.766326530612245\n",
      "0.6622448979591837\n",
      "0.7760204081632653\n",
      "0.8428571428571429\n",
      "0.8301020408163264\n",
      "0.8122448979591836\n",
      "0.8153061224489795\n",
      "0.7964285714285714\n",
      "0.8127551020408164\n",
      "0.8255102040816327\n",
      "---\n",
      "0.8239795918367346\n",
      "0.7408163265306121\n",
      "0.7668367346938775\n",
      "0.7913265306122449\n",
      "0.8035714285714285\n",
      "0.8030612244897959\n",
      "0.8020408163265306\n",
      "0.8204081632653062\n",
      "0.8321428571428571\n",
      "0.7989795918367347\n",
      "0.7525510204081632\n",
      "0.7260204081632653\n",
      "0.7729591836734695\n",
      "0.8270408163265306\n",
      "0.821938775510204\n",
      "0.8234693877551019\n",
      "0.8224489795918367\n",
      "0.8168367346938775\n",
      "0.8198979591836734\n",
      "0.8321428571428572\n",
      "---\n",
      "0.7336734693877552\n",
      "0.6821428571428572\n",
      "0.7224489795918367\n",
      "0.7168367346938775\n",
      "0.7306122448979591\n",
      "0.7346938775510204\n",
      "0.7336734693877551\n",
      "0.7183673469387755\n",
      "0.653061224489796\n",
      "0.6428571428571428\n",
      "0.6178571428571429\n",
      "0.5928571428571429\n",
      "0.6142857142857143\n",
      "0.7295918367346939\n",
      "0.7357142857142857\n",
      "0.7275510204081633\n",
      "0.7336734693877551\n",
      "0.7290816326530613\n",
      "0.738265306122449\n",
      "0.75\n",
      "---\n",
      "0.8066326530612244\n",
      "0.7612244897959184\n",
      "0.7826530612244897\n",
      "0.7974489795918368\n",
      "0.8005102040816326\n",
      "0.8081632653061225\n",
      "0.7959183673469388\n",
      "0.7816326530612245\n",
      "0.8005102040816326\n",
      "0.6964285714285715\n",
      "0.6795918367346938\n",
      "0.6826530612244899\n",
      "0.6872448979591836\n",
      "0.8147959183673469\n",
      "0.823469387755102\n",
      "0.801530612244898\n",
      "0.7948979591836735\n",
      "0.8045918367346938\n",
      "0.8\n",
      "0.823469387755102\n",
      "---\n",
      "0.8668367346938776\n",
      "0.8260204081632654\n",
      "0.8505102040816326\n",
      "0.8566326530612245\n",
      "0.861734693877551\n",
      "0.860204081632653\n",
      "0.8612244897959184\n",
      "0.8857142857142857\n",
      "0.8336734693877551\n",
      "0.7755102040816326\n",
      "0.8071428571428572\n",
      "0.7183673469387756\n",
      "0.7816326530612245\n",
      "0.8811224489795919\n",
      "0.8852040816326531\n",
      "0.8734693877551021\n",
      "0.8785714285714286\n",
      "0.8663265306122448\n",
      "0.8744897959183673\n",
      "0.8964285714285714\n",
      "---\n",
      "0.7974489795918367\n",
      "0.7285714285714285\n",
      "0.7943877551020408\n",
      "0.7811224489795918\n",
      "0.7897959183673469\n",
      "0.8030612244897959\n",
      "0.8051020408163265\n",
      "0.7408163265306122\n",
      "0.7142857142857144\n",
      "0.761734693877551\n",
      "0.7244897959183673\n",
      "0.711734693877551\n",
      "0.7719387755102041\n",
      "0.7704081632653061\n",
      "0.7984693877551019\n",
      "0.8112244897959184\n",
      "0.8086734693877551\n",
      "0.8219387755102041\n",
      "0.823469387755102\n",
      "0.8051020408163265\n",
      "---\n",
      "0.7734693877551021\n",
      "0.7071428571428571\n",
      "0.725\n",
      "0.7586734693877552\n",
      "0.7627551020408163\n",
      "0.7637755102040816\n",
      "0.7622448979591837\n",
      "0.7535714285714286\n",
      "0.7051020408163265\n",
      "0.7285714285714285\n",
      "0.7030612244897959\n",
      "0.736734693877551\n",
      "0.7214285714285714\n",
      "0.7729591836734694\n",
      "0.7392857142857143\n",
      "0.7826530612244899\n",
      "0.7826530612244896\n",
      "0.7801020408163265\n",
      "0.7683673469387755\n",
      "0.7928571428571429\n",
      "---\n",
      "0.8126020408163266 0.04252302338382062\n",
      "0.8286224489795918 0.042476106177493075\n",
      "0.7542857142857143 0.046484156007003806\n",
      "0.7893367346938776 0.04633341336087062\n",
      "0.7915816326530613 0.040785862355681865\n",
      "0.8039795918367346 0.04170886381953125\n",
      "0.8077040816326531 0.04080321855848337\n",
      "0.8041836734693877 0.04153750632244167\n",
      "0.7893367346938776 0.04843094608762157\n",
      "0.7639285714285714 0.058743990450038065\n",
      "0.7506122448979592 0.051272235655416276\n",
      "0.7242346938775509 0.04889621410977597\n",
      "0.691734693877551 0.042626810592135654\n",
      "0.7320408163265306 0.049393868739496014\n",
      "0.8129081632653061 0.04366467701882936\n",
      "0.8193877551020406 0.049322777292545715\n",
      "0.8120918367346939 0.038967736470457016\n",
      "0.8156632653061224 0.04073336594498214\n",
      "0.8144897959183673 0.040631084749200456\n",
      "0.8143367346938776 0.039905950710691175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def cat(x, **kwargs):\n",
    "    return np.concatenate(x, **kwargs)\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def predict(xtr, xt, ytr, yt, lst):\n",
    "    reg = fit_mlp(xtr, ytr, verbose=False)\n",
    "    p = predict_help(reg, xt)\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "    return p\n",
    "    \n",
    "def get_res(fctr, fct, abtr, abt):\n",
    "    return fctr-abtr, fct-abt\n",
    "\n",
    "def combine(yt, p0, p1, lst):\n",
    "    p = (p0+p1)/2\n",
    "    acc = roc_auc_score(yt, p[:,1])\n",
    "    print(acc)\n",
    "    lst.append(acc)\n",
    "\n",
    "rfc = []\n",
    "\n",
    "rab1 = []\n",
    "rab3 = []\n",
    "rab5 = []\n",
    "rab10 = []\n",
    "rab15 = []\n",
    "rab20 = []\n",
    "\n",
    "rres1 = []\n",
    "rres3 = []\n",
    "rres5 = []\n",
    "rres10 = []\n",
    "rres15 = []\n",
    "rres20 = []\n",
    "\n",
    "rens1 = []\n",
    "rens3 = []\n",
    "rens5 = []\n",
    "rens10 = []\n",
    "rens15 = []\n",
    "rens20 = []\n",
    "\n",
    "rbest = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    x0tr, x0t, x1tr, x1t, x2tr, x2t, x3tr, x3t, x4tr, x4t, x5tr, x5t, x6tr, x6t, ytr, yt = train_test_split(\n",
    "        fc, aps1, aps3, aps5, aps10, aps15, aps20, sz, stratify=sz, train_size=0.8)\n",
    "    \n",
    "    x1atr, x1at = get_res(x0tr, x0t, x1tr, x1t)\n",
    "    x2atr, x2at = get_res(x0tr, x0t, x2tr, x2t)\n",
    "    x3atr, x3at = get_res(x0tr, x0t, x3tr, x3t)\n",
    "    x4atr, x4at = get_res(x0tr, x0t, x4tr, x4t)\n",
    "    x5atr, x5at = get_res(x0tr, x0t, x5tr, x5t)\n",
    "    x6atr, x6at = get_res(x0tr, x0t, x6tr, x6t)\n",
    "\n",
    "    predict(x0tr, x0t, ytr, yt, rfc)\n",
    "    \n",
    "    p1 = predict(x1tr, x1t, ytr, yt, rab1)\n",
    "    p2 = predict(x2tr, x2t, ytr, yt, rab3)\n",
    "    p3 = predict(x3tr, x3t, ytr, yt, rab5)\n",
    "    p4 = predict(x4tr, x4t, ytr, yt, rab10)\n",
    "    p5 = predict(x5tr, x5t, ytr, yt, rab15)\n",
    "    p6 = predict(x6tr, x6t, ytr, yt, rab20)\n",
    "    \n",
    "    p1a = predict(x1atr, x1at, ytr, yt, rres1)\n",
    "    p2a = predict(x2atr, x2at, ytr, yt, rres3)\n",
    "    p3a = predict(x3atr, x3at, ytr, yt, rres5)\n",
    "    p4a = predict(x4atr, x4at, ytr, yt, rres10)\n",
    "    p5a = predict(x5atr, x5at, ytr, yt, rres15)\n",
    "    p6a = predict(x6atr, x6at, ytr, yt, rres20)\n",
    "    \n",
    "    combine(yt, p1, p1a, rens1)\n",
    "    combine(yt, p2, p2a, rens3)\n",
    "    combine(yt, p3, p3a, rens5)\n",
    "    combine(yt, p4, p4a, rens10)\n",
    "    combine(yt, p5, p5a, rens15)\n",
    "    combine(yt, p6, p6a, rens20)\n",
    "\n",
    "    combine(yt, p6, p1a, rbest)\n",
    "    \n",
    "    print('---')\n",
    "    \n",
    "print(np.mean(rfc), np.std(rfc))\n",
    "print(np.mean(rbest), np.std(rbest))\n",
    "\n",
    "print(np.mean(rab1), np.std(rab1))\n",
    "print(np.mean(rab3), np.std(rab3))\n",
    "print(np.mean(rab5), np.std(rab5))\n",
    "print(np.mean(rab10), np.std(rab10))\n",
    "print(np.mean(rab15), np.std(rab15))\n",
    "print(np.mean(rab20), np.std(rab20))\n",
    "\n",
    "print(np.mean(rres1), np.std(rres1))\n",
    "print(np.mean(rres3), np.std(rres3))\n",
    "print(np.mean(rres5), np.std(rres5))\n",
    "print(np.mean(rres10), np.std(rres10))\n",
    "print(np.mean(rres15), np.std(rres15))\n",
    "print(np.mean(rres20), np.std(rres20))\n",
    "\n",
    "print(np.mean(rens1), np.std(rens1))\n",
    "print(np.mean(rens3), np.std(rens3))\n",
    "print(np.mean(rens5), np.std(rens5))\n",
    "print(np.mean(rens10), np.std(rens10))\n",
    "print(np.mean(rens15), np.std(rens15))\n",
    "print(np.mean(rens20), np.std(rens20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87704c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
