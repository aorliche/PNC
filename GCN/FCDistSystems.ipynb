{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e01ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466\n",
      "156\n",
      "{'meta': {'AgeInMonths': 146, 'Gender': 'F', 'Ethnicity': 'AFRICAN', 'AgeGroupID': 2, 'AgeGroupEdge1': 144, 'AgeGroupEdge2': 180}, 'rest': '30', 'nback': '31', 'emoid': '31', 'ID': 600262185931}\n"
     ]
    }
   ],
   "source": [
    "# Learn systems mask for N subsystems and apply a GCN\n",
    "# This may require less than the full number of edges: 466 training subjects means each\n",
    "# training epoch must find (466x465/2)*Nsys edges, and that is just for a single window!\n",
    "# First do for resting state only\n",
    "# Later, want to split each subject scan into windows with the same model\n",
    "# Also implement multi-task GCN\n",
    "\n",
    "# Load split\n",
    "\n",
    "import pickle\n",
    "\n",
    "badIDs = [605515760919, 601983541597]\n",
    "\n",
    "with open('../../Splits/RegressionAllTasks/split1.bin', 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    train = []\n",
    "    trainDirty = d['train']\n",
    "    test = []\n",
    "    testDirty = d['test']\n",
    "    \n",
    "    # Remove bad subjects\n",
    "    for subj in trainDirty:\n",
    "        if subj['ID'] not in badIDs:\n",
    "            train.append(subj)\n",
    "            \n",
    "    for subj in testDirty:\n",
    "        if subj['ID'] not in badIDs:\n",
    "            test.append(subj)\n",
    "    \n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf9e789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "def loadTimeseries(_id, _dir):\n",
    "    ts = None\n",
    "    with open('{:s}/{:d}.bin'.format(_dir, _id), 'rb') as f:\n",
    "        ts = pickle.load(f)\n",
    "    return ts\n",
    "\n",
    "train_rest_ts = [loadTimeseries(int(subj['rest']), '../../rest_fmri_power264/timeseries') for subj in train]\n",
    "# train_nback_ts = [loadTimeseries(int(subj['nback']), '../../nback_fmri_power264/timeseries') for subj in train]\n",
    "# train_emoid_ts = [loadTimeseries(int(subj['emoid']), '../../emoid_fmri_power264/timeseries') for subj in train]\n",
    "\n",
    "test_rest_ts = [loadTimeseries(int(subj['rest']), '../../rest_fmri_power264/timeseries') for subj in test]\n",
    "# test_nback_ts = [loadTimeseries(int(subj['nback']), '../../nback_fmri_power264/timeseries') for subj in test]\n",
    "# test_emoid_ts = [loadTimeseries(int(subj['emoid']), '../../emoid_fmri_power264/timeseries') for subj in test]\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d62f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalizeSubjects(subjects):\n",
    "    for i in range(len(subjects)):\n",
    "        subj = subjects[i]\n",
    "        subj -= np.mean(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        subj /= np.std(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        if np.sum(np.isnan(subj)) > 0:\n",
    "            print(i)\n",
    "        if np.sum(np.isinf(subj)) > 0:\n",
    "            print(i)\n",
    "\n",
    "normalizeSubjects(train_rest_ts)\n",
    "# normalizeSubjects(train_nback_ts)\n",
    "# normalizeSubjects(train_emoid_ts)\n",
    "\n",
    "normalizeSubjects(test_rest_ts)\n",
    "# normalizeSubjects(test_nback_ts)\n",
    "# normalizeSubjects(test_emoid_ts)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c026aa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 264)\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Calculare pearson matrices\n",
    "\n",
    "train_p = [np.corrcoef(sub) for sub in train_rest_ts]\n",
    "test_p = [np.corrcoef(sub) for sub in test_rest_ts]\n",
    "\n",
    "print(train_p[0].shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39888f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[193   1   0]\n",
      " [217   1   0]\n",
      " [233   1   0]\n",
      " [176   1   0]\n",
      " [116   0   1]\n",
      " [246   0   1]\n",
      " [164   1   0]\n",
      " [167   0   1]\n",
      " [202   0   1]\n",
      " [108   0   1]]\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors (right now just ages, maleness, and femaless)\n",
    "\n",
    "X_train = []\n",
    "for subj in train:\n",
    "    maleness = 1 if subj['meta']['Gender'] == 'M' else 0\n",
    "    femaleness = 1 if maleness == 0 else 0\n",
    "    feat = np.array([subj['meta']['AgeInMonths'], maleness, femaleness])\n",
    "    X_train.append(feat)\n",
    "    \n",
    "X_test = []\n",
    "for subj in test:\n",
    "    maleness = 1 if subj['meta']['Gender'] == 'M' else 0\n",
    "    femaleness = 1 if maleness == 0 else 0\n",
    "    feat = np.array([subj['meta']['AgeInMonths'], maleness, femaleness])\n",
    "    X_test.append(feat)\n",
    "    \n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "print(X_train[10:20])\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2921fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Pearson matrices to pyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_p_torch = [torch.from_numpy(p).float() for p in train_p]\n",
    "test_p_torch = [torch.from_numpy(p).float() for p in test_p]\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f20c6cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 4294967296.000000 Reserved: 1484783616.000000 Allocated: 1305116160.000000 Free: 179667456.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0) \n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "print('Total: {:f} Reserved: {:f} Allocated: {:f} Free: {:f}'.format(t,r,a,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7eba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2910, -0.6650, -0.3234],\n",
      "        [ 0.8243,  0.1680, -0.2487],\n",
      "        [ 0.7814,  0.6550,  1.7756]])\n",
      "tensor([[-0.2910, -0.6650, -0.3234,  0.8243,  0.1680, -0.2487,  0.7814,  0.6550,\n",
      "          1.7756]])\n",
      "tensor([[-0.2910, -0.6650, -0.3234,  0.8243,  0.1680, -0.2487,  0.7814,  0.6550,\n",
      "          1.7756],\n",
      "        [-0.2910, -0.6650, -0.3234,  0.8243,  0.1680, -0.2487,  0.7814,  0.6550,\n",
      "          1.7756],\n",
      "        [-0.2910, -0.6650, -0.3234,  0.8243,  0.1680, -0.2487,  0.7814,  0.6550,\n",
      "          1.7756]])\n"
     ]
    }
   ],
   "source": [
    "# Test reshape\n",
    "\n",
    "a = torch.randn(3,3)\n",
    "print(a)\n",
    "a = a.reshape(1,3*3)\n",
    "print(a)\n",
    "a = a.expand(3,9)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19c9750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initing tensors...\n",
      "Einsum...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 958.00 MiB (GPU 0; 4.00 GiB total capacity; 2.93 GiB already allocated; 101.19 MiB free; 2.95 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d880e726fb5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#edges = torch.einsum('aij, bij, im, jm -> abm', ps, ps, masks, masks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'aij,im,jm->aijm'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'aijm,bijm->abm'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Features and message...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aorlichenko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(equation, *operands)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 958.00 MiB (GPU 0; 4.00 GiB total capacity; 2.93 GiB already allocated; 101.19 MiB free; 2.95 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Test efficiency\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "Nsub = 450\n",
    "Nroi = 264\n",
    "Nmask = 8\n",
    "Nfeat = 4\n",
    "Nhid = 40\n",
    "Nlat = 20\n",
    "\n",
    "print('Initing tensors...')\n",
    "ps = torch.randn(Nsub, Nroi, Nroi)\n",
    "masks = torch.randn(Nroi, Nmask, requires_grad=True)\n",
    "feat = torch.randn(Nsub, Nfeat)\n",
    "fc1 = nn.Linear(Nsub*(Nmask+Nfeat),Nhid)\n",
    "fc2 = nn.Linear(Nhid,Nlat)\n",
    "fc3 = nn.Linear(Nsub*(Nmask+Nlat),Nhid)\n",
    "fc4 = nn.Linear(Nhid,1)\n",
    "\n",
    "print('Einsum...')\n",
    "#edges = torch.einsum('aij, bij, im, jm -> abm', ps, ps, masks, masks)\n",
    "mp = torch.einsum('aij,im,jm->aijm',ps,masks,masks)\n",
    "edges = torch.einsum('aijm,bijm->abm',mp,mp)\n",
    "\n",
    "print('Features and message...')\n",
    "featRep = feat.reshape(1,Nsub*Nfeat).expand(Nsub,Nsub*Nfeat)\n",
    "msg = edges.reshape(Nsub,Nsub*Nmask)\n",
    "totalMsg = torch.cat((msg, featRep), dim=1)\n",
    "\n",
    "print('Layer 1')\n",
    "x = F.relu(fc1(totalMsg))\n",
    "h = fc2(x)\n",
    "\n",
    "print('Layer 2')\n",
    "h = h.reshape(1,Nsub*Nlat).expand(Nsub,Nsub*Nlat)\n",
    "h = torch.cat((msg, h), dim=1)\n",
    "h = F.relu(fc3(h))\n",
    "age = fc4(h)\n",
    "\n",
    "print('Loss...')\n",
    "loss = 1-torch.sum(age)\n",
    "loss += torch.sum(masks)\n",
    "for i in range(Nmask):\n",
    "    for j in range(i+1,Nmask):\n",
    "        loss += torch.sum(masks[:,i]*masks[:,j])\n",
    "\n",
    "print('Backward...')\n",
    "loss.backward()\n",
    "\n",
    "print('Complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a0f97d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# GCN model\n",
    "\n",
    "import random\n",
    "\n",
    "def updateListDict(d, key, item):\n",
    "    if key not in d.keys():\n",
    "        d[key] = []\n",
    "    d[key].append(item)\n",
    "\n",
    "Nbatch = 10\n",
    "Nsys = 4\n",
    "Nroi = train_p_torch[0].shape[0]\n",
    "Ne = 2000\n",
    "NeS = 30\n",
    "NmaxE = 50\n",
    "Nh = 10\n",
    "\n",
    "class SysGcn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SysGcn, self).__init__()\n",
    "        self.sysM = []\n",
    "        for i in range(Nsys):\n",
    "            self.sysM.append(nn.Parameter(torch.eye(Nroi)))\n",
    "        self.sysMp = nn.ParameterList(self.sysM)\n",
    "        self.fc11 = nn.Linear(NmaxE*7,20)\n",
    "        self.fc12 = nn.Linear(20,Nh)\n",
    "        self.fc91 = nn.Linear(Nh,10)\n",
    "        self.fc92 = nn.Linear(10,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pearson matrices and features are set outside the loop\n",
    "        ps = self.ps\n",
    "        feat = self.feat\n",
    "        # Mask all matrices\n",
    "        mSums = []\n",
    "        psM = []\n",
    "        for i in range(Nsys):\n",
    "            # Squared sum\n",
    "            mSums.append(torch.sum(self.sysM[i])**2)\n",
    "            psM.append([])\n",
    "            for p in ps:\n",
    "                psM[i].append(self.sysM[i]@p@self.sysM[i])\n",
    "        # Sample out of all possible edges\n",
    "        es = {}\n",
    "        for ei in range(Ne):\n",
    "            iSys = random.randint(0,Nsys-1)\n",
    "            i = random.randint(0,len(ps)-1)\n",
    "            j = random.randint(0,len(ps)-1)\n",
    "            pi = psM[iSys][i]\n",
    "            pj = psM[iSys][j]\n",
    "            # Covariance norm\n",
    "            n = torch.sum(pi*pj)/mSums[iSys]\n",
    "            updateListDict(es, i, [n, iSys, j])\n",
    "            updateListDict(es, j, [n, iSys, i])\n",
    "        # Batching\n",
    "        pred = torch.zeros(Nbatch)\n",
    "        for a in range(len(x)):\n",
    "            print('Done {0:d}'.format(a))\n",
    "            p = x[a][0]\n",
    "            age = x[a][1]\n",
    "            m = x[a][2]\n",
    "            f = x[a][3]\n",
    "            # Calc edges to NeS other subjects\n",
    "            for ei in range(NeS):\n",
    "                iSys = random.randint(0,Nsys-1)\n",
    "                i = random.randint(0,len(ps)-1)\n",
    "                pi = psM[iSys][i]\n",
    "                p_ = self.sysM[iSys]@p@self.sysM[iSys]\n",
    "                # Covariance norm\n",
    "                n = torch.sum(pi*p_)/mSums[iSys]\n",
    "                updateListDict(es, i, [n, iSys, -1])\n",
    "                updateListDict(es, -1, [n, iSys, i])\n",
    "            # Graph convolutions\n",
    "            # Hidden state\n",
    "            h = torch.zeros(feat.shape[0]+1,10)\n",
    "            # Layer 1\n",
    "            for ei in es.keys():\n",
    "                # Aggregate messages\n",
    "                msg = torch.zeros(NmaxE, 7)\n",
    "                for eii in range(len(es[ei])):\n",
    "                    if eii >= NmaxE:\n",
    "                        break\n",
    "                    e = es[ei][eii]\n",
    "                    msg[eii,0] = e[0]\n",
    "                    msg[eii,1] = e[1]\n",
    "                    if e[2] == -1:\n",
    "                        msg[eii,2] = 0\n",
    "                        msg[eii,3] = m\n",
    "                        msg[eii,4] = f\n",
    "                    else:\n",
    "                        msg[eii,2] = self.feat[e[2],0]\n",
    "                        msg[eii,3] = self.feat[e[2],1]\n",
    "                        msg[eii,4] = self.feat[e[2],2]\n",
    "                    if ei == -1:\n",
    "                        msg[eii,5] = m\n",
    "                        msg[eii,6] = f\n",
    "                    else:\n",
    "                        msg[eii,5] = self.feat[ei,1]\n",
    "                        msg[eii,6] = self.feat[ei,2]\n",
    "                # Permute rows\n",
    "                msg = msg[torch.randperm(msg.size()[0])]\n",
    "                # Flatten message\n",
    "                msg = msg.flatten()\n",
    "                # Update hidden state\n",
    "                y = F.relu(self.fc11(msg))\n",
    "                y = F.relu(self.fc12(y))\n",
    "                h[ei,:] = y\n",
    "            # Predict age based on embedding\n",
    "            y = F.relu(self.fc91(h[-1,:]))\n",
    "            pred[a] = self.fc92(y)\n",
    "        return pred, self.sysM\n",
    "    \n",
    "sysgcn = SysGcn()\n",
    "optim = torch.optim.Adam(sysgcn.parameters(), lr=1e-3)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a44170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 0 loss=371961.625000\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 1 loss=295143.625000\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 2 loss=314101.812500\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 3 loss=244405.062500\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 4 loss=289488.375000\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 5 loss=389040.531250\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 6 loss=393300.312500\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 7 loss=323468.656250\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 8 loss=411243.437500\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 9 loss=274799.500000\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 10 loss=365339.750000\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 11 loss=326264.906250\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 12 loss=380646.125000\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 13 loss=397173.656250\n",
      "Done 0\n",
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n",
      "Done 5\n",
      "Done 6\n",
      "Done 7\n",
      "Done 8\n",
      "Done 9\n",
      "Going backwards\n",
      "epoch 14 loss=411611.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-61b61a4d78e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mtruth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msysgcn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaskLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aorlichenko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-5493fe36270d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mpj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miSys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;31m# Covariance norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmSums\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miSys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mupdateListDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miSys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mupdateListDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miSys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Gcn\n",
    "\n",
    "import random\n",
    "\n",
    "N = len(train_p_torch)\n",
    "running = 0\n",
    "runningM1 = 0\n",
    "runningM2 = 0\n",
    "nEpoch = 1500\n",
    "pPeriod = 1\n",
    "\n",
    "# Want both discreteness and non-overlapping\n",
    "def maskLoss(masks):\n",
    "    disc = 0\n",
    "    nono = 0\n",
    "    for i in range(len(masks)):\n",
    "        disc += torch.sum(masks[i])\n",
    "        for j in range(len(masks)):\n",
    "            if i != j:\n",
    "                nono += torch.sum(masks[i]*masks[j])\n",
    "    return disc, nono\n",
    "\n",
    "sysgcn.ps = train_p_torch\n",
    "sysgcn.feat = X_train\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "    batch = []\n",
    "    truth = torch.zeros(Nbatch)\n",
    "    for i in range(Nbatch):\n",
    "        idx = random.randint(0,N-1)\n",
    "        p = train_p_torch[idx]\n",
    "        batch.append([p, X_train[idx,0], X_train[idx,1], X_train[idx,2]])\n",
    "        truth[i] = X_train[idx, 0]\n",
    "    optim.zero_grad()\n",
    "    pred, masks = sysgcn(batch)          \n",
    "    l1 = torch.sum((truth-pred)**2)\n",
    "    l2, l3 = maskLoss(masks)\n",
    "    running += l1.detach()\n",
    "    runningM1 += l2.detach()\n",
    "    runningM2 += l3.detach()\n",
    "    loss = l1 + l2 + l3\n",
    "    print('Going backwards')\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if epoch % pPeriod == 0 or epoch == nEpoch-1:\n",
    "        if epoch != 0:\n",
    "            if epoch % pPeriod != 0:\n",
    "                running /= epoch % pPeriod\n",
    "                runningM1 /= epoch % pPeriod\n",
    "                runningM2 /= epoch % pPeriod\n",
    "            else:\n",
    "                running /= pPeriod\n",
    "                runningM1 /= pPeriod\n",
    "                runningM2 /= pPeriod\n",
    "        print('epoch {:d} loss={:f}'.format(epoch, running))\n",
    "        running = 0\n",
    "        runningM1 = 0\n",
    "        runningM2 = 0\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68134fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
