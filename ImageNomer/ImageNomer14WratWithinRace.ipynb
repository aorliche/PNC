{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54865ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830\n"
     ]
    }
   ],
   "source": [
    "# Get subjects from demographics file\n",
    "\n",
    "import pickle\n",
    "\n",
    "demofile = '../../ImageNomer/data/anton/cohorts/test/demographics.pkl'\n",
    "\n",
    "with open(demofile, 'rb') as f:\n",
    "    demo = pickle.load(f)\n",
    "    \n",
    "print(len(list(demo['race'].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7ee61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927\n",
      "927\n"
     ]
    }
   ],
   "source": [
    "# Load big and small SNPs for all subjects with WRAT and RACE\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "snpsdir = '../../ImageNomer/data/anton/cohorts/test/snps/'\n",
    "\n",
    "big = dict()\n",
    "small = dict()\n",
    "\n",
    "for f in Path(snpsdir).iterdir():\n",
    "    mobj = re.match('([0-9]+)_set-([a-z]+)_snps.npy', f.name)\n",
    "    if not mobj:\n",
    "        continue\n",
    "    snps = np.load(f'{snpsdir}/{f.name}')\n",
    "    subj = mobj.group(1)\n",
    "    if mobj.group(2) == 'big':\n",
    "        big[subj] = snps\n",
    "    if mobj.group(2) == 'small':\n",
    "        small[subj] = snps\n",
    "\n",
    "print(len(list(big.keys())))\n",
    "print(len(list(small.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbf092f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 106863)\n",
      "(326,)\n"
     ]
    }
   ],
   "source": [
    "subs = []\n",
    "snps = []\n",
    "wrat = []\n",
    "\n",
    "for sub,race in demo['race'].items():\n",
    "    if race == 'AA':\n",
    "        subs.append(sub)\n",
    "        snps.append(big[sub])\n",
    "        wrat.append(demo['wrat'][sub])\n",
    "        \n",
    "snps = np.stack(snps)\n",
    "wrat = np.stack(wrat)\n",
    "\n",
    "# snps2 = snps\n",
    "# snps2[np.isnan(snps2)] = 0\n",
    "\n",
    "x0 = snps == 0\n",
    "x1 = snps == 1\n",
    "x2 = snps == 2\n",
    "snps2 = np.concatenate([x0,x1,x2],axis=1)\n",
    "\n",
    "print(snps2.shape)\n",
    "print(wrat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdfd25e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.755878032166695\n",
      "14.896290115366467\n",
      "13.684123136004251\n",
      "14.639846708134424\n",
      "13.180180869491576\n",
      "14.945645372954766\n",
      "13.18500073511403\n",
      "15.090998057531348\n",
      "15.027730839125338\n",
      "13.950272209479326\n",
      "14.615829176127843\n",
      "13.725455918922131\n",
      "16.288350518245082\n",
      "12.981151721559396\n",
      "14.765880426583177\n",
      "14.043708474601676\n",
      "14.752909443792298\n",
      "14.568976900299228\n",
      "15.853515245547403\n",
      "17.134390563357023\n",
      "16.907376596942523\n",
      "14.711881651458967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import torch\n",
    "\n",
    "ntrain = 250\n",
    "\n",
    "rmses = []\n",
    "\n",
    "race = 'EA'\n",
    "subset = 'small'\n",
    "\n",
    "def save(race, subset, i, w, trsubs, tsubs, rmse):\n",
    "    fname = f'../../ImageNomer/data/anton/cohorts/test/weights/snps/{race}/lasso-wrat/{subset}{i}.pkl'\n",
    "    desc = f'Lasso regression WRAT SNPs subset {subset} rmse: {rmse}'\n",
    "    dct = dict(w=w, trsubs=trsubs, tsubs=tsubs, desc=desc)\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(dct, f)\n",
    "        \n",
    "print(np.mean((wrat-np.mean(wrat))**2)**0.5)\n",
    "\n",
    "for i in range(20):\n",
    "    idcs = np.random.permutation(snps2.shape[0])\n",
    "    x = snps2\n",
    "    x = x[idcs]\n",
    "    xtr = x[:ntrain]\n",
    "    xt = x[ntrain:]\n",
    "\n",
    "    mux = np.mean(xtr, axis=0, keepdims=True)\n",
    "    sigx = np.std(xtr, axis=0, keepdims=True)\n",
    "    xtr = xtr - mux\n",
    "    xt = xt - mux\n",
    "\n",
    "    y = wrat\n",
    "    y = y[idcs]\n",
    "    ytr = y[:ntrain]\n",
    "    yt = y[ntrain:]\n",
    "\n",
    "    mu = np.mean(ytr)\n",
    "    ytr = ytr - mu\n",
    "    yt = yt - mu\n",
    "\n",
    "    clf = Lasso(alpha=0.01, max_iter=10000).fit(xtr, ytr)\n",
    "    yhat = clf.predict(xt)\n",
    "    w = clf.coef_.reshape(-1)\n",
    "\n",
    "#     xxtr = torch.from_numpy(xtr).float().cuda()\n",
    "#     xxt = torch.from_numpy(xt).float().cuda()\n",
    "#     yytr = torch.from_numpy(ytr).float().cuda()\n",
    "#     yyt = torch.from_numpy(yt).float().cuda()\n",
    "    \n",
    "#     w,_,_,_ = torch.linalg.lstsq(xxtr, yytr)\n",
    "#     yhat = xxt@w\n",
    "#     yhat = yhat.detach().cpu().numpy()\n",
    "#     w = w.detach().cpu().numpy()\n",
    "    \n",
    "    rmse = np.mean((yhat-yt)**2)**0.5\n",
    "    print(rmse)\n",
    "    rmses.append(rmse)\n",
    "    \n",
    "#     save(race, subset, i, w, \n",
    "#          [subs[j] for j in idcs[:ntrain]], [subs[j] for j in idcs[ntrain:]], rmse)\n",
    "    \n",
    "print(np.mean(rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc45e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
