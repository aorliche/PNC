{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6272696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from natsort import natsorted\n",
    "\n",
    "basedir = '../../ImageNomer/data/anton/cohorts/test'\n",
    "demoname = f'{basedir}/demographics.pkl'\n",
    "\n",
    "with open(demoname, 'rb') as f:\n",
    "    demo = pickle.load(f)\n",
    "    \n",
    "subs = natsorted(list(demo['race'].keys()))\n",
    "print(len(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c6d997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(733, 34716)\n",
      "(733,)\n",
      "0.44474761255115963\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "task = 'rest'\n",
    "pre = 'fc'\n",
    "\n",
    "# Load FC and race\n",
    "\n",
    "fcs = []\n",
    "pncrace = []\n",
    "\n",
    "for sub in subs:\n",
    "    fname = f'{basedir}/{pre}/{sub}_task-{task}_{pre}.npy'\n",
    "    if demo['race'][sub] == 'EA':\n",
    "        pncrace.append(0)\n",
    "    elif demo['race'][sub] == 'AA':\n",
    "        pncrace.append(1)\n",
    "    else:\n",
    "        continue\n",
    "    fc = np.load(fname)\n",
    "    fcs.append(fc)\n",
    "#     race.append(int(demo['sex'][sub] == 'M'))\n",
    "    \n",
    "fcs = np.stack(fcs)\n",
    "pncrace = np.array(pncrace)\n",
    "print(fcs.shape)\n",
    "print(pncrace.shape)\n",
    "print(np.mean(pncrace))\n",
    "print(pncrace[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84e7c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Load BSNIP data\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# NaN FC: Baltimore_S3130FCP1 Detroit_1570_TR_S1570PVL1\n",
    "badsub = ['Baltimore_S3130FCP1', 'Detroit_1570_TR_S1570PVL1']\n",
    "bsnip = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/BSNIP/'\n",
    "\n",
    "ts = pickle.load(open(f'{bsnip}/bsnip_rc_ts_centered.pkl', 'rb'))\n",
    "# race = pickle.load(open('../../BSNIP/race.pkl', 'rb'))\n",
    "\n",
    "for s in badsub:\n",
    "    del ts[s]\n",
    "#     del race[s]\n",
    "\n",
    "# samsung = '/run/media/anton/Samsung_T5'\n",
    "# bsnip = f'{samsung}/BSNIP'\n",
    "pheno = f'{bsnip}/Phenotype'\n",
    "\n",
    "iid = pd.read_csv(f'{pheno}/BSNIP_Imaging_ID.csv')\n",
    "idb = pd.read_csv(f'{pheno}/BSNIP_Imaging_Database.csv')\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e7da279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165\n"
     ]
    }
   ],
   "source": [
    "from math import isnan\n",
    "\n",
    "def get_field(iid, idb, subid, field):\n",
    "    subid = subid.split('_')[-1]\n",
    "    pid = iid[iid['StudyID'] == subid]['pid']\n",
    "    uid = iid[iid['StudyID'] == subid]['UID']\n",
    "    ser2 = idb[idb['Scan_ID'] == subid]\n",
    "    again = False\n",
    "    try:\n",
    "        if isnan(pid):\n",
    "            again = True\n",
    "        elif idb[idb['pid'] == int(pid)].shape[0] != 1:\n",
    "            again = True\n",
    "        else:\n",
    "            ser = idb[idb['pid'] == int(pid)]\n",
    "            return ser[field].item()\n",
    "    except:\n",
    "        again = True\n",
    "    if again and ser2.shape[0] == 1:\n",
    "        return ser2[field].item()\n",
    "    return None\n",
    "\n",
    "race = dict()\n",
    "\n",
    "for k in ts:\n",
    "    r = get_field(iid, idb, k, 'Race')\n",
    "#     race[k] = r\n",
    "    if r == 'AA' or r == 'CA':\n",
    "        race[k] = r\n",
    "        \n",
    "print(len(list(race.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f2be544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1165, 34716)\n",
      "(1165,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tx = []\n",
    "ty = []\n",
    "\n",
    "for k,v in race.items():\n",
    "    if v == 'CA':\n",
    "        ty.append(0)\n",
    "    elif v == 'AA':\n",
    "        ty.append(1)\n",
    "    else:\n",
    "        continue\n",
    "    p = np.corrcoef(ts[k])\n",
    "    a,b = np.triu_indices(264,1)\n",
    "    tx.append(p[a,b])\n",
    "        \n",
    "tx = np.stack(tx)\n",
    "ty = np.array(ty)\n",
    "\n",
    "print(tx.shape)\n",
    "print(ty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19d7f424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678111587982833\n"
     ]
    }
   ],
   "source": [
    "print(1-np.mean(ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9fabeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.8545454545454545\n",
      "0.9041769041769042\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7727272727272727\n",
      "0.8968058968058968\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7818181818181819\n",
      "0.8918918918918919\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.8181818181818182\n",
      "0.8353808353808354\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7454545454545455\n",
      "0.914004914004914\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.8363636363636363\n",
      "0.9090909090909091\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7454545454545455\n",
      "0.8820638820638821\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7363636363636363\n",
      "0.9041769041769042\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7636363636363637\n",
      "0.9213759213759214\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7454545454545455\n",
      "0.9336609336609336\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7818181818181819\n",
      "0.9213759213759214\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.8272727272727273\n",
      "0.8869778869778869\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.8545454545454545\n",
      "0.8501228501228502\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7636363636363637\n",
      "0.9238329238329238\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.8181818181818182\n",
      "0.8918918918918919\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7818181818181819\n",
      "0.9533169533169533\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7818181818181819\n",
      "0.9262899262899262\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7363636363636363\n",
      "0.9090909090909091\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.8454545454545455\n",
      "0.8796068796068796\n",
      "(664, 34716)\n",
      "(110, 34716)\n",
      "0.7818181818181819\n",
      "0.9238329238329238\n",
      "---\n",
      "0.7886363636363637\n",
      "0.03887626057587889\n",
      "0.9029484029484027\n",
      "0.027066087476682873\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ntrain = 1000\n",
    "rs = []\n",
    "ts = []\n",
    "\n",
    "for i in range(20):\n",
    "    xtr, xt, ytr, yt = train_test_split(tx, ty, stratify=ty, train_size=ntrain)\n",
    "    tr1 = np.where(ytr == 1)[0]\n",
    "    tr0 = np.where(ytr == 0)[0][:len(tr1)]\n",
    "    t1 = np.where(yt == 1)[0]\n",
    "    t0 = np.where(yt == 0)[0][:len(t1)]\n",
    "    xtr = np.concatenate([xtr[tr1], xtr[tr0]])\n",
    "    xt = np.concatenate([xt[t1], xt[t0]])\n",
    "    ytr = np.concatenate([ytr[tr1], ytr[tr0]])\n",
    "    yt = np.concatenate([yt[t1], yt[t0]])\n",
    "    print(xtr.shape)\n",
    "    print(xt.shape)\n",
    "\n",
    "    clf = LogisticRegression(C=1000, max_iter=1000).fit(xtr, ytr)\n",
    "    yhat = clf.predict(xt)\n",
    "    acc = np.mean((yhat == yt).astype(\"int\"))\n",
    "    acc = float(acc)\n",
    "    print(acc)\n",
    "    rs.append(acc)\n",
    "#     yhat = clf.predict(tx)\n",
    "#     acc = np.mean((yhat == ty).astype(\"int\"))\n",
    "#     acc = float(acc)\n",
    "#     print(acc)\n",
    "#     ts.append(acc)\n",
    "    yhat = clf.predict(fcs)\n",
    "    idcs = np.where(pncrace == 0)[0]\n",
    "    acc = np.mean((yhat[idcs] == pncrace[idcs]).astype(\"int\"))\n",
    "    acc = float(acc)\n",
    "    print(acc)\n",
    "    ts.append(acc)\n",
    "    \n",
    "print('---')\n",
    "print(np.mean(rs))\n",
    "print(np.std(rs))\n",
    "print(np.mean(ts))\n",
    "print(np.std(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4251c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5552523874488404"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.mean(pncrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2f006eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7625313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
