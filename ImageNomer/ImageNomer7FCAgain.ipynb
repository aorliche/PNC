{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e2a226c",
   "metadata": {},
   "source": [
    "# Redo FC for 20 in each of age, sex, wrat with TR=3 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9086dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'wrat', 'missingage', 'missingsex', 'missingwrat', 'failedqc']\n",
      "['emoid', 'nback', 'rest']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Using newly preprocessed subjects\n",
    "\n",
    "import pickle\n",
    "\n",
    "metadictname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_agesexwrat.pkl'\n",
    "alltsname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_PowerTS_float2.pkl'\n",
    "\n",
    "with open(metadictname, 'rb') as f:\n",
    "    metadict = pickle.load(f)\n",
    "\n",
    "with open(alltsname, 'rb') as f:\n",
    "    allts = pickle.load(f)\n",
    "    \n",
    "print(list(metadict.keys()))\n",
    "print(list(allts.keys()))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9dae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830\n",
      "(830, 264, 124)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get subjects that have all tasks and paras specified\n",
    "Functions for creating independent and response variables\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_subs(allts, metadict, tasks, paras):\n",
    "    # Get subs for all paras\n",
    "    for i,para in enumerate(paras):\n",
    "        tmpset = set([int(sub[4:]) for sub in allts[para].keys()])\n",
    "        if i == 0:\n",
    "            paraset = tmpset\n",
    "        else:\n",
    "            paraset = paraset.intersection(tmpset)\n",
    "    # Get subs for all tasks\n",
    "    for i,task in enumerate(tasks):\n",
    "        tmpset = set([sub for sub in metadict[task].keys()])\n",
    "        if i == 0:\n",
    "            taskset = tmpset\n",
    "        else:\n",
    "            taskset = paraset.intersection(tmpset)\n",
    "    # Remove QC failures\n",
    "    allsubs = taskset.intersection(paraset)\n",
    "    for badsub in metadict['failedqc']:\n",
    "        try:\n",
    "            allsubs.remove(int(badsub[4:]))\n",
    "        except:\n",
    "            pass\n",
    "    return list(allsubs)\n",
    "\n",
    "def get_X(allts, paras, subs):\n",
    "    X = []\n",
    "    for para in paras:\n",
    "        pX = [allts[para][f'sub-{sub}'] for sub in subs]\n",
    "        pX = np.stack(pX)\n",
    "        X.append(pX)\n",
    "    return X\n",
    "\n",
    "def get_y(metadict, tasks, subs):\n",
    "    y = []\n",
    "    for task in tasks:\n",
    "        if task == 'age' or task == 'wrat':\n",
    "            var = [metadict[task][sub] for sub in subs]\n",
    "            var = np.array(var)\n",
    "            y.append(var)\n",
    "        if task == 'sex':\n",
    "            maleness = [metadict[task][sub] == 'M' for sub in subs]\n",
    "            maleness = np.array(maleness)\n",
    "            sex = np.stack([maleness, 1-maleness], axis=1)\n",
    "            y.append(sex)\n",
    "    return y\n",
    "\n",
    "subs = get_subs(allts, metadict, ['wrat'], ['rest', 'nback', 'emoid'])\n",
    "print(len(subs))\n",
    "\n",
    "X = get_X(allts, ['rest', 'nback', 'emoid'], subs)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f4324cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830, 34716)\n"
     ]
    }
   ],
   "source": [
    "# TS to condensed FC\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = [cutoff[0] / nyq, cutoff[1] / nyq]\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_bandpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "tr = 3\n",
    "\n",
    "def filter_design_ts(X):\n",
    "    Xs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        nX = butter_bandpass_filter(X[i], [0.01, 0.15], 1/tr)\n",
    "        Xs.append(nX)\n",
    "    return np.stack(Xs)\n",
    "\n",
    "def ts_to_flat_fc(X):\n",
    "    p = np.corrcoef(X)\n",
    "    a,b = np.triu_indices(p[0].shape[0], 1)\n",
    "    p = p[a,b]\n",
    "    return p\n",
    "\n",
    "p = [np.stack([ts_to_flat_fc(ts) for ts in filter_design_ts(Xp)]) for Xp in X]\n",
    "# Xfiltnorm = [tsmod/np.linalg.norm(tsmod, axis=(-1), keepdims=True) for tsmod in ts]\n",
    "print(p[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f5866b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.3337, device='cuda:0')\n",
      "Done 0\n",
      "tensor(27.7029, device='cuda:0')\n",
      "Done 1\n",
      "tensor(27.0332, device='cuda:0')\n",
      "Done 2\n",
      "tensor(23.8629, device='cuda:0')\n",
      "Done 3\n",
      "tensor(26.9305, device='cuda:0')\n",
      "Done 4\n",
      "tensor(27.1087, device='cuda:0')\n",
      "Done 5\n",
      "tensor(25.4601, device='cuda:0')\n",
      "Done 6\n",
      "tensor(28.2102, device='cuda:0')\n",
      "Done 7\n",
      "tensor(24.5468, device='cuda:0')\n",
      "Done 8\n",
      "tensor(22.8939, device='cuda:0')\n",
      "Done 9\n",
      "tensor(24.0622, device='cuda:0')\n",
      "Done 10\n",
      "tensor(26.3964, device='cuda:0')\n",
      "Done 11\n",
      "tensor(28.3612, device='cuda:0')\n",
      "Done 12\n",
      "tensor(26.3250, device='cuda:0')\n",
      "Done 13\n",
      "tensor(27.2255, device='cuda:0')\n",
      "Done 14\n",
      "tensor(23.1304, device='cuda:0')\n",
      "Done 15\n",
      "tensor(28.2594, device='cuda:0')\n",
      "Done 16\n",
      "tensor(27.0746, device='cuda:0')\n",
      "Done 17\n",
      "tensor(27.1884, device='cuda:0')\n",
      "Done 18\n",
      "tensor(25.4959, device='cuda:0')\n",
      "Done 19\n",
      "---\n",
      "tensor(26.0801, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Age wrat prediction\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "mseLoss = nn.MSELoss()\n",
    "\n",
    "modidx = 2\n",
    "mod = 'emoid'\n",
    "task = \"age\"\n",
    "sm=0\n",
    "\n",
    "for ii in range(20):\n",
    "\n",
    "    ntrain = 700\n",
    "    idcs = torch.randperm(p[modidx].shape[0])\n",
    "\n",
    "    x = torch.from_numpy(p[modidx]).float().cuda()\n",
    "    x = x[idcs]\n",
    "    xtr = x[:ntrain]\n",
    "    xt = x[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, [task], subs)[0]\n",
    "    y = torch.from_numpy(y).float().cuda()\n",
    "    y = y[idcs]\n",
    "    ytr = y[:ntrain]\n",
    "    yt = y[ntrain:]\n",
    "    mu = torch.mean(ytr)\n",
    "    ytr = ytr - mu\n",
    "    yt = yt - mu\n",
    "\n",
    "    def toDict(w, acc):\n",
    "        dct = dict(w=w.detach().cpu().numpy(), \n",
    "                   trsubs=sorted([subs[i] for i in idcs[:ntrain]]),\n",
    "                   tsubs=sorted([subs[i] for i in idcs[ntrain:]]),\n",
    "                   desc=f\"Least squares FC {task} {mod} rmse: {float(acc)}\")\n",
    "        return dct\n",
    "\n",
    "    def save(dct, dr, idx):\n",
    "        base = f\"/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/test/weights\"\n",
    "        with open(f\"{base}/{dr}/{mod}{idx}.pkl\", 'wb') as f:\n",
    "            pickle.dump(dct, f)\n",
    "\n",
    "    w, _, _, _ = torch.linalg.lstsq(xtr, ytr)\n",
    "    yhat = xt@w\n",
    "    acc = mseLoss(yhat, yt)**0.5\n",
    "\n",
    "    print(acc)\n",
    "    sm += acc/20\n",
    "    save(toDict(w,acc), f'{task}_mean_zero', ii)\n",
    "    print(f'Done {ii}')\n",
    "    \n",
    "print('---')\n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40b1a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7615384615384615\n",
      "[[0.84285714 0.15714286]\n",
      " [0.33333333 0.66666667]]\n",
      "Done 0\n",
      "0.8076923076923077\n",
      "[[0.86666667 0.13333333]\n",
      " [0.27272727 0.72727273]]\n",
      "Done 1\n",
      "0.7153846153846154\n",
      "[[0.64864865 0.35135135]\n",
      " [0.19642857 0.80357143]]\n",
      "Done 2\n",
      "0.823076923076923\n",
      "[[0.8115942  0.1884058 ]\n",
      " [0.16393443 0.83606557]]\n",
      "Done 3\n",
      "0.7538461538461538\n",
      "[[0.86666667 0.13333333]\n",
      " [0.34285714 0.65714286]]\n",
      "Done 4\n",
      "0.7846153846153846\n",
      "[[0.76       0.24      ]\n",
      " [0.18181818 0.81818182]]\n",
      "Done 5\n",
      "0.7384615384615385\n",
      "[[0.72058824 0.27941176]\n",
      " [0.24193548 0.75806452]]\n",
      "Done 6\n",
      "0.7307692307692307\n",
      "[[0.78125    0.21875   ]\n",
      " [0.31818182 0.68181818]]\n",
      "Done 7\n",
      "0.8\n",
      "[[0.77464789 0.22535211]\n",
      " [0.16949153 0.83050847]]\n",
      "Done 8\n",
      "0.7307692307692307\n",
      "[[0.70149254 0.29850746]\n",
      " [0.23809524 0.76190476]]\n",
      "Done 9\n",
      "0.8307692307692308\n",
      "[[0.86075949 0.13924051]\n",
      " [0.21568627 0.78431373]]\n",
      "Done 10\n",
      "0.8\n",
      "[[0.83333333 0.16666667]\n",
      " [0.234375   0.765625  ]]\n",
      "Done 11\n",
      "0.8\n",
      "[[0.82432432 0.17567568]\n",
      " [0.23214286 0.76785714]]\n",
      "Done 12\n",
      "0.823076923076923\n",
      "[[0.88       0.12      ]\n",
      " [0.25454545 0.74545455]]\n",
      "Done 13\n",
      "0.7692307692307693\n",
      "[[0.84415584 0.15584416]\n",
      " [0.33962264 0.66037736]]\n",
      "Done 14\n",
      "0.7923076923076923\n",
      "[[0.76470588 0.23529412]\n",
      " [0.17741935 0.82258065]]\n",
      "Done 15\n",
      "0.8\n",
      "[[0.86111111 0.13888889]\n",
      " [0.27586207 0.72413793]]\n",
      "Done 16\n",
      "0.7923076923076923\n",
      "[[0.77941176 0.22058824]\n",
      " [0.19354839 0.80645161]]\n",
      "Done 17\n",
      "0.7538461538461538\n",
      "[[0.77272727 0.22727273]\n",
      " [0.265625   0.734375  ]]\n",
      "Done 18\n",
      "0.8\n",
      "[[0.76712329 0.23287671]\n",
      " [0.15789474 0.84210526]]\n",
      "Done 19\n",
      "---\n",
      "0.7803846153846153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "modidx = 2\n",
    "mod = 'emoid'\n",
    "task = \"sex\"\n",
    "sm = 0\n",
    "\n",
    "for ii in range(20):\n",
    "    ntrain = 700\n",
    "    idcs = np.arange(p[modidx].shape[0])\n",
    "    np.random.shuffle(idcs)\n",
    "\n",
    "    x = p[modidx]\n",
    "    x = x[idcs]\n",
    "    xtr = x[:ntrain]\n",
    "    xt = x[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, [task], subs)[0][:,0]\n",
    "    y = y[idcs]\n",
    "    ytr = y[:ntrain]\n",
    "    yt = y[ntrain:]\n",
    "\n",
    "    def toDict(w, acc, conf):\n",
    "        if isinstance(w, torch.Tensor):\n",
    "            w = w.detach().cpu().numpy()\n",
    "        if not isinstance(w, np.ndarray):\n",
    "            raise Exception('Not an ndarray!')\n",
    "        dct = dict(w=w, \n",
    "                   trsubs=sorted([subs[i] for i in idcs[:ntrain]]),\n",
    "                   tsubs=sorted([subs[i] for i in idcs[ntrain:]]),\n",
    "                   desc=f\"Logistic regression FC {task} {mod} acc: {float(acc)} conf: {conf}\")\n",
    "        return dct\n",
    "\n",
    "    def save(dct, dr, idx):\n",
    "        base = f\"/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/test/weights\"\n",
    "        with open(f\"{base}/{dr}/{mod}{idx}.pkl\", 'wb') as f:\n",
    "            pickle.dump(dct, f)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000, penalty='l2', C=1, solver='lbfgs').fit(xtr, ytr)\n",
    "    yhat = clf.predict(xt)\n",
    "    acc = np.sum(yhat == yt)/len(yt)\n",
    "    print(acc)\n",
    "\n",
    "    mat = confusion_matrix(yt, yhat, normalize='true', labels=[0,1])\n",
    "    print(mat)\n",
    "\n",
    "    save(toDict(clf.coef_,acc,mat), f'{task}', ii)\n",
    "    print(f'Done {ii}')\n",
    "    sm += acc/20\n",
    "    \n",
    "print('---')\n",
    "print(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca44cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares partial corr wrat rest rmse: 15.840668678283691\n",
      "15.840668678283691\n",
      "Least squares partial corr wrat rest rmse: 14.328940391540527\n",
      "14.328940391540527\n",
      "Least squares partial corr wrat rest rmse: 17.752723693847656\n",
      "17.752723693847656\n",
      "Least squares partial corr wrat rest rmse: 14.846572875976562\n",
      "14.846572875976562\n",
      "Least squares partial corr wrat rest rmse: 15.849759101867676\n",
      "15.849759101867676\n",
      "Least squares partial corr wrat rest rmse: 15.805267333984375\n",
      "15.805267333984375\n",
      "Least squares partial corr wrat rest rmse: 14.116043090820312\n",
      "14.116043090820312\n",
      "Least squares partial corr wrat rest rmse: 15.236705780029297\n",
      "15.236705780029297\n",
      "Least squares partial corr wrat rest rmse: 15.065845489501953\n",
      "15.065845489501953\n",
      "Least squares partial corr wrat rest rmse: 15.535000801086426\n",
      "15.535000801086426\n",
      "Least squares partial corr wrat rest rmse: 15.19347095489502\n",
      "15.19347095489502\n",
      "Least squares partial corr wrat rest rmse: 14.742619514465332\n",
      "14.742619514465332\n",
      "Least squares partial corr wrat rest rmse: 14.743337631225586\n",
      "14.743337631225586\n",
      "Least squares partial corr wrat rest rmse: 14.982229232788086\n",
      "14.982229232788086\n",
      "Least squares partial corr wrat rest rmse: 15.579513549804688\n",
      "15.579513549804688\n",
      "Least squares partial corr wrat rest rmse: 14.593866348266602\n",
      "14.593866348266602\n",
      "Least squares partial corr wrat rest rmse: 15.912270545959473\n",
      "15.912270545959473\n",
      "Least squares partial corr wrat rest rmse: 13.980195999145508\n",
      "13.980195999145508\n",
      "Least squares partial corr wrat rest rmse: 14.587393760681152\n",
      "14.587393760681152\n",
      "Least squares partial corr wrat rest rmse: 14.597643852233887\n",
      "14.597643852233887\n",
      "15.164503431320192\n",
      "0.8243294706784065\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy stuff\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "base = f\"/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/test/weights/partial/wrat_mean_zero\"\n",
    "\n",
    "sm = 0\n",
    "vec = []\n",
    "for f in Path(base).iterdir():\n",
    "    if 'rest' in f.name:\n",
    "        with open(f'{base}/{f.name}', 'rb') as f:\n",
    "            dct = pickle.load(f)\n",
    "            mobj = re.match('.*rmse: ([\\d.]+).*', dct['desc'])\n",
    "            print(dct['desc'])\n",
    "            print(mobj.group(1))\n",
    "            v = float(mobj.group(1))\n",
    "            vec.append(v)\n",
    "            sm += float(mobj.group(1))/20\n",
    "            \n",
    "print(sm)\n",
    "print(np.std(np.array(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c00134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
