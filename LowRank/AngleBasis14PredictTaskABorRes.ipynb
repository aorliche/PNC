{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c71a307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1529\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from natsort import natsorted\n",
    "\n",
    "basedir = '../../ImageNomer/data/anton/cohorts/PNC'\n",
    "demoname = f'{basedir}/demographics.pkl'\n",
    "\n",
    "with open(demoname, 'rb') as f:\n",
    "    demo = pickle.load(f)\n",
    "    \n",
    "subs = natsorted(list(demo['age_at_cnb'].keys()))\n",
    "print(len(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bce3a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1230, 34716), (1230,), (1230,), (1230,), (1230, 5, 264), (1230, 5, 264)]\n",
      "[(1290, 34716), (1290,), (1290,), (1290,), (1290, 5, 264), (1290, 5, 264)]\n",
      "[(1329, 34716), (1329,), (1329,), (1329,), (1329, 5, 264), (1329, 5, 264)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "basis_file = '/home/anton/Documents/Tulane/Research/PNC_Good/AngleBasis5.pkl'\n",
    "basis = pickle.load(open(basis_file, 'rb'))\n",
    "\n",
    "# FC, age, sex, race, thetas, jitter\n",
    "rest = [[],[],[],[],[],[]]\n",
    "nback = [[],[],[],[],[],[]]\n",
    "emoid = [[],[],[],[],[],[]]\n",
    "\n",
    "for sub in subs:\n",
    "    for task, struct in zip(['rest', 'nback', 'emoid'], [rest, nback, emoid]):\n",
    "        try:\n",
    "            if demo['Race'][sub] not in ['AA', 'EA']:\n",
    "                continue\n",
    "            p = np.load(f'{basedir}/fc/{sub}_task-{task}_fc.npy')\n",
    "            a = demo['age_at_cnb'][sub]\n",
    "            s = demo['Sex'][sub] == 'M'\n",
    "            r = demo['Race'][sub] == 'AA'\n",
    "            ab = basis[f'{sub}-{task}']\n",
    "            struct[1].append(a)\n",
    "            struct[2].append(s)\n",
    "            struct[3].append(r)\n",
    "            struct[0].append(p)\n",
    "            struct[4].append(ab['thetas'])\n",
    "            struct[5].append(ab['jitter'])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "for struct in [rest, nback, emoid]:\n",
    "    struct[0] = np.stack(struct[0])\n",
    "    struct[1] = np.array(struct[1])\n",
    "    struct[2] = np.array(struct[2]).astype('int')\n",
    "    struct[3] = np.array(struct[3]).astype('int')\n",
    "    struct[4] = np.stack(struct[4])\n",
    "    struct[5] = np.stack(struct[5])\n",
    "    \n",
    "    print([a.shape for a in struct])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f214c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 5, 34716)\n",
      "(1230, 34716)\n",
      "(1230, 34716)\n",
      "8\n",
      "(1290, 5, 34716)\n",
      "(1290, 34716)\n",
      "(1290, 34716)\n",
      "8\n",
      "(1329, 5, 34716)\n",
      "(1329, 34716)\n",
      "(1329, 34716)\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def rmse(yhat, y):\n",
    "    if isinstance(yhat, np.ndarray) or isinstance(yhat, int):\n",
    "        f = np.mean\n",
    "    else:\n",
    "        f = torch.mean\n",
    "    return f((y-yhat)**2)**0.5\n",
    "\n",
    "def tops(thetas, jitter):\n",
    "    t0 = np.expand_dims(thetas, 2)\n",
    "    t1 = np.expand_dims(thetas, 3)\n",
    "    j0 = np.expand_dims(jitter, 2)\n",
    "    j1 = np.expand_dims(jitter, 3)\n",
    "    ps = np.cos(t0-t1)*(j0*j1)\n",
    "    a,b = np.triu_indices(264, 1)\n",
    "    ps = ps[:,:,a,b]\n",
    "    return ps\n",
    "    \n",
    "for st in [rest, nback, emoid]:\n",
    "    ps = tops(st[4], st[5])\n",
    "    aps = np.mean(ps, axis=1)\n",
    "    res = st[0] - aps\n",
    "\n",
    "    print(ps.shape)\n",
    "    print(aps.shape)\n",
    "    print(res.shape)\n",
    "    \n",
    "    st.append(aps)\n",
    "    st.append(res)\n",
    "    print(len(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "131a3c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9374045801526718\n",
      "0.8770992366412214\n",
      "0.8961832061068702\n",
      "0.932824427480916\n",
      "0.8900763358778626\n",
      "0.9106870229007633\n",
      "0.9412213740458015\n",
      "0.8969465648854962\n",
      "0.9129770992366413\n",
      "0.932824427480916\n",
      "0.8755725190839695\n",
      "0.9083969465648855\n",
      "0.932824427480916\n",
      "0.8893129770992366\n",
      "0.9061068702290076\n",
      "0.9412213740458015\n",
      "0.8778625954198473\n",
      "0.9061068702290076\n",
      "0.932824427480916\n",
      "0.8854961832061069\n",
      "0.9053435114503817\n",
      "0.934351145038168\n",
      "0.8824427480916031\n",
      "0.9053435114503817\n",
      "0.9412213740458015\n",
      "0.8870229007633588\n",
      "0.9076335877862596\n",
      "0.9358778625954198\n",
      "0.8824427480916031\n",
      "0.9061068702290076\n",
      "---\n",
      "0.9362595419847329 0.003551874847063177\n",
      "0.8844274809160307 0.0063519523855617415\n",
      "0.9064885496183207 0.00417062240599932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cat(x, **kwargs):\n",
    "    return np.concatenate(x, **kwargs)\n",
    "\n",
    "accs0, accs1, accs2 = [], [], []\n",
    "\n",
    "mod1 = emoid\n",
    "mod2 = nback\n",
    "\n",
    "for _ in range(10):\n",
    "    x = cat([mod1[7], mod2[7]], axis=0)\n",
    "    z = cat([mod1[6], mod2[6]], axis=0)\n",
    "    w = cat([mod1[0], mod2[0]], axis=0)\n",
    "    y = cat([np.zeros(mod1[7].shape[0]), np.ones(mod2[7].shape[0])], axis=0)\n",
    "\n",
    "    xtr, xt, ztr, zt, wtr, wt, ytr, yt = train_test_split(x, z, w, y, stratify=y, train_size=0.5)\n",
    "\n",
    "    reg = LogisticRegression(C=1, max_iter=1000).fit(xtr, ytr)\n",
    "    yhat = reg.predict(xt)\n",
    "    acc = np.mean(yhat == yt)\n",
    "    print(acc)\n",
    "    accs0.append(acc)\n",
    "    \n",
    "    reg = LogisticRegression(C=1, max_iter=1000).fit(ztr, ytr)\n",
    "    yhat = reg.predict(zt)\n",
    "    acc = np.mean(yhat == yt)\n",
    "    print(acc)\n",
    "    accs1.append(acc)\n",
    "    \n",
    "    reg = LogisticRegression(C=1, max_iter=1000).fit(wtr, ytr)\n",
    "    yhat = reg.predict(wt)\n",
    "    acc = np.mean(yhat == yt)\n",
    "    print(acc)\n",
    "    accs2.append(acc)\n",
    "    \n",
    "print('---')\n",
    "for a in [accs0, accs1, accs2]:\n",
    "    print(np.mean(a), np.std(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f468408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
