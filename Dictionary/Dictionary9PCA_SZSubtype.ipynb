{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ace7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from natsort import natsorted\n",
    "\n",
    "basedir = '../../ImageNomer/data/anton/cohorts/BSNIP'\n",
    "demoname = f'{basedir}/demographics.pkl'\n",
    "\n",
    "with open(demoname, 'rb') as f:\n",
    "    demo = pickle.load(f)\n",
    "    \n",
    "subs = natsorted(list(demo['Age_cal'].keys()))\n",
    "print(len(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c2031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 34716)\n",
      "(441,)\n",
      "[1 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1\n",
      " 0 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1\n",
      " 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1\n",
      " 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1\n",
      " 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# y=0 NC y=1 SZ1 (130) y=2 SZ2 (69)\n",
    "\n",
    "task = 'unk'\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for sub in subs:\n",
    "    if demo['DXGROUP_2'][sub] not in ['SZP', 'NC']:\n",
    "        continue\n",
    "    p = np.load(f'{basedir}/fc/{sub}_task-{task}_fc.npy')\n",
    "    x.append(p)\n",
    "    if demo['DXGROUP_2'][sub] == 'SZP':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "#     if demo['DXGROUP_1'][sub] == 'SADDEPP':\n",
    "#         y.append(1)\n",
    "#     elif demo['DXGROUP_1'][sub] == 'SADBPP':\n",
    "#         y.append(2)\n",
    "#     elif demo['DXGROUP_1'][sub] == 'NC':\n",
    "#         y.append(0)\n",
    "#     else:\n",
    "#         print('Bad DXGROUP')\n",
    "#         raise 'Bad'\n",
    "#     print(y[-1], demo['DXGROUP_2'][sub])\n",
    "#     if demo['DXGROUP_1'][sub] == 'SZP':\n",
    "#         if demo['sz_subtype'][sub] == '1':\n",
    "#             y.append(1)\n",
    "#         elif demo['sz_subtype'][sub] == '2':\n",
    "#             y.append(2)\n",
    "#         else:\n",
    "#             print('Bad sz_subtype')\n",
    "#             raise 'Bad'\n",
    "#     else:\n",
    "#         y.append(0)\n",
    "    \n",
    "x = np.stack(x)\n",
    "y = np.array(y).astype('int')\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d67657d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1\n",
      " 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "130 69\n",
      "[2. 1. 0. 1. 2. 0. 2. 1. 0. 0. 0. 0. 0. 2. 0. 2. 1. 0. 0. 0. 1. 0. 1. 2.\n",
      " 2. 0. 0. 1. 2. 2. 2. 0. 1. 0. 2. 2. 0. 1. 0. 2. 1. 1. 1. 1. 1. 2. 1. 0.\n",
      " 0. 0. 2. 0. 1. 1. 1. 2. 0. 2. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 2. 2. 0. 0.\n",
      " 0. 0. 1. 1. 2. 2. 1. 0. 0. 1. 0. 1. 0. 1. 1. 2. 0. 0. 2. 0. 2. 0. 0. 1.\n",
      " 2. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 2. 1. 1. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 0. 1. 2. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 2. 0. 2. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 2. 1. 1. 0. 1. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 2. 2. 1. 0. 0. 2. 0. 1. 0. 0. 0. 2. 1. 0.\n",
      " 2. 0. 1. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 1.\n",
      " 0. 2. 0. 2. 2. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 2. 0. 2. 0. 0.\n",
      " 0. 1. 1. 0. 2. 0. 0. 2. 0. 2. 1. 2. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 2. 0. 1. 0. 1. 0. 0. 2. 0. 0. 2. 1. 0. 2. 1. 0. 2. 0.\n",
      " 2. 0. 0. 2. 2. 1. 1. 1. 1. 1. 0. 1. 0. 0. 2. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 2. 0. 1. 1. 0. 2. 2. 1. 0. 1. 0.\n",
      " 2. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 2. 0. 0. 0. 2. 2. 2. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 2. 1. 0. 1. 0. 1. 2. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=2, n_init='auto').fit(x[y != 0])\n",
    "print(km.labels_)\n",
    "# print(np.sum(km.labels_ == 0), np.sum(km.labels_ == 1))\n",
    "\n",
    "# xm = x[km.labels_ == 1]\n",
    "# ym = y[km.labels_ == 1]\n",
    "\n",
    "# print(ym)\n",
    "# print(np.sum(ym == 0), np.sum(ym == 1))\n",
    "\n",
    "ym = np.zeros(len(y))\n",
    "ym[y != 0] = km.labels_ + 1\n",
    "\n",
    "print(np.sum(ym == 1), np.sum(ym == 2))\n",
    "print(ym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077986fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "bases = dict()\n",
    "print(bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "147741d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0.4463162871152843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "basis_type = 0\n",
    "\n",
    "pca = PCA(n_components=20).fit(x[np.where(y == basis_type)[0]])\n",
    "# pca = PCA(n_components=10).fit(x)\n",
    "print(len(pca.components_))\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "\n",
    "bases[basis_type] = pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "941257ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6404494382022472\n",
      "0.550561797752809\n",
      "0.6404494382022472\n",
      "0.5617977528089888\n",
      "0.6966292134831461\n",
      "0.6292134831460674\n",
      "0.6067415730337079\n",
      "0.5730337078651685\n",
      "0.5393258426966292\n",
      "0.48314606741573035\n",
      "0.6292134831460674\n",
      "0.5955056179775281\n",
      "0.651685393258427\n",
      "0.5730337078651685\n",
      "0.6853932584269663\n",
      "0.6067415730337079\n",
      "0.5730337078651685\n",
      "0.6292134831460674\n",
      "0.6179775280898876\n",
      "0.6067415730337079\n",
      "0.5280898876404494\n",
      "0.5955056179775281\n",
      "0.6292134831460674\n",
      "0.6404494382022472\n",
      "0.6292134831460674\n",
      "0.6067415730337079\n",
      "0.6404494382022472\n",
      "0.5842696629213483\n",
      "0.5955056179775281\n",
      "0.6741573033707865\n",
      "0.5617977528089888\n",
      "0.6067415730337079\n",
      "0.6067415730337079\n",
      "0.6179775280898876\n",
      "0.6179775280898876\n",
      "0.5955056179775281\n",
      "0.6292134831460674\n",
      "0.6179775280898876\n",
      "0.6067415730337079\n",
      "0.6179775280898876\n",
      "0.5617977528089888\n",
      "0.6629213483146067\n",
      "0.5393258426966292\n",
      "0.5955056179775281\n",
      "0.5842696629213483\n",
      "0.6404494382022472\n",
      "0.5393258426966292\n",
      "0.5955056179775281\n",
      "0.6292134831460674\n",
      "0.6067415730337079\n",
      "---\n",
      "0.6049438202247192\n",
      "0.04078264753986756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def rmse(a, b):\n",
    "    return np.mean((a-b)**2, axis=1)**0.5\n",
    "\n",
    "basis_type = 0\n",
    "idcs = np.arange(x.shape[0]) \n",
    "# idcs = np.where(y != 2)[0]\n",
    "xx = bases[basis_type].transform(x[idcs])\n",
    "yy = y[idcs]\n",
    "yy = yy != 0\n",
    "yy = yy.astype('int')\n",
    "\n",
    "accs = []\n",
    "\n",
    "for _ in range(50):\n",
    "    # Select balanced set\n",
    "    a, b = np.sum(yy == 0), np.sum(yy == 1)\n",
    "    num = min(a,b)\n",
    "    g1x, g2x = xx[yy == 0], xx[yy == 1]\n",
    "    g1idcs = np.random.permutation(g1x.shape[0])[0:num]\n",
    "    g2idcs = np.random.permutation(g2x.shape[0])[0:num]\n",
    "    xxx = np.concatenate([g1x[g1idcs], g2x[g2idcs]])\n",
    "    yyy = np.concatenate([np.zeros(num), np.ones(num)])\n",
    "    \n",
    "    xtr, xt, ytr, yt = train_test_split(xxx, yyy, stratify=yyy, train_size=0.8)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=1000).fit(xtr, ytr)\n",
    "    yhat = lr.predict(xt)\n",
    "    acc = np.mean(yhat == yt)\n",
    "    print(acc)\n",
    "    \n",
    "    accs.append(acc)\n",
    "    \n",
    "print('---')\n",
    "print(np.mean(accs))\n",
    "print(np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01cb3c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "0.8214285714285714\n",
      "0.5357142857142857\n",
      "0.7142857142857143\n",
      "0.7857142857142857\n",
      "0.6071428571428571\n",
      "0.6785714285714286\n",
      "0.6428571428571429\n",
      "0.75\n",
      "0.75\n",
      "0.6785714285714286\n",
      "0.7857142857142857\n",
      "0.6428571428571429\n",
      "0.7857142857142857\n",
      "0.75\n",
      "0.75\n",
      "0.6785714285714286\n",
      "0.6428571428571429\n",
      "0.6428571428571429\n",
      "0.75\n",
      "---\n",
      "0.7053571428571428\n",
      "0.07041694340403697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idcs = np.arange(x.shape[0]) \n",
    "# idcs = np.where(ym != 2)[0]\n",
    "xx = x[idcs]\n",
    "yy = ym[idcs]\n",
    "# xx = xm\n",
    "# yy = ym\n",
    "yy = yy != 0\n",
    "yy = yy.astype('int')\n",
    "\n",
    "accs = []\n",
    "\n",
    "for _ in range(20):\n",
    "    # Select balanced set\n",
    "    a, b = np.sum(yy == 0), np.sum(yy == 1)\n",
    "    num = 69 #min(a,b)\n",
    "    g1x, g2x = xx[yy == 0], xx[yy == 1]\n",
    "    g1idcs = np.random.permutation(g1x.shape[0])[0:num]\n",
    "    g2idcs = np.random.permutation(g2x.shape[0])[0:num]\n",
    "    xxx = np.concatenate([g1x[g1idcs], g2x[g2idcs]])\n",
    "    yyy = np.concatenate([np.zeros(num), np.ones(num)])\n",
    "    \n",
    "    xtr, xt, ytr, yt = train_test_split(xxx, yyy, stratify=yyy, train_size=0.8)\n",
    "\n",
    "    lr = LogisticRegression(C=1000, max_iter=1000).fit(xtr, ytr)\n",
    "    yhat = lr.predict(xt)\n",
    "    acc = np.mean(yhat == yt)\n",
    "    print(acc)\n",
    "    \n",
    "    accs.append(acc)\n",
    "    \n",
    "print('---')\n",
    "print(np.mean(accs))\n",
    "print(np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43bfafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "demo['bp_subtype'] = dict()\n",
    "\n",
    "i = 0\n",
    "for sub in subs:\n",
    "    if demo['DXGROUP_2'][sub] not in ['BPP', 'NC']:\n",
    "        continue\n",
    "    if ym[i] == 0 and demo['DXGROUP_2'][sub] != 'NC':\n",
    "        print('Bad')\n",
    "    if ym[i] in [1,2] and demo['DXGROUP_2'][sub] == 'NC':\n",
    "        print('Bad')\n",
    "    if ym[i] in [1,2]:\n",
    "        demo['bp_subtype'][sub] = ym[i]\n",
    "    i += 1\n",
    "    \n",
    "print('Complete')\n",
    "print(len(demo['bp_subtype']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c3cb138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(demo, open(demoname, 'wb'))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a951b1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45714285714285713"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y[y != 0] != ym[ym != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "basis_type = 0\n",
    "\n",
    "class Basis(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Basis, self).__init__()\n",
    "        self.A = nn.Parameter(torch.randn(dim,264,2).float().cuda())\n",
    "        \n",
    "    def compute(self, dim=0):\n",
    "        A = self.A[dim]\n",
    "        A = A@A.T\n",
    "        A = A/torch.linalg.norm(A)\n",
    "        a,b = torch.triu_indices(264,264,offset=1)\n",
    "        return A[a,b]\n",
    "    \n",
    "    def to_img(self, dim=0):\n",
    "        A = self.A[dim]\n",
    "        A = A@A.T\n",
    "        A = A/torch.linalg.norm(A)\n",
    "        return A.detach().cpu().numpy()\n",
    "    \n",
    "    def scramble(self, dim):\n",
    "        with torch.no_grad():\n",
    "            self.A[dim] *= 0\n",
    "            self.A[dim] += torch.randn(264,2).float().cuda()\n",
    "    \n",
    "# xtr, xt, ytr, yt = train_test_split(x, y, stratify=y, train_size=0.8)\n",
    "\n",
    "# xtr = torch.from_numpy(xtr).float().cuda()\n",
    "# xt = torch.from_numpy(xt).float().cuda()\n",
    "# ytr = torch.from_numpy(ytr).float().cuda()\n",
    "# yt = torch.from_numpy(yt).float().cuda()\n",
    "\n",
    "xtr = torch.from_numpy(x).float().cuda()\n",
    "\n",
    "# mu = torch.mean(ytr)\n",
    "# ytr = ytr-mu\n",
    "# yt = yt-mu\n",
    "    \n",
    "w = nn.Parameter(torch.randn(1,xtr.shape[0]).float().cuda())\n",
    "u = nn.Parameter(torch.randn(1).float().cuda())\n",
    "    \n",
    "basis = Basis(3)\n",
    "optim = torch.optim.Adam(basis.parameters(), lr=1e-1, weight_decay=0)\n",
    "\n",
    "nepochs = 200\n",
    "pperiod = 10\n",
    "eye = torch.eye(1).float().cuda()\n",
    "\n",
    "def rmse(a,b):\n",
    "    return torch.mean((a-b)**2)**0.5\n",
    "\n",
    "for n in range(basis.A.shape[0]):\n",
    "    tgt = xtr\n",
    "    cur = None\n",
    "    print(f'Cur residual')\n",
    "    with torch.no_grad():\n",
    "        for m in range(n):\n",
    "            A = basis.compute(m)\n",
    "            A = A.unsqueeze(1).detach()\n",
    "            w,_,_,_ = torch.linalg.lstsq(A.T@A+1e-3*eye, A.T@tgt.T)\n",
    "            xhat = (A@w).T\n",
    "            tgt = tgt - xhat\n",
    "            cur = cur + xhat if cur is not None else xhat\n",
    "            print(float(rmse(cur, xtr)))\n",
    "        print(f'Fitting {n}')\n",
    "    if n > 0:\n",
    "        start_loss = float(rmse(cur, xtr))\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        A = basis.compute(n)\n",
    "        A = A.unsqueeze(1)\n",
    "        w,_,_,_ = torch.linalg.lstsq(A.T@A+1e-3*eye, A.T@tgt.T)\n",
    "        xhat = (A@w).T\n",
    "        rloss = rmse(tgt, xhat)\n",
    "        rloss.backward()\n",
    "        optim.step()\n",
    "        if epoch == 0 and n == 0:\n",
    "            start_loss = float(rloss)\n",
    "        if epoch % 50 == 49 and float(rloss)/start_loss > 0.9995:\n",
    "            print('Scrambling')\n",
    "            basis.scramble(n)\n",
    "        if epoch % pperiod == 0 or epoch == nepochs:\n",
    "            print(f'{epoch} {float(rloss)}')\n",
    "        \n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
