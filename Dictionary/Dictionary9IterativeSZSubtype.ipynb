{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ace7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from natsort import natsorted\n",
    "\n",
    "basedir = '../../ImageNomer/data/anton/cohorts/BSNIP'\n",
    "demoname = f'{basedir}/demographics.pkl'\n",
    "\n",
    "with open(demoname, 'rb') as f:\n",
    "    demo = pickle.load(f)\n",
    "    \n",
    "subs = natsorted(list(demo['Age_cal'].keys()))\n",
    "print(len(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c2031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 34716)\n",
      "(441,)\n",
      "[2 1 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# y=0 NC y=1 SZ1 (130) y=2 SZ2 (69)\n",
    "\n",
    "task = 'unk'\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for sub in subs:\n",
    "    if demo['DXGROUP_1'][sub] not in ['SZP', 'NC']:\n",
    "        continue\n",
    "    p = np.load(f'{basedir}/fc/{sub}_task-{task}_fc.npy')\n",
    "    x.append(p)\n",
    "    if demo['DXGROUP_1'][sub] == 'SZP':\n",
    "        if demo['sz_subtype'][sub] == '1':\n",
    "            y.append(1)\n",
    "        elif demo['sz_subtype'][sub] == '2':\n",
    "            y.append(2)\n",
    "        else:\n",
    "            print('Bad sz_subtype')\n",
    "            raise 'Bad'\n",
    "    else:\n",
    "        y.append(0)\n",
    "    \n",
    "x = np.stack(x)\n",
    "y = np.array(y).astype('int')\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "077986fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "bases = dict()\n",
    "print(bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "147741d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0.4288267852657342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "basis_type = 0\n",
    "\n",
    "pca = PCA(n_components=20).fit(x[np.where(y == basis_type)[0]])\n",
    "print(len(pca.components_))\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "\n",
    "bases[basis_type] = pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "941257ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6933333333333334\n",
      "0.7733333333333333\n",
      "0.7333333333333333\n",
      "0.72\n",
      "0.7733333333333333\n",
      "0.7466666666666667\n",
      "0.7066666666666667\n",
      "0.7866666666666666\n",
      "0.7733333333333333\n",
      "0.76\n",
      "0.7866666666666666\n",
      "0.7733333333333333\n",
      "0.7733333333333333\n",
      "0.7466666666666667\n",
      "0.72\n",
      "0.6666666666666666\n",
      "0.72\n",
      "0.72\n",
      "0.7333333333333333\n",
      "0.84\n",
      "---\n",
      "0.7473333333333334\n",
      "0.03852272056851644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "basis_type = 2\n",
    "xx = bases[basis_type].transform(x[np.where(y != 2)[0]])\n",
    "yy = y[np.where(y != 2)[0]]\n",
    "yy = yy.astype('int')\n",
    "\n",
    "accs = []\n",
    "\n",
    "for _ in range(20):\n",
    "    xtr, xt, ytr, yt = train_test_split(xx, yy, stratify=yy, train_size=0.8)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=1000).fit(xtr, ytr)\n",
    "    yhat = lr.predict(xt)\n",
    "    acc = np.mean(yhat == yt)\n",
    "    print(acc)\n",
    "    \n",
    "    accs.append(acc)\n",
    "    \n",
    "print('---')\n",
    "print(np.mean(accs))\n",
    "print(np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "basis_type = 0\n",
    "\n",
    "class Basis(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Basis, self).__init__()\n",
    "        self.A = nn.Parameter(torch.randn(dim,264,2).float().cuda())\n",
    "        \n",
    "    def compute(self, dim=0):\n",
    "        A = self.A[dim]\n",
    "        A = A@A.T\n",
    "        A = A/torch.linalg.norm(A)\n",
    "        a,b = torch.triu_indices(264,264,offset=1)\n",
    "        return A[a,b]\n",
    "    \n",
    "    def to_img(self, dim=0):\n",
    "        A = self.A[dim]\n",
    "        A = A@A.T\n",
    "        A = A/torch.linalg.norm(A)\n",
    "        return A.detach().cpu().numpy()\n",
    "    \n",
    "    def scramble(self, dim):\n",
    "        with torch.no_grad():\n",
    "            self.A[dim] *= 0\n",
    "            self.A[dim] += torch.randn(264,2).float().cuda()\n",
    "    \n",
    "# xtr, xt, ytr, yt = train_test_split(x, y, stratify=y, train_size=0.8)\n",
    "\n",
    "# xtr = torch.from_numpy(xtr).float().cuda()\n",
    "# xt = torch.from_numpy(xt).float().cuda()\n",
    "# ytr = torch.from_numpy(ytr).float().cuda()\n",
    "# yt = torch.from_numpy(yt).float().cuda()\n",
    "\n",
    "xtr = torch.from_numpy(x).float().cuda()\n",
    "\n",
    "# mu = torch.mean(ytr)\n",
    "# ytr = ytr-mu\n",
    "# yt = yt-mu\n",
    "    \n",
    "w = nn.Parameter(torch.randn(1,xtr.shape[0]).float().cuda())\n",
    "u = nn.Parameter(torch.randn(1).float().cuda())\n",
    "    \n",
    "basis = Basis(3)\n",
    "optim = torch.optim.Adam(basis.parameters(), lr=1e-1, weight_decay=0)\n",
    "\n",
    "nepochs = 200\n",
    "pperiod = 10\n",
    "eye = torch.eye(1).float().cuda()\n",
    "\n",
    "def rmse(a,b):\n",
    "    return torch.mean((a-b)**2)**0.5\n",
    "\n",
    "for n in range(basis.A.shape[0]):\n",
    "    tgt = xtr\n",
    "    cur = None\n",
    "    print(f'Cur residual')\n",
    "    with torch.no_grad():\n",
    "        for m in range(n):\n",
    "            A = basis.compute(m)\n",
    "            A = A.unsqueeze(1).detach()\n",
    "            w,_,_,_ = torch.linalg.lstsq(A.T@A+1e-3*eye, A.T@tgt.T)\n",
    "            xhat = (A@w).T\n",
    "            tgt = tgt - xhat\n",
    "            cur = cur + xhat if cur is not None else xhat\n",
    "            print(float(rmse(cur, xtr)))\n",
    "        print(f'Fitting {n}')\n",
    "    if n > 0:\n",
    "        start_loss = float(rmse(cur, xtr))\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        A = basis.compute(n)\n",
    "        A = A.unsqueeze(1)\n",
    "        w,_,_,_ = torch.linalg.lstsq(A.T@A+1e-3*eye, A.T@tgt.T)\n",
    "        xhat = (A@w).T\n",
    "        rloss = rmse(tgt, xhat)\n",
    "        rloss.backward()\n",
    "        optim.step()\n",
    "        if epoch == 0 and n == 0:\n",
    "            start_loss = float(rloss)\n",
    "        if epoch % 50 == 49 and float(rloss)/start_loss > 0.9995:\n",
    "            print('Scrambling')\n",
    "            basis.scramble(n)\n",
    "        if epoch % pperiod == 0 or epoch == nepochs:\n",
    "            print(f'{epoch} {float(rloss)}')\n",
    "        \n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
