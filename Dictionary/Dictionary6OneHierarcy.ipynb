{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8afeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from natsort import natsorted\n",
    "\n",
    "basedir = '../../ImageNomer/data/anton/cohorts/BSNIP'\n",
    "demoname = f'{basedir}/demographics.pkl'\n",
    "\n",
    "with open(demoname, 'rb') as f:\n",
    "    demo = pickle.load(f)\n",
    "    \n",
    "subs = natsorted(list(demo['Age_cal'].keys()))\n",
    "print(len(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79da8470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 34716)\n",
      "(199,)\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "task = 'unk'\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for sub in subs:\n",
    "    if demo['DXGROUP_1'][sub] not in ['SZP']:\n",
    "        continue\n",
    "    p = np.load(f'{basedir}/fc/{sub}_task-{task}_fc.npy')\n",
    "    x.append(p)\n",
    "    y.append(demo['DXGROUP_1'][sub] == 'SZP')\n",
    "#     y.append(int(demo['Age_cal'][sub]))\n",
    "#     y.append(demo['sex'][sub] == 'M')\n",
    "    \n",
    "x = np.stack(x)\n",
    "y = np.array(y).astype('int')\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "daa5b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.30041778087615967 0.06931471079587936 5.2317696827230975e-05\n",
      "100 0.27650895714759827 0.0016299727139994502 0.00016258323739748448\n",
      "200 0.2583323121070862 0.000595811870880425 1.2642681213037577e-05\n",
      "300 0.24686454236507416 0.0003258798096794635 2.4507649868610315e-05\n",
      "400 0.2390260100364685 0.0002105140156345442 0.00010135425691260025\n",
      "500 0.23380713164806366 0.0001492653100285679 9.912601854011882e-06\n",
      "600 0.2303261160850525 0.00011229042866034433 5.297432835504878e-06\n",
      "700 0.22801250219345093 8.801214426057413e-05 6.346812733681872e-05\n",
      "800 0.22647391259670258 7.108746649464592e-05 2.5211867978214286e-05\n",
      "900 0.22545738518238068 5.873909321962856e-05 6.708497039653594e-06\n",
      "Complete\n",
      "0 0.30041778087615967 0.06931471079587936 0.0002032474149018526\n",
      "100 0.2733308672904968 0.001649963902309537 3.424021997489035e-05\n",
      "200 0.25229761004447937 0.0006095599965192378 9.37818822421832e-06\n",
      "300 0.23649589717388153 0.0003344826400279999 1.8237487893202342e-05\n",
      "400 0.2249564230442047 0.00021605254733003676 4.886086571787018e-06\n",
      "500 0.21680280566215515 0.00015291679301299155 2.6210750547761563e-06\n",
      "600 0.21119189262390137 0.00011472883488750085 4.071145667694509e-06\n",
      "700 0.2074064165353775 8.965146116679534e-05 3.0217481707950355e-06\n",
      "800 0.2048887014389038 7.218692189780995e-05 7.393508099085011e-07\n",
      "900 0.2032313197851181 5.9474412410054356e-05 1.3458697139867581e-05\n",
      "Complete\n",
      "0 0.30041778087615967 0.06931471079587936 0.0003422474837861955\n",
      "100 0.30037960410118103 0.0016498810146003962 3.223679959774017e-05\n",
      "200 0.3002093732357025 0.0006094752461649477 3.8235280953813344e-05\n",
      "300 0.2999567985534668 0.0003344284777995199 3.3570963751117233e-06\n",
      "400 0.2998477816581726 0.0002160217409254983 8.023096597753465e-06\n",
      "500 0.299770712852478 0.0001528872235212475 1.217710860146326e-06\n",
      "600 0.29971596598625183 0.00011470793833723292 1.530681743133755e-06\n",
      "700 0.2996574640274048 8.963210711954162e-05 2.5291083716183493e-07\n",
      "800 0.29961591958999634 7.21731994417496e-05 1.7267274188270676e-06\n",
      "900 0.29957520961761475 5.945974407950416e-05 4.849006927543087e-06\n",
      "Complete\n",
      "0 0.30041778087615967 0.06931471079587936 0.0007112856837920845\n",
      "100 0.2736459970474243 0.001649958430789411 2.6956044166581705e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39mbasis\u001b[38;5;241m.\u001b[39mget_mask_loss() \n\u001b[1;32m     80\u001b[0m sloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\u001b[38;5;241m*\u001b[39mbasis\u001b[38;5;241m.\u001b[39mget_similarity_loss()\n\u001b[0;32m---> 81\u001b[0m \u001b[43m(\u001b[49m\u001b[43mmloss\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mrloss\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m pperiod \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m nepochs:\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Basis(nn.Module):\n",
    "    def __init__(self, nsub):\n",
    "        super(Basis, self).__init__()\n",
    "        self.A = nn.Parameter(torch.randn(3,264,2).float().cuda()) \n",
    "        self.m = nn.Parameter(torch.zeros(nsub).float().cuda())\n",
    "        self.w = nn.Parameter(torch.zeros(3,nsub).float().cuda())\n",
    "        self.s = nn.Sigmoid()\n",
    "        \n",
    "    def get_mask_loss(self):\n",
    "        m = self.s(self.m)\n",
    "        loss = -torch.mean(m*torch.log(m)+(1-m)*torch.log(1-m))\n",
    "        return loss\n",
    "    \n",
    "    def get_similarity_loss(self):\n",
    "        A1 = self.compute(1)\n",
    "        A2 = self.compute(2)\n",
    "        return torch.abs(torch.sum(A1*A2))\n",
    "        \n",
    "    def compute(self, group):\n",
    "        A = self.A[group]\n",
    "        A = A@A.T\n",
    "        A = A/torch.linalg.norm(A)\n",
    "        a,b = torch.triu_indices(264,264,offset=1)\n",
    "        return A[a,b]\n",
    "    \n",
    "    def recon(self, apply_mask):\n",
    "        m = self.s(self.m)\n",
    "        w = self.w\n",
    "        A0 = self.compute(0)\n",
    "        A1 = self.compute(1)\n",
    "        A2 = self.compute(2)\n",
    "        x = [\n",
    "            A0.unsqueeze(0)*w[0].unsqueeze(1),\n",
    "            A1.unsqueeze(0)*w[1].unsqueeze(1)*m.unsqueeze(1),\n",
    "            A2.unsqueeze(0)*w[2].unsqueeze(1)*(1-m).unsqueeze(1)\n",
    "        ]\n",
    "        return sum(x)\n",
    "    \n",
    "# xtr, xt, ytr, yt = train_test_split(x, y, stratify=y, train_size=0.8)\n",
    "\n",
    "# xtr = x[np.where(y == 1)[0]]\n",
    "# print(xtr.shape)\n",
    "\n",
    "res = []\n",
    "\n",
    "for _ in range(20):\n",
    "    xtr = x\n",
    "\n",
    "    xtr = torch.from_numpy(xtr).float().cuda()\n",
    "    # xt = torch.from_numpy(xt).float().cuda()\n",
    "    # ytr = torch.from_numpy(ytr).float().cuda()\n",
    "    # yt = torch.from_numpy(yt).float().cuda()\n",
    "\n",
    "    # mu = torch.mean(ytr)\n",
    "    # ytr = ytr-mu\n",
    "    # yt = yt-mu\n",
    "\n",
    "    basis = Basis(xtr.shape[0])\n",
    "    optim = torch.optim.Adam(basis.parameters(), lr=1e-1, weight_decay=0)\n",
    "\n",
    "    nepochs = 1000\n",
    "    pperiod = 100\n",
    "\n",
    "    def rmse(a,b):\n",
    "        return torch.mean((a-b)**2)**0.5\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        optim.zero_grad()\n",
    "        xhat = basis.recon(epoch > 100)\n",
    "        rloss = rmse(xtr, xhat)\n",
    "        mloss = 0.1*basis.get_mask_loss() \n",
    "        sloss = 0.1*basis.get_similarity_loss()\n",
    "        (mloss+rloss+sloss).backward()\n",
    "        optim.step()\n",
    "        if epoch % pperiod == 0 or epoch == nepochs:\n",
    "            print(f'{epoch} {float(rloss)} {float(mloss)} {float(sloss)}')\n",
    "\n",
    "    print('Complete')\n",
    "\n",
    "    res.append(basis.s(basis.m).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b7d3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9205755e-05, 4.6003031e-05, 9.9995482e-01, 5.0445648e-05,\n",
       "       9.9995601e-01, 9.9995506e-01, 9.9995601e-01, 9.9995852e-01,\n",
       "       4.7505637e-05, 9.9995518e-01, 9.9995494e-01, 9.9995625e-01,\n",
       "       9.9995804e-01, 9.9995470e-01, 9.9995852e-01, 9.9995804e-01,\n",
       "       9.9995697e-01, 9.9995530e-01, 9.9995673e-01, 9.9995673e-01,\n",
       "       4.7431400e-05, 9.9996006e-01, 9.9995589e-01, 4.6634577e-05,\n",
       "       9.9995494e-01, 4.7426649e-05, 9.9995506e-01, 9.9995613e-01,\n",
       "       9.9995470e-01, 9.9995697e-01, 9.9995553e-01, 9.9995530e-01,\n",
       "       9.9995482e-01, 9.9995840e-01, 9.9995911e-01, 9.9995577e-01,\n",
       "       4.6670571e-05, 9.9995518e-01, 9.9995470e-01, 9.9995530e-01,\n",
       "       9.9995458e-01, 9.9996114e-01, 9.9995685e-01, 4.6979032e-05,\n",
       "       9.9995530e-01, 9.9995863e-01, 9.9996328e-01, 9.9995482e-01,\n",
       "       9.9995506e-01, 4.7836224e-05, 4.8340848e-05, 9.9995530e-01,\n",
       "       9.9995875e-01, 4.8886304e-05, 9.9995589e-01, 4.7244779e-05,\n",
       "       9.9995863e-01, 4.6509911e-05, 9.9995530e-01, 4.6765908e-05,\n",
       "       4.7392154e-05, 9.9995553e-01, 9.9995470e-01, 9.9995661e-01,\n",
       "       4.8438676e-05, 9.9995577e-01, 9.9995613e-01, 9.9995601e-01,\n",
       "       9.9995697e-01, 4.7525984e-05, 5.0214305e-05, 9.9995506e-01,\n",
       "       9.9995470e-01, 9.9995565e-01, 9.9995494e-01, 9.9995494e-01,\n",
       "       5.1018746e-05, 9.9996090e-01, 4.7528159e-05, 9.9995506e-01,\n",
       "       9.9995506e-01, 4.8073663e-05, 9.9995565e-01, 9.9995482e-01,\n",
       "       4.6574671e-05, 9.9996495e-01, 9.9995470e-01, 4.6952879e-05,\n",
       "       9.9995506e-01, 9.9996114e-01, 9.9995494e-01, 9.9995482e-01,\n",
       "       9.9995494e-01, 9.9995613e-01, 9.9995530e-01, 9.9995518e-01,\n",
       "       9.9995470e-01, 4.7707483e-05, 9.9995840e-01, 4.9313003e-05,\n",
       "       9.9995470e-01, 4.9988412e-05, 4.7319580e-05, 9.9995744e-01,\n",
       "       4.8505197e-05, 9.9996090e-01, 9.9995470e-01, 5.0800278e-05,\n",
       "       9.9995613e-01, 4.9032442e-05, 9.9995744e-01, 9.9995494e-01,\n",
       "       9.9995697e-01, 9.9995685e-01, 9.9995792e-01, 9.9995482e-01,\n",
       "       9.9995553e-01, 9.9995506e-01, 9.9995542e-01, 4.7958270e-05,\n",
       "       9.9995553e-01, 9.9996126e-01, 5.0427130e-05, 9.9995494e-01,\n",
       "       4.7191781e-05, 9.9995673e-01, 4.9841470e-05, 9.9995637e-01,\n",
       "       4.7882964e-05, 9.9996006e-01, 9.9995518e-01, 4.7057369e-05,\n",
       "       4.7873968e-05, 9.9995553e-01, 9.9995482e-01, 9.9995577e-01,\n",
       "       9.9995649e-01, 4.7977806e-05, 4.7976162e-05, 9.9995708e-01,\n",
       "       9.9995708e-01, 4.7577545e-05, 5.2697233e-05, 9.9995482e-01,\n",
       "       5.0482464e-05, 9.9995661e-01, 9.9996233e-01, 9.9995744e-01,\n",
       "       9.9995649e-01, 9.9995577e-01, 4.7947389e-05, 9.9995494e-01,\n",
       "       4.6369922e-05, 9.9995494e-01, 9.9995697e-01, 4.7454247e-05,\n",
       "       9.9995494e-01, 9.9995506e-01, 9.9995577e-01, 9.9995530e-01,\n",
       "       4.8110764e-05, 9.9995589e-01, 4.6423815e-05, 9.9995482e-01,\n",
       "       9.9995470e-01, 9.9995542e-01, 9.9995697e-01, 9.9995553e-01,\n",
       "       9.9995506e-01, 4.9248803e-05, 9.9995911e-01, 4.7372454e-05,\n",
       "       9.9995470e-01, 9.9995828e-01, 4.8377973e-05, 9.9995589e-01,\n",
       "       9.9995470e-01, 9.9995565e-01, 9.9995553e-01, 9.9995482e-01,\n",
       "       9.9996126e-01, 9.9995685e-01, 9.9995816e-01, 9.9995863e-01,\n",
       "       9.9995542e-01, 9.9995470e-01, 4.6326473e-05, 9.9995565e-01,\n",
       "       9.9995494e-01, 9.9996042e-01, 4.6424389e-05, 9.9995494e-01,\n",
       "       4.6402834e-05, 4.9815571e-05, 9.9995470e-01, 9.9995577e-01,\n",
       "       9.9995565e-01, 9.9995530e-01, 9.9995494e-01], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaaf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
