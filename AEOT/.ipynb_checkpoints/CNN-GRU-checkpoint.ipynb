{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf359d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n",
      "155\n",
      "{'meta': {'AgeInMonths': 110, 'Gender': 'M', 'Ethnicity': 'AFRICAN', 'AgeGroupID': 1, 'AgeGroupEdge1': 103, 'AgeGroupEdge2': 144}, 'rest': '765', 'nback': '790', 'emoid': '554', 'ID': 608665596582}\n"
     ]
    }
   ],
   "source": [
    "# Bad subjects\n",
    "# Bad IDs: 605515760919, 601983541597\n",
    "\n",
    "# Load split\n",
    "\n",
    "import pickle\n",
    "\n",
    "badIDs = [605515760919, 601983541597]\n",
    "\n",
    "with open('../../Splits/RegressionAllTasks/split3.bin', 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    train = []\n",
    "    trainDirty = d['train']\n",
    "    test = []\n",
    "    testDirty = d['test']\n",
    "    \n",
    "    # Remove bad subjects\n",
    "    for subj in trainDirty:\n",
    "        if subj['ID'] not in badIDs:\n",
    "            train.append(subj)\n",
    "            \n",
    "    for subj in testDirty:\n",
    "        if subj['ID'] not in badIDs:\n",
    "            test.append(subj)\n",
    "    \n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9ce92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "def loadTimeseries(_id, _dir):\n",
    "    ts = None\n",
    "    with open('{:s}/{:d}.bin'.format(_dir, _id), 'rb') as f:\n",
    "        ts = pickle.load(f)\n",
    "    return ts\n",
    "\n",
    "train_rest_ts = [loadTimeseries(int(subj['emoid']), '../../emoid_fmri_power264/timeseries') for subj in train]\n",
    "# train_nback_ts = [loadTimeseries(int(subj['nback']), '../../nback_fmri_power264/timeseries') for subj in train]\n",
    "# train_emoid_ts = [loadTimeseries(int(subj['emoid']), '../../emoid_fmri_power264/timeseries') for subj in train]\n",
    "\n",
    "test_rest_ts = [loadTimeseries(int(subj['emoid']), '../../emoid_fmri_power264/timeseries') for subj in test]\n",
    "# test_nback_ts = [loadTimeseries(int(subj['nback']), '../../nback_fmri_power264/timeseries') for subj in test]\n",
    "# test_emoid_ts = [loadTimeseries(int(subj['emoid']), '../../emoid_fmri_power264/timeseries') for subj in test]\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884a0b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalizeSubjects(subjects):\n",
    "    for i in range(len(subjects)):\n",
    "        subj = subjects[i]\n",
    "        subj -= np.mean(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        subj /= np.std(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        if np.sum(np.isnan(subj)) > 0:\n",
    "            print(i)\n",
    "        if np.sum(np.isinf(subj)) > 0:\n",
    "            print(i)\n",
    "\n",
    "normalizeSubjects(train_rest_ts)\n",
    "# normalizeSubjects(train_nback_ts)\n",
    "# normalizeSubjects(train_emoid_ts)\n",
    "\n",
    "normalizeSubjects(test_rest_ts)\n",
    "# normalizeSubjects(test_nback_ts)\n",
    "# normalizeSubjects(test_emoid_ts)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e2d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Create labels (ages)\n",
    "\n",
    "y_train = np.vstack([subj['meta']['AgeInMonths'] for subj in train])\n",
    "y_test = np.vstack([subj['meta']['AgeInMonths'] for subj in test])\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dda299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([210, 264])\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "train_rest_ts_torch = [torch.from_numpy(subj.T).float().cuda() for subj in train_rest_ts]\n",
    "test_rest_ts_torch = [torch.from_numpy(subj.T).float().cuda() for subj in test_rest_ts]\n",
    "\n",
    "# print(train_rest_ts_torch[0].device)\n",
    "print(train_rest_ts_torch[0].shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1152f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 4294967296.000000 Reserved: 1451229184.000000 Allocated: 290975744.000000 Free: 1160253440.000000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0) \n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "print('Total: {:f} Reserved: {:f} Allocated: {:f} Free: {:f}'.format(t,r,a,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f23fc4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "nt = train_rest_ts_torch[0].shape[0]\n",
    "nroi = train_rest_ts_torch[0].shape[1]\n",
    "nBatch = 10\n",
    "nc = 8\n",
    "sz1 = math.floor((nt-4-5)/2+1)\n",
    "sz2 = math.floor((nt-8-5)/2+1)\n",
    "\n",
    "class CNNGRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNGRU, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,nc,(5,1)).cuda() # Output size (nt-4)x1\n",
    "#         self.conv2 = nn.Conv2d(1,nc,(9,nroi)).cuda() # Output size (nt-8)x1\n",
    "#         self.mp1 = nn.MaxPool2d((5,1),(2,1)) # Output size (A-10)/5+1)x1 \n",
    "        self.gru1 = nn.GRU(input_size=nroi*nc, hidden_size=20, batch_first=True).cuda()\n",
    "        self.fc1 = nn.Linear(20,100).cuda()\n",
    "        self.fc2 = nn.Linear(100,1).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        nb = x.shape[0]\n",
    "        x = x.unsqueeze(1)\n",
    "#         a = self.mp1(F.relu(self.conv1(x)))\n",
    "#         b = self.mp1(F.relu(self.conv2(x)))\n",
    "#         x = torch.cat((a,b),dim=2)\n",
    "#         x = x.squeeze(3)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = x.reshape([nb,nt-4,nroi*nc])\n",
    "#         x = x.permute(0,2,1)\n",
    "        _,x = self.gru1(x)\n",
    "        x = x.permute(1,0,2)\n",
    "        x = x.reshape([nb,20])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "cnngru = CNNGRU()\n",
    "optimcnn = torch.optim.Adam(cnngru.parameters(), lr=1e-3)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5332890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=357023.250000\n",
      "epoch 200 loss=245609.765625\n",
      "epoch 400 loss=33839.601562\n",
      "epoch 600 loss=15029.769531\n",
      "epoch 800 loss=11990.166016\n",
      "epoch 1000 loss=6368.849609\n",
      "epoch 1200 loss=2215.676758\n",
      "epoch 1400 loss=786.935852\n",
      "epoch 1600 loss=314.139252\n",
      "epoch 1800 loss=214.011948\n",
      "epoch 1999 loss=145.032349\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "# Train CNN\n",
    "\n",
    "import random\n",
    "\n",
    "N = len(train_rest_ts_torch)\n",
    "running = 0\n",
    "nEpoch = 2000\n",
    "pPeriod = 200\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "    batch = []\n",
    "    truth = torch.zeros(nBatch).cuda()\n",
    "    for i in range(nBatch):\n",
    "        idx = random.randint(0,N-1)\n",
    "        subj = train_rest_ts_torch[idx]\n",
    "        batch.append(subj)\n",
    "        truth[i] = y_train[idx,0]\n",
    "    batch = torch.stack(batch,dim=0)\n",
    "    optimcnn.zero_grad()\n",
    "    pred = cnngru(batch).flatten()\n",
    "    loss = torch.sum((truth-pred)**2)\n",
    "    loss.backward()\n",
    "    running += loss.cpu()\n",
    "    optimcnn.step()\n",
    "    if epoch % pPeriod == 0 or epoch == nEpoch-1:\n",
    "        if epoch != 0:\n",
    "            running /= pPeriod\n",
    "        print('epoch {:d} loss={:f}'.format(epoch, running))\n",
    "        running = 0\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e208092",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 258.00 MiB (GPU 0; 4.00 GiB total capacity; 2.45 GiB already allocated; 128.19 MiB free; 2.78 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e205616b34e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0myPred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnngru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# yPred = Xtest@w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aorlichenko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-b58b479ccae7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#         x = torch.cat((a,b),dim=2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#         x = x.squeeze(3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnroi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aorlichenko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aorlichenko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aorlichenko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 258.00 MiB (GPU 0; 4.00 GiB total capacity; 2.45 GiB already allocated; 128.19 MiB free; 2.78 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = y_test.flatten()\n",
    "X = []\n",
    "\n",
    "for subj in test_rest_ts_torch:\n",
    "    X.append(subj)\n",
    "    \n",
    "X = torch.stack(X, dim=0)\n",
    "yPred = cnngru(X).flatten().cpu().detach().numpy()\n",
    "\n",
    "# yPred = Xtest@w\n",
    "\n",
    "idcs = np.argsort(y)\n",
    "yPred = yPred[idcs]\n",
    "y = y[idcs]\n",
    "\n",
    "corr = np.corrcoef(y, yPred)\n",
    "rmse = (np.sum((y-yPred)**2)/len(y))**0.5/12\n",
    "mae = np.sum(np.abs(y-yPred))/12/len(y)\n",
    "\n",
    "print(corr)\n",
    "print(rmse)\n",
    "print(mae)\n",
    "\n",
    "plt.plot(y, label='Truth')\n",
    "plt.plot(yPred, label='Prediction')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(y, yPred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252566b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
