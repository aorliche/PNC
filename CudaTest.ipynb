{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f35947c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = np.random.randn(10,10)\n",
    "plt.imshow(im)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629a0525",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m zeros \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:216\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    220\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "zeros = torch.randn(10,10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68c546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |     512 B  |     512 B  |     512 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |     512 B  |     512 B  |     512 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |     512 B  |     512 B  |     512 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |     512 B  |     512 B  |     512 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|       from large pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    2047 KB |    2047 KB |    2047 KB |       0 B  |\n",
      "|       from large pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|       from small pool |    2047 KB |    2047 KB |    2047 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767aef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA TITAN Xp', major=6, minor=1, total_memory=12196MB, multi_processor_count=30)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "555e083e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 2.  Target sizes: [2, 3, 4].  Tensor sizes: [2, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],[\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(B)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 2.  Target sizes: [2, 3, 4].  Tensor sizes: [2, 3]"
     ]
    }
   ],
   "source": [
    "B = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(B)\n",
    "print(B.expand(2,3,4))\n",
    "# print(B.expand(3,3))\n",
    "# print(B.expand(3,3,3))\n",
    "# C = B.expand(3,3,3).float()\n",
    "# print(C[0,0,2])\n",
    "# print(torch.nn.Softmax(dim=2)(C))\n",
    "# print(torch.sum(C,dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2571487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
