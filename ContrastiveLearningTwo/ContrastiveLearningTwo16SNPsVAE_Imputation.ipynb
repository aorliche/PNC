{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb80fd34-69fb-49df-a8c4-afd2b096ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "ours2orig = [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
    "28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 254, 41, 42, 43, 44, 45,\n",
    "46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
    "65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85,\n",
    "86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103,\n",
    "104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
    "119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 136, 138, 132,\n",
    "133, 134, 135, 220, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
    "153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
    "168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 185, 186,\n",
    "187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
    "202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
    "217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
    "233, 137, 234, 235, 236, 237, 238, 239, 240, 241, 250, 251, 255, 256, 257,\n",
    "258, 259, 260, 261, 262, 263, 242, 243, 244, 245, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
    "9, 10, 11, 83, 84, 131, 139, 140, 141, 181, 182, 183, 184, 246, 247, 248,\n",
    "249, 252, 253]\n",
    "\n",
    "def vec2mat(v):\n",
    "    a,b = np.triu_indices(264,1)\n",
    "    m = np.zeros((264,264))\n",
    "    m[a,b] = v\n",
    "    return m+m.T\n",
    "\n",
    "def remap(fc, roimap=ours2orig):\n",
    "    fc = fc[roimap,:]\n",
    "    fc = fc[:,roimap]\n",
    "    return fc\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf48325-5662-466e-be78-282bf533de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1155, 34716), (1155, 34716), (1155, 34716), (1155,), (1155,), (1155,)]\n"
     ]
    }
   ],
   "source": [
    "# Load FC\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "pncdir = '/home/anton/Documents/Tulane/Research/data-sav/anton/cohorts/PNC/'\n",
    "lowrankdir = '/home/anton/Documents/Tulane/Research/Work/ContrastiveLearning/PNC/Top10/'\n",
    "pncdemo = pickle.load(open(f'{pncdir}/demographics.pkl', 'rb'))\n",
    "no_snps_subs = pickle.load(open('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/fc_subs_no_snps.pkl', 'rb'))\n",
    "\n",
    "rest = []\n",
    "nback = []\n",
    "emoid = []\n",
    "restmat = []\n",
    "nbackmat = []\n",
    "emoidmat = []\n",
    "race = []\n",
    "sex = []\n",
    "age = []\n",
    "subids = []\n",
    "\n",
    "a,b = np.triu_indices(264,1)\n",
    "\n",
    "for sub in pncdemo['age_at_cnb']:\n",
    "    if sub in no_snps_subs:\n",
    "        continue\n",
    "    try:\n",
    "        ra = pncdemo['Race'][sub]\n",
    "        ag = pncdemo['age_at_cnb'][sub]\n",
    "        se = pncdemo['Sex'][sub]\n",
    "        if ra not in ['AA', 'EA']:\n",
    "            continue\n",
    "        ra = ra == 'AA'\n",
    "        se = se == 'M'\n",
    "        r = np.load(f'{pncdir}/fc/{sub}_task-rest_fc.npy')\n",
    "        n = np.load(f'{pncdir}/fc/{sub}_task-nback_fc.npy')\n",
    "        e = np.load(f'{pncdir}/fc/{sub}_task-emoid_fc.npy')\n",
    "        r = remap(vec2mat(r))\n",
    "        n = remap(vec2mat(n))\n",
    "        e = remap(vec2mat(e))\n",
    "        race.append(ra)\n",
    "        sex.append(se)\n",
    "        age.append(ag)\n",
    "        rest.append(r[a,b])\n",
    "        nback.append(n[a,b])\n",
    "        emoid.append(e[a,b])\n",
    "        subids.append(sub)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "rest = np.stack(rest)\n",
    "nback = np.stack(nback)\n",
    "emoid = np.stack(emoid)\n",
    "race = np.array(race).astype('int')\n",
    "sex = np.array(sex).astype('int')\n",
    "age = np.array(age)\n",
    "\n",
    "print([a.shape for a in [rest, nback, emoid, race, sex, age]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55384c16-f6d1-405e-89f0-cfd3ce47e4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 35621)\n"
     ]
    }
   ],
   "source": [
    "# Load big SNPs\n",
    "\n",
    "snps = []\n",
    "no_snps_subs = []\n",
    "\n",
    "snps_file = pickle.load(open('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/snps_all_subs_big.pkl', 'rb'))\n",
    "\n",
    "for sub in subids:\n",
    "    if sub not in snps_file:\n",
    "        print(sub)\n",
    "        # no_snps_subs.append(sub)\n",
    "    snps.append(snps_file[sub])\n",
    "\n",
    "snps = np.stack(snps)\n",
    "snps[np.isnan(snps)] = 0\n",
    "\n",
    "print(snps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecee3f79-ff6d-40a9-b186-0fc6fb88aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0005006632164482196 -8.185157212843205e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x = np.concatenate([snps == 0, snps == 1, snps == 2], axis=1)\n",
    "reg_sex = LogisticRegression(C=100).fit(x, sex)\n",
    "sex_w = torch.from_numpy(reg_sex.coef_[0]).float().cuda()\n",
    "sex_i = reg_sex.intercept_[0]\n",
    "\n",
    "reg_race = LogisticRegression(C=100).fit(x, race)\n",
    "race_w = torch.from_numpy(reg_race.coef_[0]).float().cuda()\n",
    "race_i = reg_race.intercept_[0]\n",
    "\n",
    "print(sex_i, race_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f29c42-157b-456c-a78b-865416fd9050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0996 496.8074 8.3837 0.9681 0.7192\n",
      "50 0.8227 237.7499 102.4761 4.6636 1.4635\n",
      "100 0.8055 172.5006 61.9317 0.2397 0.4492\n",
      "150 0.7881 139.64 55.0384 0.1591 2.1719\n",
      "200 0.7795 122.492 32.3756 0.0274 2.1036\n",
      "250 0.7746 116.4112 16.8059 0.0035 1.3108\n",
      "300 0.7674 111.8734 8.9569 0.0277 0.8102\n",
      "350 0.7612 109.2959 9.3614 0.0 0.3745\n",
      "400 0.7542 106.9593 9.2727 0.1211 0.0129\n",
      "450 0.7466 107.5152 5.865 0.0 1.5885\n",
      "500 0.738 108.4111 5.578 0.0 0.0002\n",
      "550 0.7277 109.8885 7.9253 0.0 0.0532\n",
      "600 0.7162 112.3953 9.9409 0.0 0.0\n",
      "650 0.7034 116.0281 7.9009 0.1606 0.1067\n",
      "700 0.6897 120.5462 9.6379 0.0007 0.0\n",
      "750 0.6754 126.9243 8.5222 0.1237 0.0\n",
      "800 0.6539 136.2475 7.4531 0.0 0.0427\n",
      "850 0.6343 145.9561 9.5334 0.0 0.0\n",
      "900 0.6157 155.1873 9.2258 0.0598 0.1735\n",
      "950 0.5913 164.5624 7.2158 0.0 0.0\n",
      "1000 0.5674 181.0469 9.7436 0.0 0.0753\n",
      "1050 0.5438 199.7682 8.2757 0.0 0.2369\n",
      "1100 0.5168 209.8891 9.4044 0.0475 0.0358\n",
      "1150 0.4919 226.4533 9.4991 0.0 0.0\n",
      "1200 0.466 239.135 9.9402 0.0 0.0\n",
      "1250 0.4382 251.6127 10.7259 0.0 0.0\n",
      "1300 0.4069 261.3392 9.2714 0.0907 0.3308\n",
      "1350 0.3926 275.2989 10.7429 0.0 0.0\n",
      "1400 0.3566 292.2217 9.5817 0.0 0.0\n",
      "1450 0.3373 302.4823 7.2462 0.0 0.0\n",
      "1500 0.309 308.5792 7.4539 0.0 0.0\n",
      "1550 0.2794 320.9106 7.7181 0.0 1.0189\n",
      "1600 0.257 322.9054 5.9191 0.0 0.0\n",
      "1650 0.2386 328.3875 5.0081 0.0081 0.0001\n",
      "1700 0.2169 334.1267 6.4123 0.0 0.0\n",
      "1750 0.1935 340.4874 5.9882 0.0 0.0\n",
      "1800 0.1706 335.1567 4.9142 0.0 0.0\n",
      "1850 0.2062 325.7947 16.3803 0.0 0.0\n",
      "1900 0.1377 332.1404 4.8691 0.0 0.0\n",
      "1950 0.1252 329.4676 3.7617 0.0 0.0\n",
      "1999 0.121 326.6542 3.7657 0.0 0.4754\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def rmse(a, b, mean=torch.mean):\n",
    "    return mean((a-b)**2)**0.5\n",
    "\n",
    "def pretty(x):\n",
    "    return f'{round(float(x), 4)}'\n",
    "\n",
    "class SNPVAE(nn.Module):\n",
    "    def __init__(self, snpd, ld):\n",
    "        super(SNPVAE, self).__init__()\n",
    "        self.ld = ld\n",
    "        self.enc1 = nn.Linear(snpd*3, 1000).float().cuda()\n",
    "        self.enc2 = nn.Linear(1000, ld).float().cuda()\n",
    "        self.dec1 = nn.Linear(ld+2, 1000).float().cuda()\n",
    "        self.dec20 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec21 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec22 = nn.Linear(1000, snpd).float().cuda()\n",
    "\n",
    "    def enc(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        z = self.enc2(x)\n",
    "        return z\n",
    "\n",
    "    def gen(self, n):\n",
    "        return torch.randn(n, self.ld).float().cuda()#/(10**0.5)\n",
    "\n",
    "    def dec(self, z, sex, race):\n",
    "        z = torch.cat([z, sex.unsqueeze(1), race.unsqueeze(1)], dim=1)\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x0 = self.dec20(x)\n",
    "        x1 = self.dec21(x)\n",
    "        x2 = self.dec22(x)\n",
    "        return torch.stack([x0, x1, x2], dim=1)\n",
    "\n",
    "def latent_loss(z):\n",
    "    C = z.T@z\n",
    "    mu = torch.mean(z, dim=0)\n",
    "    tgt1 = torch.eye(z.shape[-1]).float().cuda()*len(z)#/10\n",
    "    tgt2 = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    lossC = rmse(C, tgt1)\n",
    "    lossmu = rmse(mu, tgt2)\n",
    "    return lossC, lossmu, C, mu\n",
    "\n",
    "def decor_loss(z, sex, race):\n",
    "    sex = sex - torch.mean(sex)\n",
    "    race = race - torch.mean(race)\n",
    "    sexp = torch.einsum('n,nz->z', sex, z)\n",
    "    racep = torch.einsum('n,nz->z', race, z)\n",
    "    tgt = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    loss_sex = rmse(sexp, tgt)\n",
    "    loss_race = rmse(racep, tgt)\n",
    "    return loss_sex + loss_race\n",
    "\n",
    "def klloss(z):\n",
    "    N = z.shape[1]\n",
    "    sigma = torch.std(z, dim=0)\n",
    "    mu = torch.mean(z, dim=0)\n",
    "    loss = torch.sum(sigma**2)+torch.sum(mu**2)-2*torch.sum(torch.log(sigma))\n",
    "    return loss\n",
    "\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "# snpvae = SNPVAE(10433, 30)\n",
    "snpvae = SNPVAE(35621, 100)\n",
    "optim = torch.optim.Adam(snpvae.parameters(), lr=1e-3, weight_decay=0)\n",
    "\n",
    "xclass = torch.from_numpy(snps).long().cuda()\n",
    "x = torch.cat([xclass == 0, xclass == 1, xclass == 2], dim=1).float().cuda()\n",
    "sex_t = torch.from_numpy(sex).float().cuda()\n",
    "race_t = torch.from_numpy(race).float().cuda()\n",
    "\n",
    "nepochs = 2000\n",
    "pperiod = 50\n",
    "\n",
    "for e in range(nepochs):\n",
    "    optim.zero_grad()\n",
    "    z = snpvae.enc(x[:800])\n",
    "    logits = snpvae.dec(z, sex_t[:800], race_t[:800])\n",
    "    loss_ce = ce(logits, xclass[:800])\n",
    "    loss_kl = klloss(z)\n",
    "    # loss_C, loss_mu, C, _ = latent_loss(z)\n",
    "    loss_decor = decor_loss(z, sex_t[:800], race_t[:800])\n",
    "    # Generative loss\n",
    "    sx_t = random.randint(0,1)*torch.ones(100).long().cuda()\n",
    "    rc_t = random.randint(0,1)*torch.ones(100).long().cuda()\n",
    "    z = snpvae.gen(100)\n",
    "    logits = snpvae.dec(z, sx_t, rc_t)\n",
    "    logits = torch.cat([logits[:,0], logits[:,1], logits[:,2]], dim=1).float().cuda()\n",
    "    sx_hat = logits@sex_w + sex_i\n",
    "    rc_hat = logits@race_w + race_i\n",
    "    sex_loss = ce(torch.stack([-sx_hat, sx_hat], dim=1), sx_t)\n",
    "    race_loss = ce(torch.stack([-rc_hat, rc_hat], dim=1), rc_t)\n",
    "    # (loss_ce+1e-4*loss_C+1e-4*loss_mu+1e-4*loss_decor+0.001*sex_loss+0.001*race_loss).backward()\n",
    "    (loss_ce+2e-4*loss_kl+2e-4*loss_decor+0.001*sex_loss+0.001*race_loss).backward()\n",
    "    optim.step()\n",
    "    if e % pperiod == 0 or e == nepochs-1:\n",
    "        # print(f'{e} {pretty(loss_ce)} {pretty(loss_C)} {pretty(loss_mu)} {pretty(loss_decor)} {pretty(sex_loss)} {pretty(race_loss)}')\n",
    "        print(f'{e} {pretty(loss_ce)} {pretty(loss_kl)} {pretty(loss_decor)} {pretty(sex_loss)} {pretty(race_loss)}')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7125f62-be0a-4072-9bea-c272ae89c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Save VAE\n",
    "\n",
    "torch.save(snpvae.state_dict(), '/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/vae_snps_big_1000_z100_cov2.torch')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de56938-b034-4e1e-ac1d-0a2df4763d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def rmse(a, b, mean=torch.mean):\n",
    "    return mean((a-b)**2)**0.5\n",
    "\n",
    "def pretty(x):\n",
    "    return f'{round(float(x), 4)}'\n",
    "\n",
    "class SNPVAE(nn.Module):\n",
    "    def __init__(self, snpd, ld):\n",
    "        super(SNPVAE, self).__init__()\n",
    "        self.ld = ld\n",
    "        self.enc1 = nn.Linear(snpd*3, 1000).float().cuda()\n",
    "        self.enc2 = nn.Linear(1000, ld).float().cuda()\n",
    "        self.dec1 = nn.Linear(ld+2, 1000).float().cuda()\n",
    "        self.dec20 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec21 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec22 = nn.Linear(1000, snpd).float().cuda()\n",
    "\n",
    "    def enc(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        z = self.enc2(x)\n",
    "        return z\n",
    "\n",
    "    def gen(self, n):\n",
    "        return torch.randn(n, self.ld).float().cuda()/(10**0.5)\n",
    "\n",
    "    def dec(self, z, sex, race):\n",
    "        z = torch.cat([z, sex.unsqueeze(1), race.unsqueeze(1)], dim=1)\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x0 = self.dec20(x)\n",
    "        x1 = self.dec21(x)\n",
    "        x2 = self.dec22(x)\n",
    "        return torch.stack([x0, x1, x2], dim=1)\n",
    "\n",
    "def latent_loss(z):\n",
    "    C = z.T@z\n",
    "    mu = torch.mean(z, dim=0)\n",
    "    tgt1 = torch.eye(z.shape[-1]).float().cuda()*len(z)/10\n",
    "    tgt2 = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    lossC = rmse(C, tgt1)\n",
    "    lossmu = rmse(mu, tgt2)\n",
    "    return lossC, lossmu, C, mu\n",
    "\n",
    "def decor_loss(z, sex, race):\n",
    "    sex = sex - torch.mean(sex)\n",
    "    race = race - torch.mean(race)\n",
    "    sexp = torch.einsum('n,nz->z', sex, z)\n",
    "    racep = torch.einsum('n,nz->z', race, z)\n",
    "    tgt = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    loss_sex = rmse(sexp, tgt)\n",
    "    loss_race = rmse(racep, tgt)\n",
    "    return loss_sex + loss_race\n",
    "\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "# snpvae = SNPVAE(10433, 30)\n",
    "snpvae = SNPVAE(35621, 100)\n",
    "snpvae.load_state_dict(torch.load('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/vae_snps_big_1000_z100_cov2.torch'))\n",
    "snpvae.eval()\n",
    "\n",
    "xclass = torch.from_numpy(snps).long().cuda()\n",
    "x = torch.cat([xclass == 0, xclass == 1, xclass == 2], dim=1).float().cuda()\n",
    "sex_t = torch.from_numpy(sex).float().cuda()\n",
    "race_t = torch.from_numpy(race).float().cuda()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2026ff77-a122-4404-8251-f2f7cdc76deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33629, device='cuda:0')\n",
      "tensor(29759, device='cuda:0')\n",
      "tensor(35621, device='cuda:0')\n",
      "tensor(33496, device='cuda:0')\n",
      "tensor(35327, device='cuda:0')\n",
      "tensor(35504, device='cuda:0')\n",
      "tensor(35431, device='cuda:0')\n",
      "tensor(34295, device='cuda:0')\n",
      "tensor(33910, device='cuda:0')\n",
      "tensor(35308, device='cuda:0')\n",
      "tensor(29521, device='cuda:0')\n",
      "tensor(35581, device='cuda:0')\n",
      "tensor(35425, device='cuda:0')\n",
      "tensor(34509, device='cuda:0')\n",
      "tensor(32095, device='cuda:0')\n",
      "tensor(32433, device='cuda:0')\n",
      "tensor(34485, device='cuda:0')\n",
      "tensor(35492, device='cuda:0')\n",
      "tensor(35406, device='cuda:0')\n",
      "tensor(35494, device='cuda:0')\n",
      "tensor(35621, device='cuda:0')\n",
      "tensor(35478, device='cuda:0')\n",
      "tensor(33117, device='cuda:0')\n",
      "tensor(35364, device='cuda:0')\n",
      "tensor(32256, device='cuda:0')\n",
      "tensor(31379, device='cuda:0')\n",
      "tensor(31255, device='cuda:0')\n",
      "tensor(32366, device='cuda:0')\n",
      "tensor(30948, device='cuda:0')\n",
      "tensor(31583, device='cuda:0')\n",
      "tensor(34977, device='cuda:0')\n",
      "tensor(35475, device='cuda:0')\n",
      "tensor(35190, device='cuda:0')\n",
      "tensor(34390, device='cuda:0')\n",
      "tensor(34436, device='cuda:0')\n",
      "tensor(35076, device='cuda:0')\n",
      "tensor(31155, device='cuda:0')\n",
      "tensor(33870, device='cuda:0')\n",
      "tensor(34057, device='cuda:0')\n",
      "tensor(32401, device='cuda:0')\n",
      "tensor(32534, device='cuda:0')\n",
      "tensor(29066, device='cuda:0')\n",
      "tensor(35431, device='cuda:0')\n",
      "tensor(35569, device='cuda:0')\n",
      "tensor(33620, device='cuda:0')\n",
      "tensor(34561, device='cuda:0')\n",
      "tensor(32671, device='cuda:0')\n",
      "tensor(33350, device='cuda:0')\n",
      "tensor(34446, device='cuda:0')\n",
      "tensor(32176, device='cuda:0')\n",
      "tensor(34636, device='cuda:0')\n",
      "tensor(33931, device='cuda:0')\n",
      "tensor(35235, device='cuda:0')\n",
      "tensor(35395, device='cuda:0')\n",
      "tensor(34280, device='cuda:0')\n",
      "tensor(35597, device='cuda:0')\n",
      "tensor(35410, device='cuda:0')\n",
      "tensor(35104, device='cuda:0')\n",
      "tensor(33475, device='cuda:0')\n",
      "tensor(32098, device='cuda:0')\n",
      "tensor(32749, device='cuda:0')\n",
      "tensor(32597, device='cuda:0')\n",
      "tensor(35104, device='cuda:0')\n",
      "tensor(31109, device='cuda:0')\n",
      "tensor(35460, device='cuda:0')\n",
      "tensor(34875, device='cuda:0')\n",
      "tensor(35533, device='cuda:0')\n",
      "tensor(35567, device='cuda:0')\n",
      "tensor(32625, device='cuda:0')\n",
      "tensor(35535, device='cuda:0')\n",
      "tensor(34883, device='cuda:0')\n",
      "tensor(32039, device='cuda:0')\n",
      "tensor(35366, device='cuda:0')\n",
      "tensor(33428, device='cuda:0')\n",
      "tensor(35577, device='cuda:0')\n",
      "tensor(34618, device='cuda:0')\n",
      "tensor(33373, device='cuda:0')\n",
      "tensor(35582, device='cuda:0')\n",
      "tensor(31245, device='cuda:0')\n",
      "tensor(34918, device='cuda:0')\n",
      "tensor(32785, device='cuda:0')\n",
      "tensor(34320, device='cuda:0')\n",
      "tensor(33529, device='cuda:0')\n",
      "tensor(34103, device='cuda:0')\n",
      "tensor(30486, device='cuda:0')\n",
      "tensor(35516, device='cuda:0')\n",
      "tensor(35604, device='cuda:0')\n",
      "tensor(35410, device='cuda:0')\n",
      "tensor(35532, device='cuda:0')\n",
      "tensor(35529, device='cuda:0')\n",
      "tensor(31999, device='cuda:0')\n",
      "tensor(32035, device='cuda:0')\n",
      "tensor(35412, device='cuda:0')\n",
      "tensor(33646, device='cuda:0')\n",
      "tensor(31700, device='cuda:0')\n",
      "tensor(33250, device='cuda:0')\n",
      "tensor(35599, device='cuda:0')\n",
      "tensor(35563, device='cuda:0')\n",
      "tensor(35384, device='cuda:0')\n",
      "tensor(32986, device='cuda:0')\n",
      "tensor(32038, device='cuda:0')\n",
      "tensor(32487, device='cuda:0')\n",
      "tensor(34416, device='cuda:0')\n",
      "tensor(30879, device='cuda:0')\n",
      "tensor(35601, device='cuda:0')\n",
      "tensor(30441, device='cuda:0')\n",
      "tensor(34251, device='cuda:0')\n",
      "tensor(35621, device='cuda:0')\n",
      "tensor(33781, device='cuda:0')\n",
      "tensor(34888, device='cuda:0')\n",
      "tensor(34252, device='cuda:0')\n",
      "tensor(35532, device='cuda:0')\n",
      "tensor(34447, device='cuda:0')\n",
      "tensor(35585, device='cuda:0')\n",
      "tensor(35372, device='cuda:0')\n",
      "tensor(33200, device='cuda:0')\n",
      "tensor(30475, device='cuda:0')\n",
      "tensor(35621, device='cuda:0')\n",
      "tensor(35621, device='cuda:0')\n",
      "tensor(29704, device='cuda:0')\n",
      "tensor(35356, device='cuda:0')\n",
      "tensor(34462, device='cuda:0')\n",
      "tensor(33511, device='cuda:0')\n",
      "tensor(32400, device='cuda:0')\n",
      "tensor(32202, device='cuda:0')\n",
      "tensor(35453, device='cuda:0')\n",
      "tensor(31632, device='cuda:0')\n",
      "tensor(29875, device='cuda:0')\n",
      "tensor(34308, device='cuda:0')\n",
      "tensor(35260, device='cuda:0')\n",
      "tensor(32905, device='cuda:0')\n",
      "tensor(31616, device='cuda:0')\n",
      "tensor(34473, device='cuda:0')\n",
      "tensor(33568, device='cuda:0')\n",
      "tensor(28750, device='cuda:0')\n",
      "tensor(33637, device='cuda:0')\n",
      "tensor(35392, device='cuda:0')\n",
      "tensor(35612, device='cuda:0')\n",
      "tensor(35450, device='cuda:0')\n",
      "tensor(35553, device='cuda:0')\n",
      "tensor(31968, device='cuda:0')\n",
      "tensor(32390, device='cuda:0')\n",
      "tensor(33638, device='cuda:0')\n",
      "tensor(35528, device='cuda:0')\n",
      "tensor(34716, device='cuda:0')\n",
      "tensor(35611, device='cuda:0')\n",
      "tensor(35068, device='cuda:0')\n",
      "tensor(35470, device='cuda:0')\n",
      "tensor(35533, device='cuda:0')\n",
      "tensor(35481, device='cuda:0')\n",
      "tensor(33011, device='cuda:0')\n",
      "tensor(35555, device='cuda:0')\n",
      "tensor(35449, device='cuda:0')\n",
      "tensor(29399, device='cuda:0')\n",
      "tensor(33565, device='cuda:0')\n",
      "tensor(34019, device='cuda:0')\n",
      "tensor(34681, device='cuda:0')\n",
      "tensor(31892, device='cuda:0')\n",
      "tensor(28831, device='cuda:0')\n",
      "tensor(35558, device='cuda:0')\n",
      "tensor(34419, device='cuda:0')\n",
      "tensor(34632, device='cuda:0')\n",
      "tensor(32970, device='cuda:0')\n",
      "tensor(35452, device='cuda:0')\n",
      "tensor(33824, device='cuda:0')\n",
      "tensor(27572, device='cuda:0')\n",
      "tensor(35315, device='cuda:0')\n",
      "tensor(29640, device='cuda:0')\n",
      "tensor(35445, device='cuda:0')\n",
      "tensor(35444, device='cuda:0')\n",
      "tensor(33572, device='cuda:0')\n",
      "tensor(29070, device='cuda:0')\n",
      "tensor(32849, device='cuda:0')\n",
      "tensor(35267, device='cuda:0')\n",
      "tensor(34544, device='cuda:0')\n",
      "tensor(34952, device='cuda:0')\n",
      "tensor(35513, device='cuda:0')\n",
      "tensor(33640, device='cuda:0')\n",
      "tensor(34486, device='cuda:0')\n",
      "tensor(35584, device='cuda:0')\n",
      "tensor(35405, device='cuda:0')\n",
      "tensor(34342, device='cuda:0')\n",
      "tensor(31827, device='cuda:0')\n",
      "tensor(35589, device='cuda:0')\n",
      "tensor(35375, device='cuda:0')\n",
      "tensor(31349, device='cuda:0')\n",
      "tensor(33854, device='cuda:0')\n",
      "tensor(34254, device='cuda:0')\n",
      "tensor(35616, device='cuda:0')\n",
      "tensor(34860, device='cuda:0')\n",
      "tensor(31028, device='cuda:0')\n",
      "tensor(31323, device='cuda:0')\n",
      "tensor(33636, device='cuda:0')\n",
      "tensor(30513, device='cuda:0')\n",
      "tensor(28662, device='cuda:0')\n",
      "tensor(35058, device='cuda:0')\n",
      "tensor(35568, device='cuda:0')\n",
      "tensor(34428, device='cuda:0')\n",
      "tensor(35146, device='cuda:0')\n",
      "tensor(31049, device='cuda:0')\n",
      "tensor([2, 2, 1,  ..., 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 2, 1,  ..., 2, 2, 2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = snpvae.enc(x)\n",
    "    logits = snpvae.dec(z, sex_t, race_t)\n",
    "    xhat = torch.argmax(logits, dim=1)\n",
    "\n",
    "for i in range(800,1000):\n",
    "    print(torch.sum(xhat[i] == xclass[i]))\n",
    "print(xhat[2])\n",
    "print(xclass[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774b0d69-6e50-4a69-aee2-c2706a4c8a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, fcd, ld):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fcd = fcd\n",
    "        self.ld = ld\n",
    "        self.enc1 = nn.Linear(fcd, 1000).float().cuda()\n",
    "        self.enc2 = nn.Linear(1000, ld).float().cuda()\n",
    "        self.dec1 = nn.Linear(ld+6, 1000).float().cuda()\n",
    "        self.dec2 = nn.Linear(1000, fcd).float().cuda()\n",
    "\n",
    "    def enc(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        z = self.enc2(x)\n",
    "        return z\n",
    "\n",
    "    def gen(self, n):\n",
    "        return torch.randn(n, self.ld).float().cuda()/(10**0.5)\n",
    "    \n",
    "    def dec(self, z, age, sex, race, rest, nback, emoid):\n",
    "        z = torch.cat([z, age.unsqueeze(1), sex.unsqueeze(1), race.unsqueeze(1), \n",
    "                       rest.unsqueeze(1), nback.unsqueeze(1), emoid.unsqueeze(1)], dim=1)\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x = self.dec2(x)\n",
    "        return x\n",
    "\n",
    "def rmse(a, b, mean=torch.mean):\n",
    "    return mean((a-b)**2)**0.5\n",
    "\n",
    "def pretty(x):\n",
    "    return f'{round(float(x), 4)}'\n",
    "\n",
    "vae = VAE(34716, 30)\n",
    "vae.load_state_dict(torch.load('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/vae_1000_z30_cov6.torch'))\n",
    "vae.eval()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebb6ce0-6629-42ec-8809-a7fd986bd873",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (40000x100 and 50x20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     ztask \u001b[38;5;241m=\u001b[39m zemoid\n\u001b[0;32m---> 54\u001b[0m sims \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mztask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midcs1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzsnp\u001b[49m\u001b[43m[\u001b[49m\u001b[43midcs2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m loss_cl \u001b[38;5;241m=\u001b[39m cl_loss(sims, pidcs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     56\u001b[0m loss_cl\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mSimilarity.forward\u001b[0;34m(self, zfc, zsnp)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, zfc, zsnp):\n\u001b[1;32m      9\u001b[0m     zfc \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfca1(zfc))\n\u001b[0;32m---> 10\u001b[0m     zsnp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfcb1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzsnp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([zfc, zsnp], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(z)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (40000x100 and 50x20)"
     ]
    }
   ],
   "source": [
    "class Similarity(nn.Module):\n",
    "    def __init__(self, ldfc, ldsnp):\n",
    "        super(Similarity, self).__init__()\n",
    "        self.fca1 = nn.Linear(ldfc, 20).float().cuda()\n",
    "        self.fcb1 = nn.Linear(ldsnp, 20).float().cuda()\n",
    "        self.fc2 = nn.Linear(40, 1).float().cuda()\n",
    "\n",
    "    def forward(self, zfc, zsnp):\n",
    "        zfc = F.relu(self.fca1(zfc))\n",
    "        zsnp = F.relu(self.fcb1(zsnp))\n",
    "        z = torch.cat([zfc, zsnp], dim=1)\n",
    "        z = self.fc2(z)\n",
    "        return z\n",
    "\n",
    "def cl_loss(sims, pidcs, tau):\n",
    "    pp = sims[pidcs]\n",
    "    ep = torch.sum(torch.exp(pp/tau))\n",
    "    en = torch.sum(torch.exp(sims/tau))\n",
    "    loss = -torch.log(ep/en)\n",
    "    return loss\n",
    "\n",
    "sim = Similarity(30, 50)\n",
    "optim = torch.optim.Adam(sim.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "with torch.no_grad():\n",
    "    zrest = vae.enc(torch.from_numpy(rest).float().cuda())\n",
    "    znback = vae.enc(torch.from_numpy(nback).float().cuda())\n",
    "    zemoid = vae.enc(torch.from_numpy(emoid).float().cuda())\n",
    "    zsnp = snpvae.enc(x)\n",
    "\n",
    "nepochs = 20000\n",
    "pperiod = 500\n",
    "nb = 200\n",
    "\n",
    "for e in range(nepochs):\n",
    "    optim.zero_grad()\n",
    "    sidcs = np.random.permutation(len(x))[:nb]\n",
    "    idcs1 = []\n",
    "    idcs2 = []\n",
    "    pidcs = []\n",
    "    for i in range(nb):\n",
    "        idcs1.append(np.ones(nb)*sidcs[i])\n",
    "        idcs2.append(sidcs)\n",
    "        pidcs.append(nb*i+i)\n",
    "    idcs1 = np.array(np.concatenate(idcs1))\n",
    "    idcs2 = np.array(np.concatenate(idcs2))\n",
    "    pidcs = np.array(pidcs)\n",
    "    if e % 3 == 0:\n",
    "        ztask = zrest\n",
    "    elif e % 3 == 1:\n",
    "        ztask = znback\n",
    "    else:\n",
    "        ztask = zemoid\n",
    "    sims = sim(ztask[idcs1], zsnp[idcs2])\n",
    "    loss_cl = cl_loss(sims, pidcs, 1)\n",
    "    loss_cl.backward()\n",
    "    optim.step()\n",
    "    if e % pperiod == 0 or e == nepochs-1:\n",
    "        print(f'{e} {pretty(loss_cl)}')\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf2b5d07-7c7b-4ffa-9ac6-02241bbfad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5060987525150905\n",
      "1 0.5055681287726358\n",
      "1 0.5063547686116701\n",
      "1 0.506019879275654\n",
      "1 0.5075904225352114\n",
      "1 0.5070614084507042\n",
      "1 0.5079449496981892\n",
      "1 0.5068706639839033\n",
      "1 0.506313722334004\n",
      "1 0.5060567404426559\n",
      "1 0.5034149698189134\n",
      "1 0.5059128370221327\n",
      "1 0.5074739637826963\n",
      "1 0.5060327565392354\n",
      "1 0.5091603219315896\n",
      "1 0.5066175452716298\n",
      "1 0.5060531187122737\n",
      "1 0.5069287726358149\n",
      "1 0.5048663179074446\n",
      "1 0.505982615694165\n",
      "---\n",
      "1.0\n",
      "0.0\n",
      "0.5064161327967807\n",
      "0.0011519840217475612\n"
     ]
    }
   ],
   "source": [
    "# Test PC imputation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "\n",
    "xreal = x.detach().cpu().numpy()\n",
    "\n",
    "xtr = xreal[:800]\n",
    "xt = xreal[800:]\n",
    "sx = torch.from_numpy(sex[800:]).float().cuda()\n",
    "rc = torch.from_numpy(race[800:]).float().cuda()\n",
    "x2t = snps[800:]\n",
    "\n",
    "accs_pca = []\n",
    "accs_vae = []\n",
    "# accs_sample = []\n",
    "n = 35000\n",
    "\n",
    "for _ in range(20):\n",
    "\n",
    "    # xtr, xt, x2tr, x2t, _, zr, _, zn, _, ze, _, sx, _, rc = train_test_split(xreal, snps, zrest, znback, zemoid, sex_t, race_t, train_size=0.8)\n",
    "\n",
    "    # sx[:] = torch.randint(low=0,high=2,size=[len(sx)])\n",
    "    # rc[:] = torch.randint(low=0,high=2,size=[len(rc)])\n",
    "    \n",
    "    miss = np.random.permutation(snps.shape[-1])[:n]\n",
    "    # pca = PCA(n_components=1).fit(xtr)\n",
    "    \n",
    "    xtt = xt+0\n",
    "    cls = np.random.randint(low=0, high=3, size=(n))\n",
    "    xtt[:,miss] = (cls == 0)+0\n",
    "    xtt[:,miss+1*snps.shape[-1]] = (cls == 1)+0\n",
    "    xtt[:,miss+2*snps.shape[-1]] = (cls == 2)+0\n",
    "    \n",
    "    # xtt_pca = pca.transform(xtt)\n",
    "    # xtt_bak = pca.inverse_transform(xtt_pca)\n",
    "    \n",
    "    # xtt_bak = xtt_bak.reshape(xtt_bak.shape[0], 3, snps.shape[-1])\n",
    "    # xtt_bak = np.argmax(xtt_bak, axis=1)\n",
    "    \n",
    "    # acc = np.mean(np.sum(xtt_bak[:,miss] == x2t[:,miss], axis=1))\n",
    "    # accs_pca.append(acc/n)\n",
    "    accs_pca.append(1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = snpvae.enc(torch.from_numpy(xtt).float().cuda())\n",
    "        logits = snpvae.dec(z, sx, rc)\n",
    "        logits = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    acc = np.mean(np.sum(logits[:,miss] == x2t[:,miss], axis=1))\n",
    "    accs_vae.append(acc/n)\n",
    "\n",
    "    print(accs_pca[-1], accs_vae[-1])\n",
    "\n",
    "    # myaccs = []\n",
    "    \n",
    "    # for i in range(len(zr)):\n",
    "    #     with torch.no_grad():\n",
    "    #         zz = snpvae.gen(100)\n",
    "    #         sims1 = sim(zr[i:i+1].repeat([100,1]), zz)\n",
    "    #         sims2 = sim(zn[i:i+1].repeat([100,1]), zz)\n",
    "    #         sims3 = sim(ze[i:i+1].repeat([100,1]), zz)\n",
    "    #         sims = sims1+sims2+sims3\n",
    "\n",
    "    #         idcs = torch.argsort(sims, descending=True)\n",
    "    #         best = 0\n",
    "    #         for j in idcs[:50]:\n",
    "    #             logits = snpvae.dec(zz[j:j+1], sx[i:i+1], rc[i:i+1])\n",
    "    #             logits = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "    #             acc = np.sum(logits[0,miss] == x2t[i,miss])\n",
    "    #             if acc > best:\n",
    "    #                 best = acc\n",
    "    #         myaccs.append(best/n)\n",
    "\n",
    "    # print(np.mean(myaccs))\n",
    "\n",
    "print('---')\n",
    "print(np.mean(accs_pca))\n",
    "print(np.std(accs_pca))\n",
    "print(np.mean(accs_vae))\n",
    "print(np.std(accs_vae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ad0eb-cd91-4849-b514-bbeb98199716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
