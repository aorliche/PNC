{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb80fd34-69fb-49df-a8c4-afd2b096ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "ours2orig = [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
    "28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 254, 41, 42, 43, 44, 45,\n",
    "46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
    "65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85,\n",
    "86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103,\n",
    "104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
    "119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 136, 138, 132,\n",
    "133, 134, 135, 220, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
    "153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
    "168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 185, 186,\n",
    "187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
    "202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
    "217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
    "233, 137, 234, 235, 236, 237, 238, 239, 240, 241, 250, 251, 255, 256, 257,\n",
    "258, 259, 260, 261, 262, 263, 242, 243, 244, 245, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
    "9, 10, 11, 83, 84, 131, 139, 140, 141, 181, 182, 183, 184, 246, 247, 248,\n",
    "249, 252, 253]\n",
    "\n",
    "def vec2mat(v):\n",
    "    a,b = np.triu_indices(264,1)\n",
    "    m = np.zeros((264,264))\n",
    "    m[a,b] = v\n",
    "    return m+m.T\n",
    "\n",
    "def remap(fc, roimap=ours2orig):\n",
    "    fc = fc[roimap,:]\n",
    "    fc = fc[:,roimap]\n",
    "    return fc\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf48325-5662-466e-be78-282bf533de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1155, 34716), (1155, 34716), (1155, 34716), (1155,), (1155,), (1155,)]\n"
     ]
    }
   ],
   "source": [
    "# Load FC\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "pncdir = '/home/anton/Documents/Tulane/Research/data-sav/anton/cohorts/PNC/'\n",
    "lowrankdir = '/home/anton/Documents/Tulane/Research/Work/ContrastiveLearning/PNC/Top10/'\n",
    "pncdemo = pickle.load(open(f'{pncdir}/demographics.pkl', 'rb'))\n",
    "no_snps_subs = pickle.load(open('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/fc_subs_no_snps.pkl', 'rb'))\n",
    "\n",
    "rest = []\n",
    "nback = []\n",
    "emoid = []\n",
    "restmat = []\n",
    "nbackmat = []\n",
    "emoidmat = []\n",
    "race = []\n",
    "sex = []\n",
    "age = []\n",
    "subids = []\n",
    "\n",
    "a,b = np.triu_indices(264,1)\n",
    "\n",
    "for sub in pncdemo['age_at_cnb']:\n",
    "    if sub in no_snps_subs:\n",
    "        continue\n",
    "    try:\n",
    "        ra = pncdemo['Race'][sub]\n",
    "        ag = pncdemo['age_at_cnb'][sub]\n",
    "        se = pncdemo['Sex'][sub]\n",
    "        if ra not in ['AA', 'EA']:\n",
    "            continue\n",
    "        ra = ra == 'AA'\n",
    "        se = se == 'M'\n",
    "        r = np.load(f'{pncdir}/fc/{sub}_task-rest_fc.npy')\n",
    "        n = np.load(f'{pncdir}/fc/{sub}_task-nback_fc.npy')\n",
    "        e = np.load(f'{pncdir}/fc/{sub}_task-emoid_fc.npy')\n",
    "        r = remap(vec2mat(r))\n",
    "        n = remap(vec2mat(n))\n",
    "        e = remap(vec2mat(e))\n",
    "        race.append(ra)\n",
    "        sex.append(se)\n",
    "        age.append(ag)\n",
    "        rest.append(r[a,b])\n",
    "        nback.append(n[a,b])\n",
    "        emoid.append(e[a,b])\n",
    "        subids.append(sub)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "rest = np.stack(rest)\n",
    "nback = np.stack(nback)\n",
    "emoid = np.stack(emoid)\n",
    "race = np.array(race).astype('int')\n",
    "sex = np.array(sex).astype('int')\n",
    "age = np.array(age)\n",
    "\n",
    "print([a.shape for a in [rest, nback, emoid, race, sex, age]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55384c16-f6d1-405e-89f0-cfd3ce47e4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1155, 35621)\n"
     ]
    }
   ],
   "source": [
    "# Load big SNPs\n",
    "\n",
    "snps = []\n",
    "no_snps_subs = []\n",
    "\n",
    "snps_file = pickle.load(open('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/snps_all_subs_big.pkl', 'rb'))\n",
    "\n",
    "for sub in subids:\n",
    "    if sub not in snps_file:\n",
    "        print(sub)\n",
    "        # no_snps_subs.append(sub)\n",
    "    snps.append(snps_file[sub])\n",
    "\n",
    "snps = np.stack(snps)\n",
    "snps[np.isnan(snps)] = 0\n",
    "\n",
    "print(snps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecee3f79-ff6d-40a9-b186-0fc6fb88aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0005006632164482196 -8.185157212843205e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x = np.concatenate([snps == 0, snps == 1, snps == 2], axis=1)\n",
    "reg_sex = LogisticRegression(C=100).fit(x, sex)\n",
    "sex_w = torch.from_numpy(reg_sex.coef_[0]).float().cuda()\n",
    "sex_i = reg_sex.intercept_[0]\n",
    "\n",
    "reg_race = LogisticRegression(C=100).fit(x, race)\n",
    "race_w = torch.from_numpy(reg_race.coef_[0]).float().cuda()\n",
    "race_i = reg_race.intercept_[0]\n",
    "\n",
    "print(sex_i, race_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f29c42-157b-456c-a78b-865416fd9050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0996 495.1114 8.9425 0.7943 0.686\n",
      "50 0.818 236.5216 114.2848 0.6166 0.1589\n",
      "100 0.793 178.3679 92.8692 9.1297 1.3124\n",
      "150 0.7846 149.6176 58.9078 0.2203 2.1239\n",
      "200 0.7771 126.9605 38.0855 0.0005 1.5954\n",
      "250 0.7711 115.9695 21.9576 0.0 1.9035\n",
      "300 0.768 110.2836 9.4672 0.0025 0.0791\n",
      "350 0.7573 107.6932 6.0683 0.0 0.2005\n",
      "400 0.7492 107.5668 5.9909 0.0 0.2137\n",
      "450 0.7402 107.4356 9.7797 0.0 0.0122\n",
      "500 0.7301 108.6387 10.5787 0.0146 0.0\n",
      "550 0.7181 111.1208 9.9408 0.012 0.0001\n",
      "600 0.7051 114.5532 8.8856 0.0 0.0\n",
      "650 0.6904 120.3466 8.4786 0.0001 0.0\n",
      "700 0.6726 126.4744 8.7006 0.0 0.0\n",
      "750 0.6533 136.0909 12.9022 0.0 0.0\n",
      "800 0.6316 145.6172 7.437 0.0 0.0772\n",
      "850 0.6134 155.0848 9.3268 0.0 0.0194\n",
      "900 0.5847 170.1376 8.1898 0.0 0.0\n",
      "950 0.5602 182.2786 8.5867 0.0334 0.08\n",
      "1000 0.5381 196.4132 10.145 0.0 0.2963\n",
      "1050 0.5067 214.8439 6.7683 0.0004 0.6351\n",
      "1100 0.4884 222.6009 9.7857 0.0 0.046\n",
      "1150 0.4448 241.8507 6.9536 0.0 0.0\n",
      "1200 0.4217 257.3643 8.5657 0.0 0.0\n",
      "1250 0.3892 269.6463 6.0951 0.0 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m loss_kl \u001b[38;5;241m=\u001b[39m klloss(z)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# loss_C, loss_mu, C, _ = latent_loss(z)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m loss_decor \u001b[38;5;241m=\u001b[39m \u001b[43mdecor_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msex_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrace_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Generative loss\u001b[39;00m\n\u001b[1;32m     88\u001b[0m sx_t \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mcuda()\n",
      "Cell \u001b[0;32mIn[17], line 53\u001b[0m, in \u001b[0;36mdecor_loss\u001b[0;34m(z, sex, race)\u001b[0m\n\u001b[1;32m     51\u001b[0m sexp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn,nz->z\u001b[39m\u001b[38;5;124m'\u001b[39m, sex, z)\n\u001b[1;32m     52\u001b[0m racep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn,nz->z\u001b[39m\u001b[38;5;124m'\u001b[39m, race, z)\n\u001b[0;32m---> 53\u001b[0m tgt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m loss_sex \u001b[38;5;241m=\u001b[39m rmse(sexp, tgt)\n\u001b[1;32m     55\u001b[0m loss_race \u001b[38;5;241m=\u001b[39m rmse(racep, tgt)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def rmse(a, b, mean=torch.mean):\n",
    "    return mean((a-b)**2)**0.5\n",
    "\n",
    "def pretty(x):\n",
    "    return f'{round(float(x), 4)}'\n",
    "\n",
    "class SNPVAE(nn.Module):\n",
    "    def __init__(self, snpd, ld):\n",
    "        super(SNPVAE, self).__init__()\n",
    "        self.ld = ld\n",
    "        self.enc1 = nn.Linear(snpd*3, 1000).float().cuda()\n",
    "        self.enc2 = nn.Linear(1000, ld).float().cuda()\n",
    "        self.dec1 = nn.Linear(ld+2, 1000).float().cuda()\n",
    "        self.dec20 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec21 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec22 = nn.Linear(1000, snpd).float().cuda()\n",
    "\n",
    "    def enc(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        z = self.enc2(x)\n",
    "        return z\n",
    "\n",
    "    def gen(self, n):\n",
    "        return torch.randn(n, self.ld).float().cuda()#/(10**0.5)\n",
    "\n",
    "    def dec(self, z, sex, race):\n",
    "        z = torch.cat([z, sex.unsqueeze(1), race.unsqueeze(1)], dim=1)\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x0 = self.dec20(x)\n",
    "        x1 = self.dec21(x)\n",
    "        x2 = self.dec22(x)\n",
    "        return torch.stack([x0, x1, x2], dim=1)\n",
    "\n",
    "def latent_loss(z):\n",
    "    C = z.T@z\n",
    "    mu = torch.mean(z, dim=0)\n",
    "    tgt1 = torch.eye(z.shape[-1]).float().cuda()*len(z)#/10\n",
    "    tgt2 = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    lossC = rmse(C, tgt1)\n",
    "    lossmu = rmse(mu, tgt2)\n",
    "    return lossC, lossmu, C, mu\n",
    "\n",
    "def decor_loss(z, sex, race):\n",
    "    sex = sex - torch.mean(sex)\n",
    "    race = race - torch.mean(race)\n",
    "    sexp = torch.einsum('n,nz->z', sex, z)\n",
    "    racep = torch.einsum('n,nz->z', race, z)\n",
    "    tgt = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    loss_sex = rmse(sexp, tgt)\n",
    "    loss_race = rmse(racep, tgt)\n",
    "    return loss_sex + loss_race\n",
    "\n",
    "def klloss(z):\n",
    "    N = z.shape[1]\n",
    "    sigma = torch.std(z, dim=0)\n",
    "    mu = torch.mean(z, dim=0)\n",
    "    loss = torch.sum(sigma**2)+torch.sum(mu**2)-2*torch.sum(torch.log(sigma))\n",
    "    return loss\n",
    "\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "# snpvae = SNPVAE(10433, 30)\n",
    "snpvae = SNPVAE(35621, 100)\n",
    "optim = torch.optim.Adam(snpvae.parameters(), lr=1e-3, weight_decay=0)\n",
    "\n",
    "xclass = torch.from_numpy(snps).long().cuda()\n",
    "x = torch.cat([xclass == 0, xclass == 1, xclass == 2], dim=1).float().cuda()\n",
    "sex_t = torch.from_numpy(sex).float().cuda()\n",
    "race_t = torch.from_numpy(race).float().cuda()\n",
    "\n",
    "nepochs = 2000\n",
    "pperiod = 50\n",
    "\n",
    "for e in range(nepochs):\n",
    "    optim.zero_grad()\n",
    "    z = snpvae.enc(x[:800])\n",
    "    logits = snpvae.dec(z, sex_t[:800], race_t[:800])\n",
    "    loss_ce = ce(logits, xclass[:800])\n",
    "    loss_kl = klloss(z)\n",
    "    # loss_C, loss_mu, C, _ = latent_loss(z)\n",
    "    loss_decor = decor_loss(z, sex_t[:800], race_t[:800])\n",
    "    # Generative loss\n",
    "    sx_t = random.randint(0,1)*torch.ones(100).long().cuda()\n",
    "    rc_t = random.randint(0,1)*torch.ones(100).long().cuda()\n",
    "    z = snpvae.gen(100)\n",
    "    logits = snpvae.dec(z, sx_t, rc_t)\n",
    "    logits = torch.cat([logits[:,0], logits[:,1], logits[:,2]], dim=1).float().cuda()\n",
    "    sx_hat = logits@sex_w + sex_i\n",
    "    rc_hat = logits@race_w + race_i\n",
    "    sex_loss = ce(torch.stack([-sx_hat, sx_hat], dim=1), sx_t)\n",
    "    race_loss = ce(torch.stack([-rc_hat, rc_hat], dim=1), rc_t)\n",
    "    # (loss_ce+1e-4*loss_C+1e-4*loss_mu+1e-4*loss_decor+0.001*sex_loss+0.001*race_loss).backward()\n",
    "    (loss_ce+2e-4*loss_kl+2e-4*loss_decor+0.001*sex_loss+0.001*race_loss).backward()\n",
    "    optim.step()\n",
    "    if e % pperiod == 0 or e == nepochs-1:\n",
    "        # print(f'{e} {pretty(loss_ce)} {pretty(loss_C)} {pretty(loss_mu)} {pretty(loss_decor)} {pretty(sex_loss)} {pretty(race_loss)}')\n",
    "        print(f'{e} {pretty(loss_ce)} {pretty(loss_kl)} {pretty(loss_decor)} {pretty(sex_loss)} {pretty(race_loss)}')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7125f62-be0a-4072-9bea-c272ae89c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Save VAE\n",
    "\n",
    "torch.save(snpvae.state_dict(), '/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/vae_snps_big_1000_z100_cov2.torch')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de56938-b034-4e1e-ac1d-0a2df4763d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def rmse(a, b, mean=torch.mean):\n",
    "    return mean((a-b)**2)**0.5\n",
    "\n",
    "def pretty(x):\n",
    "    return f'{round(float(x), 4)}'\n",
    "\n",
    "class SNPVAE(nn.Module):\n",
    "    def __init__(self, snpd, ld):\n",
    "        super(SNPVAE, self).__init__()\n",
    "        self.ld = ld\n",
    "        self.enc1 = nn.Linear(snpd*3, 1000).float().cuda()\n",
    "        self.enc2 = nn.Linear(1000, ld).float().cuda()\n",
    "        self.dec1 = nn.Linear(ld+2, 1000).float().cuda()\n",
    "        self.dec20 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec21 = nn.Linear(1000, snpd).float().cuda()\n",
    "        self.dec22 = nn.Linear(1000, snpd).float().cuda()\n",
    "\n",
    "    def enc(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        z = self.enc2(x)\n",
    "        return z\n",
    "\n",
    "    def gen(self, n):\n",
    "        return torch.randn(n, self.ld).float().cuda()/(10**0.5)\n",
    "\n",
    "    def dec(self, z, sex, race):\n",
    "        z = torch.cat([z, sex.unsqueeze(1), race.unsqueeze(1)], dim=1)\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x0 = self.dec20(x)\n",
    "        x1 = self.dec21(x)\n",
    "        x2 = self.dec22(x)\n",
    "        return torch.stack([x0, x1, x2], dim=1)\n",
    "\n",
    "def latent_loss(z):\n",
    "    C = z.T@z\n",
    "    mu = torch.mean(z, dim=0)\n",
    "    tgt1 = torch.eye(z.shape[-1]).float().cuda()*len(z)/10\n",
    "    tgt2 = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    lossC = rmse(C, tgt1)\n",
    "    lossmu = rmse(mu, tgt2)\n",
    "    return lossC, lossmu, C, mu\n",
    "\n",
    "def decor_loss(z, sex, race):\n",
    "    sex = sex - torch.mean(sex)\n",
    "    race = race - torch.mean(race)\n",
    "    sexp = torch.einsum('n,nz->z', sex, z)\n",
    "    racep = torch.einsum('n,nz->z', race, z)\n",
    "    tgt = torch.zeros(z.shape[-1]).float().cuda()\n",
    "    loss_sex = rmse(sexp, tgt)\n",
    "    loss_race = rmse(racep, tgt)\n",
    "    return loss_sex + loss_race\n",
    "\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "# snpvae = SNPVAE(10433, 30)\n",
    "snpvae = SNPVAE(35621, 100)\n",
    "snpvae.load_state_dict(torch.load('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/vae_snps_big_1000_z100_cov2.torch'))\n",
    "snpvae.eval()\n",
    "\n",
    "xclass = torch.from_numpy(snps).long().cuda()\n",
    "x = torch.cat([xclass == 0, xclass == 1, xclass == 2], dim=1).float().cuda()\n",
    "sex_t = torch.from_numpy(sex).float().cuda()\n",
    "race_t = torch.from_numpy(race).float().cuda()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2026ff77-a122-4404-8251-f2f7cdc76deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21049, device='cuda:0')\n",
      "tensor(19758, device='cuda:0')\n",
      "tensor(19505, device='cuda:0')\n",
      "tensor(20727, device='cuda:0')\n",
      "tensor(24977, device='cuda:0')\n",
      "tensor(19562, device='cuda:0')\n",
      "tensor(20977, device='cuda:0')\n",
      "tensor(19544, device='cuda:0')\n",
      "tensor(21001, device='cuda:0')\n",
      "tensor(19915, device='cuda:0')\n",
      "tensor(21158, device='cuda:0')\n",
      "tensor(19837, device='cuda:0')\n",
      "tensor(22974, device='cuda:0')\n",
      "tensor(19653, device='cuda:0')\n",
      "tensor(20703, device='cuda:0')\n",
      "tensor(20925, device='cuda:0')\n",
      "tensor(20951, device='cuda:0')\n",
      "tensor(19560, device='cuda:0')\n",
      "tensor(19543, device='cuda:0')\n",
      "tensor(22505, device='cuda:0')\n",
      "tensor(21596, device='cuda:0')\n",
      "tensor(19811, device='cuda:0')\n",
      "tensor(21314, device='cuda:0')\n",
      "tensor(19461, device='cuda:0')\n",
      "tensor(19871, device='cuda:0')\n",
      "tensor(20729, device='cuda:0')\n",
      "tensor(21162, device='cuda:0')\n",
      "tensor(20525, device='cuda:0')\n",
      "tensor(19618, device='cuda:0')\n",
      "tensor(20133, device='cuda:0')\n",
      "tensor(19340, device='cuda:0')\n",
      "tensor(20900, device='cuda:0')\n",
      "tensor(23016, device='cuda:0')\n",
      "tensor(21380, device='cuda:0')\n",
      "tensor(20114, device='cuda:0')\n",
      "tensor(19279, device='cuda:0')\n",
      "tensor(19810, device='cuda:0')\n",
      "tensor(20700, device='cuda:0')\n",
      "tensor(19704, device='cuda:0')\n",
      "tensor(19344, device='cuda:0')\n",
      "tensor(19762, device='cuda:0')\n",
      "tensor(20855, device='cuda:0')\n",
      "tensor(19150, device='cuda:0')\n",
      "tensor(19636, device='cuda:0')\n",
      "tensor(20623, device='cuda:0')\n",
      "tensor(19381, device='cuda:0')\n",
      "tensor(19529, device='cuda:0')\n",
      "tensor(19670, device='cuda:0')\n",
      "tensor(21286, device='cuda:0')\n",
      "tensor(19734, device='cuda:0')\n",
      "tensor(19679, device='cuda:0')\n",
      "tensor(19468, device='cuda:0')\n",
      "tensor(23154, device='cuda:0')\n",
      "tensor(20429, device='cuda:0')\n",
      "tensor(19522, device='cuda:0')\n",
      "tensor(19926, device='cuda:0')\n",
      "tensor(19598, device='cuda:0')\n",
      "tensor(20914, device='cuda:0')\n",
      "tensor(21249, device='cuda:0')\n",
      "tensor(21392, device='cuda:0')\n",
      "tensor(20520, device='cuda:0')\n",
      "tensor(19445, device='cuda:0')\n",
      "tensor(19244, device='cuda:0')\n",
      "tensor(21133, device='cuda:0')\n",
      "tensor(19564, device='cuda:0')\n",
      "tensor(19823, device='cuda:0')\n",
      "tensor(19628, device='cuda:0')\n",
      "tensor(19521, device='cuda:0')\n",
      "tensor(21450, device='cuda:0')\n",
      "tensor(20780, device='cuda:0')\n",
      "tensor(21539, device='cuda:0')\n",
      "tensor(21086, device='cuda:0')\n",
      "tensor(19931, device='cuda:0')\n",
      "tensor(19595, device='cuda:0')\n",
      "tensor(19741, device='cuda:0')\n",
      "tensor(20155, device='cuda:0')\n",
      "tensor(20815, device='cuda:0')\n",
      "tensor(19485, device='cuda:0')\n",
      "tensor(19422, device='cuda:0')\n",
      "tensor(19515, device='cuda:0')\n",
      "tensor(19333, device='cuda:0')\n",
      "tensor(20311, device='cuda:0')\n",
      "tensor(20481, device='cuda:0')\n",
      "tensor(19635, device='cuda:0')\n",
      "tensor(20631, device='cuda:0')\n",
      "tensor(23315, device='cuda:0')\n",
      "tensor(19466, device='cuda:0')\n",
      "tensor(19211, device='cuda:0')\n",
      "tensor(19792, device='cuda:0')\n",
      "tensor(19284, device='cuda:0')\n",
      "tensor(20549, device='cuda:0')\n",
      "tensor(20103, device='cuda:0')\n",
      "tensor(19629, device='cuda:0')\n",
      "tensor(20754, device='cuda:0')\n",
      "tensor(19928, device='cuda:0')\n",
      "tensor(19742, device='cuda:0')\n",
      "tensor(19476, device='cuda:0')\n",
      "tensor(19491, device='cuda:0')\n",
      "tensor(19885, device='cuda:0')\n",
      "tensor(19541, device='cuda:0')\n",
      "tensor(21255, device='cuda:0')\n",
      "tensor(19732, device='cuda:0')\n",
      "tensor(19670, device='cuda:0')\n",
      "tensor(21099, device='cuda:0')\n",
      "tensor(19413, device='cuda:0')\n",
      "tensor(20768, device='cuda:0')\n",
      "tensor(20430, device='cuda:0')\n",
      "tensor(19473, device='cuda:0')\n",
      "tensor(19515, device='cuda:0')\n",
      "tensor(19299, device='cuda:0')\n",
      "tensor(19815, device='cuda:0')\n",
      "tensor(19923, device='cuda:0')\n",
      "tensor(20826, device='cuda:0')\n",
      "tensor(21819, device='cuda:0')\n",
      "tensor(19709, device='cuda:0')\n",
      "tensor(20839, device='cuda:0')\n",
      "tensor(20627, device='cuda:0')\n",
      "tensor(19478, device='cuda:0')\n",
      "tensor(19919, device='cuda:0')\n",
      "tensor(19563, device='cuda:0')\n",
      "tensor(19795, device='cuda:0')\n",
      "tensor(20107, device='cuda:0')\n",
      "tensor(20471, device='cuda:0')\n",
      "tensor(21354, device='cuda:0')\n",
      "tensor(19447, device='cuda:0')\n",
      "tensor(19390, device='cuda:0')\n",
      "tensor(19461, device='cuda:0')\n",
      "tensor(19916, device='cuda:0')\n",
      "tensor(21201, device='cuda:0')\n",
      "tensor(19670, device='cuda:0')\n",
      "tensor(20503, device='cuda:0')\n",
      "tensor(20657, device='cuda:0')\n",
      "tensor(20616, device='cuda:0')\n",
      "tensor(19453, device='cuda:0')\n",
      "tensor(19470, device='cuda:0')\n",
      "tensor(22686, device='cuda:0')\n",
      "tensor(20758, device='cuda:0')\n",
      "tensor(23211, device='cuda:0')\n",
      "tensor(19691, device='cuda:0')\n",
      "tensor(19675, device='cuda:0')\n",
      "tensor(21079, device='cuda:0')\n",
      "tensor(21613, device='cuda:0')\n",
      "tensor(20567, device='cuda:0')\n",
      "tensor(19854, device='cuda:0')\n",
      "tensor(19344, device='cuda:0')\n",
      "tensor(18130, device='cuda:0')\n",
      "tensor(19696, device='cuda:0')\n",
      "tensor(19268, device='cuda:0')\n",
      "tensor(19407, device='cuda:0')\n",
      "tensor(19796, device='cuda:0')\n",
      "tensor(20580, device='cuda:0')\n",
      "tensor(19444, device='cuda:0')\n",
      "tensor(19775, device='cuda:0')\n",
      "tensor(21382, device='cuda:0')\n",
      "tensor(19621, device='cuda:0')\n",
      "tensor(19713, device='cuda:0')\n",
      "tensor(21207, device='cuda:0')\n",
      "tensor(19504, device='cuda:0')\n",
      "tensor(19656, device='cuda:0')\n",
      "tensor(18796, device='cuda:0')\n",
      "tensor(19269, device='cuda:0')\n",
      "tensor(19910, device='cuda:0')\n",
      "tensor(21004, device='cuda:0')\n",
      "tensor(19528, device='cuda:0')\n",
      "tensor(21657, device='cuda:0')\n",
      "tensor(19622, device='cuda:0')\n",
      "tensor(20723, device='cuda:0')\n",
      "tensor(19257, device='cuda:0')\n",
      "tensor(21119, device='cuda:0')\n",
      "tensor(22972, device='cuda:0')\n",
      "tensor(19711, device='cuda:0')\n",
      "tensor(21319, device='cuda:0')\n",
      "tensor(19578, device='cuda:0')\n",
      "tensor(19783, device='cuda:0')\n",
      "tensor(21052, device='cuda:0')\n",
      "tensor(20074, device='cuda:0')\n",
      "tensor(19250, device='cuda:0')\n",
      "tensor(19732, device='cuda:0')\n",
      "tensor(21141, device='cuda:0')\n",
      "tensor(19669, device='cuda:0')\n",
      "tensor(19354, device='cuda:0')\n",
      "tensor(19905, device='cuda:0')\n",
      "tensor(21147, device='cuda:0')\n",
      "tensor(19570, device='cuda:0')\n",
      "tensor(20878, device='cuda:0')\n",
      "tensor(20911, device='cuda:0')\n",
      "tensor(19897, device='cuda:0')\n",
      "tensor(20498, device='cuda:0')\n",
      "tensor(19272, device='cuda:0')\n",
      "tensor(20347, device='cuda:0')\n",
      "tensor(20169, device='cuda:0')\n",
      "tensor(20208, device='cuda:0')\n",
      "tensor(21392, device='cuda:0')\n",
      "tensor(21044, device='cuda:0')\n",
      "tensor(20645, device='cuda:0')\n",
      "tensor(20416, device='cuda:0')\n",
      "tensor(21367, device='cuda:0')\n",
      "tensor(21586, device='cuda:0')\n",
      "tensor(19754, device='cuda:0')\n",
      "tensor(19542, device='cuda:0')\n",
      "tensor([2, 2, 1,  ..., 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 2, 1,  ..., 2, 2, 2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = snpvae.enc(x)\n",
    "    logits = snpvae.dec(z, sex_t, race_t)\n",
    "    xhat = torch.argmax(logits, dim=1)\n",
    "\n",
    "for i in range(800,1000):\n",
    "    print(torch.sum(xhat[i] == xclass[i]))\n",
    "print(xhat[2])\n",
    "print(xclass[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774b0d69-6e50-4a69-aee2-c2706a4c8a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, fcd, ld):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fcd = fcd\n",
    "        self.ld = ld\n",
    "        self.enc1 = nn.Linear(fcd, 1000).float().cuda()\n",
    "        self.enc2 = nn.Linear(1000, ld).float().cuda()\n",
    "        self.dec1 = nn.Linear(ld+6, 1000).float().cuda()\n",
    "        self.dec2 = nn.Linear(1000, fcd).float().cuda()\n",
    "\n",
    "    def enc(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        z = self.enc2(x)\n",
    "        return z\n",
    "\n",
    "    def gen(self, n):\n",
    "        return torch.randn(n, self.ld).float().cuda()/(10**0.5)\n",
    "    \n",
    "    def dec(self, z, age, sex, race, rest, nback, emoid):\n",
    "        z = torch.cat([z, age.unsqueeze(1), sex.unsqueeze(1), race.unsqueeze(1), \n",
    "                       rest.unsqueeze(1), nback.unsqueeze(1), emoid.unsqueeze(1)], dim=1)\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x = self.dec2(x)\n",
    "        return x\n",
    "\n",
    "def rmse(a, b, mean=torch.mean):\n",
    "    return mean((a-b)**2)**0.5\n",
    "\n",
    "def pretty(x):\n",
    "    return f'{round(float(x), 4)}'\n",
    "\n",
    "vae = VAE(34716, 30)\n",
    "vae.load_state_dict(torch.load('/home/anton/Documents/Tulane/Research/ImageNomer/data/PNC/vae_1000_z30_cov6.torch'))\n",
    "vae.eval()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebb6ce0-6629-42ec-8809-a7fd986bd873",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (40000x100 and 50x20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     ztask \u001b[38;5;241m=\u001b[39m zemoid\n\u001b[0;32m---> 54\u001b[0m sims \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mztask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midcs1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzsnp\u001b[49m\u001b[43m[\u001b[49m\u001b[43midcs2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m loss_cl \u001b[38;5;241m=\u001b[39m cl_loss(sims, pidcs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     56\u001b[0m loss_cl\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m, in \u001b[0;36mSimilarity.forward\u001b[0;34m(self, zfc, zsnp)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, zfc, zsnp):\n\u001b[1;32m      9\u001b[0m     zfc \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfca1(zfc))\n\u001b[0;32m---> 10\u001b[0m     zsnp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfcb1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzsnp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([zfc, zsnp], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(z)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (40000x100 and 50x20)"
     ]
    }
   ],
   "source": [
    "class Similarity(nn.Module):\n",
    "    def __init__(self, ldfc, ldsnp):\n",
    "        super(Similarity, self).__init__()\n",
    "        self.fca1 = nn.Linear(ldfc, 20).float().cuda()\n",
    "        self.fcb1 = nn.Linear(ldsnp, 20).float().cuda()\n",
    "        self.fc2 = nn.Linear(40, 1).float().cuda()\n",
    "\n",
    "    def forward(self, zfc, zsnp):\n",
    "        zfc = F.relu(self.fca1(zfc))\n",
    "        zsnp = F.relu(self.fcb1(zsnp))\n",
    "        z = torch.cat([zfc, zsnp], dim=1)\n",
    "        z = self.fc2(z)\n",
    "        return z\n",
    "\n",
    "def cl_loss(sims, pidcs, tau):\n",
    "    pp = sims[pidcs]\n",
    "    ep = torch.sum(torch.exp(pp/tau))\n",
    "    en = torch.sum(torch.exp(sims/tau))\n",
    "    loss = -torch.log(ep/en)\n",
    "    return loss\n",
    "\n",
    "sim = Similarity(30, 50)\n",
    "optim = torch.optim.Adam(sim.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "with torch.no_grad():\n",
    "    zrest = vae.enc(torch.from_numpy(rest).float().cuda())\n",
    "    znback = vae.enc(torch.from_numpy(nback).float().cuda())\n",
    "    zemoid = vae.enc(torch.from_numpy(emoid).float().cuda())\n",
    "    zsnp = snpvae.enc(x)\n",
    "\n",
    "nepochs = 20000\n",
    "pperiod = 500\n",
    "nb = 200\n",
    "\n",
    "for e in range(nepochs):\n",
    "    optim.zero_grad()\n",
    "    sidcs = np.random.permutation(len(x))[:nb]\n",
    "    idcs1 = []\n",
    "    idcs2 = []\n",
    "    pidcs = []\n",
    "    for i in range(nb):\n",
    "        idcs1.append(np.ones(nb)*sidcs[i])\n",
    "        idcs2.append(sidcs)\n",
    "        pidcs.append(nb*i+i)\n",
    "    idcs1 = np.array(np.concatenate(idcs1))\n",
    "    idcs2 = np.array(np.concatenate(idcs2))\n",
    "    pidcs = np.array(pidcs)\n",
    "    if e % 3 == 0:\n",
    "        ztask = zrest\n",
    "    elif e % 3 == 1:\n",
    "        ztask = znback\n",
    "    else:\n",
    "        ztask = zemoid\n",
    "    sims = sim(ztask[idcs1], zsnp[idcs2])\n",
    "    loss_cl = cl_loss(sims, pidcs, 1)\n",
    "    loss_cl.backward()\n",
    "    optim.step()\n",
    "    if e % pperiod == 0 or e == nepochs-1:\n",
    "        print(f'{e} {pretty(loss_cl)}')\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf2b5d07-7c7b-4ffa-9ac6-02241bbfad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6086478873239437 0.5499154929577464\n",
      "0.6289859154929577 0.5612676056338028\n",
      "0.6399154929577464 0.5911549295774647\n",
      "0.5908169014084507 0.5376901408450704\n",
      "0.6336619718309859 0.5776619718309859\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m xtt_bak \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39minverse_transform(xtt_pca)\n\u001b[1;32m     38\u001b[0m xtt_bak \u001b[38;5;241m=\u001b[39m xtt_bak\u001b[38;5;241m.\u001b[39mreshape(xtt_bak\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m3\u001b[39m, snps\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m xtt_bak \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtt_bak\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msum(xtt_bak[:,miss] \u001b[38;5;241m==\u001b[39m x2t[:,miss], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     42\u001b[0m accs_pca\u001b[38;5;241m.\u001b[39mappend(acc\u001b[38;5;241m/\u001b[39mn)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test PC imputation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "\n",
    "xreal = x.detach().cpu().numpy()\n",
    "\n",
    "xtr = xreal[:800]\n",
    "xt = xreal[800:]\n",
    "sx = torch.from_numpy(sex[800:]).float().cuda()\n",
    "rc = torch.from_numpy(race[800:]).float().cuda()\n",
    "x2t = snps[800:]\n",
    "\n",
    "accs_pca = []\n",
    "accs_vae = []\n",
    "# accs_sample = []\n",
    "n = 100\n",
    "\n",
    "for _ in range(10):\n",
    "\n",
    "    # xtr, xt, x2tr, x2t, _, zr, _, zn, _, ze, _, sx, _, rc = train_test_split(xreal, snps, zrest, znback, zemoid, sex_t, race_t, train_size=0.8)\n",
    "\n",
    "    # sx[:] = torch.randint(low=0,high=2,size=[len(sx)])\n",
    "    # rc[:] = torch.randint(low=0,high=2,size=[len(rc)])\n",
    "    \n",
    "    miss = np.random.permutation(snps.shape[-1])[:n]\n",
    "    pca = PCA(n_components=1).fit(xtr)\n",
    "    \n",
    "    xtt = xt+0\n",
    "    cls = np.random.randint(low=0, high=3, size=(n))\n",
    "    xtt[:,miss] = (cls == 0)+0\n",
    "    xtt[:,miss+1*snps.shape[-1]] = (cls == 1)+0\n",
    "    xtt[:,miss+2*snps.shape[-1]] = (cls == 2)+0\n",
    "    \n",
    "    xtt_pca = pca.transform(xtt)\n",
    "    xtt_bak = pca.inverse_transform(xtt_pca)\n",
    "    \n",
    "    xtt_bak = xtt_bak.reshape(xtt_bak.shape[0], 3, snps.shape[-1])\n",
    "    xtt_bak = np.argmax(xtt_bak, axis=1)\n",
    "    \n",
    "    acc = np.mean(np.sum(xtt_bak[:,miss] == x2t[:,miss], axis=1))\n",
    "    accs_pca.append(acc/n)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = snpvae.enc(torch.from_numpy(xtt).float().cuda())\n",
    "        logits = snpvae.dec(z, sx, rc)\n",
    "        logits = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    acc = np.mean(np.sum(logits[:,miss] == x2t[:,miss], axis=1))\n",
    "    accs_vae.append(acc/n)\n",
    "\n",
    "    print(accs_pca[-1], accs_vae[-1])\n",
    "\n",
    "    # myaccs = []\n",
    "    \n",
    "    # for i in range(len(zr)):\n",
    "    #     with torch.no_grad():\n",
    "    #         zz = snpvae.gen(100)\n",
    "    #         sims1 = sim(zr[i:i+1].repeat([100,1]), zz)\n",
    "    #         sims2 = sim(zn[i:i+1].repeat([100,1]), zz)\n",
    "    #         sims3 = sim(ze[i:i+1].repeat([100,1]), zz)\n",
    "    #         sims = sims1+sims2+sims3\n",
    "\n",
    "    #         idcs = torch.argsort(sims, descending=True)\n",
    "    #         best = 0\n",
    "    #         for j in idcs[:50]:\n",
    "    #             logits = snpvae.dec(zz[j:j+1], sx[i:i+1], rc[i:i+1])\n",
    "    #             logits = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
    "    #             acc = np.sum(logits[0,miss] == x2t[i,miss])\n",
    "    #             if acc > best:\n",
    "    #                 best = acc\n",
    "    #         myaccs.append(best/n)\n",
    "\n",
    "    # print(np.mean(myaccs))\n",
    "\n",
    "print('---')\n",
    "print(np.mean(accs_pca))\n",
    "print(np.std(accs_pca))\n",
    "print(np.mean(accs_vae))\n",
    "print(np.std(accs_vae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ad0eb-cd91-4849-b514-bbeb98199716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
