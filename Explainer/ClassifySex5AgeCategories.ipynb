{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c20b41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load meta dict\n",
    "\n",
    "with open('../../PNC/MegaMeta.bin', 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "    \n",
    "print(len(list(meta.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53313e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Load splits\n",
    "\n",
    "with open('../../Work/Explainer/Splits/EmoidNbackWrat10FoldCV.pkl', 'rb') as f:\n",
    "    splits = pickle.load(f)\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c958f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558,)\n",
      "(62,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(len(np.concatenate([splits[0][0],splits[0][1]])))\n",
    "\n",
    "def getTrainTestIdcs(splits, splitId, makeTorch=True):\n",
    "    lookup = dict()\n",
    "    allSplit0Ids = np.concatenate([splits[0][0],splits[0][1]])\n",
    "    for i in range(620):\n",
    "        lookup[allSplit0Ids[i]] = i\n",
    "    trainIdcs = []\n",
    "    testIdcs = []\n",
    "    for key in splits[splitId][0]:\n",
    "        trainIdcs.append(lookup[key])\n",
    "    for key in splits[splitId][1]:\n",
    "        testIdcs.append(lookup[key])\n",
    "    trainIdcs = np.array(trainIdcs)\n",
    "    testIdcs = np.array(testIdcs)\n",
    "    if makeTorch:\n",
    "        trainIdcs = torch.from_numpy(trainIdcs).cuda()\n",
    "        testIdcs = torch.from_numpy(testIdcs).cuda()\n",
    "    return trainIdcs, testIdcs\n",
    "\n",
    "a,b = getTrainTestIdcs(splits, 4, False)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25966b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0\n",
      "Finished 100\n",
      "Finished 200\n",
      "Finished 300\n",
      "Finished 400\n",
      "Finished 500\n",
      "Finished 600\n",
      "Finished train 619\n"
     ]
    }
   ],
   "source": [
    "p_nback = np.zeros([620,264,264])\n",
    "p_emoid = np.zeros([620,264,264])\n",
    "age_class = np.zeros([620])\n",
    "ages = np.zeros([620])\n",
    "sexes = np.zeros([620],dtype='long')\n",
    "\n",
    "split0Ids = np.concatenate([splits[0][0],splits[0][1]])\n",
    "\n",
    "for i in np.arange(620):\n",
    "    subId = split0Ids[i]\n",
    "    p_nback[i] = np.corrcoef(meta[subId]['nbackData'])\n",
    "    p_emoid[i] = np.corrcoef(meta[subId]['emoidData'])\n",
    "    sex = meta[subId]['meta']['Gender']\n",
    "    if sex == 'M':\n",
    "        sexes[i] = 0\n",
    "    elif sex == 'F':\n",
    "        sexes[i] = 1\n",
    "    else:\n",
    "        raise Exception(f'bad sex {sex} for subject {subId}')\n",
    "    age = int(meta[subId]['meta']['AgeInMonths'])/12\n",
    "    if age < 8:\n",
    "        raise Exception(f'bad age {age} for subject {subId}')\n",
    "    elif age < 12:\n",
    "        age_class[i] = 0\n",
    "    elif age < 14:\n",
    "        age_class[i] = 1\n",
    "    elif age < 16:\n",
    "        age_class[i] = 2\n",
    "    elif age < 18:\n",
    "        age_class[i] = 3\n",
    "    elif age < 23:\n",
    "        age_class[i] = 4\n",
    "    else:\n",
    "        raise Exception(f'bad age {age} for subject {subId}')\n",
    "    ages[i] = age\n",
    "    if i % 100 == 0:\n",
    "        print(f'Finished {i}')\n",
    "        \n",
    "print(f'Finished train {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcc9e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(age_class, bins=5, histtype='step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a360ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([620, 139392])\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Convert to torch\n",
    "\n",
    "import torch\n",
    "\n",
    "p_nback_t = torch.from_numpy(p_nback).reshape(-1,264*264).float().cuda()\n",
    "p_emoid_t = torch.from_numpy(p_emoid).reshape(-1,264*264).float().cuda()\n",
    "sexes_t = torch.from_numpy(sexes).cuda()\n",
    "ages_t = torch.from_numpy(ages).float().cuda()\n",
    "\n",
    "feat_t = torch.cat([p_nback_t, p_emoid_t], dim=1)\n",
    "\n",
    "print(feat_t.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "248e1822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([110, 110])\n",
      "torch.Size([620, 620])\n",
      "epoch 0 loss=0.7086866497993469\n",
      "epoch 200 loss=0.5276670455932617\n",
      "epoch 400 loss=0.3400748074054718\n",
      "epoch 600 loss=0.2507993280887604\n",
      "epoch 800 loss=0.19032169878482819\n",
      "epoch 1000 loss=0.16103608906269073\n",
      "epoch 1200 loss=0.13406318426132202\n",
      "epoch 1400 loss=0.1211162582039833\n",
      "epoch 1600 loss=0.11279167979955673\n",
      "epoch 1800 loss=0.10442298650741577\n",
      "epoch 2000 loss=0.09801977872848511\n",
      "epoch 2200 loss=0.09040134400129318\n",
      "epoch 2400 loss=0.08180487155914307\n",
      "epoch 2600 loss=0.07556667178869247\n",
      "epoch 2800 loss=0.07193608582019806\n",
      "epoch 2999 loss=0.0698019340634346\n",
      "Complete GCN 7\n",
      "Correct 326 out of 510\n",
      "0.6392156862745098%\n"
     ]
    }
   ],
   "source": [
    "# For a small train and test set size we can expect accuracy to be between 50-65%\n",
    "\n",
    "Atrain = calcEdges(feat_t[0:110], feat_t[0:110]) + torch.eye(110).float().cuda()\n",
    "A = calcEdges(feat_t, feat_t) + torch.eye(620).float().cuda()\n",
    "\n",
    "print(Atrain.shape)\n",
    "print(A.shape)\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = nn.Linear(2*264*264,100).float().cuda()\n",
    "        self.gc2 = nn.Linear(100,2).float().cuda()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "#             self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        A = x[0]\n",
    "        z = x[1]\n",
    "        a = A@z\n",
    "        a = F.relu(self.gc1(a))\n",
    "        a = A@a\n",
    "        a = self.gc2(a)\n",
    "        return a\n",
    "    \n",
    "gcn = GCN()\n",
    "optim = torch.optim.Adam(gcn.parameters(), lr=1e-5, weight_decay=0.2)\n",
    "\n",
    "nEpoch = 3000 # 2000 for age pred, 3000 for sex classification\n",
    "pPrint = 200\n",
    "\n",
    "sexes_t_train = sexes_t[0:110]\n",
    "ages_t_train = ages_t[0:110]\n",
    "feat_t_train = feat_t[0:110]\n",
    "\n",
    "for epoch in range(nEpoch):\n",
    "    optim.zero_grad()\n",
    "    pred = gcn([Atrain,feat_t_train]).squeeze()\n",
    "    loss = gcn.loss(pred, sexes_t_train)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if epoch % pPrint == 0 or epoch == nEpoch-1:\n",
    "        print(f'epoch {epoch} loss={loss}')\n",
    "\n",
    "print(f'Complete GCN quick test')\n",
    "\n",
    "prob = gcn([A,feat_t]).squeeze()[110:].detach().cpu().numpy()\n",
    "y = sexes_t[110:].detach().cpu().numpy()\n",
    "pred = np.argmax(prob, axis=1)\n",
    "res = np.sum(pred == y)\n",
    "\n",
    "print(f'Correct {res} out of {y.shape[0]}')\n",
    "print(f'{res/y.shape[0]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec289fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([130, 130])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6879032850265503\n",
      "epoch 200 loss=0.412393182516098\n",
      "epoch 400 loss=0.2272118777036667\n",
      "epoch 600 loss=0.15324009954929352\n",
      "epoch 800 loss=0.1275622695684433\n",
      "epoch 1000 loss=0.11700189858675003\n",
      "epoch 1200 loss=0.10889285057783127\n",
      "epoch 1400 loss=0.10081732273101807\n",
      "epoch 1600 loss=0.0956365093588829\n",
      "epoch 1800 loss=0.0906781554222107\n",
      "epoch 2000 loss=0.08545796573162079\n",
      "epoch 2200 loss=0.08087798953056335\n",
      "epoch 2400 loss=0.07457595318555832\n",
      "epoch 2600 loss=0.07153423130512238\n",
      "epoch 2800 loss=0.06909450888633728\n",
      "epoch 2999 loss=0.06668110191822052\n",
      "Complete GCN 0\n",
      "Correct 7 out of 10\n",
      "epoch 0 loss=0.7037715315818787\n",
      "epoch 200 loss=0.06136135011911392\n",
      "epoch 400 loss=0.043328657746315\n",
      "epoch 600 loss=0.03817896544933319\n",
      "epoch 800 loss=0.035882458090782166\n",
      "epoch 999 loss=0.033946555107831955\n",
      "Complete MLP 0\n",
      "Correct 7 out of 10\n",
      "torch.Size([125, 125])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6848324537277222\n",
      "epoch 200 loss=0.318599671125412\n",
      "epoch 400 loss=0.15910594165325165\n",
      "epoch 600 loss=0.11415471136569977\n",
      "epoch 800 loss=0.10078046470880508\n",
      "epoch 1000 loss=0.08377805352210999\n",
      "epoch 1200 loss=0.07855308055877686\n",
      "epoch 1400 loss=0.07454349100589752\n",
      "epoch 1600 loss=0.07166307419538498\n",
      "epoch 1800 loss=0.0684119164943695\n",
      "epoch 2000 loss=0.06590230017900467\n",
      "epoch 2200 loss=0.060352127999067307\n",
      "epoch 2400 loss=0.05872222036123276\n",
      "epoch 2600 loss=0.05471957474946976\n",
      "epoch 2800 loss=0.05395617336034775\n",
      "epoch 2999 loss=0.05208370089530945\n",
      "Complete GCN 1\n",
      "Correct 13 out of 15\n",
      "epoch 0 loss=0.7161657810211182\n",
      "epoch 200 loss=0.06073225289583206\n",
      "epoch 400 loss=0.042126044631004333\n",
      "epoch 600 loss=0.03685054928064346\n",
      "epoch 800 loss=0.034299205988645554\n",
      "epoch 999 loss=0.03311615064740181\n",
      "Complete MLP 1\n",
      "Correct 12 out of 15\n",
      "torch.Size([130, 130])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.7265794277191162\n",
      "epoch 200 loss=0.45942461490631104\n",
      "epoch 400 loss=0.23696042597293854\n",
      "epoch 600 loss=0.14602579176425934\n",
      "epoch 800 loss=0.11789499223232269\n",
      "epoch 1000 loss=0.10345979779958725\n",
      "epoch 1200 loss=0.0957900881767273\n",
      "epoch 1400 loss=0.08799243718385696\n",
      "epoch 1600 loss=0.08294001966714859\n",
      "epoch 1800 loss=0.07937502861022949\n",
      "epoch 2000 loss=0.07541412115097046\n",
      "epoch 2200 loss=0.0709989070892334\n",
      "epoch 2400 loss=0.06574089080095291\n",
      "epoch 2600 loss=0.06442314386367798\n",
      "epoch 2800 loss=0.06255412846803665\n",
      "epoch 2999 loss=0.05988120287656784\n",
      "Complete GCN 2\n",
      "Correct 7 out of 10\n",
      "epoch 0 loss=0.6800096035003662\n",
      "epoch 200 loss=0.05870239436626434\n",
      "epoch 400 loss=0.04450332373380661\n",
      "epoch 600 loss=0.03910231590270996\n",
      "epoch 800 loss=0.03792482987046242\n",
      "epoch 999 loss=0.035538434982299805\n",
      "Complete MLP 2\n",
      "Correct 7 out of 10\n",
      "torch.Size([122, 122])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6773888468742371\n",
      "epoch 200 loss=0.3434891402721405\n",
      "epoch 400 loss=0.14926055073738098\n",
      "epoch 600 loss=0.09130845218896866\n",
      "epoch 800 loss=0.07816200703382492\n",
      "epoch 1000 loss=0.07206572592258453\n",
      "epoch 1200 loss=0.06721363961696625\n",
      "epoch 1400 loss=0.06465743482112885\n",
      "epoch 1600 loss=0.061279602348804474\n",
      "epoch 1800 loss=0.05911393091082573\n",
      "epoch 2000 loss=0.059343382716178894\n",
      "epoch 2200 loss=0.05588851869106293\n",
      "epoch 2400 loss=0.05366984382271767\n",
      "epoch 2600 loss=0.06126140430569649\n",
      "epoch 2800 loss=0.04626796394586563\n",
      "epoch 2999 loss=0.04543500393629074\n",
      "Complete GCN 3\n",
      "Correct 9 out of 18\n",
      "epoch 0 loss=0.6902561783790588\n",
      "epoch 200 loss=0.05315191298723221\n",
      "epoch 400 loss=0.039090465754270554\n",
      "epoch 600 loss=0.035149767994880676\n",
      "epoch 800 loss=0.032528284937143326\n",
      "epoch 999 loss=0.031588613986968994\n",
      "Complete MLP 3\n",
      "Correct 10 out of 18\n",
      "torch.Size([124, 124])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.7236462235450745\n",
      "epoch 200 loss=0.4538238048553467\n",
      "epoch 400 loss=0.2313949018716812\n",
      "epoch 600 loss=0.16235195100307465\n",
      "epoch 800 loss=0.13977985084056854\n",
      "epoch 1000 loss=0.1233573853969574\n",
      "epoch 1200 loss=0.10463118553161621\n",
      "epoch 1400 loss=0.0935601219534874\n",
      "epoch 1600 loss=0.08708275854587555\n",
      "epoch 1800 loss=0.08008208870887756\n",
      "epoch 2000 loss=0.07660900056362152\n",
      "epoch 2200 loss=0.07370766252279282\n",
      "epoch 2400 loss=0.06655330210924149\n",
      "epoch 2600 loss=0.06478618830442429\n",
      "epoch 2800 loss=0.0636470839381218\n",
      "epoch 2999 loss=0.06197277829051018\n",
      "Complete GCN 4\n",
      "Correct 12 out of 16\n",
      "epoch 0 loss=0.6953046321868896\n",
      "epoch 200 loss=0.05957837402820587\n",
      "epoch 400 loss=0.04046539217233658\n",
      "epoch 600 loss=0.036770906299352646\n",
      "epoch 800 loss=0.03369126468896866\n",
      "epoch 999 loss=0.03263957425951958\n",
      "Complete MLP 4\n",
      "Correct 12 out of 16\n",
      "torch.Size([124, 124])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6788442730903625\n",
      "epoch 200 loss=0.34342941641807556\n",
      "epoch 400 loss=0.1733091175556183\n",
      "epoch 600 loss=0.113363116979599\n",
      "epoch 800 loss=0.08698692917823792\n",
      "epoch 1000 loss=0.07351993024349213\n",
      "epoch 1200 loss=0.0673743337392807\n",
      "epoch 1400 loss=0.06322723627090454\n",
      "epoch 1600 loss=0.23173484206199646\n",
      "epoch 1800 loss=0.06454338878393173\n",
      "epoch 2000 loss=0.06065559387207031\n",
      "epoch 2200 loss=0.05688804015517235\n",
      "epoch 2400 loss=0.05744889751076698\n",
      "epoch 2600 loss=0.05138494074344635\n",
      "epoch 2800 loss=0.050590384751558304\n",
      "epoch 2999 loss=0.04796518757939339\n",
      "Complete GCN 5\n",
      "Correct 11 out of 16\n",
      "epoch 0 loss=0.684512734413147\n",
      "epoch 200 loss=0.06643030047416687\n",
      "epoch 400 loss=0.05153911933302879\n",
      "epoch 600 loss=0.043808240443468094\n",
      "epoch 800 loss=0.036764372140169144\n",
      "epoch 999 loss=0.03470924124121666\n",
      "Complete MLP 5\n",
      "Correct 11 out of 16\n",
      "torch.Size([125, 125])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6808046698570251\n",
      "epoch 200 loss=0.3501751720905304\n",
      "epoch 400 loss=0.15515802800655365\n",
      "epoch 600 loss=0.10659947991371155\n",
      "epoch 800 loss=0.09198442846536636\n",
      "epoch 1000 loss=0.08375304192304611\n",
      "epoch 1200 loss=0.07915104180574417\n",
      "epoch 1400 loss=0.07411860674619675\n",
      "epoch 1600 loss=0.0710575133562088\n",
      "epoch 1800 loss=0.06930302828550339\n",
      "epoch 2000 loss=0.06764400005340576\n",
      "epoch 2200 loss=0.06045544147491455\n",
      "epoch 2400 loss=0.057359274476766586\n",
      "epoch 2600 loss=0.05457764118909836\n",
      "epoch 2800 loss=0.05165841802954674\n",
      "epoch 2999 loss=0.05134071037173271\n",
      "Complete GCN 6\n",
      "Correct 12 out of 15\n",
      "epoch 0 loss=0.7203331589698792\n",
      "epoch 200 loss=0.06723832339048386\n",
      "epoch 400 loss=0.047778937965631485\n",
      "epoch 600 loss=0.042263213545084\n",
      "epoch 800 loss=0.03964589536190033\n",
      "epoch 999 loss=0.03752419725060463\n",
      "Complete MLP 6\n",
      "Correct 12 out of 15\n",
      "torch.Size([124, 124])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6936479210853577\n",
      "epoch 200 loss=0.501981794834137\n",
      "epoch 400 loss=0.2627975046634674\n",
      "epoch 600 loss=0.15042448043823242\n",
      "epoch 800 loss=0.12390845268964767\n",
      "epoch 1000 loss=0.10173608362674713\n",
      "epoch 1200 loss=0.08730419725179672\n",
      "epoch 1400 loss=0.08102661371231079\n",
      "epoch 1600 loss=0.0771794244647026\n",
      "epoch 1800 loss=0.07525302469730377\n",
      "epoch 2000 loss=0.07095383107662201\n",
      "epoch 2200 loss=0.06709633022546768\n",
      "epoch 2400 loss=0.06381701678037643\n",
      "epoch 2600 loss=0.06163850799202919\n",
      "epoch 2800 loss=0.05953913554549217\n",
      "epoch 2999 loss=0.05778010934591293\n",
      "Complete GCN 7\n",
      "Correct 13 out of 16\n",
      "epoch 0 loss=0.6848725080490112\n",
      "epoch 200 loss=0.053169913589954376\n",
      "epoch 400 loss=0.04347100108861923\n",
      "epoch 600 loss=0.04019627347588539\n",
      "epoch 800 loss=0.03601016104221344\n",
      "epoch 999 loss=0.03464676812291145\n",
      "Complete MLP 7\n",
      "Correct 14 out of 16\n",
      "torch.Size([134, 134])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6836128234863281\n",
      "epoch 200 loss=0.3321548104286194\n",
      "epoch 400 loss=0.16025035083293915\n",
      "epoch 600 loss=0.10536554455757141\n",
      "epoch 800 loss=0.0900956317782402\n",
      "epoch 1000 loss=0.08245378732681274\n",
      "epoch 1200 loss=0.07715488970279694\n",
      "epoch 1400 loss=0.0722769945859909\n",
      "epoch 1600 loss=0.06904353946447372\n",
      "epoch 1800 loss=0.06628655642271042\n",
      "epoch 2000 loss=0.06456974893808365\n",
      "epoch 2200 loss=0.06151258572936058\n",
      "epoch 2400 loss=0.057003602385520935\n",
      "epoch 2600 loss=0.05594421550631523\n",
      "epoch 2800 loss=0.0535808727145195\n",
      "epoch 2999 loss=0.0521870031952858\n",
      "Complete GCN 8\n",
      "Correct 5 out of 6\n",
      "epoch 0 loss=0.7066867351531982\n",
      "epoch 200 loss=0.04938390478491783\n",
      "epoch 400 loss=0.03998352587223053\n",
      "epoch 600 loss=0.03623071685433388\n",
      "epoch 800 loss=0.033520057797431946\n",
      "epoch 999 loss=0.03137638047337532\n",
      "Complete MLP 8\n",
      "Correct 5 out of 6\n",
      "torch.Size([122, 122])\n",
      "torch.Size([140, 140])\n",
      "epoch 0 loss=0.6823713183403015\n",
      "epoch 200 loss=0.34899473190307617\n",
      "epoch 400 loss=0.15357020497322083\n",
      "epoch 600 loss=0.09949232637882233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 800 loss=0.08087141811847687\n",
      "epoch 1000 loss=0.07171343266963959\n",
      "epoch 1200 loss=0.0662323608994484\n",
      "epoch 1400 loss=0.06225023791193962\n",
      "epoch 1600 loss=0.05937856808304787\n",
      "epoch 1800 loss=0.056283123791217804\n",
      "epoch 2000 loss=0.05446283891797066\n",
      "epoch 2200 loss=0.0706624984741211\n",
      "epoch 2400 loss=0.06198384240269661\n",
      "epoch 2600 loss=0.056919705122709274\n",
      "epoch 2800 loss=0.054728180170059204\n",
      "epoch 2999 loss=0.05402395501732826\n",
      "Complete GCN 9\n",
      "Correct 14 out of 18\n",
      "epoch 0 loss=0.6916165947914124\n",
      "epoch 200 loss=0.05448877066373825\n",
      "epoch 400 loss=0.04162682592868805\n",
      "epoch 600 loss=0.036715298891067505\n",
      "epoch 800 loss=0.033692821860313416\n",
      "epoch 999 loss=0.032551299780607224\n",
      "Complete MLP 9\n",
      "Correct 14 out of 18\n",
      "[ 7. 13.  7.  9. 12. 11. 12. 13.  5. 14.]\n",
      "[ 7. 12.  7. 10. 12. 11. 12. 14.  5. 14.]\n",
      "[10. 15. 10. 18. 16. 16. 15. 16.  6. 18.]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ageCls = 4\n",
    "outputDir = f'ClassifySex5AgeCategories/AgeGroup{ageCls}'\n",
    "\n",
    "nCorrectGCN = np.zeros(10)\n",
    "nCorrectMLP = np.zeros(10)\n",
    "nTotal = np.zeros(10)\n",
    "\n",
    "for split in range(10):\n",
    "    trainIdcsAll, testIdcsAll = getTrainTestIdcs(splits, split, True)\n",
    "    \n",
    "    allIdcs = np.argwhere(age_class == ageCls).flatten()\n",
    "    \n",
    "    idcs = np.intersect1d(allIdcs, trainIdcsAll.detach().cpu().numpy())\n",
    "    trainIdcs = torch.from_numpy(idcs).cuda()\n",
    "    \n",
    "    idcs = np.intersect1d(allIdcs, testIdcsAll.detach().cpu().numpy())\n",
    "    testIdcs = torch.from_numpy(idcs).cuda()\n",
    "    \n",
    "    idcs = np.argwhere(np.isin(allIdcs, idcs)).flatten()\n",
    "    testIdcsReindexed = torch.from_numpy(idcs).cuda()\n",
    "    \n",
    "    allIdcs = torch.from_numpy(allIdcs).cuda()\n",
    "\n",
    "    def normalize(A):\n",
    "        if A.shape[0] != A.shape[1]:\n",
    "            raise Exception(\"Bad A shape\")\n",
    "        d = torch.sum(A,dim=1)**0.5\n",
    "        return ((A/d).T/d).T\n",
    "\n",
    "    # Cosine similarity\n",
    "    def calcEdges(ps1, ps2):\n",
    "        nB = ps1.shape[0]\n",
    "        e = torch.einsum('ai,bi->ab',ps1,ps2)\n",
    "        F1 = torch.einsum('ai,ai->a',ps1,ps1)**0.5\n",
    "        F2 = torch.einsum('ai,ai->a',ps2,ps2)**0.5\n",
    "        e /= F1.unsqueeze(1)\n",
    "        e /= F2.unsqueeze(1).T\n",
    "    #     e = torch.einsum('aij,bij->ab',ps1,ps2)\n",
    "    #     F1 = torch.einsum('aij,aij->a',ps1,ps1)**0.5\n",
    "    #     F2 = torch.einsum('aij,aij->a',ps2,ps2)**0.5\n",
    "    #     e /= F1.unsqueeze(1)\n",
    "    #     e /= F2.unsqueeze(1).T\n",
    "        return normalize(e-torch.eye(nB).float().cuda())\n",
    "\n",
    "    Atrain = calcEdges(feat_t[trainIdcs], feat_t[trainIdcs]) + torch.eye(trainIdcs.shape[0]).float().cuda()\n",
    "    A = calcEdges(feat_t[allIdcs], feat_t[allIdcs]) + torch.eye(allIdcs.shape[0]).float().cuda()\n",
    "\n",
    "    print(Atrain.shape)\n",
    "    print(A.shape)\n",
    "\n",
    "    class GCN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(GCN, self).__init__()\n",
    "            self.gc1 = nn.Linear(2*264*264,100).float().cuda()\n",
    "            self.gc2 = nn.Linear(100,2).float().cuda()\n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "#             self.loss = nn.MSELoss()\n",
    "\n",
    "        def forward(self, x):\n",
    "            A = x[0]\n",
    "            z = x[1]\n",
    "            a = A@z\n",
    "            a = F.relu(self.gc1(a))\n",
    "            a = A@a\n",
    "            a = self.gc2(a)\n",
    "            return a\n",
    "\n",
    "    gcn = GCN()\n",
    "    optim = torch.optim.Adam(gcn.parameters(), lr=1e-5, weight_decay=0.2)\n",
    "\n",
    "    nEpoch = 3000 # 2000 for age pred, 3000 for sex classification\n",
    "    pPrint = 200\n",
    "\n",
    "    sexes_t_train = sexes_t[trainIdcs]\n",
    "    ages_t_train = ages_t[trainIdcs]\n",
    "    feat_t_train = feat_t[trainIdcs]\n",
    "\n",
    "    for epoch in range(nEpoch):\n",
    "        optim.zero_grad()\n",
    "        pred = gcn([Atrain,feat_t_train]).squeeze()\n",
    "        loss = gcn.loss(pred, sexes_t_train)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if epoch % pPrint == 0 or epoch == nEpoch-1:\n",
    "            print(f'epoch {epoch} loss={loss}')\n",
    "\n",
    "    print(f'Complete GCN {split}')\n",
    "    \n",
    "    torch.save(gcn.state_dict(), f'../../Work/Explainer/Models/{outputDir}/gcn{split}.pkl')\n",
    "    \n",
    "    prob = gcn([A,feat_t[allIdcs]]).squeeze()[testIdcsReindexed].detach().cpu().numpy()\n",
    "    y = sexes_t[testIdcs].detach().cpu().numpy()\n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    res = np.sum(pred == y)\n",
    "\n",
    "    print(f'Correct {res} out of {y.shape[0]}')\n",
    "    \n",
    "    nCorrectGCN[split] = res\n",
    "    \n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(2*264*264,100).float().cuda()\n",
    "            self.fc2 = nn.Linear(100,2).float().cuda()\n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "#             self.loss = nn.MSELoss()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    mlp = MLP()\n",
    "    optim = torch.optim.Adam(mlp.parameters(), lr=2e-5, weight_decay=0.2)\n",
    "\n",
    "    nEpoch = 1000\n",
    "    pPrint = 200\n",
    "\n",
    "    for epoch in range(nEpoch):\n",
    "        optim.zero_grad()\n",
    "        pred = mlp(feat_t_train).squeeze()\n",
    "        loss = mlp.loss(pred, sexes_t_train)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if epoch % pPrint == 0 or epoch == nEpoch-1:\n",
    "            print(f'epoch {epoch} loss={loss}')\n",
    "\n",
    "    print(f'Complete MLP {split}')\n",
    "    \n",
    "    torch.save(mlp.state_dict(), f'../../Work/Explainer/Models/{outputDir}/mlp{split}.pkl')\n",
    "\n",
    "    prob = mlp(feat_t[allIdcs]).squeeze()[testIdcsReindexed].detach().cpu().numpy()\n",
    "    y = sexes_t[testIdcs].detach().cpu().numpy()\n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    res = np.sum(pred == y)\n",
    "\n",
    "    print(f'Correct {res} out of {y.shape[0]}')\n",
    "    \n",
    "    nCorrectMLP[split] = res\n",
    "    nTotal[split] = y.shape[0]\n",
    "    \n",
    "print(nCorrectGCN)\n",
    "print(nCorrectMLP)\n",
    "print(nTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77f20a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357142857142858"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(nCorrectGCN)/np.sum(nTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7bffb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7428571428571429"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(nCorrectMLP)/np.sum(nTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9209b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
