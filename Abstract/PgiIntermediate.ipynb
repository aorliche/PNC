{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4966fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load meta dict\n",
    "\n",
    "with open('../../PNC/AllSubjectsMeta.bin', 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "    \n",
    "# Load rest subject ids and splits\n",
    "\n",
    "with open('../../Work/Abstract/PaperBin/AllThreeSplit.bin', 'rb') as f:\n",
    "    splits = pickle.load(f)\n",
    "    subids = splits['allThreeYesWrat']\n",
    "    groups = splits['groups']\n",
    "    \n",
    "print(len(subids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1bb392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "subidsNp = np.array(subids)\n",
    "\n",
    "# Load timeseries\n",
    "\n",
    "def loadSeries(prefix, para, idx):\n",
    "    with open('{:}/{:}_fmri_power264/timeseries/{:}.bin'.format(prefix, para, idx), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "rest_ts = [loadSeries('../../PNC', 'rest', meta[subid]['rest']) for subid in subidsNp]\n",
    "nback_ts = [loadSeries('../../PNC', 'nback', meta[subid]['nback']) for subid in subidsNp]\n",
    "emoid_ts = [loadSeries('../../PNC', 'emoid', meta[subid]['emoid']) for subid in subidsNp]\n",
    "\n",
    "print('Loading complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac3044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalizeSubjects(subjects):\n",
    "    for i in range(len(subjects)):\n",
    "        subj = subjects[i]\n",
    "        subj -= np.mean(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        subj /= np.std(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        if np.sum(np.isnan(subj)) > 0:\n",
    "            print(i)\n",
    "        if np.sum(np.isinf(subj)) > 0:\n",
    "            print(i)\n",
    "\n",
    "normalizeSubjects(rest_ts)\n",
    "normalizeSubjects(nback_ts)\n",
    "normalizeSubjects(emoid_ts)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5f1911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 264, 264)\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Calculate pearson matrices\n",
    "\n",
    "rest_p = np.stack([np.corrcoef(sub) for sub in rest_ts])\n",
    "nback_p = np.stack([np.corrcoef(sub) for sub in nback_ts])\n",
    "emoid_p = np.stack([np.corrcoef(sub) for sub in emoid_ts])\n",
    "\n",
    "print(rest_p.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308b9679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 322\n",
      "[[223   1   0]\n",
      " [190   0   1]\n",
      " [197   0   1]\n",
      " [145   1   0]\n",
      " [148   0   1]\n",
      " [142   0   1]\n",
      " [123   1   0]\n",
      " [176   1   0]\n",
      " [129   0   1]\n",
      " [173   1   0]]\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors (right now just ages, maleness, and femaless)\n",
    "\n",
    "males = 0\n",
    "females = 0\n",
    "\n",
    "X_all = []\n",
    "for subid in subidsNp:\n",
    "    subj = meta[subid]\n",
    "    maleness = 1 if subj['meta']['Gender'] == 'M' else 0\n",
    "    femaleness = 1 if maleness == 0 else 0\n",
    "    feat = np.array([subj['meta']['AgeInMonths'], maleness, femaleness])\n",
    "    X_all.append(feat)\n",
    "    if maleness == 1:\n",
    "        males += 1\n",
    "    if femaleness == 1:\n",
    "        females += 1\n",
    "X_all = np.vstack(X_all)\n",
    "\n",
    "print(f'{males} {females}')\n",
    "print(X_all[10:20])\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24cdbb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([593, 34716])\n",
      "torch.Size([593, 34716])\n",
      "torch.Size([593, 34716])\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def convertTorch(p):\n",
    "    t = torch.from_numpy(p).float()\n",
    "    u = []\n",
    "    for i in range(t.shape[0]):\n",
    "        u.append(t[i][torch.triu_indices(264,264,offset=1).unbind()])\n",
    "    return torch.stack(u).cuda()\n",
    "\n",
    "rest_p_t = convertTorch(rest_p)\n",
    "nback_p_t = convertTorch(nback_p)\n",
    "emoid_p_t = convertTorch(emoid_p)\n",
    "\n",
    "print(rest_p_t.shape)\n",
    "print(nback_p_t.shape)\n",
    "print(emoid_p_t.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbace03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "wratDict = dict()\n",
    "\n",
    "with open('../../PNC/wrat.csv', 'r') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        wratDict[line[0]] = {'raw': line[2], 'std': line[3]}\n",
    "\n",
    "wrat = []\n",
    "\n",
    "for key in subids:\n",
    "    wrat.append(float(wratDict[str(key)]['std']))\n",
    "    \n",
    "wrat = np.array(wrat)\n",
    "wrat_t = torch.from_numpy(wrat).float().cuda()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511082b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def makePoly(ps):\n",
    "    pps = []\n",
    "    for i in range(ps.shape[0]):\n",
    "        p = ps[i].flatten()\n",
    "        pp = nPoly*[None]\n",
    "        for j in range(nPoly):\n",
    "            pp[j] = p**(j+1)\n",
    "        pps.append(torch.stack(pp))\n",
    "    return torch.stack(pps)\n",
    "\n",
    "def arith(n):\n",
    "    return int(n*(n+1)/2)\n",
    "\n",
    "def mask(e):\n",
    "    return e - torch.diag(torch.diag(e))\n",
    "\n",
    "class MiniPgi(nn.Module):\n",
    "    def __init__(self, w, nPara, nPoly, nTgts, dp=0.5, relu=0.1):\n",
    "        super(MiniPgi, self).__init__()\n",
    "        self.masks = []\n",
    "        if type(w) == int:\n",
    "            w = nTgts*[w]\n",
    "        for i in range(nTgts):\n",
    "            self.masks.append(nn.Parameter(\n",
    "                0.01*torch.ones(nPara,nPoly,arith(263),w[i]).float().cuda()\n",
    "                +0.001*torch.randn(nPara,nPoly,arith(263),w[i]).float().cuda()\n",
    "            ))\n",
    "        self.dp = nn.Dropout(p=dp)\n",
    "        self.relu = []\n",
    "        for i in range(nTgts):\n",
    "            rel = relu if type(relu) == float or type(relu) == int else relu[i]\n",
    "            self.relu.append(nn.LeakyReLU(negative_slope=rel))\n",
    "    \n",
    "    def getLatentsAndEdges(self, x, idx):\n",
    "        y = torch.einsum('abcd,bcde->ae', x, self.masks[idx])\n",
    "        e = y@y.T\n",
    "        return y, e\n",
    "        \n",
    "    def forward(self, x, age=None, gender=None, wrat=None):\n",
    "        x = self.dp(x)\n",
    "        lbls = [age, gender, wrat]\n",
    "        res = []\n",
    "        ss = []\n",
    "        for i,lbl in enumerate(lbls):\n",
    "            _, e = self.getLatentsAndEdges(x, i)\n",
    "            idcs = torch.logical_not(torch.any(lbl, dim=1))\n",
    "            e[:,idcs] = 0\n",
    "            e = self.relu[i](mask(e))\n",
    "            s = torch.sum(e, dim=1)\n",
    "            e = e/s.unsqueeze(1)\n",
    "            res.append(e@lbl)\n",
    "            ss.append(s)\n",
    "        return res, ss\n",
    "        \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "205644ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=(1591.887939453125, 0.6936230063438416, 257.26080322265625, 9.615461349487305)\n",
      "epoch 200 loss=(1572.80224609375, 0.6936047077178955, 257.26019287109375, 5.83980131149292)\n",
      "epoch 400 loss=(1569.08837890625, 0.6936105489730835, 257.260498046875, 4.937052249908447)\n",
      "epoch 600 loss=(1060.85595703125, 0.6936168074607849, 257.26080322265625, 16.621685028076172)\n",
      "epoch 800 loss=(436.553466796875, 0.6936041712760925, 257.25714111328125, 32.35264205932617)\n",
      "epoch 1000 loss=(261.0439147949219, 0.6936041712760925, 257.2572326660156, 38.61881637573242)\n",
      "epoch 1200 loss=(205.9494171142578, 0.693602442741394, 257.2554626464844, 40.3409309387207)\n",
      "epoch 1400 loss=(171.29598999023438, 0.6935980916023254, 257.2557373046875, 40.86528396606445)\n",
      "epoch 1600 loss=(146.37510681152344, 0.6935871839523315, 257.2554016113281, 41.766029357910156)\n",
      "epoch 1800 loss=(129.70065307617188, 0.6935849189758301, 257.2554016113281, 41.91110610961914)\n",
      "epoch 2000 loss=(115.4173355102539, 0.6935838460922241, 257.2526550292969, 42.68148422241211)\n",
      "epoch 2200 loss=(103.48609161376953, 0.693572461605072, 257.25177001953125, 42.109954833984375)\n",
      "epoch 2400 loss=(97.01622009277344, 0.69356769323349, 257.253173828125, 41.25725555419922)\n",
      "epoch 2600 loss=(95.60383605957031, 0.6935650110244751, 257.25140380859375, 40.85061264038086)\n",
      "epoch 2800 loss=(90.58234405517578, 0.6935523152351379, 257.2498474121094, 39.974334716796875)\n",
      "epoch 3000 loss=(84.7747573852539, 0.6935601234436035, 257.2515869140625, 39.7705078125)\n",
      "epoch 3200 loss=(82.01751708984375, 0.6935374140739441, 257.2489318847656, 38.58122253417969)\n",
      "epoch 3400 loss=(78.21044921875, 0.6935281753540039, 257.2503356933594, 37.40296173095703)\n",
      "epoch 3600 loss=(76.69928741455078, 0.6935362219810486, 257.2505798339844, 37.37344741821289)\n",
      "epoch 3800 loss=(77.80781555175781, 0.6935185194015503, 257.2492980957031, 35.99244689941406)\n",
      "epoch 4000 loss=(71.44562530517578, 0.6935153603553772, 257.2488708496094, 35.22526550292969)\n",
      "epoch 4200 loss=(70.98631286621094, 0.6935127377510071, 257.2484130859375, 34.90047836303711)\n",
      "epoch 4400 loss=(70.49016571044922, 0.6935059428215027, 257.2475891113281, 34.1181755065918)\n",
      "epoch 4600 loss=(67.11158752441406, 0.6934999823570251, 257.24725341796875, 33.862728118896484)\n",
      "epoch 4800 loss=(66.95136260986328, 0.6934957504272461, 257.2471923828125, 33.397647857666016)\n",
      "epoch 5000 loss=(64.82342529296875, 0.6934859752655029, 257.2470703125, 32.37627410888672)\n",
      "epoch 5200 loss=(63.66804885864258, 0.6934806704521179, 257.24639892578125, 31.83327293395996)\n",
      "epoch 5400 loss=(63.74829864501953, 0.6934836506843567, 257.24859619140625, 31.179128646850586)\n",
      "epoch 5600 loss=(61.757110595703125, 0.6934816837310791, 257.2463684082031, 31.447059631347656)\n",
      "epoch 5800 loss=(63.02570343017578, 0.6934680342674255, 257.2477111816406, 30.615806579589844)\n",
      "epoch 6000 loss=(57.92658615112305, 0.6934610605239868, 257.24566650390625, 30.265544891357422)\n",
      "epoch 6200 loss=(62.90116500854492, 0.6934706568717957, 257.2478332519531, 29.760211944580078)\n",
      "epoch 6400 loss=(58.95473098754883, 0.6934661865234375, 257.2463073730469, 28.96377182006836)\n",
      "epoch 6600 loss=(58.534271240234375, 0.6934579610824585, 257.2486877441406, 28.814287185668945)\n",
      "epoch 6800 loss=(61.1739616394043, 0.6934533715248108, 257.2467041015625, 28.674318313598633)\n",
      "epoch 7000 loss=(56.96392822265625, 0.6934629082679749, 257.24737548828125, 28.2744140625)\n",
      "epoch 7200 loss=(57.185630798339844, 0.693452775478363, 257.2464904785156, 28.136314392089844)\n",
      "epoch 7400 loss=(56.93050765991211, 0.6934497952461243, 257.2474365234375, 27.56900978088379)\n",
      "epoch 7600 loss=(58.50218963623047, 0.6934532523155212, 257.24700927734375, 26.991689682006836)\n",
      "epoch 7800 loss=(55.489418029785156, 0.6934568285942078, 257.2473449707031, 27.009723663330078)\n",
      "epoch 8000 loss=(56.8726921081543, 0.6934540867805481, 257.24713134765625, 26.567148208618164)\n",
      "epoch 8200 loss=(54.28931427001953, 0.6934534907341003, 257.2474670410156, 26.215242385864258)\n",
      "epoch 8400 loss=(54.24256134033203, 0.6934576034545898, 257.2469482421875, 26.04875946044922)\n",
      "epoch 8600 loss=(54.764957427978516, 0.6934471130371094, 257.2464294433594, 25.913015365600586)\n",
      "epoch 8800 loss=(54.470008850097656, 0.6934548616409302, 257.2463684082031, 25.27781867980957)\n",
      "epoch 9000 loss=(53.94215774536133, 0.6934494972229004, 257.2452697753906, 25.36366081237793)\n",
      "epoch 9200 loss=(51.531124114990234, 0.693455696105957, 257.2452392578125, 24.994056701660156)\n",
      "epoch 9400 loss=(55.05295944213867, 0.6934625506401062, 257.2448425292969, 24.60296058654785)\n",
      "epoch 9600 loss=(52.26982498168945, 0.6934431195259094, 257.2386169433594, 24.515424728393555)\n",
      "epoch 9800 loss=(51.52963638305664, 0.6934502124786377, 257.2230529785156, 23.938119888305664)\n",
      "epoch 9999 loss=(50.20268630981445, 0.6934438943862915, 257.19085693359375, 24.159610748291016)\n",
      "Finished training\n",
      "0 (24.375732421875, 0.6500000357627869, 14.648987770080566)\n"
     ]
    }
   ],
   "source": [
    "ceLoss = torch.nn.CrossEntropyLoss()\n",
    "mseLoss = torch.nn.MSELoss()\n",
    "nEpochs = 10000\n",
    "pPeriod = 200\n",
    "thresh = torch.Tensor((40,3.2e-1,20)).float().cuda()\n",
    "\n",
    "nPoly = 1\n",
    "para = [makePoly(nback_p_t), makePoly(emoid_p_t)]\n",
    "    \n",
    "rmse = []\n",
    "\n",
    "for i in range(1):\n",
    "    pgigcn = MiniPgi((10, 20, 20), len(para), nPoly, 3, 0.5, (0, 0, 0))\n",
    "    optim = torch.optim.Adam(pgigcn.masks, lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "    trainIdcs = groups[i][0]\n",
    "    testIdcs = groups[i][1]\n",
    "    \n",
    "    X = torch.stack(para, dim=1)\n",
    "    X = X[trainIdcs]\n",
    "    Y = torch.from_numpy(X_all[trainIdcs]).float().cuda()\n",
    "    \n",
    "    gen = Y[:,1:]\n",
    "    wrt = wrat_t[trainIdcs].unsqueeze(1)\n",
    "    age = Y[:,0].unsqueeze(1)\n",
    "    \n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        res, ss = pgigcn(X, age=age, gender=gen, wrat=wrt)\n",
    "        loss0 = mseLoss(res[0], age)\n",
    "        loss1 = ceLoss(res[1], gen)\n",
    "        loss2 = mseLoss(res[2], wrt)\n",
    "        loss = torch.stack([loss0, loss1, loss2])\n",
    "        lossR = 0\n",
    "        for s in ss:\n",
    "            lossR += 100*torch.sum((1/s)**0.5)\n",
    "        torch.sum(loss + lossR).backward()\n",
    "        optim.step()\n",
    "        if (epoch % pPeriod == 0 or epoch == nEpochs-1):\n",
    "            print(f'epoch {epoch} loss={(float(loss0), float(loss1), float(loss2), float(lossR))}')\n",
    "        if torch.all(loss < thresh):\n",
    "            print('Early stopping')\n",
    "            break\n",
    "            \n",
    "    print('Finished training')\n",
    "    \n",
    "    pgigcn.eval()\n",
    "    \n",
    "    X = torch.stack(para, dim=1)\n",
    "    Y = torch.from_numpy(X_all).float().cuda()\n",
    "        \n",
    "    gen = Y[:,1:]\n",
    "    wrt = wrat_t.unsqueeze(1)\n",
    "    age = Y[:,0].unsqueeze(1)\n",
    "\n",
    "    gen0 = gen.clone().detach()\n",
    "    gen0[testIdcs] = 0\n",
    "    wrt0 = wrt.clone().detach()\n",
    "    wrt0[testIdcs] = 0\n",
    "    age0 = age.clone().detach()\n",
    "    age0[testIdcs] = 0\n",
    "    \n",
    "    res, ss = pgigcn(X, age=age0, gender=gen0, wrat=wrt0)\n",
    "    loss0 = mseLoss(res[0][testIdcs].detach(), age[testIdcs]).cpu().numpy()**0.5\n",
    "    frac1 = torch.sum(torch.argmax(res[1].detach(), dim=1)[testIdcs] \n",
    "                     == torch.argmax(gen[testIdcs], dim=1))/testIdcs.shape[0]\n",
    "    loss2 = mseLoss(res[2][testIdcs].detach(), wrt[testIdcs]).cpu().numpy()**0.5\n",
    "    \n",
    "    rmse.append((float(loss0), float(frac1), float(loss2)))\n",
    "    print(i, end=' ')\n",
    "    print(rmse[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58e3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
