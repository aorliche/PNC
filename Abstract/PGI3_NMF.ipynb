{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48041cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load meta dict\n",
    "\n",
    "with open('../../PNC/AllSubjectsMeta.bin', 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "    \n",
    "# Load rest subject ids and splits\n",
    "\n",
    "with open('../../Work/Abstract/PaperBin/AllThreeSplit.bin', 'rb') as f:\n",
    "    splits = pickle.load(f)\n",
    "    subids = splits['allThreeYesWrat']\n",
    "    groups = splits['groups']\n",
    "    \n",
    "print(len(subids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7da4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "subidsNp = np.array(subids)\n",
    "\n",
    "# Load timeseries\n",
    "\n",
    "def loadSeries(prefix, para, idx):\n",
    "    with open('{:}/{:}_fmri_power264/timeseries/{:}.bin'.format(prefix, para, idx), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "rest_ts = [loadSeries('../../PNC', 'rest', meta[subid]['rest']) for subid in subidsNp]\n",
    "nback_ts = [loadSeries('../../PNC', 'nback', meta[subid]['nback']) for subid in subidsNp]\n",
    "emoid_ts = [loadSeries('../../PNC', 'emoid', meta[subid]['emoid']) for subid in subidsNp]\n",
    "\n",
    "print('Loading complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e1a412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalizeSubjects(subjects):\n",
    "    for i in range(len(subjects)):\n",
    "        subj = subjects[i]\n",
    "        subj -= np.mean(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        subj /= np.std(subj, axis=1, keepdims=True)@np.ones([1,subj.shape[1]])\n",
    "        if np.sum(np.isnan(subj)) > 0:\n",
    "            print(i)\n",
    "        if np.sum(np.isinf(subj)) > 0:\n",
    "            print(i)\n",
    "\n",
    "normalizeSubjects(rest_ts)\n",
    "normalizeSubjects(nback_ts)\n",
    "normalizeSubjects(emoid_ts)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87573fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 264, 264)\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Calculate pearson matrices\n",
    "\n",
    "rest_p = np.stack([np.corrcoef(sub) for sub in rest_ts])\n",
    "nback_p = np.stack([np.corrcoef(sub) for sub in nback_ts])\n",
    "emoid_p = np.stack([np.corrcoef(sub) for sub in emoid_ts])\n",
    "\n",
    "print(rest_p.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83eebb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 322\n",
      "[[223   1   0]\n",
      " [190   0   1]\n",
      " [197   0   1]\n",
      " [145   1   0]\n",
      " [148   0   1]\n",
      " [142   0   1]\n",
      " [123   1   0]\n",
      " [176   1   0]\n",
      " [129   0   1]\n",
      " [173   1   0]]\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors (right now just ages, maleness, and femaless)\n",
    "\n",
    "males = 0\n",
    "females = 0\n",
    "\n",
    "X_all = []\n",
    "for subid in subidsNp:\n",
    "    subj = meta[subid]\n",
    "    maleness = 1 if subj['meta']['Gender'] == 'M' else 0\n",
    "    femaleness = 1 if maleness == 0 else 0\n",
    "    feat = np.array([subj['meta']['AgeInMonths'], maleness, femaleness])\n",
    "    X_all.append(feat)\n",
    "    if maleness == 1:\n",
    "        males += 1\n",
    "    if femaleness == 1:\n",
    "        females += 1\n",
    "X_all = np.vstack(X_all)\n",
    "\n",
    "print(f'{males} {females}')\n",
    "print(X_all[10:20])\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03bee6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([593, 34716])\n",
      "torch.Size([593, 34716])\n",
      "torch.Size([593, 34716])\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def convertTorch(p):\n",
    "    t = torch.from_numpy(p).float()\n",
    "    u = []\n",
    "    for i in range(t.shape[0]):\n",
    "        u.append(t[i][torch.triu_indices(264,264,offset=1).unbind()])\n",
    "    return torch.stack(u).cuda()\n",
    "\n",
    "rest_p_t = convertTorch(rest_p)\n",
    "nback_p_t = convertTorch(nback_p)\n",
    "emoid_p_t = convertTorch(emoid_p)\n",
    "\n",
    "print(rest_p_t.shape)\n",
    "print(nback_p_t.shape)\n",
    "print(emoid_p_t.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36856b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "wratDict = dict()\n",
    "\n",
    "with open('../../PNC/wrat.csv', 'r') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "    for line in lines:\n",
    "        line = line.strip().split(',')\n",
    "        wratDict[line[0]] = {'raw': line[2], 'std': line[3]}\n",
    "\n",
    "wrat = []\n",
    "\n",
    "for key in subids:\n",
    "    wrat.append(float(wratDict[str(key)]['std']))\n",
    "    \n",
    "wrat = np.array(wrat)\n",
    "wrat_t = torch.from_numpy(wrat).float().cuda()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc9c688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def makePoly(ps):\n",
    "    pps = []\n",
    "    for i in range(ps.shape[0]):\n",
    "        p = ps[i].flatten()\n",
    "        pp = nPoly*[None]\n",
    "        for j in range(nPoly):\n",
    "            pp[j] = p**(j+1)\n",
    "        pps.append(torch.stack(pp))\n",
    "    return torch.stack(pps)\n",
    "\n",
    "def arith(n):\n",
    "    return int(n*(n+1)/2)\n",
    "\n",
    "def mask(e):\n",
    "    return e - torch.diag(torch.diag(e))\n",
    "\n",
    "class MiniPgi(nn.Module):\n",
    "    def __init__(self, w, nPara, nPoly, nTgts, dp=0.5, relu=0.1):\n",
    "        super(MiniPgi, self).__init__()\n",
    "        self.masks = []\n",
    "        if type(w) == int:\n",
    "            w = nTgts*[w]\n",
    "        for i in range(nTgts):\n",
    "            self.masks.append(nn.Parameter(\n",
    "                0.01*torch.ones(nPara,nPoly,arith(263),w[i]).float().cuda()\n",
    "                +0.001*torch.randn(nPara,nPoly,arith(263),w[i]).float().cuda()\n",
    "            ))\n",
    "        self.dp = nn.Dropout(p=dp)\n",
    "        self.relu = []\n",
    "        for i in range(nTgts):\n",
    "            rel = relu if type(relu) == float or type(relu) == int else relu[i]\n",
    "            self.relu.append(nn.LeakyReLU(negative_slope=rel))\n",
    "    \n",
    "    def getLatentsAndEdges(self, x, idx):\n",
    "        y = torch.einsum('abcd,bcde->ae', x, self.masks[idx])\n",
    "        e = y@y.T\n",
    "        return y, e\n",
    "        \n",
    "    def forward(self, x, age=None, gender=None, wrat=None):\n",
    "        x = self.dp(x)\n",
    "        lbls = [age, gender, wrat]\n",
    "        res = []\n",
    "        for i,lbl in enumerate(lbls):\n",
    "            _, e = self.getLatentsAndEdges(x, i)\n",
    "            idcs = torch.logical_not(torch.any(lbl, dim=1))\n",
    "            e[:,idcs] = 0\n",
    "            e = self.relu[i](mask(e))\n",
    "            s = torch.sum(e, dim=1)\n",
    "            e = e/s.unsqueeze(1)\n",
    "            res.append(e@lbl)\n",
    "        return res\n",
    "        \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b332369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=(1604.88671875, 0.6920773386955261, 257.2871398925781, 0.0)\n",
      "epoch 200 loss=(1599.9012451171875, 0.4183705747127533, 257.28729248046875, 0.0)\n",
      "epoch 400 loss=(1605.887451171875, 0.36124739050865173, 255.22109985351562, 0.0)\n",
      "epoch 600 loss=(1605.2891845703125, 0.34499526023864746, 257.00469970703125, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "0 (34.39707565307617, 0.8333333730697632, 14.658626556396484)\n",
      "epoch 0 loss=(2043.017822265625, 0.6903658509254456, 267.3212890625, 0.0)\n",
      "epoch 200 loss=(1547.0286865234375, 0.45039913058280945, 250.3934326171875, 0.0)\n",
      "epoch 400 loss=(1544.4755859375, 0.35791757702827454, 250.06971740722656, 0.0)\n",
      "epoch 600 loss=(1548.4580078125, 0.34072282910346985, 246.99774169921875, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "1 (39.55796432495117, 0.8166667222976685, 16.635272979736328)\n",
      "epoch 0 loss=(1574.7952880859375, 0.6911529898643494, 537.5813598632812, 0.0)\n",
      "epoch 200 loss=(1573.1409912109375, 0.416223406791687, 246.692138671875, 0.0)\n",
      "epoch 400 loss=(1558.1097412109375, 0.3539165258407593, 246.8941192626953, 0.0)\n",
      "epoch 600 loss=(1571.7333984375, 0.3361665904521942, 246.8072509765625, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "2 (36.395015716552734, 0.8000000715255737, 17.516836166381836)\n",
      "epoch 0 loss=(1679.711181640625, 0.6934465765953064, 267.42889404296875, 0.0)\n",
      "epoch 200 loss=(1532.90234375, 0.44386646151542664, 254.498046875, 0.0)\n",
      "epoch 400 loss=(1529.835693359375, 0.3704598546028137, 254.18246459960938, 0.0)\n",
      "epoch 600 loss=(1528.218994140625, 0.34334757924079895, 254.34349060058594, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "3 (40.351593017578125, 0.8305084705352783, 15.501710891723633)\n",
      "epoch 0 loss=(1976.203857421875, 0.6905366778373718, 258.7522888183594, 0.0)\n",
      "epoch 200 loss=(1516.1156005859375, 0.43623918294906616, 256.0082092285156, 0.0)\n",
      "epoch 400 loss=(1522.6435546875, 0.3633010983467102, 255.76837158203125, 0.0)\n",
      "epoch 600 loss=(1515.9501953125, 0.33610647916793823, 255.70458984375, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "4 (41.29444885253906, 0.7796609997749329, 15.057029724121094)\n",
      "epoch 0 loss=(2083.322509765625, 0.6942498683929443, 251.00869750976562, 0.0)\n",
      "epoch 200 loss=(1533.45361328125, 0.4369809329509735, 249.61619567871094, 0.0)\n",
      "epoch 400 loss=(1537.885498046875, 0.36937248706817627, 250.47203063964844, 0.0)\n",
      "epoch 600 loss=(1527.7569580078125, 0.3399125933647156, 250.46441650390625, 0.0)\n",
      "epoch 800 loss=(1536.1229248046875, 0.3281441628932953, 250.47174072265625, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "5 (40.90435791015625, 0.7966101765632629, 16.483007431030273)\n",
      "epoch 0 loss=(1591.168212890625, 0.6925286650657654, 300.33502197265625, 0.0)\n",
      "epoch 200 loss=(1568.9017333984375, 0.6007870435714722, 247.4466094970703, 0.0)\n",
      "epoch 400 loss=(1565.72216796875, 0.4069289565086365, 247.39352416992188, 0.0)\n",
      "epoch 600 loss=(1571.1744384765625, 0.3554198741912842, 247.49461364746094, 0.0)\n",
      "epoch 800 loss=(1577.0894775390625, 0.3375883400440216, 247.54534912109375, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "6 (37.452735900878906, 0.8305084705352783, 17.334640502929688)\n",
      "epoch 0 loss=(1490.881103515625, 0.6936221718788147, 260.3302307128906, 0.0)\n",
      "epoch 200 loss=(1291.97021484375, 0.411321222782135, 254.22518920898438, 0.0)\n",
      "epoch 400 loss=(1037.3116455078125, 0.3601285219192505, 254.2178192138672, 0.0)\n",
      "epoch 600 loss=(785.4098510742188, 0.34220731258392334, 254.1923065185547, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "7 (30.842248916625977, 0.7796609997749329, 15.615303993225098)\n",
      "epoch 0 loss=(3965.79541015625, 0.6932567358016968, 261.5626525878906, 0.0)\n",
      "epoch 200 loss=(1581.5660400390625, 0.47304898500442505, 251.88816833496094, 0.0)\n",
      "epoch 400 loss=(1550.096435546875, 0.3873218595981598, 251.97132873535156, 0.0)\n",
      "epoch 600 loss=(1548.7410888671875, 0.3414357900619507, 251.96466064453125, 0.0)\n",
      "epoch 800 loss=(1552.353759765625, 0.32540637254714966, 251.91749572753906, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "8 (39.18369674682617, 0.7118644118309021, 16.133134841918945)\n",
      "epoch 0 loss=(2442.765869140625, 0.6915215849876404, 501.5451354980469, 0.0)\n",
      "epoch 200 loss=(1549.862548828125, 0.42494943737983704, 260.523193359375, 0.0)\n",
      "epoch 400 loss=(1539.3331298828125, 0.37171670794487, 260.36053466796875, 0.0)\n",
      "epoch 600 loss=(1545.550048828125, 0.3335411548614502, 260.4797058105469, 0.0)\n",
      "Early stopping\n",
      "Finished training\n",
      "9 (39.37202453613281, 0.7457627058029175, 13.642721176147461)\n"
     ]
    }
   ],
   "source": [
    "ceLoss = torch.nn.CrossEntropyLoss()\n",
    "mseLoss = torch.nn.MSELoss()\n",
    "nEpochs = 5000\n",
    "pPeriod = 200\n",
    "thresh = torch.Tensor((40,3.2e-1,20)).float().cuda()\n",
    "\n",
    "nPoly = 1\n",
    "para = [makePoly(nback_p_t), makePoly(emoid_p_t)]\n",
    "    \n",
    "rmse = []\n",
    "\n",
    "for i in range(10):\n",
    "    pgigcn = MiniPgi((2, 5, 10), len(para), nPoly, 3, 0.5, (0.2, 0.01, 1))\n",
    "    optim = torch.optim.Adam(pgigcn.masks, lr=2e-5, weight_decay=2e-5)\n",
    "\n",
    "    trainIdcs = groups[i][0]\n",
    "    testIdcs = groups[i][1]\n",
    "    \n",
    "    X = torch.stack(para, dim=1)\n",
    "    X = X[trainIdcs]\n",
    "    Y = torch.from_numpy(X_all[trainIdcs]).float().cuda()\n",
    "    \n",
    "    gen = Y[:,1:]\n",
    "    wrt = wrat_t[trainIdcs].unsqueeze(1)\n",
    "    age = Y[:,0].unsqueeze(1)\n",
    "    \n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        res = pgigcn(X, age=age, gender=gen, wrat=wrt)\n",
    "        loss0 = mseLoss(res[0], age)\n",
    "        loss1 = ceLoss(res[1], gen)\n",
    "        loss2 = mseLoss(res[2], wrt)\n",
    "        loss = torch.stack([loss0, loss1, loss2])\n",
    "        torch.sum(loss).backward()\n",
    "        optim.step()\n",
    "        if (epoch % pPeriod == 0 or epoch == nEpochs-1):\n",
    "            print(f'epoch {epoch} loss={(float(loss0), float(loss1), float(loss2))}')\n",
    "        if torch.all(loss < thresh):\n",
    "            print('Early stopping')\n",
    "            break\n",
    "            \n",
    "    print('Finished training')\n",
    "    \n",
    "    pgigcn.eval()\n",
    "    \n",
    "    X = torch.stack(para, dim=1)\n",
    "    Y = torch.from_numpy(X_all).float().cuda()\n",
    "        \n",
    "    gen = Y[:,1:]\n",
    "    wrt = wrat_t.unsqueeze(1)\n",
    "    age = Y[:,0].unsqueeze(1)\n",
    "\n",
    "    gen0 = gen.clone().detach()\n",
    "    gen0[testIdcs] = 0\n",
    "    wrt0 = wrt.clone().detach()\n",
    "    wrt0[testIdcs] = 0\n",
    "    age0 = age.clone().detach()\n",
    "    age0[testIdcs] = 0\n",
    "    \n",
    "    res, ss = pgigcn(X, age=age0, gender=gen0, wrat=wrt0)\n",
    "    loss0 = mseLoss(res[0][testIdcs].detach(), age[testIdcs]).cpu().numpy()**0.5\n",
    "    frac1 = torch.sum(torch.argmax(res[1].detach(), dim=1)[testIdcs] \n",
    "                     == torch.argmax(gen[testIdcs], dim=1))/testIdcs.shape[0]\n",
    "    loss2 = mseLoss(res[2][testIdcs].detach(), wrt[testIdcs]).cpu().numpy()**0.5\n",
    "    \n",
    "    rmse.append((float(loss0), float(frac1), float(loss2)))\n",
    "    print(i, end=' ')\n",
    "    print(rmse[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f2b9b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333730697632\n",
      "0.8166667222976685\n",
      "0.8000000715255737\n",
      "0.8305084705352783\n",
      "0.7796609997749329\n",
      "0.7966101765632629\n",
      "0.8305084705352783\n",
      "0.7796609997749329\n",
      "0.7118644118309021\n",
      "0.7457627058029175\n"
     ]
    }
   ],
   "source": [
    "for a,b,c in rmse:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98a19729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(6094822.5000, device='cuda:0'), tensor(699011.1250, device='cuda:0'), tensor(12366456., device='cuda:0'))\n",
      "tensor(22.1522, device='cuda:0')\n",
      "(tensor(0.0013, device='cuda:0'), tensor(0.1015, device='cuda:0'), tensor(0.3642, device='cuda:0'))\n",
      "tensor(0.0053, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch.linalg\n",
    "\n",
    "es = []\n",
    "for i in range(3):\n",
    "    _,e = pgigcn.getLatentsAndEdges(X, i)\n",
    "    es.append(e.detach())\n",
    "\n",
    "E = sum(es)\n",
    "\n",
    "nSub = E.shape[0]\n",
    "w = 11\n",
    "\n",
    "U = torch.rand(nSub, w).float().cuda()\n",
    "\n",
    "for i in range(2):\n",
    "    A, res0, rank, sigma = torch.linalg.lstsq(U,es[0])\n",
    "    B, res1, rank, sigma = torch.linalg.lstsq(U,es[1])\n",
    "    C, res2, rank, sigma = torch.linalg.lstsq(U,es[2])\n",
    "    print(f'{(res0[0], res1[0], res2[0])}')\n",
    "    U, res, rank, sigma = torch.linalg.lstsq((A+B+C).T,E.T)\n",
    "    U = U.T\n",
    "    print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68cc269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8667, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "UA = U@B\n",
    "idcs = torch.logical_not(torch.any(gen0, dim=1))\n",
    "UA[:,idcs] = 0\n",
    "UA = pgigcn.relu[1](mask(UA))\n",
    "s = torch.sum(UA, dim=1)\n",
    "UA /= s.unsqueeze(1)\n",
    "res = UA@gen0\n",
    "# loss = mseLoss(res[testIdcs].detach(), wrt[testIdcs]).cpu().numpy()**0.5\n",
    "frac1 = torch.sum(torch.argmax(res.detach(), dim=1)[testIdcs] \n",
    "                     == torch.argmax(gen[testIdcs], dim=1))/testIdcs.shape[0]\n",
    "print(frac1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc70c013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0')\n",
      "tensor([], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "Xf = X.reshape(X.shape[0],-1)\n",
    "\n",
    "MU, res, rank, sigma = torch.linalg.lstsq(Xf,U)\n",
    "print(res)\n",
    "MC, res, rank, sigma = torch.linalg.lstsq(Xf,C.T)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd3d7e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 35.7946,  52.9134,  30.6744,  ...,  49.7341,  63.4010,  45.6183],\n",
      "        [  6.1951,  39.1063,   7.1359,  ...,  73.0908,  28.1651, 107.8551],\n",
      "        [ 84.5367,  53.7470,  70.6902,  ...,  21.5250,  76.6547, -12.5471],\n",
      "        ...,\n",
      "        [ 96.5503,  52.9031,  59.2112,  ...,  34.4210,  96.1620,   1.3936],\n",
      "        [ 38.5524,  69.2021,  31.6161,  ...,  75.1384,  77.7418,  81.0949],\n",
      "        [ 80.8732,  42.9717,  57.8032,  ...,  11.5973,  76.9860, -27.9158]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 35.7946,   6.1951,  84.5368,  ...,  96.5504,  38.5524,  80.8733],\n",
      "        [ 52.9133,  39.1062,  53.7470,  ...,  52.9031,  69.2021,  42.9717],\n",
      "        [ 30.6744,   7.1359,  70.6902,  ...,  59.2112,  31.6161,  57.8032],\n",
      "        ...,\n",
      "        [ 49.7340,  73.0908,  21.5250,  ...,  34.4210,  75.1383,  11.5973],\n",
      "        [ 63.4010,  28.1651,  76.6547,  ...,  96.1620,  77.7418,  76.9860],\n",
      "        [ 45.6183, 107.8551, -12.5472,  ...,   1.3936,  81.0949, -27.9158]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(Xf@MC)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c49dab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7656.2363, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(E[0]**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925c16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
