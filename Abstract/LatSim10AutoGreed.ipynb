{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b4edc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../PNC_Good/MegaMeta3.pkl', 'rb') as f: \n",
    "    meta = pickle.load(f)\n",
    "    \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c267bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620\n",
      "620\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "with open('../../Work/LatentSim/Splits.pkl', 'rb') as f:\n",
    "    keys, groups = pickle.load(f)\n",
    "    \n",
    "print(len(keys))\n",
    "print(len(groups[0][0])+len(groups[0][1]))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c155e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 264, 231)\n",
      "(620, 264, 210)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nback = np.stack([meta[key]['nback'] for key in keys])\n",
    "emoid = np.stack([meta[key]['emoid'] for key in keys])\n",
    "\n",
    "print(nback.shape)\n",
    "print(emoid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb8175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 264, 264)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "def getFC(timeSeries, kind='correlation', transpose=True):\n",
    "    connMeasure = ConnectivityMeasure(kind=kind)\n",
    "    if transpose:\n",
    "        timeSeries = np.transpose(timeSeries, axes=(0,2,1))\n",
    "    return connMeasure.fit_transform(timeSeries)\n",
    "\n",
    "nback_p = getFC(nback)\n",
    "emoid_p = getFC(emoid)\n",
    "\n",
    "print(nback_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6709a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([620, 34716])\n",
      "torch.Size([620, 34716])\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def convertTorch(p):\n",
    "    t = torch.from_numpy(p).float()\n",
    "    u = []\n",
    "    for i in range(t.shape[0]):\n",
    "        u.append(t[i][torch.triu_indices(264,264,offset=1).unbind()])\n",
    "    return torch.stack(u).cuda()\n",
    "\n",
    "nback_p_t = convertTorch(nback_p)\n",
    "emoid_p_t = convertTorch(emoid_p)\n",
    "\n",
    "print(nback_p_t.shape)\n",
    "print(emoid_p_t.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b3b60e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm complete\n"
     ]
    }
   ],
   "source": [
    "mu_nback = torch.mean(nback_p_t, dim=0, keepdim=True)\n",
    "mu_emoid = torch.mean(emoid_p_t, dim=0, keepdim=True)\n",
    "std_nback = torch.std(nback_p_t, dim=0, keepdim=True)\n",
    "std_emoid = torch.std(emoid_p_t, dim=0, keepdim=True)\n",
    "\n",
    "nback_p_t = (nback_p_t - mu_nback)/std_nback\n",
    "emoid_p_t = (emoid_p_t - mu_emoid)/std_emoid\n",
    "\n",
    "print('Norm complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0614b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([-2.2998, -3.0133], device='cuda:0'),\n",
      "indices=tensor([603, 350], device='cuda:0'))\n",
      "torch.return_types.min(\n",
      "values=tensor([-2.7284, -3.0616], device='cuda:0'),\n",
      "indices=tensor([351,  33], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(nback_p_t[:,420:422],dim=0))\n",
    "print(torch.min(emoid_p_t[:,420:422],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1285ea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620,)\n",
      "(620, 2)\n",
      "(620,)\n"
     ]
    }
   ],
   "source": [
    "age = np.stack([meta[key]['AgeInMonths'] for key in keys])\n",
    "gen = np.stack([np.array([meta[key]['Gender'] == 'M', meta[key]['Gender'] == 'F']) for key in keys]).astype(int)\n",
    "wrt = np.stack([meta[key]['wratStd'] for key in keys])\n",
    "\n",
    "print(age.shape)\n",
    "print(gen.shape)\n",
    "print(wrt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3851f994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "age_t = torch.from_numpy(age).float().cuda()\n",
    "gen_t = torch.from_numpy(gen).float().cuda()\n",
    "wrt_t = torch.from_numpy(wrt).float().cuda()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31067220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def arith(n):\n",
    "    return int(n*(n+1)/2)\n",
    "\n",
    "def mask(e):\n",
    "    return e - torch.diag(torch.diag(e.detach()))\n",
    "\n",
    "class LatSim(nn.Module):\n",
    "    def __init__(self, nTgts, inp, dp=0, edp=0.1):\n",
    "        super(LatSim, self).__init__()\n",
    "        self.active = nn.Parameter(1e-4*torch.randn(nTgts,inp.shape[-1],2).float().cuda())\n",
    "        self.dp = nn.Dropout(p=dp)\n",
    "        self.edp = nn.Dropout(p=edp)\n",
    "    \n",
    "    def getLatentsAndEdges(self, x, i):\n",
    "        e = 1e-10\n",
    "        y = torch.einsum('ac,ce->ae', x, self.active[i])\n",
    "        e = e+y@y.T\n",
    "        return y, y, e\n",
    "        \n",
    "    def forward(self, x, y, testIdcs=None):\n",
    "        res = []\n",
    "        es = []\n",
    "        x = self.dp(x)\n",
    "        for i in range(self.active.shape[0]):\n",
    "            _, _, e = self.getLatentsAndEdges(x[:,i,:], i)\n",
    "            if testIdcs is not None:\n",
    "                e[:,testIdcs] = 0\n",
    "            e = self.edp(e)\n",
    "            e = mask(e)\n",
    "            e[e == 0] = float('-inf')\n",
    "            e = F.softmax(e, dim=1)\n",
    "            es.append(e)\n",
    "            res.append(e@y)\n",
    "        return res, es\n",
    "\n",
    "def validate(model, X, y, testIdcs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        res, _ = model(X, y, testIdcs)\n",
    "        avg = torch.mean(torch.stack(res), dim=0)\n",
    "        if res[0].dim() == 1:\n",
    "            loss = mseLoss(avg[testIdcs], y[testIdcs]).cpu().numpy()**0.5\n",
    "        else:\n",
    "            corr = (torch.argmax(avg, dim=1) == torch.argmax(y, dim=1))[testIdcs]\n",
    "            loss = torch.sum(corr)/len(testIdcs)\n",
    "    model.train()\n",
    "    return loss\n",
    "        \n",
    "ceLoss = torch.nn.CrossEntropyLoss()\n",
    "mseLoss = torch.nn.MSELoss()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e81b89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "topRegions = np.zeros((10,10,2,5,2)) # Group, N, para, top5, {index, value}\n",
    "topRMSE = np.zeros((10,10,3)) # Group, N, {train, val, test}\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "226099ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21453, 30472, 27868, 32298, 30909])\n",
      "tensor([14448, 31983, 27311, 13717, 26818])\n",
      "epoch 0 loss=1514.965576171875\n",
      "New best validation epoch 0 loss=44.584468841552734\n",
      "epoch 200 loss=1508.76318359375\n",
      "New best validation epoch 200 loss=44.53342819213867\n",
      "epoch 400 loss=1499.925048828125\n",
      "New best validation epoch 400 loss=44.35356140136719\n",
      "epoch 600 loss=1463.062255859375\n",
      "New best validation epoch 600 loss=44.04001235961914\n",
      "epoch 800 loss=1456.7655029296875\n",
      "New best validation epoch 800 loss=43.64316177368164\n",
      "epoch 1000 loss=1451.6063232421875\n",
      "New best validation epoch 1000 loss=43.323760986328125\n",
      "epoch 1200 loss=1437.9384765625\n",
      "New best validation epoch 1200 loss=43.103851318359375\n",
      "epoch 1400 loss=1433.675537109375\n",
      "New best validation epoch 1400 loss=42.96253967285156\n",
      "epoch 1600 loss=1443.7581787109375\n",
      "New best validation epoch 1600 loss=42.864295959472656\n",
      "epoch 1800 loss=1445.268310546875\n",
      "New best validation epoch 1800 loss=42.77638244628906\n",
      "epoch 2000 loss=1425.880126953125\n",
      "New best validation epoch 2000 loss=42.71994400024414\n",
      "epoch 2200 loss=1407.6566162109375\n",
      "New best validation epoch 2200 loss=42.66758346557617\n",
      "epoch 2400 loss=1419.479248046875\n",
      "New best validation epoch 2400 loss=42.63527297973633\n",
      "epoch 2600 loss=1409.586181640625\n",
      "New best validation epoch 2600 loss=42.59803009033203\n",
      "epoch 2800 loss=1394.944091796875\n",
      "New best validation epoch 2800 loss=42.593360900878906\n",
      "epoch 3000 loss=1428.97900390625\n",
      "New best validation epoch 3000 loss=42.56085968017578\n",
      "epoch 3200 loss=1397.97412109375\n",
      "New best validation epoch 3200 loss=42.530799865722656\n",
      "epoch 3400 loss=1456.03515625\n",
      "New best validation epoch 3400 loss=42.5217170715332\n",
      "epoch 3600 loss=1420.53564453125\n",
      "epoch 3800 loss=1418.764404296875\n",
      "New best validation epoch 3800 loss=42.51933288574219\n",
      "epoch 4000 loss=1408.03515625\n",
      "epoch 4200 loss=1390.740234375\n",
      "New best validation epoch 4200 loss=42.51875305175781\n",
      "epoch 4400 loss=1403.20263671875\n",
      "New best validation epoch 4400 loss=42.51741409301758\n",
      "epoch 4600 loss=1423.7884521484375\n",
      "New best validation epoch 4600 loss=42.50309371948242\n",
      "epoch 4800 loss=1411.8070068359375\n",
      "New best validation epoch 4800 loss=42.49567413330078\n",
      "epoch 4999 loss=1398.4052734375\n",
      "New best validation epoch 4999 loss=42.49493408203125\n",
      "Finished training\n",
      "FINISHED 0 0 36.705726623535156\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431])\n",
      "epoch 0 loss=1515.9246826171875\n",
      "New best validation epoch 0 loss=44.584468841552734\n",
      "epoch 200 loss=1495.625\n",
      "New best validation epoch 200 loss=44.38740539550781\n",
      "epoch 400 loss=1442.7913818359375\n",
      "New best validation epoch 400 loss=43.542171478271484\n",
      "epoch 600 loss=1430.31103515625\n",
      "New best validation epoch 600 loss=42.672508239746094\n",
      "epoch 800 loss=1418.5242919921875\n",
      "New best validation epoch 800 loss=42.29862594604492\n",
      "epoch 1000 loss=1408.973388671875\n",
      "New best validation epoch 1000 loss=42.110496520996094\n",
      "epoch 1200 loss=1399.464599609375\n",
      "New best validation epoch 1200 loss=42.01266860961914\n",
      "epoch 1400 loss=1397.15234375\n",
      "New best validation epoch 1400 loss=41.940250396728516\n",
      "epoch 1600 loss=1401.1390380859375\n",
      "New best validation epoch 1600 loss=41.893287658691406\n",
      "epoch 1800 loss=1382.58984375\n",
      "New best validation epoch 1800 loss=41.819393157958984\n",
      "epoch 2000 loss=1367.878662109375\n",
      "New best validation epoch 2000 loss=41.77555465698242\n",
      "epoch 2200 loss=1385.8934326171875\n",
      "New best validation epoch 2200 loss=41.751644134521484\n",
      "epoch 2400 loss=1344.8773193359375\n",
      "epoch 2600 loss=1364.636962890625\n",
      "New best validation epoch 2600 loss=41.722373962402344\n",
      "epoch 2800 loss=1391.1341552734375\n",
      "epoch 3000 loss=1391.908935546875\n",
      "epoch 3200 loss=1342.79443359375\n",
      "New best validation epoch 3200 loss=41.711753845214844\n",
      "epoch 3400 loss=1377.0057373046875\n",
      "epoch 3600 loss=1363.158935546875\n",
      "epoch 3800 loss=1412.416748046875\n",
      "epoch 4000 loss=1389.6761474609375\n",
      "epoch 4200 loss=1341.1834716796875\n",
      "epoch 4400 loss=1336.0155029296875\n",
      "epoch 4600 loss=1349.27734375\n",
      "epoch 4800 loss=1363.2508544921875\n",
      "epoch 4999 loss=1383.7088623046875\n",
      "Finished training\n",
      "FINISHED 0 1 36.31230163574219\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694])\n",
      "epoch 0 loss=1516.540283203125\n",
      "New best validation epoch 0 loss=44.584468841552734\n",
      "epoch 200 loss=1477.4681396484375\n",
      "New best validation epoch 200 loss=44.0837516784668\n",
      "epoch 400 loss=1406.7386474609375\n",
      "New best validation epoch 400 loss=42.471275329589844\n",
      "epoch 600 loss=1386.602294921875\n",
      "New best validation epoch 600 loss=41.78826141357422\n",
      "epoch 800 loss=1394.051513671875\n",
      "New best validation epoch 800 loss=41.54387664794922\n",
      "epoch 1000 loss=1382.779296875\n",
      "New best validation epoch 1000 loss=41.43851089477539\n",
      "epoch 1200 loss=1365.6907958984375\n",
      "New best validation epoch 1200 loss=41.36721420288086\n",
      "epoch 1400 loss=1347.706298828125\n",
      "New best validation epoch 1400 loss=41.338653564453125\n",
      "epoch 1600 loss=1347.05712890625\n",
      "New best validation epoch 1600 loss=41.2878532409668\n",
      "epoch 1800 loss=1333.152099609375\n",
      "New best validation epoch 1800 loss=41.19923400878906\n",
      "epoch 2000 loss=1369.8284912109375\n",
      "epoch 2200 loss=1368.41796875\n",
      "epoch 2400 loss=1324.102294921875\n",
      "epoch 2600 loss=1382.2371826171875\n",
      "epoch 2800 loss=1338.3388671875\n",
      "epoch 3000 loss=1362.5389404296875\n",
      "epoch 3200 loss=1345.042724609375\n",
      "epoch 3400 loss=1345.267822265625\n",
      "epoch 3600 loss=1354.1123046875\n",
      "epoch 3800 loss=1348.571044921875\n",
      "epoch 4000 loss=1343.8544921875\n",
      "epoch 4200 loss=1360.923583984375\n",
      "epoch 4400 loss=1353.26806640625\n",
      "epoch 4600 loss=1360.6727294921875\n",
      "epoch 4800 loss=1376.2440185546875\n",
      "epoch 4999 loss=1345.2896728515625\n",
      "Finished training\n",
      "FINISHED 0 2 36.20907211303711\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883, 11584,  6773, 29237, 17100, 13326])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694,  3100, 11693,  3848, 21191, 16415])\n",
      "epoch 0 loss=1512.340576171875\n",
      "New best validation epoch 0 loss=44.58445739746094\n",
      "epoch 200 loss=1450.68994140625\n",
      "New best validation epoch 200 loss=43.5775146484375\n",
      "epoch 400 loss=1381.341064453125\n",
      "New best validation epoch 400 loss=41.7055778503418\n",
      "epoch 600 loss=1336.9130859375\n",
      "New best validation epoch 600 loss=41.23570251464844\n",
      "epoch 800 loss=1349.8919677734375\n",
      "New best validation epoch 800 loss=41.02037811279297\n",
      "epoch 1000 loss=1334.947265625\n",
      "New best validation epoch 1000 loss=40.8884162902832\n",
      "epoch 1200 loss=1288.6944580078125\n",
      "New best validation epoch 1200 loss=40.697513580322266\n",
      "epoch 1400 loss=1307.4287109375\n",
      "New best validation epoch 1400 loss=40.685848236083984\n",
      "epoch 1600 loss=1315.41748046875\n",
      "New best validation epoch 1600 loss=40.53372573852539\n",
      "epoch 1800 loss=1324.4443359375\n",
      "New best validation epoch 1800 loss=40.43830871582031\n",
      "epoch 2000 loss=1284.991943359375\n",
      "New best validation epoch 2000 loss=40.391658782958984\n",
      "epoch 2200 loss=1307.107666015625\n",
      "epoch 2400 loss=1315.939453125\n",
      "epoch 2600 loss=1305.00439453125\n",
      "epoch 2800 loss=1311.16259765625\n",
      "New best validation epoch 2800 loss=40.38553237915039\n",
      "epoch 3000 loss=1304.997314453125\n",
      "New best validation epoch 3000 loss=40.38416290283203\n",
      "epoch 3200 loss=1298.278076171875\n",
      "epoch 3400 loss=1315.1282958984375\n",
      "New best validation epoch 3400 loss=40.379825592041016\n",
      "epoch 3600 loss=1314.3194580078125\n",
      "epoch 3800 loss=1298.12353515625\n",
      "epoch 4000 loss=1320.8193359375\n",
      "epoch 4200 loss=1300.218505859375\n",
      "New best validation epoch 4200 loss=40.36753463745117\n",
      "epoch 4400 loss=1267.015380859375\n",
      "epoch 4600 loss=1330.440673828125\n",
      "epoch 4800 loss=1294.3934326171875\n",
      "epoch 4999 loss=1325.96142578125\n",
      "Finished training\n",
      "FINISHED 0 3 35.696495056152344\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883, 11584,  6773, 29237, 17100, 13326,\n",
      "        19912,  9287,  5389,  8626, 20458])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694,  3100, 11693,  3848, 21191, 16415,\n",
      "         8316, 20759, 21188, 19022, 27682])\n",
      "epoch 0 loss=1514.4818115234375\n",
      "New best validation epoch 0 loss=44.58445358276367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1400.08056640625\n",
      "New best validation epoch 200 loss=42.78111267089844\n",
      "epoch 400 loss=1319.410888671875\n",
      "New best validation epoch 400 loss=41.17200469970703\n",
      "epoch 600 loss=1323.3118896484375\n",
      "New best validation epoch 600 loss=40.778385162353516\n",
      "epoch 800 loss=1330.853759765625\n",
      "New best validation epoch 800 loss=40.47073745727539\n",
      "epoch 1000 loss=1321.8226318359375\n",
      "New best validation epoch 1000 loss=40.25212097167969\n",
      "epoch 1200 loss=1282.978759765625\n",
      "New best validation epoch 1200 loss=40.12028121948242\n",
      "epoch 1400 loss=1299.459228515625\n",
      "New best validation epoch 1400 loss=39.93958282470703\n",
      "epoch 1600 loss=1294.9368896484375\n",
      "New best validation epoch 1600 loss=39.80863571166992\n",
      "epoch 1800 loss=1289.9908447265625\n",
      "New best validation epoch 1800 loss=39.7999382019043\n",
      "epoch 2000 loss=1202.357177734375\n",
      "New best validation epoch 2000 loss=39.70452117919922\n",
      "epoch 2200 loss=1253.3778076171875\n",
      "New best validation epoch 2200 loss=39.69339370727539\n",
      "epoch 2400 loss=1251.5908203125\n",
      "epoch 2600 loss=1276.57080078125\n",
      "New best validation epoch 2600 loss=39.6723518371582\n",
      "epoch 2800 loss=1265.27392578125\n",
      "New best validation epoch 2800 loss=39.625343322753906\n",
      "epoch 3000 loss=1261.53662109375\n",
      "epoch 3200 loss=1247.496826171875\n",
      "epoch 3400 loss=1248.293212890625\n",
      "epoch 3600 loss=1264.729736328125\n",
      "epoch 3800 loss=1291.4534912109375\n",
      "epoch 4000 loss=1270.76953125\n",
      "epoch 4200 loss=1282.57373046875\n",
      "epoch 4400 loss=1253.22998046875\n",
      "epoch 4600 loss=1259.0025634765625\n",
      "epoch 4800 loss=1256.874267578125\n",
      "epoch 4999 loss=1283.612548828125\n",
      "New best validation epoch 4999 loss=39.597999572753906\n",
      "Finished training\n",
      "FINISHED 0 4 34.91453552246094\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883, 11584,  6773, 29237, 17100, 13326,\n",
      "        19912,  9287,  5389,  8626, 20458, 32879,   715, 14412, 30039, 20058])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694,  3100, 11693,  3848, 21191, 16415,\n",
      "         8316, 20759, 21188, 19022, 27682, 27931,  8765,  2559, 18057, 23659])\n",
      "epoch 0 loss=1516.04443359375\n",
      "New best validation epoch 0 loss=44.584434509277344\n",
      "epoch 200 loss=1373.62451171875\n",
      "New best validation epoch 200 loss=42.16115951538086\n",
      "epoch 400 loss=1339.9991455078125\n",
      "New best validation epoch 400 loss=40.91948699951172\n",
      "epoch 600 loss=1305.3270263671875\n",
      "New best validation epoch 600 loss=40.50334167480469\n",
      "epoch 800 loss=1287.444091796875\n",
      "New best validation epoch 800 loss=40.21337127685547\n",
      "epoch 1000 loss=1308.3372802734375\n",
      "New best validation epoch 1000 loss=39.89554977416992\n",
      "epoch 1200 loss=1278.4571533203125\n",
      "New best validation epoch 1200 loss=39.68606185913086\n",
      "epoch 1400 loss=1285.92919921875\n",
      "New best validation epoch 1400 loss=39.5635986328125\n",
      "epoch 1600 loss=1265.6328125\n",
      "New best validation epoch 1600 loss=39.452171325683594\n",
      "epoch 1800 loss=1263.839111328125\n",
      "New best validation epoch 1800 loss=39.34162139892578\n",
      "epoch 2000 loss=1272.7440185546875\n",
      "New best validation epoch 2000 loss=39.282752990722656\n",
      "epoch 2200 loss=1245.177001953125\n",
      "New best validation epoch 2200 loss=39.26213073730469\n",
      "epoch 2400 loss=1249.122314453125\n",
      "New best validation epoch 2400 loss=39.239402770996094\n",
      "epoch 2600 loss=1240.501220703125\n",
      "New best validation epoch 2600 loss=39.17013168334961\n",
      "epoch 2800 loss=1297.234130859375\n",
      "epoch 3000 loss=1276.74853515625\n",
      "epoch 3200 loss=1235.199462890625\n",
      "epoch 3400 loss=1293.154541015625\n",
      "New best validation epoch 3400 loss=39.160396575927734\n",
      "epoch 3600 loss=1238.6375732421875\n",
      "epoch 3800 loss=1252.434814453125\n",
      "epoch 4000 loss=1232.73193359375\n",
      "epoch 4200 loss=1250.023193359375\n",
      "epoch 4400 loss=1243.064697265625\n",
      "New best validation epoch 4400 loss=39.1311149597168\n",
      "epoch 4600 loss=1241.304931640625\n",
      "epoch 4800 loss=1274.4521484375\n",
      "epoch 4999 loss=1269.110595703125\n",
      "Finished training\n",
      "FINISHED 0 5 35.012977600097656\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883, 11584,  6773, 29237, 17100, 13326,\n",
      "        19912,  9287,  5389,  8626, 20458, 32879,   715, 14412, 30039, 20058,\n",
      "        27622, 23386, 24127, 12128, 29171])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694,  3100, 11693,  3848, 21191, 16415,\n",
      "         8316, 20759, 21188, 19022, 27682, 27931,  8765,  2559, 18057, 23659,\n",
      "         5717,   930, 12970, 26561, 22642])\n",
      "epoch 0 loss=1512.825927734375\n",
      "New best validation epoch 0 loss=44.584434509277344\n",
      "epoch 200 loss=1393.5517578125\n",
      "New best validation epoch 200 loss=41.83723068237305\n",
      "epoch 400 loss=1334.40771484375\n",
      "New best validation epoch 400 loss=40.86885452270508\n",
      "epoch 600 loss=1288.96923828125\n",
      "New best validation epoch 600 loss=40.36977005004883\n",
      "epoch 800 loss=1282.8778076171875\n",
      "New best validation epoch 800 loss=39.99116134643555\n",
      "epoch 1000 loss=1270.706298828125\n",
      "New best validation epoch 1000 loss=39.6859245300293\n",
      "epoch 1200 loss=1257.320068359375\n",
      "New best validation epoch 1200 loss=39.447818756103516\n",
      "epoch 1400 loss=1251.2078857421875\n",
      "New best validation epoch 1400 loss=39.30641174316406\n",
      "epoch 1600 loss=1264.54931640625\n",
      "New best validation epoch 1600 loss=39.251678466796875\n",
      "epoch 1800 loss=1238.0635986328125\n",
      "New best validation epoch 1800 loss=39.21723937988281\n",
      "epoch 2000 loss=1236.20556640625\n",
      "New best validation epoch 2000 loss=39.071258544921875\n",
      "epoch 2200 loss=1249.9488525390625\n",
      "New best validation epoch 2200 loss=39.03433609008789\n",
      "epoch 2400 loss=1249.915283203125\n",
      "epoch 2600 loss=1227.700439453125\n",
      "epoch 2800 loss=1233.014892578125\n",
      "epoch 3000 loss=1253.03076171875\n",
      "New best validation epoch 3000 loss=38.98475646972656\n",
      "epoch 3200 loss=1263.283447265625\n",
      "epoch 3400 loss=1195.6248779296875\n",
      "epoch 3600 loss=1208.1890869140625\n",
      "epoch 3800 loss=1234.8631591796875\n",
      "epoch 4000 loss=1235.5965576171875\n",
      "epoch 4200 loss=1236.95703125\n",
      "epoch 4400 loss=1227.457275390625\n",
      "epoch 4600 loss=1250.63818359375\n",
      "epoch 4800 loss=1304.9169921875\n",
      "epoch 4999 loss=1253.8349609375\n",
      "New best validation epoch 4999 loss=38.932342529296875\n",
      "Finished training\n",
      "FINISHED 0 6 34.9321174621582\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883, 11584,  6773, 29237, 17100, 13326,\n",
      "        19912,  9287,  5389,  8626, 20458, 32879,   715, 14412, 30039, 20058,\n",
      "        27622, 23386, 24127, 12128, 29171, 11813, 20786, 17223,  1941,  1234])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694,  3100, 11693,  3848, 21191, 16415,\n",
      "         8316, 20759, 21188, 19022, 27682, 27931,  8765,  2559, 18057, 23659,\n",
      "         5717,   930, 12970, 26561, 22642, 16264,   630, 25114, 11503, 16147])\n",
      "epoch 0 loss=1513.94970703125\n",
      "New best validation epoch 0 loss=44.58441162109375\n",
      "epoch 200 loss=1354.2913818359375\n",
      "New best validation epoch 200 loss=41.47666549682617\n",
      "epoch 400 loss=1310.7611083984375\n",
      "New best validation epoch 400 loss=40.625064849853516\n",
      "epoch 600 loss=1260.199951171875\n",
      "New best validation epoch 600 loss=40.108619689941406\n",
      "epoch 800 loss=1244.86181640625\n",
      "New best validation epoch 800 loss=39.67261505126953\n",
      "epoch 1000 loss=1252.14892578125\n",
      "New best validation epoch 1000 loss=39.31757736206055\n",
      "epoch 1200 loss=1232.6834716796875\n",
      "New best validation epoch 1200 loss=39.083065032958984\n",
      "epoch 1400 loss=1233.40087890625\n",
      "New best validation epoch 1400 loss=38.89273452758789\n",
      "epoch 1600 loss=1204.045654296875\n",
      "New best validation epoch 1600 loss=38.83761978149414\n",
      "epoch 1800 loss=1233.75439453125\n",
      "New best validation epoch 1800 loss=38.73637008666992\n",
      "epoch 2000 loss=1195.8035888671875\n",
      "New best validation epoch 2000 loss=38.670310974121094\n",
      "epoch 2200 loss=1265.6669921875\n",
      "epoch 2400 loss=1194.1865234375\n",
      "epoch 2600 loss=1223.9705810546875\n",
      "epoch 2800 loss=1169.266845703125\n",
      "New best validation epoch 2800 loss=38.65048599243164\n",
      "epoch 3000 loss=1243.401611328125\n",
      "New best validation epoch 3000 loss=38.60932159423828\n",
      "epoch 3200 loss=1221.685302734375\n",
      "epoch 3400 loss=1187.318603515625\n",
      "epoch 3600 loss=1226.9227294921875\n",
      "epoch 3800 loss=1243.3826904296875\n",
      "epoch 4000 loss=1209.6015625\n",
      "epoch 4200 loss=1195.439453125\n",
      "epoch 4400 loss=1260.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4600 loss=1177.824462890625\n",
      "epoch 4800 loss=1210.73779296875\n",
      "epoch 4999 loss=1198.4017333984375\n",
      "Finished training\n",
      "FINISHED 0 7 34.63932800292969\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883, 11584,  6773, 29237, 17100, 13326,\n",
      "        19912,  9287,  5389,  8626, 20458, 32879,   715, 14412, 30039, 20058,\n",
      "        27622, 23386, 24127, 12128, 29171, 11813, 20786, 17223,  1941,  1234,\n",
      "        34696, 20560, 19667, 15013, 13523])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694,  3100, 11693,  3848, 21191, 16415,\n",
      "         8316, 20759, 21188, 19022, 27682, 27931,  8765,  2559, 18057, 23659,\n",
      "         5717,   930, 12970, 26561, 22642, 16264,   630, 25114, 11503, 16147,\n",
      "        23949, 29565, 18493, 11071, 27864])\n",
      "epoch 0 loss=1518.7772216796875\n",
      "New best validation epoch 0 loss=44.58441162109375\n",
      "epoch 200 loss=1359.158447265625\n",
      "New best validation epoch 200 loss=41.353153228759766\n",
      "epoch 400 loss=1285.2703857421875\n",
      "New best validation epoch 400 loss=40.44743347167969\n",
      "epoch 600 loss=1233.574951171875\n",
      "New best validation epoch 600 loss=39.88064956665039\n",
      "epoch 800 loss=1232.114990234375\n",
      "New best validation epoch 800 loss=39.389808654785156\n",
      "epoch 1000 loss=1242.18505859375\n",
      "New best validation epoch 1000 loss=39.01070022583008\n",
      "epoch 1200 loss=1195.54296875\n",
      "New best validation epoch 1200 loss=38.76473617553711\n",
      "epoch 1400 loss=1168.5068359375\n",
      "New best validation epoch 1400 loss=38.566749572753906\n",
      "epoch 1600 loss=1214.1123046875\n",
      "New best validation epoch 1600 loss=38.439796447753906\n",
      "epoch 1800 loss=1177.632568359375\n",
      "epoch 2000 loss=1193.441650390625\n",
      "New best validation epoch 2000 loss=38.391841888427734\n",
      "epoch 2200 loss=1196.232666015625\n",
      "New best validation epoch 2200 loss=38.39022445678711\n",
      "epoch 2400 loss=1189.04736328125\n",
      "epoch 2600 loss=1185.4620361328125\n",
      "epoch 2800 loss=1217.3489990234375\n",
      "epoch 3000 loss=1201.41064453125\n",
      "epoch 3200 loss=1205.22119140625\n",
      "New best validation epoch 3200 loss=38.3790397644043\n",
      "epoch 3400 loss=1198.175537109375\n",
      "epoch 3600 loss=1160.7183837890625\n",
      "epoch 3800 loss=1180.4439697265625\n",
      "New best validation epoch 3800 loss=38.37488555908203\n",
      "epoch 4000 loss=1201.259033203125\n",
      "epoch 4200 loss=1225.9193115234375\n",
      "New best validation epoch 4200 loss=38.35195541381836\n",
      "epoch 4400 loss=1172.468505859375\n",
      "New best validation epoch 4400 loss=38.33372497558594\n",
      "epoch 4600 loss=1221.4324951171875\n",
      "epoch 4800 loss=1156.3726806640625\n",
      "epoch 4999 loss=1218.98681640625\n",
      "Finished training\n",
      "FINISHED 0 8 33.958919525146484\n",
      "tensor([21453, 30472, 27868, 32298, 30909,  8840, 25586,    82, 15662, 29181,\n",
      "        13965, 22747,   668, 26496, 14883, 11584,  6773, 29237, 17100, 13326,\n",
      "        19912,  9287,  5389,  8626, 20458, 32879,   715, 14412, 30039, 20058,\n",
      "        27622, 23386, 24127, 12128, 29171, 11813, 20786, 17223,  1941,  1234,\n",
      "        34696, 20560, 19667, 15013, 13523, 13347, 31602, 27388, 12212, 23851])\n",
      "tensor([14448, 31983, 27311, 13717, 26818, 15188, 24769, 28412, 11955, 25431,\n",
      "        22139, 23745, 16214, 10306, 31694,  3100, 11693,  3848, 21191, 16415,\n",
      "         8316, 20759, 21188, 19022, 27682, 27931,  8765,  2559, 18057, 23659,\n",
      "         5717,   930, 12970, 26561, 22642, 16264,   630, 25114, 11503, 16147,\n",
      "        23949, 29565, 18493, 11071, 27864, 14152, 28898,  8362,  1991, 10366])\n",
      "epoch 0 loss=1514.6907958984375\n",
      "New best validation epoch 0 loss=44.58439636230469\n",
      "epoch 200 loss=1348.7947998046875\n",
      "New best validation epoch 200 loss=41.19845199584961\n",
      "epoch 400 loss=1275.9564208984375\n",
      "New best validation epoch 400 loss=40.328556060791016\n",
      "epoch 600 loss=1228.2359619140625\n",
      "New best validation epoch 600 loss=39.57942581176758\n",
      "epoch 800 loss=1221.6058349609375\n",
      "New best validation epoch 800 loss=38.991424560546875\n",
      "epoch 1000 loss=1172.4267578125\n",
      "New best validation epoch 1000 loss=38.570091247558594\n",
      "epoch 1200 loss=1220.664794921875\n",
      "New best validation epoch 1200 loss=38.27305603027344\n",
      "epoch 1400 loss=1214.491943359375\n",
      "New best validation epoch 1400 loss=38.071861267089844\n",
      "epoch 1600 loss=1165.5546875\n",
      "New best validation epoch 1600 loss=38.02326583862305\n",
      "epoch 1800 loss=1166.2451171875\n",
      "New best validation epoch 1800 loss=37.969852447509766\n",
      "epoch 2000 loss=1212.5867919921875\n",
      "New best validation epoch 2000 loss=37.901100158691406\n",
      "epoch 2200 loss=1154.215576171875\n",
      "New best validation epoch 2200 loss=37.856605529785156\n",
      "epoch 2400 loss=1145.1085205078125\n",
      "epoch 2600 loss=1184.289306640625\n",
      "New best validation epoch 2600 loss=37.819122314453125\n",
      "epoch 2800 loss=1209.104736328125\n",
      "epoch 3000 loss=1153.2181396484375\n",
      "epoch 3200 loss=1176.513671875\n",
      "New best validation epoch 3200 loss=37.78205871582031\n",
      "epoch 3400 loss=1176.437744140625\n",
      "epoch 3600 loss=1173.764892578125\n",
      "epoch 3800 loss=1190.817626953125\n",
      "epoch 4000 loss=1175.11474609375\n",
      "epoch 4200 loss=1181.1494140625\n",
      "New best validation epoch 4200 loss=37.76818084716797\n",
      "epoch 4400 loss=1136.9189453125\n",
      "New best validation epoch 4400 loss=37.761409759521484\n",
      "epoch 4600 loss=1133.935302734375\n",
      "epoch 4800 loss=1164.0968017578125\n",
      "epoch 4999 loss=1188.8465576171875\n",
      "Finished training\n",
      "FINISHED 0 9 33.40850830078125\n",
      "tensor([17802, 23003, 18607, 19980,   974])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069])\n",
      "epoch 0 loss=1474.2890625\n",
      "New best validation epoch 0 loss=44.033294677734375\n",
      "epoch 200 loss=1467.3665771484375\n",
      "New best validation epoch 200 loss=43.97332763671875\n",
      "epoch 400 loss=1452.1611328125\n",
      "New best validation epoch 400 loss=43.765811920166016\n",
      "epoch 600 loss=1424.92138671875\n",
      "New best validation epoch 600 loss=43.41136169433594\n",
      "epoch 800 loss=1408.421875\n",
      "New best validation epoch 800 loss=42.94791030883789\n",
      "epoch 1000 loss=1352.37841796875\n",
      "New best validation epoch 1000 loss=42.489524841308594\n",
      "epoch 1200 loss=1383.493408203125\n",
      "New best validation epoch 1200 loss=42.142738342285156\n",
      "epoch 1400 loss=1326.567626953125\n",
      "New best validation epoch 1400 loss=41.92168426513672\n",
      "epoch 1600 loss=1342.6673583984375\n",
      "New best validation epoch 1600 loss=41.81190490722656\n",
      "epoch 1800 loss=1348.348876953125\n",
      "New best validation epoch 1800 loss=41.75525665283203\n",
      "epoch 2000 loss=1353.65283203125\n",
      "New best validation epoch 2000 loss=41.69233703613281\n",
      "epoch 2200 loss=1345.62451171875\n",
      "New best validation epoch 2200 loss=41.6469612121582\n",
      "epoch 2400 loss=1334.201171875\n",
      "New best validation epoch 2400 loss=41.61666488647461\n",
      "epoch 2600 loss=1349.00537109375\n",
      "New best validation epoch 2600 loss=41.57567596435547\n",
      "epoch 2800 loss=1322.904296875\n",
      "New best validation epoch 2800 loss=41.533546447753906\n",
      "epoch 3000 loss=1346.217529296875\n",
      "New best validation epoch 3000 loss=41.5279541015625\n",
      "epoch 3200 loss=1328.49365234375\n",
      "New best validation epoch 3200 loss=41.50798797607422\n",
      "epoch 3400 loss=1333.88232421875\n",
      "New best validation epoch 3400 loss=41.490848541259766\n",
      "epoch 3600 loss=1364.5218505859375\n",
      "New best validation epoch 3600 loss=41.478515625\n",
      "epoch 3800 loss=1333.6171875\n",
      "epoch 4000 loss=1299.810791015625\n",
      "New best validation epoch 4000 loss=41.477317810058594\n",
      "epoch 4200 loss=1310.0289306640625\n",
      "New best validation epoch 4200 loss=41.4559211730957\n",
      "epoch 4400 loss=1360.03515625\n",
      "epoch 4600 loss=1344.5970458984375\n",
      "New best validation epoch 4600 loss=41.4520263671875\n",
      "epoch 4800 loss=1302.22021484375\n",
      "epoch 4999 loss=1352.607666015625\n",
      "Finished training\n",
      "FINISHED 1 0 41.36019515991211\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423])\n",
      "epoch 0 loss=1470.485595703125\n",
      "New best validation epoch 0 loss=44.033294677734375\n",
      "epoch 200 loss=1451.960693359375\n",
      "New best validation epoch 200 loss=43.73705291748047\n",
      "epoch 400 loss=1403.823974609375\n",
      "New best validation epoch 400 loss=42.70250701904297\n",
      "epoch 600 loss=1325.647705078125\n",
      "New best validation epoch 600 loss=41.59662628173828\n",
      "epoch 800 loss=1333.927734375\n",
      "New best validation epoch 800 loss=41.08316421508789\n",
      "epoch 1000 loss=1334.0257568359375\n",
      "New best validation epoch 1000 loss=40.89373779296875\n",
      "epoch 1200 loss=1323.5677490234375\n",
      "New best validation epoch 1200 loss=40.799747467041016\n",
      "epoch 1400 loss=1321.2371826171875\n",
      "New best validation epoch 1400 loss=40.706382751464844\n",
      "epoch 1600 loss=1324.701416015625\n",
      "New best validation epoch 1600 loss=40.68016815185547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1800 loss=1324.90966796875\n",
      "New best validation epoch 1800 loss=40.65116882324219\n",
      "epoch 2000 loss=1333.7294921875\n",
      "New best validation epoch 2000 loss=40.59654998779297\n",
      "epoch 2200 loss=1295.1319580078125\n",
      "New best validation epoch 2200 loss=40.53187942504883\n",
      "epoch 2400 loss=1323.0989990234375\n",
      "epoch 2600 loss=1323.052734375\n",
      "epoch 2800 loss=1325.386962890625\n",
      "epoch 3000 loss=1318.428466796875\n",
      "New best validation epoch 3000 loss=40.5144157409668\n",
      "epoch 3200 loss=1299.0667724609375\n",
      "epoch 3400 loss=1314.5164794921875\n",
      "epoch 3600 loss=1330.2763671875\n",
      "New best validation epoch 3600 loss=40.513710021972656\n",
      "epoch 3800 loss=1333.3616943359375\n",
      "epoch 4000 loss=1313.02392578125\n",
      "New best validation epoch 4000 loss=40.50653076171875\n",
      "epoch 4200 loss=1326.73193359375\n",
      "epoch 4400 loss=1318.129150390625\n",
      "epoch 4600 loss=1273.178955078125\n",
      "epoch 4800 loss=1327.54541015625\n",
      "epoch 4999 loss=1282.1971435546875\n",
      "Finished training\n",
      "FINISHED 1 1 41.272544860839844\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408])\n",
      "epoch 0 loss=1470.5859375\n",
      "New best validation epoch 0 loss=44.03329086303711\n",
      "epoch 200 loss=1434.3958740234375\n",
      "New best validation epoch 200 loss=43.27865219116211\n",
      "epoch 400 loss=1350.55029296875\n",
      "New best validation epoch 400 loss=41.249671936035156\n",
      "epoch 600 loss=1340.4617919921875\n",
      "New best validation epoch 600 loss=40.486900329589844\n",
      "epoch 800 loss=1314.6102294921875\n",
      "New best validation epoch 800 loss=40.254974365234375\n",
      "epoch 1000 loss=1294.813720703125\n",
      "New best validation epoch 1000 loss=40.2047119140625\n",
      "epoch 1200 loss=1299.2117919921875\n",
      "New best validation epoch 1200 loss=40.113983154296875\n",
      "epoch 1400 loss=1302.924072265625\n",
      "New best validation epoch 1400 loss=40.07417297363281\n",
      "epoch 1600 loss=1286.0260009765625\n",
      "New best validation epoch 1600 loss=40.035911560058594\n",
      "epoch 1800 loss=1307.6441650390625\n",
      "epoch 2000 loss=1279.452392578125\n",
      "New best validation epoch 2000 loss=39.94643783569336\n",
      "epoch 2200 loss=1266.50390625\n",
      "epoch 2400 loss=1288.86376953125\n",
      "epoch 2600 loss=1319.04443359375\n",
      "New best validation epoch 2600 loss=39.94598388671875\n",
      "epoch 2800 loss=1315.3861083984375\n",
      "New best validation epoch 2800 loss=39.91054153442383\n",
      "epoch 3000 loss=1307.40478515625\n",
      "epoch 3200 loss=1267.8681640625\n",
      "New best validation epoch 3200 loss=39.903804779052734\n",
      "epoch 3400 loss=1276.4580078125\n",
      "epoch 3600 loss=1283.060546875\n",
      "epoch 3800 loss=1285.4085693359375\n",
      "epoch 4000 loss=1272.4775390625\n",
      "epoch 4200 loss=1275.7708740234375\n",
      "epoch 4400 loss=1274.01513671875\n",
      "epoch 4600 loss=1302.81396484375\n",
      "epoch 4800 loss=1259.782470703125\n",
      "epoch 4999 loss=1266.2681884765625\n",
      "Finished training\n",
      "FINISHED 1 2 41.20476150512695\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255, 21331, 19659, 33384, 22508, 26527])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408, 23124,   256,  4442, 33126, 29602])\n",
      "epoch 0 loss=1472.5765380859375\n",
      "New best validation epoch 0 loss=44.03328323364258\n",
      "epoch 200 loss=1397.0003662109375\n",
      "New best validation epoch 200 loss=42.666778564453125\n",
      "epoch 400 loss=1339.4034423828125\n",
      "New best validation epoch 400 loss=40.58369445800781\n",
      "epoch 600 loss=1307.387451171875\n",
      "New best validation epoch 600 loss=40.15483093261719\n",
      "epoch 800 loss=1298.892333984375\n",
      "New best validation epoch 800 loss=40.02014923095703\n",
      "epoch 1000 loss=1264.862060546875\n",
      "New best validation epoch 1000 loss=39.89684295654297\n",
      "epoch 1200 loss=1288.807373046875\n",
      "New best validation epoch 1200 loss=39.811859130859375\n",
      "epoch 1400 loss=1317.498046875\n",
      "New best validation epoch 1400 loss=39.781803131103516\n",
      "epoch 1600 loss=1299.236083984375\n",
      "New best validation epoch 1600 loss=39.75446319580078\n",
      "epoch 1800 loss=1257.600341796875\n",
      "New best validation epoch 1800 loss=39.737239837646484\n",
      "epoch 2000 loss=1298.89697265625\n",
      "New best validation epoch 2000 loss=39.65201950073242\n",
      "epoch 2200 loss=1266.4693603515625\n",
      "epoch 2400 loss=1294.141357421875\n",
      "epoch 2600 loss=1271.00048828125\n",
      "New best validation epoch 2600 loss=39.624595642089844\n",
      "epoch 2800 loss=1256.31201171875\n",
      "epoch 3000 loss=1283.0491943359375\n",
      "epoch 3200 loss=1260.013427734375\n",
      "epoch 3400 loss=1279.626220703125\n",
      "epoch 3600 loss=1302.8917236328125\n",
      "epoch 3800 loss=1284.043701171875\n",
      "epoch 4000 loss=1292.460693359375\n",
      "epoch 4200 loss=1263.34130859375\n",
      "epoch 4400 loss=1277.092041015625\n",
      "epoch 4600 loss=1290.087158203125\n",
      "epoch 4800 loss=1238.7667236328125\n",
      "epoch 4999 loss=1260.5733642578125\n",
      "New best validation epoch 4999 loss=39.60612869262695\n",
      "Finished training\n",
      "FINISHED 1 3 41.03325653076172\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255, 21331, 19659, 33384, 22508, 26527,\n",
      "        22099, 20632, 31542, 11205,  6853])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408, 23124,   256,  4442, 33126, 29602,\n",
      "        12740, 28653,  6778, 32043, 24723])\n",
      "epoch 0 loss=1471.131591796875\n",
      "New best validation epoch 0 loss=44.033267974853516\n",
      "epoch 200 loss=1376.2020263671875\n",
      "New best validation epoch 200 loss=41.96465301513672\n",
      "epoch 400 loss=1305.64697265625\n",
      "New best validation epoch 400 loss=40.0198860168457\n",
      "epoch 600 loss=1305.029541015625\n",
      "New best validation epoch 600 loss=39.689247131347656\n",
      "epoch 800 loss=1272.027587890625\n",
      "New best validation epoch 800 loss=39.510963439941406\n",
      "epoch 1000 loss=1259.611572265625\n",
      "New best validation epoch 1000 loss=39.37256622314453\n",
      "epoch 1200 loss=1275.8271484375\n",
      "New best validation epoch 1200 loss=39.3382568359375\n",
      "epoch 1400 loss=1248.692626953125\n",
      "New best validation epoch 1400 loss=39.14086151123047\n",
      "epoch 1600 loss=1262.998779296875\n",
      "New best validation epoch 1600 loss=39.090431213378906\n",
      "epoch 1800 loss=1288.830322265625\n",
      "epoch 2000 loss=1262.8719482421875\n",
      "New best validation epoch 2000 loss=39.012847900390625\n",
      "epoch 2200 loss=1236.893310546875\n",
      "epoch 2400 loss=1254.3533935546875\n",
      "New best validation epoch 2400 loss=38.922264099121094\n",
      "epoch 2600 loss=1259.7657470703125\n",
      "epoch 2800 loss=1221.16357421875\n",
      "epoch 3000 loss=1280.450439453125\n",
      "epoch 3200 loss=1271.4207763671875\n",
      "epoch 3400 loss=1230.2332763671875\n",
      "epoch 3600 loss=1227.635498046875\n",
      "New best validation epoch 3600 loss=38.91663360595703\n",
      "epoch 3800 loss=1231.259765625\n",
      "New best validation epoch 3800 loss=38.889530181884766\n",
      "epoch 4000 loss=1254.4544677734375\n",
      "epoch 4200 loss=1250.7606201171875\n",
      "epoch 4400 loss=1243.6512451171875\n",
      "epoch 4600 loss=1190.2398681640625\n",
      "epoch 4800 loss=1241.3631591796875\n",
      "epoch 4999 loss=1261.5819091796875\n",
      "Finished training\n",
      "FINISHED 1 4 40.3910026550293\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255, 21331, 19659, 33384, 22508, 26527,\n",
      "        22099, 20632, 31542, 11205,  6853,  4019,  7398,   336, 28327,  5515])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408, 23124,   256,  4442, 33126, 29602,\n",
      "        12740, 28653,  6778, 32043, 24723, 30073,  7093, 27447, 19234, 32846])\n",
      "epoch 0 loss=1472.4296875\n",
      "New best validation epoch 0 loss=44.03325271606445\n",
      "epoch 200 loss=1327.1146240234375\n",
      "New best validation epoch 200 loss=41.175819396972656\n",
      "epoch 400 loss=1295.171142578125\n",
      "New best validation epoch 400 loss=39.66193771362305\n",
      "epoch 600 loss=1274.009033203125\n",
      "New best validation epoch 600 loss=39.27653884887695\n",
      "epoch 800 loss=1298.87109375\n",
      "New best validation epoch 800 loss=39.09294891357422\n",
      "epoch 1000 loss=1257.467041015625\n",
      "New best validation epoch 1000 loss=38.97814178466797\n",
      "epoch 1200 loss=1245.2789306640625\n",
      "New best validation epoch 1200 loss=38.81598663330078\n",
      "epoch 1400 loss=1238.8099365234375\n",
      "New best validation epoch 1400 loss=38.71199035644531\n",
      "epoch 1600 loss=1211.85498046875\n",
      "New best validation epoch 1600 loss=38.6274528503418\n",
      "epoch 1800 loss=1228.8367919921875\n",
      "New best validation epoch 1800 loss=38.555965423583984\n",
      "epoch 2000 loss=1239.267822265625\n",
      "New best validation epoch 2000 loss=38.51545715332031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2200 loss=1229.8330078125\n",
      "New best validation epoch 2200 loss=38.492767333984375\n",
      "epoch 2400 loss=1255.124755859375\n",
      "epoch 2600 loss=1208.54638671875\n",
      "epoch 2800 loss=1210.5614013671875\n",
      "New best validation epoch 2800 loss=38.465721130371094\n",
      "epoch 3000 loss=1249.16650390625\n",
      "epoch 3200 loss=1250.02685546875\n",
      "epoch 3400 loss=1241.46923828125\n",
      "epoch 3600 loss=1236.066650390625\n",
      "New best validation epoch 3600 loss=38.45565414428711\n",
      "epoch 3800 loss=1236.5174560546875\n",
      "epoch 4000 loss=1217.41357421875\n",
      "epoch 4200 loss=1213.1221923828125\n",
      "epoch 4400 loss=1214.9935302734375\n",
      "New best validation epoch 4400 loss=38.37540054321289\n",
      "epoch 4600 loss=1259.031494140625\n",
      "epoch 4800 loss=1248.1934814453125\n",
      "epoch 4999 loss=1238.1748046875\n",
      "Finished training\n",
      "FINISHED 1 5 40.145912170410156\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255, 21331, 19659, 33384, 22508, 26527,\n",
      "        22099, 20632, 31542, 11205,  6853,  4019,  7398,   336, 28327,  5515,\n",
      "        22614, 21788,  7444,  5586, 21678])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408, 23124,   256,  4442, 33126, 29602,\n",
      "        12740, 28653,  6778, 32043, 24723, 30073,  7093, 27447, 19234, 32846,\n",
      "        23625, 22204,   872, 14385, 20718])\n",
      "epoch 0 loss=1469.8680419921875\n",
      "New best validation epoch 0 loss=44.03324508666992\n",
      "epoch 200 loss=1336.3138427734375\n",
      "New best validation epoch 200 loss=40.726097106933594\n",
      "epoch 400 loss=1268.533935546875\n",
      "New best validation epoch 400 loss=39.34756088256836\n",
      "epoch 600 loss=1222.3350830078125\n",
      "New best validation epoch 600 loss=38.92436599731445\n",
      "epoch 800 loss=1233.82080078125\n",
      "New best validation epoch 800 loss=38.608036041259766\n",
      "epoch 1000 loss=1219.521240234375\n",
      "New best validation epoch 1000 loss=38.382083892822266\n",
      "epoch 1200 loss=1261.99755859375\n",
      "New best validation epoch 1200 loss=38.25572204589844\n",
      "epoch 1400 loss=1192.360595703125\n",
      "New best validation epoch 1400 loss=38.19308090209961\n",
      "epoch 1600 loss=1187.333984375\n",
      "New best validation epoch 1600 loss=38.05622863769531\n",
      "epoch 1800 loss=1213.6395263671875\n",
      "New best validation epoch 1800 loss=37.97874069213867\n",
      "epoch 2000 loss=1216.008544921875\n",
      "New best validation epoch 2000 loss=37.8879280090332\n",
      "epoch 2200 loss=1221.95654296875\n",
      "epoch 2400 loss=1163.470703125\n",
      "New best validation epoch 2400 loss=37.86667251586914\n",
      "epoch 2600 loss=1198.39453125\n",
      "New best validation epoch 2600 loss=37.84926223754883\n",
      "epoch 2800 loss=1188.75390625\n",
      "New best validation epoch 2800 loss=37.77367401123047\n",
      "epoch 3000 loss=1198.809326171875\n",
      "New best validation epoch 3000 loss=37.771968841552734\n",
      "epoch 3200 loss=1192.6982421875\n",
      "New best validation epoch 3200 loss=37.75292205810547\n",
      "epoch 3400 loss=1177.8497314453125\n",
      "epoch 3600 loss=1214.3494873046875\n",
      "New best validation epoch 3600 loss=37.68425369262695\n",
      "epoch 3800 loss=1177.05712890625\n",
      "epoch 4000 loss=1209.2589111328125\n",
      "epoch 4200 loss=1212.0736083984375\n",
      "epoch 4400 loss=1184.83935546875\n",
      "epoch 4600 loss=1221.0472412109375\n",
      "epoch 4800 loss=1188.830078125\n",
      "epoch 4999 loss=1203.9827880859375\n",
      "Finished training\n",
      "FINISHED 1 6 39.4167594909668\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255, 21331, 19659, 33384, 22508, 26527,\n",
      "        22099, 20632, 31542, 11205,  6853,  4019,  7398,   336, 28327,  5515,\n",
      "        22614, 21788,  7444,  5586, 21678, 11773,   893,   203, 27169, 31661])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408, 23124,   256,  4442, 33126, 29602,\n",
      "        12740, 28653,  6778, 32043, 24723, 30073,  7093, 27447, 19234, 32846,\n",
      "        23625, 22204,   872, 14385, 20718,   290,  7249, 33877, 34596,  2194])\n",
      "epoch 0 loss=1472.986572265625\n",
      "New best validation epoch 0 loss=44.03324890136719\n",
      "epoch 200 loss=1321.849609375\n",
      "New best validation epoch 200 loss=40.512184143066406\n",
      "epoch 400 loss=1253.6572265625\n",
      "New best validation epoch 400 loss=39.36675262451172\n",
      "epoch 600 loss=1217.527099609375\n",
      "New best validation epoch 600 loss=38.88017272949219\n",
      "epoch 800 loss=1214.8094482421875\n",
      "New best validation epoch 800 loss=38.490928649902344\n",
      "epoch 1000 loss=1209.2708740234375\n",
      "New best validation epoch 1000 loss=38.29432678222656\n",
      "epoch 1200 loss=1233.638916015625\n",
      "New best validation epoch 1200 loss=38.04804611206055\n",
      "epoch 1400 loss=1170.8011474609375\n",
      "New best validation epoch 1400 loss=37.94874572753906\n",
      "epoch 1600 loss=1178.049560546875\n",
      "New best validation epoch 1600 loss=37.94635009765625\n",
      "epoch 1800 loss=1187.8704833984375\n",
      "New best validation epoch 1800 loss=37.816505432128906\n",
      "epoch 2000 loss=1149.8692626953125\n",
      "New best validation epoch 2000 loss=37.729759216308594\n",
      "epoch 2200 loss=1159.0244140625\n",
      "New best validation epoch 2200 loss=37.71302795410156\n",
      "epoch 2400 loss=1153.156005859375\n",
      "New best validation epoch 2400 loss=37.66219711303711\n",
      "epoch 2600 loss=1180.130615234375\n",
      "New best validation epoch 2600 loss=37.62108612060547\n",
      "epoch 2800 loss=1201.6116943359375\n",
      "epoch 3000 loss=1199.99609375\n",
      "epoch 3200 loss=1177.965087890625\n",
      "epoch 3400 loss=1199.5311279296875\n",
      "epoch 3600 loss=1163.03125\n",
      "New best validation epoch 3600 loss=37.60918045043945\n",
      "epoch 3800 loss=1152.6494140625\n",
      "epoch 4000 loss=1181.475341796875\n",
      "epoch 4200 loss=1164.393310546875\n",
      "epoch 4400 loss=1174.468017578125\n",
      "epoch 4600 loss=1208.698974609375\n",
      "epoch 4800 loss=1188.5360107421875\n",
      "epoch 4999 loss=1206.576904296875\n",
      "Finished training\n",
      "FINISHED 1 7 39.00510025024414\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255, 21331, 19659, 33384, 22508, 26527,\n",
      "        22099, 20632, 31542, 11205,  6853,  4019,  7398,   336, 28327,  5515,\n",
      "        22614, 21788,  7444,  5586, 21678, 11773,   893,   203, 27169, 31661,\n",
      "         2527, 18011, 14985,  4832,  7566])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408, 23124,   256,  4442, 33126, 29602,\n",
      "        12740, 28653,  6778, 32043, 24723, 30073,  7093, 27447, 19234, 32846,\n",
      "        23625, 22204,   872, 14385, 20718,   290,  7249, 33877, 34596,  2194,\n",
      "        27175, 23143, 10216,  8326,  6033])\n",
      "epoch 0 loss=1470.28955078125\n",
      "New best validation epoch 0 loss=44.0332145690918\n",
      "epoch 200 loss=1288.556640625\n",
      "New best validation epoch 200 loss=40.2180061340332\n",
      "epoch 400 loss=1268.6806640625\n",
      "New best validation epoch 400 loss=39.16907501220703\n",
      "epoch 600 loss=1193.907958984375\n",
      "New best validation epoch 600 loss=38.576045989990234\n",
      "epoch 800 loss=1192.34716796875\n",
      "New best validation epoch 800 loss=38.2411003112793\n",
      "epoch 1000 loss=1175.5064697265625\n",
      "New best validation epoch 1000 loss=37.85590362548828\n",
      "epoch 1200 loss=1199.026123046875\n",
      "New best validation epoch 1200 loss=37.62845993041992\n",
      "epoch 1400 loss=1158.612548828125\n",
      "New best validation epoch 1400 loss=37.45100784301758\n",
      "epoch 1600 loss=1160.303955078125\n",
      "New best validation epoch 1600 loss=37.21478271484375\n",
      "epoch 1800 loss=1171.2781982421875\n",
      "epoch 2000 loss=1189.935791015625\n",
      "epoch 2200 loss=1156.8087158203125\n",
      "epoch 2400 loss=1154.9373779296875\n",
      "New best validation epoch 2400 loss=37.19998550415039\n",
      "epoch 2600 loss=1147.095458984375\n",
      "New best validation epoch 2600 loss=37.111724853515625\n",
      "epoch 2800 loss=1142.1033935546875\n",
      "epoch 3000 loss=1145.23583984375\n",
      "New best validation epoch 3000 loss=37.10228729248047\n",
      "epoch 3200 loss=1157.396240234375\n",
      "epoch 3400 loss=1179.909423828125\n",
      "epoch 3600 loss=1186.97216796875\n",
      "epoch 3800 loss=1173.054443359375\n",
      "epoch 4000 loss=1163.44921875\n",
      "New best validation epoch 4000 loss=37.01245880126953\n",
      "epoch 4200 loss=1154.4827880859375\n",
      "epoch 4400 loss=1164.423095703125\n",
      "epoch 4600 loss=1174.595947265625\n",
      "epoch 4800 loss=1138.074462890625\n",
      "epoch 4999 loss=1163.107666015625\n",
      "Finished training\n",
      "FINISHED 1 8 38.48189926147461\n",
      "tensor([17802, 23003, 18607, 19980,   974, 13114, 12885, 34703, 27572, 30183,\n",
      "         1141, 34365,  4683, 24159, 28255, 21331, 19659, 33384, 22508, 26527,\n",
      "        22099, 20632, 31542, 11205,  6853,  4019,  7398,   336, 28327,  5515,\n",
      "        22614, 21788,  7444,  5586, 21678, 11773,   893,   203, 27169, 31661,\n",
      "         2527, 18011, 14985,  4832,  7566, 12612,  1086,  6563, 14473, 17760])\n",
      "tensor([ 9994, 32776,  2243,  6974, 10069, 10613, 33401, 22656, 15919, 16423,\n",
      "        25932, 19958,  5720, 20638, 16408, 23124,   256,  4442, 33126, 29602,\n",
      "        12740, 28653,  6778, 32043, 24723, 30073,  7093, 27447, 19234, 32846,\n",
      "        23625, 22204,   872, 14385, 20718,   290,  7249, 33877, 34596,  2194,\n",
      "        27175, 23143, 10216,  8326,  6033, 25396, 14201, 31731, 14268, 29143])\n",
      "epoch 0 loss=1470.21923828125\n",
      "New best validation epoch 0 loss=44.033206939697266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1289.05078125\n",
      "New best validation epoch 200 loss=39.7162971496582\n",
      "epoch 400 loss=1219.921630859375\n",
      "New best validation epoch 400 loss=38.744625091552734\n",
      "epoch 600 loss=1179.0880126953125\n",
      "New best validation epoch 600 loss=38.13559341430664\n",
      "epoch 800 loss=1171.364013671875\n",
      "New best validation epoch 800 loss=37.72028350830078\n",
      "epoch 1000 loss=1175.9154052734375\n",
      "New best validation epoch 1000 loss=37.455745697021484\n",
      "epoch 1200 loss=1121.072509765625\n",
      "New best validation epoch 1200 loss=37.15599060058594\n",
      "epoch 1400 loss=1156.416015625\n",
      "New best validation epoch 1400 loss=37.02592086791992\n",
      "epoch 1600 loss=1161.6573486328125\n",
      "New best validation epoch 1600 loss=36.88869094848633\n",
      "epoch 1800 loss=1129.6248779296875\n",
      "New best validation epoch 1800 loss=36.854148864746094\n",
      "epoch 2000 loss=1110.344970703125\n",
      "epoch 2200 loss=1122.358154296875\n",
      "New best validation epoch 2200 loss=36.77326965332031\n",
      "epoch 2400 loss=1124.2418212890625\n",
      "epoch 2600 loss=1156.28466796875\n",
      "New best validation epoch 2600 loss=36.650997161865234\n",
      "epoch 2800 loss=1140.8472900390625\n",
      "New best validation epoch 2800 loss=36.63909149169922\n",
      "epoch 3000 loss=1131.0185546875\n",
      "epoch 3200 loss=1134.003173828125\n",
      "epoch 3400 loss=1106.136962890625\n",
      "epoch 3600 loss=1169.6546630859375\n",
      "New best validation epoch 3600 loss=36.571346282958984\n",
      "epoch 3800 loss=1120.087646484375\n",
      "epoch 4000 loss=1135.04248046875\n",
      "epoch 4200 loss=1111.8154296875\n",
      "New best validation epoch 4200 loss=36.512916564941406\n",
      "epoch 4400 loss=1132.910400390625\n",
      "epoch 4600 loss=1139.36181640625\n",
      "epoch 4800 loss=1189.0643310546875\n",
      "epoch 4999 loss=1169.2529296875\n",
      "Finished training\n",
      "FINISHED 1 9 38.433448791503906\n",
      "tensor([12709, 33676, 26080,  3835, 31146])\n",
      "tensor([32598, 25831, 11713,   371, 13393])\n",
      "epoch 0 loss=1538.480712890625\n",
      "New best validation epoch 0 loss=42.66290283203125\n",
      "epoch 200 loss=1534.1156005859375\n",
      "New best validation epoch 200 loss=42.586158752441406\n",
      "epoch 400 loss=1523.4881591796875\n",
      "New best validation epoch 400 loss=42.33134078979492\n",
      "epoch 600 loss=1514.455810546875\n",
      "New best validation epoch 600 loss=41.92588806152344\n",
      "epoch 800 loss=1479.7747802734375\n",
      "New best validation epoch 800 loss=41.442020416259766\n",
      "epoch 1000 loss=1447.831787109375\n",
      "New best validation epoch 1000 loss=40.99030685424805\n",
      "epoch 1200 loss=1433.4661865234375\n",
      "New best validation epoch 1200 loss=40.68711471557617\n",
      "epoch 1400 loss=1463.26171875\n",
      "New best validation epoch 1400 loss=40.47288513183594\n",
      "epoch 1600 loss=1429.048583984375\n",
      "New best validation epoch 1600 loss=40.32813262939453\n",
      "epoch 1800 loss=1470.3154296875\n",
      "New best validation epoch 1800 loss=40.23245620727539\n",
      "epoch 2000 loss=1434.697021484375\n",
      "New best validation epoch 2000 loss=40.145408630371094\n",
      "epoch 2200 loss=1404.942138671875\n",
      "New best validation epoch 2200 loss=40.09059524536133\n",
      "epoch 2400 loss=1428.3193359375\n",
      "New best validation epoch 2400 loss=40.03102111816406\n",
      "epoch 2600 loss=1465.787841796875\n",
      "New best validation epoch 2600 loss=39.998836517333984\n",
      "epoch 2800 loss=1462.76171875\n",
      "New best validation epoch 2800 loss=39.94747543334961\n",
      "epoch 3000 loss=1399.2113037109375\n",
      "New best validation epoch 3000 loss=39.914527893066406\n",
      "epoch 3200 loss=1435.18603515625\n",
      "New best validation epoch 3200 loss=39.88596725463867\n",
      "epoch 3400 loss=1400.1180419921875\n",
      "New best validation epoch 3400 loss=39.86912536621094\n",
      "epoch 3600 loss=1417.8076171875\n",
      "New best validation epoch 3600 loss=39.859771728515625\n",
      "epoch 3800 loss=1442.5849609375\n",
      "New best validation epoch 3800 loss=39.82913589477539\n",
      "epoch 4000 loss=1421.701904296875\n",
      "epoch 4200 loss=1434.326904296875\n",
      "New best validation epoch 4200 loss=39.82249450683594\n",
      "epoch 4400 loss=1454.025146484375\n",
      "New best validation epoch 4400 loss=39.815155029296875\n",
      "epoch 4600 loss=1439.063720703125\n",
      "epoch 4800 loss=1449.06396484375\n",
      "epoch 4999 loss=1416.8719482421875\n",
      "New best validation epoch 4999 loss=39.781681060791016\n",
      "Finished training\n",
      "FINISHED 2 0 35.495582580566406\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634])\n",
      "epoch 0 loss=1541.56396484375\n",
      "New best validation epoch 0 loss=42.66290283203125\n",
      "epoch 200 loss=1518.417236328125\n",
      "New best validation epoch 200 loss=42.361175537109375\n",
      "epoch 400 loss=1462.049560546875\n",
      "New best validation epoch 400 loss=41.363731384277344\n",
      "epoch 600 loss=1427.29296875\n",
      "New best validation epoch 600 loss=40.339149475097656\n",
      "epoch 800 loss=1381.740966796875\n",
      "New best validation epoch 800 loss=39.89845275878906\n",
      "epoch 1000 loss=1382.1365966796875\n",
      "New best validation epoch 1000 loss=39.70630645751953\n",
      "epoch 1200 loss=1400.1160888671875\n",
      "New best validation epoch 1200 loss=39.6136474609375\n",
      "epoch 1400 loss=1397.0941162109375\n",
      "New best validation epoch 1400 loss=39.57781982421875\n",
      "epoch 1600 loss=1376.610107421875\n",
      "New best validation epoch 1600 loss=39.517574310302734\n",
      "epoch 1800 loss=1355.9517822265625\n",
      "New best validation epoch 1800 loss=39.44794845581055\n",
      "epoch 2000 loss=1378.614013671875\n",
      "New best validation epoch 2000 loss=39.4297981262207\n",
      "epoch 2200 loss=1374.08935546875\n",
      "New best validation epoch 2200 loss=39.37942123413086\n",
      "epoch 2400 loss=1378.22314453125\n",
      "epoch 2600 loss=1370.3851318359375\n",
      "New best validation epoch 2600 loss=39.33045196533203\n",
      "epoch 2800 loss=1410.5653076171875\n",
      "New best validation epoch 2800 loss=39.31113815307617\n",
      "epoch 3000 loss=1369.330322265625\n",
      "epoch 3200 loss=1400.07470703125\n",
      "New best validation epoch 3200 loss=39.300872802734375\n",
      "epoch 3400 loss=1387.3284912109375\n",
      "New best validation epoch 3400 loss=39.287044525146484\n",
      "epoch 3600 loss=1403.332763671875\n",
      "epoch 3800 loss=1376.095703125\n",
      "epoch 4000 loss=1378.5194091796875\n",
      "epoch 4200 loss=1382.0579833984375\n",
      "New best validation epoch 4200 loss=39.26227569580078\n",
      "epoch 4400 loss=1353.6961669921875\n",
      "epoch 4600 loss=1407.0194091796875\n",
      "epoch 4800 loss=1347.095458984375\n",
      "epoch 4999 loss=1410.1351318359375\n",
      "Finished training\n",
      "FINISHED 2 1 34.81305694580078\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163])\n",
      "epoch 0 loss=1541.1995849609375\n",
      "New best validation epoch 0 loss=42.662899017333984\n",
      "epoch 200 loss=1493.1087646484375\n",
      "New best validation epoch 200 loss=41.980987548828125\n",
      "epoch 400 loss=1417.7109375\n",
      "New best validation epoch 400 loss=40.23881530761719\n",
      "epoch 600 loss=1409.463623046875\n",
      "New best validation epoch 600 loss=39.50360870361328\n",
      "epoch 800 loss=1401.76123046875\n",
      "New best validation epoch 800 loss=39.28156280517578\n",
      "epoch 1000 loss=1367.436767578125\n",
      "New best validation epoch 1000 loss=39.167022705078125\n",
      "epoch 1200 loss=1370.062255859375\n",
      "New best validation epoch 1200 loss=39.05381774902344\n",
      "epoch 1400 loss=1364.3275146484375\n",
      "New best validation epoch 1400 loss=39.043575286865234\n",
      "epoch 1600 loss=1354.582763671875\n",
      "New best validation epoch 1600 loss=38.975341796875\n",
      "epoch 1800 loss=1328.613037109375\n",
      "New best validation epoch 1800 loss=38.86412048339844\n",
      "epoch 2000 loss=1362.6019287109375\n",
      "New best validation epoch 2000 loss=38.8320198059082\n",
      "epoch 2200 loss=1309.148193359375\n",
      "New best validation epoch 2200 loss=38.77190017700195\n",
      "epoch 2400 loss=1327.554931640625\n",
      "New best validation epoch 2400 loss=38.73416519165039\n",
      "epoch 2600 loss=1354.43017578125\n",
      "epoch 2800 loss=1349.421875\n",
      "New best validation epoch 2800 loss=38.731529235839844\n",
      "epoch 3000 loss=1361.88916015625\n",
      "New best validation epoch 3000 loss=38.693233489990234\n",
      "epoch 3200 loss=1368.076904296875\n",
      "New best validation epoch 3200 loss=38.6585578918457\n",
      "epoch 3400 loss=1361.6429443359375\n",
      "epoch 3600 loss=1337.4111328125\n",
      "epoch 3800 loss=1366.403076171875\n",
      "epoch 4000 loss=1350.283203125\n",
      "New best validation epoch 4000 loss=38.637939453125\n",
      "epoch 4200 loss=1346.00390625\n",
      "epoch 4400 loss=1351.582763671875\n",
      "epoch 4600 loss=1323.12744140625\n",
      "epoch 4800 loss=1356.9224853515625\n",
      "New best validation epoch 4800 loss=38.615970611572266\n",
      "epoch 4999 loss=1340.36669921875\n",
      "Finished training\n",
      "FINISHED 2 2 34.2037353515625\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012,  1261, 25758, 20773,  7192, 34096])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163, 23457, 17234, 29409,  7953, 22070])\n",
      "epoch 0 loss=1540.6630859375\n",
      "New best validation epoch 0 loss=42.66289138793945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1474.7884521484375\n",
      "New best validation epoch 200 loss=41.54997253417969\n",
      "epoch 400 loss=1409.392578125\n",
      "New best validation epoch 400 loss=39.6629753112793\n",
      "epoch 600 loss=1390.343994140625\n",
      "New best validation epoch 600 loss=39.179656982421875\n",
      "epoch 800 loss=1368.9676513671875\n",
      "New best validation epoch 800 loss=38.92446517944336\n",
      "epoch 1000 loss=1336.0379638671875\n",
      "New best validation epoch 1000 loss=38.79145431518555\n",
      "epoch 1200 loss=1352.4237060546875\n",
      "New best validation epoch 1200 loss=38.61396789550781\n",
      "epoch 1400 loss=1345.759521484375\n",
      "New best validation epoch 1400 loss=38.463218688964844\n",
      "epoch 1600 loss=1348.583984375\n",
      "New best validation epoch 1600 loss=38.35246276855469\n",
      "epoch 1800 loss=1340.4580078125\n",
      "epoch 2000 loss=1317.4091796875\n",
      "New best validation epoch 2000 loss=38.3349609375\n",
      "epoch 2200 loss=1335.971923828125\n",
      "New best validation epoch 2200 loss=38.21315002441406\n",
      "epoch 2400 loss=1328.89599609375\n",
      "New best validation epoch 2400 loss=38.18586730957031\n",
      "epoch 2600 loss=1317.815185546875\n",
      "epoch 2800 loss=1345.45947265625\n",
      "epoch 3000 loss=1335.21435546875\n",
      "New best validation epoch 3000 loss=38.12815856933594\n",
      "epoch 3200 loss=1384.3924560546875\n",
      "epoch 3400 loss=1292.677001953125\n",
      "epoch 3600 loss=1350.2734375\n",
      "epoch 3800 loss=1327.9344482421875\n",
      "New best validation epoch 3800 loss=38.117820739746094\n",
      "epoch 4000 loss=1332.6673583984375\n",
      "epoch 4200 loss=1336.625732421875\n",
      "epoch 4400 loss=1314.7427978515625\n",
      "epoch 4600 loss=1352.4456787109375\n",
      "New best validation epoch 4600 loss=38.11744689941406\n",
      "epoch 4800 loss=1342.0252685546875\n",
      "New best validation epoch 4800 loss=38.11704635620117\n",
      "epoch 4999 loss=1320.52880859375\n",
      "New best validation epoch 4999 loss=38.10297393798828\n",
      "Finished training\n",
      "FINISHED 2 3 33.82398986816406\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012,  1261, 25758, 20773,  7192, 34096,\n",
      "        22233, 29462, 19975, 26733, 24801])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163, 23457, 17234, 29409,  7953, 22070,\n",
      "         2807,  3757,  2568,  5627,  2879])\n",
      "epoch 0 loss=1538.0242919921875\n",
      "New best validation epoch 0 loss=42.66289138793945\n",
      "epoch 200 loss=1460.217041015625\n",
      "New best validation epoch 200 loss=40.971988677978516\n",
      "epoch 400 loss=1401.73486328125\n",
      "New best validation epoch 400 loss=39.371944427490234\n",
      "epoch 600 loss=1380.969970703125\n",
      "New best validation epoch 600 loss=38.935516357421875\n",
      "epoch 800 loss=1351.6318359375\n",
      "New best validation epoch 800 loss=38.714820861816406\n",
      "epoch 1000 loss=1378.0169677734375\n",
      "New best validation epoch 1000 loss=38.462120056152344\n",
      "epoch 1200 loss=1341.02001953125\n",
      "New best validation epoch 1200 loss=38.35980224609375\n",
      "epoch 1400 loss=1363.62353515625\n",
      "New best validation epoch 1400 loss=38.212284088134766\n",
      "epoch 1600 loss=1333.8314208984375\n",
      "New best validation epoch 1600 loss=38.11516571044922\n",
      "epoch 1800 loss=1349.575439453125\n",
      "New best validation epoch 1800 loss=38.11149597167969\n",
      "epoch 2000 loss=1328.2840576171875\n",
      "New best validation epoch 2000 loss=38.033653259277344\n",
      "epoch 2200 loss=1331.68701171875\n",
      "epoch 2400 loss=1318.429443359375\n",
      "epoch 2600 loss=1337.73046875\n",
      "New best validation epoch 2600 loss=37.985721588134766\n",
      "epoch 2800 loss=1304.170654296875\n",
      "New best validation epoch 2800 loss=37.967559814453125\n",
      "epoch 3000 loss=1327.771240234375\n",
      "New best validation epoch 3000 loss=37.9449462890625\n",
      "epoch 3200 loss=1306.357421875\n",
      "New best validation epoch 3200 loss=37.91672134399414\n",
      "epoch 3400 loss=1325.4967041015625\n",
      "New best validation epoch 3400 loss=37.88121032714844\n",
      "epoch 3600 loss=1327.632568359375\n",
      "epoch 3800 loss=1338.474365234375\n",
      "New best validation epoch 3800 loss=37.85903549194336\n",
      "epoch 4000 loss=1284.036865234375\n",
      "epoch 4200 loss=1289.1151123046875\n",
      "New best validation epoch 4200 loss=37.83679962158203\n",
      "epoch 4400 loss=1346.1630859375\n",
      "epoch 4600 loss=1325.567626953125\n",
      "New best validation epoch 4600 loss=37.832340240478516\n",
      "epoch 4800 loss=1321.701416015625\n",
      "epoch 4999 loss=1334.02978515625\n",
      "Finished training\n",
      "FINISHED 2 4 33.7801399230957\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012,  1261, 25758, 20773,  7192, 34096,\n",
      "        22233, 29462, 19975, 26733, 24801, 33922,  9720, 28904, 11067,  4503])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163, 23457, 17234, 29409,  7953, 22070,\n",
      "         2807,  3757,  2568,  5627,  2879, 25411, 25633,  4108, 10876, 25685])\n",
      "epoch 0 loss=1539.416748046875\n",
      "New best validation epoch 0 loss=42.662864685058594\n",
      "epoch 200 loss=1426.2435302734375\n",
      "New best validation epoch 200 loss=40.42592239379883\n",
      "epoch 400 loss=1367.2020263671875\n",
      "New best validation epoch 400 loss=39.147159576416016\n",
      "epoch 600 loss=1367.2587890625\n",
      "New best validation epoch 600 loss=38.84521484375\n",
      "epoch 800 loss=1348.8294677734375\n",
      "New best validation epoch 800 loss=38.537025451660156\n",
      "epoch 1000 loss=1328.8226318359375\n",
      "New best validation epoch 1000 loss=38.3836784362793\n",
      "epoch 1200 loss=1329.6888427734375\n",
      "New best validation epoch 1200 loss=38.1973991394043\n",
      "epoch 1400 loss=1324.792236328125\n",
      "New best validation epoch 1400 loss=38.03559875488281\n",
      "epoch 1600 loss=1312.5469970703125\n",
      "New best validation epoch 1600 loss=38.023109436035156\n",
      "epoch 1800 loss=1307.5450439453125\n",
      "New best validation epoch 1800 loss=37.95549392700195\n",
      "epoch 2000 loss=1298.9200439453125\n",
      "New best validation epoch 2000 loss=37.911476135253906\n",
      "epoch 2200 loss=1312.066650390625\n",
      "New best validation epoch 2200 loss=37.892051696777344\n",
      "epoch 2400 loss=1339.7410888671875\n",
      "New best validation epoch 2400 loss=37.817543029785156\n",
      "epoch 2600 loss=1293.238525390625\n",
      "New best validation epoch 2600 loss=37.79972457885742\n",
      "epoch 2800 loss=1310.10107421875\n",
      "New best validation epoch 2800 loss=37.74201583862305\n",
      "epoch 3000 loss=1297.6552734375\n",
      "epoch 3200 loss=1309.8431396484375\n",
      "epoch 3400 loss=1322.193359375\n",
      "New best validation epoch 3400 loss=37.698482513427734\n",
      "epoch 3600 loss=1321.995361328125\n",
      "New best validation epoch 3600 loss=37.696651458740234\n",
      "epoch 3800 loss=1281.495361328125\n",
      "New best validation epoch 3800 loss=37.69623947143555\n",
      "epoch 4000 loss=1275.4925537109375\n",
      "epoch 4200 loss=1327.513916015625\n",
      "epoch 4400 loss=1302.7811279296875\n",
      "epoch 4600 loss=1286.6488037109375\n",
      "epoch 4800 loss=1292.0174560546875\n",
      "New best validation epoch 4800 loss=37.6517448425293\n",
      "epoch 4999 loss=1254.86669921875\n",
      "New best validation epoch 4999 loss=37.618988037109375\n",
      "Finished training\n",
      "FINISHED 2 5 33.36487579345703\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012,  1261, 25758, 20773,  7192, 34096,\n",
      "        22233, 29462, 19975, 26733, 24801, 33922,  9720, 28904, 11067,  4503,\n",
      "        20799, 29077, 24587,  7306, 20004])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163, 23457, 17234, 29409,  7953, 22070,\n",
      "         2807,  3757,  2568,  5627,  2879, 25411, 25633,  4108, 10876, 25685,\n",
      "        32536, 22872, 11357, 21665,  8115])\n",
      "epoch 0 loss=1541.565185546875\n",
      "New best validation epoch 0 loss=42.662864685058594\n",
      "epoch 200 loss=1419.182373046875\n",
      "New best validation epoch 200 loss=39.86798858642578\n",
      "epoch 400 loss=1370.6123046875\n",
      "New best validation epoch 400 loss=38.98358917236328\n",
      "epoch 600 loss=1329.4559326171875\n",
      "New best validation epoch 600 loss=38.622337341308594\n",
      "epoch 800 loss=1316.06103515625\n",
      "New best validation epoch 800 loss=38.25927734375\n",
      "epoch 1000 loss=1307.512451171875\n",
      "New best validation epoch 1000 loss=38.01194763183594\n",
      "epoch 1200 loss=1294.078369140625\n",
      "New best validation epoch 1200 loss=37.810096740722656\n",
      "epoch 1400 loss=1286.94970703125\n",
      "New best validation epoch 1400 loss=37.762359619140625\n",
      "epoch 1600 loss=1257.236328125\n",
      "New best validation epoch 1600 loss=37.6646842956543\n",
      "epoch 1800 loss=1323.94189453125\n",
      "New best validation epoch 1800 loss=37.5485954284668\n",
      "epoch 2000 loss=1302.314208984375\n",
      "New best validation epoch 2000 loss=37.46187210083008\n",
      "epoch 2200 loss=1295.2733154296875\n",
      "epoch 2400 loss=1294.6424560546875\n",
      "New best validation epoch 2400 loss=37.414215087890625\n",
      "epoch 2600 loss=1275.09423828125\n",
      "New best validation epoch 2600 loss=37.2640266418457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2800 loss=1316.39990234375\n",
      "epoch 3000 loss=1320.2303466796875\n",
      "New best validation epoch 3000 loss=37.26232147216797\n",
      "epoch 3200 loss=1283.1510009765625\n",
      "New best validation epoch 3200 loss=37.258888244628906\n",
      "epoch 3400 loss=1291.4359130859375\n",
      "epoch 3600 loss=1319.0130615234375\n",
      "New best validation epoch 3600 loss=37.211891174316406\n",
      "epoch 3800 loss=1281.804931640625\n",
      "epoch 4000 loss=1315.21630859375\n",
      "epoch 4200 loss=1263.0638427734375\n",
      "epoch 4400 loss=1309.071044921875\n",
      "epoch 4600 loss=1313.59423828125\n",
      "epoch 4800 loss=1311.1396484375\n",
      "epoch 4999 loss=1303.255126953125\n",
      "Finished training\n",
      "FINISHED 2 6 33.15499496459961\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012,  1261, 25758, 20773,  7192, 34096,\n",
      "        22233, 29462, 19975, 26733, 24801, 33922,  9720, 28904, 11067,  4503,\n",
      "        20799, 29077, 24587,  7306, 20004, 22772,  4506, 21504,  6693, 23133])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163, 23457, 17234, 29409,  7953, 22070,\n",
      "         2807,  3757,  2568,  5627,  2879, 25411, 25633,  4108, 10876, 25685,\n",
      "        32536, 22872, 11357, 21665,  8115, 23219,  4642, 12734, 26259, 14030])\n",
      "epoch 0 loss=1540.935546875\n",
      "New best validation epoch 0 loss=42.66284942626953\n",
      "epoch 200 loss=1397.13037109375\n",
      "New best validation epoch 200 loss=39.4992561340332\n",
      "epoch 400 loss=1351.941650390625\n",
      "New best validation epoch 400 loss=38.61587142944336\n",
      "epoch 600 loss=1306.1712646484375\n",
      "New best validation epoch 600 loss=38.06624221801758\n",
      "epoch 800 loss=1298.6497802734375\n",
      "New best validation epoch 800 loss=37.635833740234375\n",
      "epoch 1000 loss=1277.14208984375\n",
      "New best validation epoch 1000 loss=37.436302185058594\n",
      "epoch 1200 loss=1251.386962890625\n",
      "New best validation epoch 1200 loss=37.152164459228516\n",
      "epoch 1400 loss=1289.20263671875\n",
      "New best validation epoch 1400 loss=36.97294998168945\n",
      "epoch 1600 loss=1257.3607177734375\n",
      "New best validation epoch 1600 loss=36.87590026855469\n",
      "epoch 1800 loss=1262.401123046875\n",
      "New best validation epoch 1800 loss=36.796451568603516\n",
      "epoch 2000 loss=1261.4447021484375\n",
      "New best validation epoch 2000 loss=36.68532180786133\n",
      "epoch 2200 loss=1252.2322998046875\n",
      "epoch 2400 loss=1239.9539794921875\n",
      "New best validation epoch 2400 loss=36.65399932861328\n",
      "epoch 2600 loss=1285.60205078125\n",
      "New best validation epoch 2600 loss=36.57050704956055\n",
      "epoch 2800 loss=1249.2742919921875\n",
      "epoch 3000 loss=1266.946044921875\n",
      "epoch 3200 loss=1238.77880859375\n",
      "New best validation epoch 3200 loss=36.56554412841797\n",
      "epoch 3400 loss=1290.9002685546875\n",
      "epoch 3600 loss=1229.607177734375\n",
      "epoch 3800 loss=1242.2757568359375\n",
      "New best validation epoch 3800 loss=36.53620147705078\n",
      "epoch 4000 loss=1269.09814453125\n",
      "New best validation epoch 4000 loss=36.535030364990234\n",
      "epoch 4200 loss=1232.509033203125\n",
      "epoch 4400 loss=1244.1497802734375\n",
      "epoch 4600 loss=1278.0146484375\n",
      "epoch 4800 loss=1268.458984375\n",
      "epoch 4999 loss=1230.666015625\n",
      "Finished training\n",
      "FINISHED 2 7 32.35818862915039\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012,  1261, 25758, 20773,  7192, 34096,\n",
      "        22233, 29462, 19975, 26733, 24801, 33922,  9720, 28904, 11067,  4503,\n",
      "        20799, 29077, 24587,  7306, 20004, 22772,  4506, 21504,  6693, 23133,\n",
      "        20281,  7862, 26140, 32677, 22856])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163, 23457, 17234, 29409,  7953, 22070,\n",
      "         2807,  3757,  2568,  5627,  2879, 25411, 25633,  4108, 10876, 25685,\n",
      "        32536, 22872, 11357, 21665,  8115, 23219,  4642, 12734, 26259, 14030,\n",
      "        21919,  5005, 22260,  9703, 28554])\n",
      "epoch 0 loss=1541.385498046875\n",
      "New best validation epoch 0 loss=42.66282272338867\n",
      "epoch 200 loss=1389.5052490234375\n",
      "New best validation epoch 200 loss=39.241390228271484\n",
      "epoch 400 loss=1312.049560546875\n",
      "New best validation epoch 400 loss=38.494720458984375\n",
      "epoch 600 loss=1293.74755859375\n",
      "New best validation epoch 600 loss=37.88886642456055\n",
      "epoch 800 loss=1273.25146484375\n",
      "New best validation epoch 800 loss=37.471649169921875\n",
      "epoch 1000 loss=1247.301025390625\n",
      "New best validation epoch 1000 loss=37.098060607910156\n",
      "epoch 1200 loss=1242.57470703125\n",
      "New best validation epoch 1200 loss=36.839351654052734\n",
      "epoch 1400 loss=1243.0185546875\n",
      "New best validation epoch 1400 loss=36.54243850708008\n",
      "epoch 1600 loss=1266.31982421875\n",
      "New best validation epoch 1600 loss=36.50275421142578\n",
      "epoch 1800 loss=1251.687744140625\n",
      "New best validation epoch 1800 loss=36.41802978515625\n",
      "epoch 2000 loss=1227.2059326171875\n",
      "New best validation epoch 2000 loss=36.39650344848633\n",
      "epoch 2200 loss=1238.972900390625\n",
      "New best validation epoch 2200 loss=36.26267623901367\n",
      "epoch 2400 loss=1211.7672119140625\n",
      "epoch 2600 loss=1229.1798095703125\n",
      "New best validation epoch 2600 loss=36.22251510620117\n",
      "epoch 2800 loss=1233.5322265625\n",
      "epoch 3000 loss=1213.9710693359375\n",
      "epoch 3200 loss=1260.333740234375\n",
      "epoch 3400 loss=1203.7769775390625\n",
      "New best validation epoch 3400 loss=36.222076416015625\n",
      "epoch 3600 loss=1235.0111083984375\n",
      "epoch 3800 loss=1286.5908203125\n",
      "New best validation epoch 3800 loss=36.18150329589844\n",
      "epoch 4000 loss=1284.63037109375\n",
      "New best validation epoch 4000 loss=36.16176223754883\n",
      "epoch 4200 loss=1270.1239013671875\n",
      "epoch 4400 loss=1219.634521484375\n",
      "epoch 4600 loss=1197.6767578125\n",
      "New best validation epoch 4600 loss=36.08597946166992\n",
      "epoch 4800 loss=1247.6162109375\n",
      "epoch 4999 loss=1238.47412109375\n",
      "Finished training\n",
      "FINISHED 2 8 32.156314849853516\n",
      "tensor([12709, 33676, 26080,  3835, 31146,   483, 29515, 15887,  4293, 19526,\n",
      "        18589, 14064, 24369, 21502, 16012,  1261, 25758, 20773,  7192, 34096,\n",
      "        22233, 29462, 19975, 26733, 24801, 33922,  9720, 28904, 11067,  4503,\n",
      "        20799, 29077, 24587,  7306, 20004, 22772,  4506, 21504,  6693, 23133,\n",
      "        20281,  7862, 26140, 32677, 22856, 18335, 17020, 24323, 16800, 19780])\n",
      "tensor([32598, 25831, 11713,   371, 13393,  5226, 33542,  4244, 29416, 21634,\n",
      "        23735,  5273,  4069, 29163, 20163, 23457, 17234, 29409,  7953, 22070,\n",
      "         2807,  3757,  2568,  5627,  2879, 25411, 25633,  4108, 10876, 25685,\n",
      "        32536, 22872, 11357, 21665,  8115, 23219,  4642, 12734, 26259, 14030,\n",
      "        21919,  5005, 22260,  9703, 28554, 14862,  5325,  6911,  1979, 23167])\n",
      "epoch 0 loss=1542.0374755859375\n",
      "New best validation epoch 0 loss=42.66279983520508\n",
      "epoch 200 loss=1385.0028076171875\n",
      "New best validation epoch 200 loss=39.03678894042969\n",
      "epoch 400 loss=1308.21875\n",
      "New best validation epoch 400 loss=38.20222473144531\n",
      "epoch 600 loss=1271.81884765625\n",
      "New best validation epoch 600 loss=37.51458740234375\n",
      "epoch 800 loss=1275.8519287109375\n",
      "New best validation epoch 800 loss=36.95775604248047\n",
      "epoch 1000 loss=1272.4091796875\n",
      "New best validation epoch 1000 loss=36.50602340698242\n",
      "epoch 1200 loss=1221.0\n",
      "New best validation epoch 1200 loss=36.203792572021484\n",
      "epoch 1400 loss=1221.2318115234375\n",
      "New best validation epoch 1400 loss=35.95927429199219\n",
      "epoch 1600 loss=1222.413330078125\n",
      "New best validation epoch 1600 loss=35.76383590698242\n",
      "epoch 1800 loss=1192.379638671875\n",
      "epoch 2000 loss=1232.192138671875\n",
      "New best validation epoch 2000 loss=35.66263961791992\n",
      "epoch 2200 loss=1230.315185546875\n",
      "epoch 2400 loss=1196.844482421875\n",
      "New best validation epoch 2400 loss=35.51818084716797\n",
      "epoch 2600 loss=1211.876953125\n",
      "epoch 2800 loss=1213.3914794921875\n",
      "epoch 3000 loss=1213.96630859375\n",
      "epoch 3200 loss=1172.25048828125\n",
      "New best validation epoch 3200 loss=35.47848892211914\n",
      "epoch 3400 loss=1235.29345703125\n",
      "epoch 3600 loss=1219.258056640625\n",
      "epoch 3800 loss=1178.317626953125\n",
      "epoch 4000 loss=1218.7861328125\n",
      "epoch 4200 loss=1235.828369140625\n",
      "epoch 4400 loss=1250.3658447265625\n",
      "epoch 4600 loss=1161.588134765625\n",
      "epoch 4800 loss=1209.6181640625\n",
      "epoch 4999 loss=1229.002685546875\n",
      "Finished training\n",
      "FINISHED 2 9 31.890155792236328\n",
      "tensor([18275, 12226, 16178, 29074, 21032])\n",
      "tensor([30610,  8079, 31432, 28233, 26493])\n",
      "epoch 0 loss=1514.5843505859375\n",
      "New best validation epoch 0 loss=43.697364807128906\n",
      "epoch 200 loss=1511.366943359375\n",
      "New best validation epoch 200 loss=43.66788101196289\n",
      "epoch 400 loss=1502.1976318359375\n",
      "New best validation epoch 400 loss=43.56067657470703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600 loss=1486.128173828125\n",
      "New best validation epoch 600 loss=43.36565399169922\n",
      "epoch 800 loss=1478.424560546875\n",
      "New best validation epoch 800 loss=43.11166000366211\n",
      "epoch 1000 loss=1466.140869140625\n",
      "New best validation epoch 1000 loss=42.88039779663086\n",
      "epoch 1200 loss=1447.3671875\n",
      "New best validation epoch 1200 loss=42.721458435058594\n",
      "epoch 1400 loss=1443.8392333984375\n",
      "New best validation epoch 1400 loss=42.6323356628418\n",
      "epoch 1600 loss=1454.771240234375\n",
      "New best validation epoch 1600 loss=42.5842399597168\n",
      "epoch 1800 loss=1457.0364990234375\n",
      "New best validation epoch 1800 loss=42.535762786865234\n",
      "epoch 2000 loss=1439.0003662109375\n",
      "New best validation epoch 2000 loss=42.50938415527344\n",
      "epoch 2200 loss=1455.010009765625\n",
      "New best validation epoch 2200 loss=42.49095153808594\n",
      "epoch 2400 loss=1454.865966796875\n",
      "epoch 2600 loss=1438.3568115234375\n",
      "New best validation epoch 2600 loss=42.482635498046875\n",
      "epoch 2800 loss=1445.73974609375\n",
      "New best validation epoch 2800 loss=42.45792770385742\n",
      "epoch 3000 loss=1457.17236328125\n",
      "New best validation epoch 3000 loss=42.457828521728516\n",
      "epoch 3200 loss=1456.394775390625\n",
      "epoch 3400 loss=1446.147705078125\n",
      "New best validation epoch 3400 loss=42.453922271728516\n",
      "epoch 3600 loss=1430.3460693359375\n",
      "New best validation epoch 3600 loss=42.43696594238281\n",
      "epoch 3800 loss=1448.8602294921875\n",
      "epoch 4000 loss=1435.9599609375\n",
      "epoch 4200 loss=1430.8818359375\n",
      "New best validation epoch 4200 loss=42.429115295410156\n",
      "epoch 4400 loss=1422.002685546875\n",
      "epoch 4600 loss=1430.90478515625\n",
      "epoch 4800 loss=1454.019287109375\n",
      "New best validation epoch 4800 loss=42.42882537841797\n",
      "epoch 4999 loss=1464.5194091796875\n",
      "New best validation epoch 4999 loss=42.422550201416016\n",
      "Finished training\n",
      "FINISHED 3 0 37.52241897583008\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510])\n",
      "epoch 0 loss=1516.2801513671875\n",
      "New best validation epoch 0 loss=43.69736099243164\n",
      "epoch 200 loss=1492.396484375\n",
      "New best validation epoch 200 loss=43.51545333862305\n",
      "epoch 400 loss=1430.382080078125\n",
      "New best validation epoch 400 loss=42.811649322509766\n",
      "epoch 600 loss=1400.125244140625\n",
      "New best validation epoch 600 loss=41.9553337097168\n",
      "epoch 800 loss=1403.8704833984375\n",
      "New best validation epoch 800 loss=41.555686950683594\n",
      "epoch 1000 loss=1395.654541015625\n",
      "New best validation epoch 1000 loss=41.40937423706055\n",
      "epoch 1200 loss=1382.1556396484375\n",
      "New best validation epoch 1200 loss=41.30391311645508\n",
      "epoch 1400 loss=1367.7431640625\n",
      "New best validation epoch 1400 loss=41.26584243774414\n",
      "epoch 1600 loss=1373.6839599609375\n",
      "New best validation epoch 1600 loss=41.20402526855469\n",
      "epoch 1800 loss=1388.8895263671875\n",
      "New best validation epoch 1800 loss=41.193145751953125\n",
      "epoch 2000 loss=1374.407958984375\n",
      "New best validation epoch 2000 loss=41.15201950073242\n",
      "epoch 2200 loss=1376.2806396484375\n",
      "epoch 2400 loss=1383.9794921875\n",
      "New best validation epoch 2400 loss=41.14284896850586\n",
      "epoch 2600 loss=1383.6405029296875\n",
      "New best validation epoch 2600 loss=41.13177490234375\n",
      "epoch 2800 loss=1400.8720703125\n",
      "New best validation epoch 2800 loss=41.126163482666016\n",
      "epoch 3000 loss=1434.363037109375\n",
      "epoch 3200 loss=1407.1824951171875\n",
      "epoch 3400 loss=1340.04296875\n",
      "epoch 3600 loss=1393.628662109375\n",
      "New best validation epoch 3600 loss=41.121952056884766\n",
      "epoch 3800 loss=1354.0887451171875\n",
      "New best validation epoch 3800 loss=41.042449951171875\n",
      "epoch 4000 loss=1373.7952880859375\n",
      "epoch 4200 loss=1376.9158935546875\n",
      "epoch 4400 loss=1356.0677490234375\n",
      "epoch 4600 loss=1340.6815185546875\n",
      "epoch 4800 loss=1370.8348388671875\n",
      "epoch 4999 loss=1374.03173828125\n",
      "New best validation epoch 4999 loss=41.035831451416016\n",
      "Finished training\n",
      "FINISHED 3 1 35.77573776245117\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765])\n",
      "epoch 0 loss=1516.966552734375\n",
      "New best validation epoch 0 loss=43.697357177734375\n",
      "epoch 200 loss=1487.7484130859375\n",
      "New best validation epoch 200 loss=43.32040786743164\n",
      "epoch 400 loss=1423.7080078125\n",
      "New best validation epoch 400 loss=42.213016510009766\n",
      "epoch 600 loss=1394.73388671875\n",
      "New best validation epoch 600 loss=41.59075927734375\n",
      "epoch 800 loss=1400.0936279296875\n",
      "New best validation epoch 800 loss=41.33992004394531\n",
      "epoch 1000 loss=1400.7713623046875\n",
      "New best validation epoch 1000 loss=41.20177459716797\n",
      "epoch 1200 loss=1393.454833984375\n",
      "New best validation epoch 1200 loss=41.10169982910156\n",
      "epoch 1400 loss=1393.5418701171875\n",
      "New best validation epoch 1400 loss=41.02427291870117\n",
      "epoch 1600 loss=1358.29443359375\n",
      "New best validation epoch 1600 loss=40.970176696777344\n",
      "epoch 1800 loss=1379.291259765625\n",
      "New best validation epoch 1800 loss=40.92290115356445\n",
      "epoch 2000 loss=1388.2646484375\n",
      "New best validation epoch 2000 loss=40.8642578125\n",
      "epoch 2200 loss=1332.7728271484375\n",
      "epoch 2400 loss=1357.1741943359375\n",
      "New best validation epoch 2400 loss=40.84760665893555\n",
      "epoch 2600 loss=1342.7386474609375\n",
      "epoch 2800 loss=1362.005126953125\n",
      "New best validation epoch 2800 loss=40.816139221191406\n",
      "epoch 3000 loss=1385.85400390625\n",
      "epoch 3200 loss=1388.284912109375\n",
      "New best validation epoch 3200 loss=40.7573356628418\n",
      "epoch 3400 loss=1351.578125\n",
      "epoch 3600 loss=1342.2132568359375\n",
      "epoch 3800 loss=1381.2615966796875\n",
      "epoch 4000 loss=1360.49267578125\n",
      "epoch 4200 loss=1348.994140625\n",
      "epoch 4400 loss=1370.84033203125\n",
      "epoch 4600 loss=1355.402587890625\n",
      "epoch 4800 loss=1378.5091552734375\n",
      "New best validation epoch 4800 loss=40.74263000488281\n",
      "epoch 4999 loss=1359.264404296875\n",
      "Finished training\n",
      "FINISHED 3 2 35.600093841552734\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961, 32835, 29167, 21665,  2548,  9700])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765, 12355, 24520, 15146, 31520, 31817])\n",
      "epoch 0 loss=1516.98291015625\n",
      "New best validation epoch 0 loss=43.697357177734375\n",
      "epoch 200 loss=1459.78759765625\n",
      "New best validation epoch 200 loss=42.950538635253906\n",
      "epoch 400 loss=1408.6240234375\n",
      "New best validation epoch 400 loss=41.527896881103516\n",
      "epoch 600 loss=1381.7279052734375\n",
      "New best validation epoch 600 loss=41.05022048950195\n",
      "epoch 800 loss=1374.4539794921875\n",
      "New best validation epoch 800 loss=40.741600036621094\n",
      "epoch 1000 loss=1358.150146484375\n",
      "New best validation epoch 1000 loss=40.54861831665039\n",
      "epoch 1200 loss=1370.42578125\n",
      "New best validation epoch 1200 loss=40.380393981933594\n",
      "epoch 1400 loss=1337.126220703125\n",
      "New best validation epoch 1400 loss=40.29280090332031\n",
      "epoch 1600 loss=1352.4046630859375\n",
      "New best validation epoch 1600 loss=40.240203857421875\n",
      "epoch 1800 loss=1338.83642578125\n",
      "New best validation epoch 1800 loss=40.16092300415039\n",
      "epoch 2000 loss=1309.149169921875\n",
      "New best validation epoch 2000 loss=40.09402847290039\n",
      "epoch 2200 loss=1320.230712890625\n",
      "New best validation epoch 2200 loss=40.0880241394043\n",
      "epoch 2400 loss=1328.37060546875\n",
      "New best validation epoch 2400 loss=40.062660217285156\n",
      "epoch 2600 loss=1331.6502685546875\n",
      "New best validation epoch 2600 loss=40.028236389160156\n",
      "epoch 2800 loss=1331.19189453125\n",
      "New best validation epoch 2800 loss=40.018707275390625\n",
      "epoch 3000 loss=1332.40576171875\n",
      "New best validation epoch 3000 loss=39.99814987182617\n",
      "epoch 3200 loss=1304.860595703125\n",
      "epoch 3400 loss=1336.607177734375\n",
      "epoch 3600 loss=1331.9451904296875\n",
      "New best validation epoch 3600 loss=39.968875885009766\n",
      "epoch 3800 loss=1315.7498779296875\n",
      "epoch 4000 loss=1339.5279541015625\n",
      "epoch 4200 loss=1342.2919921875\n",
      "epoch 4400 loss=1327.81103515625\n",
      "New best validation epoch 4400 loss=39.96717834472656\n",
      "epoch 4600 loss=1345.207763671875\n",
      "epoch 4800 loss=1335.78515625\n",
      "New best validation epoch 4800 loss=39.954402923583984\n",
      "epoch 4999 loss=1356.169921875\n",
      "Finished training\n",
      "FINISHED 3 3 34.609230041503906\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961, 32835, 29167, 21665,  2548,  9700,\n",
      "        10463, 32654, 29662, 11026, 15366])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765, 12355, 24520, 15146, 31520, 31817,\n",
      "        18701, 18976, 19934, 22085, 15813])\n",
      "epoch 0 loss=1515.794677734375\n",
      "New best validation epoch 0 loss=43.69734191894531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1425.653076171875\n",
      "New best validation epoch 200 loss=42.283267974853516\n",
      "epoch 400 loss=1353.0389404296875\n",
      "New best validation epoch 400 loss=40.70663070678711\n",
      "epoch 600 loss=1351.0213623046875\n",
      "New best validation epoch 600 loss=40.24928665161133\n",
      "epoch 800 loss=1338.1995849609375\n",
      "New best validation epoch 800 loss=40.00166320800781\n",
      "epoch 1000 loss=1314.08203125\n",
      "New best validation epoch 1000 loss=39.85032272338867\n",
      "epoch 1200 loss=1306.7584228515625\n",
      "New best validation epoch 1200 loss=39.748023986816406\n",
      "epoch 1400 loss=1320.51513671875\n",
      "New best validation epoch 1400 loss=39.62141036987305\n",
      "epoch 1600 loss=1288.006591796875\n",
      "New best validation epoch 1600 loss=39.54998016357422\n",
      "epoch 1800 loss=1314.1370849609375\n",
      "New best validation epoch 1800 loss=39.478843688964844\n",
      "epoch 2000 loss=1294.73779296875\n",
      "New best validation epoch 2000 loss=39.43766403198242\n",
      "epoch 2200 loss=1330.4583740234375\n",
      "epoch 2400 loss=1302.91162109375\n",
      "epoch 2600 loss=1324.8798828125\n",
      "epoch 2800 loss=1319.3193359375\n",
      "epoch 3000 loss=1316.3148193359375\n",
      "New best validation epoch 3000 loss=39.434837341308594\n",
      "epoch 3200 loss=1298.2083740234375\n",
      "epoch 3400 loss=1297.69482421875\n",
      "epoch 3600 loss=1281.554443359375\n",
      "New best validation epoch 3600 loss=39.41831588745117\n",
      "epoch 3800 loss=1344.4471435546875\n",
      "epoch 4000 loss=1305.780029296875\n",
      "epoch 4200 loss=1313.666259765625\n",
      "New best validation epoch 4200 loss=39.37120819091797\n",
      "epoch 4400 loss=1289.0018310546875\n",
      "epoch 4600 loss=1290.5517578125\n",
      "epoch 4800 loss=1300.22119140625\n",
      "epoch 4999 loss=1314.197998046875\n",
      "Finished training\n",
      "FINISHED 3 4 34.55897521972656\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961, 32835, 29167, 21665,  2548,  9700,\n",
      "        10463, 32654, 29662, 11026, 15366, 26384, 24710, 26811, 10297, 28444])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765, 12355, 24520, 15146, 31520, 31817,\n",
      "        18701, 18976, 19934, 22085, 15813, 30949, 16850, 20575, 31627, 14447])\n",
      "epoch 0 loss=1516.0087890625\n",
      "New best validation epoch 0 loss=43.69732666015625\n",
      "epoch 200 loss=1395.458740234375\n",
      "New best validation epoch 200 loss=41.5614013671875\n",
      "epoch 400 loss=1345.885498046875\n",
      "New best validation epoch 400 loss=40.10310363769531\n",
      "epoch 600 loss=1318.9862060546875\n",
      "New best validation epoch 600 loss=39.62327575683594\n",
      "epoch 800 loss=1306.3973388671875\n",
      "New best validation epoch 800 loss=39.35337829589844\n",
      "epoch 1000 loss=1287.0933837890625\n",
      "New best validation epoch 1000 loss=39.130916595458984\n",
      "epoch 1200 loss=1261.680908203125\n",
      "New best validation epoch 1200 loss=38.92428970336914\n",
      "epoch 1400 loss=1232.4798583984375\n",
      "New best validation epoch 1400 loss=38.85502243041992\n",
      "epoch 1600 loss=1260.58056640625\n",
      "New best validation epoch 1600 loss=38.82548904418945\n",
      "epoch 1800 loss=1286.8133544921875\n",
      "New best validation epoch 1800 loss=38.741695404052734\n",
      "epoch 2000 loss=1260.962890625\n",
      "epoch 2200 loss=1256.2567138671875\n",
      "epoch 2400 loss=1269.7230224609375\n",
      "epoch 2600 loss=1303.6424560546875\n",
      "New best validation epoch 2600 loss=38.7322998046875\n",
      "epoch 2800 loss=1247.45849609375\n",
      "New best validation epoch 2800 loss=38.68600845336914\n",
      "epoch 3000 loss=1241.8770751953125\n",
      "epoch 3200 loss=1291.8680419921875\n",
      "epoch 3400 loss=1278.170654296875\n",
      "epoch 3600 loss=1273.746826171875\n",
      "epoch 3800 loss=1232.28271484375\n",
      "New best validation epoch 3800 loss=38.6620979309082\n",
      "epoch 4000 loss=1263.879638671875\n",
      "epoch 4200 loss=1289.2908935546875\n",
      "epoch 4400 loss=1247.8070068359375\n",
      "New best validation epoch 4400 loss=38.63650131225586\n",
      "epoch 4600 loss=1243.031494140625\n",
      "epoch 4800 loss=1273.1370849609375\n",
      "epoch 4999 loss=1260.0062255859375\n",
      "Finished training\n",
      "FINISHED 3 5 33.68522644042969\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961, 32835, 29167, 21665,  2548,  9700,\n",
      "        10463, 32654, 29662, 11026, 15366, 26384, 24710, 26811, 10297, 28444,\n",
      "        18429, 29156, 11218, 14820, 26510])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765, 12355, 24520, 15146, 31520, 31817,\n",
      "        18701, 18976, 19934, 22085, 15813, 30949, 16850, 20575, 31627, 14447,\n",
      "        33746, 32993,  2783, 26091,  1245])\n",
      "epoch 0 loss=1515.435546875\n",
      "New best validation epoch 0 loss=43.69732666015625\n",
      "epoch 200 loss=1376.8173828125\n",
      "New best validation epoch 200 loss=41.02605438232422\n",
      "epoch 400 loss=1331.608154296875\n",
      "New best validation epoch 400 loss=39.84559631347656\n",
      "epoch 600 loss=1306.9820556640625\n",
      "New best validation epoch 600 loss=39.452999114990234\n",
      "epoch 800 loss=1276.0833740234375\n",
      "New best validation epoch 800 loss=39.13005828857422\n",
      "epoch 1000 loss=1283.378662109375\n",
      "New best validation epoch 1000 loss=38.947914123535156\n",
      "epoch 1200 loss=1256.060546875\n",
      "New best validation epoch 1200 loss=38.71672058105469\n",
      "epoch 1400 loss=1232.090087890625\n",
      "New best validation epoch 1400 loss=38.673824310302734\n",
      "epoch 1600 loss=1264.303955078125\n",
      "New best validation epoch 1600 loss=38.5392951965332\n",
      "epoch 1800 loss=1275.105712890625\n",
      "New best validation epoch 1800 loss=38.48983383178711\n",
      "epoch 2000 loss=1267.483642578125\n",
      "epoch 2200 loss=1269.85400390625\n",
      "New best validation epoch 2200 loss=38.46866989135742\n",
      "epoch 2400 loss=1223.984130859375\n",
      "New best validation epoch 2400 loss=38.4206657409668\n",
      "epoch 2600 loss=1215.0985107421875\n",
      "epoch 2800 loss=1235.5445556640625\n",
      "epoch 3000 loss=1226.6826171875\n",
      "New best validation epoch 3000 loss=38.415687561035156\n",
      "epoch 3200 loss=1209.24072265625\n",
      "epoch 3400 loss=1237.25927734375\n",
      "epoch 3600 loss=1274.49169921875\n",
      "epoch 3800 loss=1247.62255859375\n",
      "New best validation epoch 3800 loss=38.399436950683594\n",
      "epoch 4000 loss=1247.8138427734375\n",
      "epoch 4200 loss=1268.221435546875\n",
      "epoch 4400 loss=1251.3651123046875\n",
      "epoch 4600 loss=1261.746337890625\n",
      "epoch 4800 loss=1230.3719482421875\n",
      "epoch 4999 loss=1229.4705810546875\n",
      "Finished training\n",
      "FINISHED 3 6 33.23442840576172\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961, 32835, 29167, 21665,  2548,  9700,\n",
      "        10463, 32654, 29662, 11026, 15366, 26384, 24710, 26811, 10297, 28444,\n",
      "        18429, 29156, 11218, 14820, 26510, 30353,  3627, 10894, 26784,  4994])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765, 12355, 24520, 15146, 31520, 31817,\n",
      "        18701, 18976, 19934, 22085, 15813, 30949, 16850, 20575, 31627, 14447,\n",
      "        33746, 32993,  2783, 26091,  1245, 25587, 30032, 30947, 22853,  1244])\n",
      "epoch 0 loss=1518.4833984375\n",
      "New best validation epoch 0 loss=43.69731903076172\n",
      "epoch 200 loss=1378.6302490234375\n",
      "New best validation epoch 200 loss=40.71580123901367\n",
      "epoch 400 loss=1333.183349609375\n",
      "New best validation epoch 400 loss=39.69922637939453\n",
      "epoch 600 loss=1292.6043701171875\n",
      "New best validation epoch 600 loss=39.22478485107422\n",
      "epoch 800 loss=1257.4744873046875\n",
      "New best validation epoch 800 loss=38.89165496826172\n",
      "epoch 1000 loss=1276.6654052734375\n",
      "New best validation epoch 1000 loss=38.64764404296875\n",
      "epoch 1200 loss=1237.0321044921875\n",
      "New best validation epoch 1200 loss=38.51960372924805\n",
      "epoch 1400 loss=1251.58154296875\n",
      "New best validation epoch 1400 loss=38.304534912109375\n",
      "epoch 1600 loss=1242.5205078125\n",
      "New best validation epoch 1600 loss=38.27113723754883\n",
      "epoch 1800 loss=1221.269775390625\n",
      "New best validation epoch 1800 loss=38.20592498779297\n",
      "epoch 2000 loss=1187.8271484375\n",
      "New best validation epoch 2000 loss=38.19948196411133\n",
      "epoch 2200 loss=1231.8466796875\n",
      "New best validation epoch 2200 loss=38.15110397338867\n",
      "epoch 2400 loss=1227.837890625\n",
      "epoch 2600 loss=1228.16162109375\n",
      "epoch 2800 loss=1201.188720703125\n",
      "New best validation epoch 2800 loss=38.136558532714844\n",
      "epoch 3000 loss=1220.3701171875\n",
      "New best validation epoch 3000 loss=38.117462158203125\n",
      "epoch 3200 loss=1256.929931640625\n",
      "epoch 3400 loss=1238.0279541015625\n",
      "epoch 3600 loss=1231.6707763671875\n",
      "epoch 3800 loss=1183.7900390625\n",
      "epoch 4000 loss=1202.342041015625\n",
      "epoch 4200 loss=1233.056396484375\n",
      "epoch 4400 loss=1221.903076171875\n",
      "epoch 4600 loss=1240.2440185546875\n",
      "epoch 4800 loss=1242.064697265625\n",
      "epoch 4999 loss=1265.41845703125\n",
      "New best validation epoch 4999 loss=38.11442947387695\n",
      "Finished training\n",
      "FINISHED 3 7 32.97969436645508\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961, 32835, 29167, 21665,  2548,  9700,\n",
      "        10463, 32654, 29662, 11026, 15366, 26384, 24710, 26811, 10297, 28444,\n",
      "        18429, 29156, 11218, 14820, 26510, 30353,  3627, 10894, 26784,  4994,\n",
      "         6382, 26626, 33026, 26911, 26203])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765, 12355, 24520, 15146, 31520, 31817,\n",
      "        18701, 18976, 19934, 22085, 15813, 30949, 16850, 20575, 31627, 14447,\n",
      "        33746, 32993,  2783, 26091,  1245, 25587, 30032, 30947, 22853,  1244,\n",
      "        18866, 13614, 27342, 17135, 25090])\n",
      "epoch 0 loss=1516.321533203125\n",
      "New best validation epoch 0 loss=43.69730758666992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1368.62109375\n",
      "New best validation epoch 200 loss=40.37782287597656\n",
      "epoch 400 loss=1295.693359375\n",
      "New best validation epoch 400 loss=39.5526008605957\n",
      "epoch 600 loss=1247.4822998046875\n",
      "New best validation epoch 600 loss=39.103904724121094\n",
      "epoch 800 loss=1247.0172119140625\n",
      "New best validation epoch 800 loss=38.6937370300293\n",
      "epoch 1000 loss=1193.8856201171875\n",
      "New best validation epoch 1000 loss=38.456180572509766\n",
      "epoch 1200 loss=1219.3544921875\n",
      "New best validation epoch 1200 loss=38.31665802001953\n",
      "epoch 1400 loss=1228.981689453125\n",
      "New best validation epoch 1400 loss=38.154632568359375\n",
      "epoch 1600 loss=1215.0750732421875\n",
      "New best validation epoch 1600 loss=38.09759521484375\n",
      "epoch 1800 loss=1215.7113037109375\n",
      "New best validation epoch 1800 loss=38.04149627685547\n",
      "epoch 2000 loss=1212.247314453125\n",
      "New best validation epoch 2000 loss=38.016761779785156\n",
      "epoch 2200 loss=1218.4599609375\n",
      "New best validation epoch 2200 loss=37.95466232299805\n",
      "epoch 2400 loss=1217.9605712890625\n",
      "epoch 2600 loss=1187.419677734375\n",
      "epoch 2800 loss=1191.593505859375\n",
      "epoch 3000 loss=1213.731201171875\n",
      "New best validation epoch 3000 loss=37.907135009765625\n",
      "epoch 3200 loss=1196.070556640625\n",
      "epoch 3400 loss=1223.6728515625\n",
      "New best validation epoch 3400 loss=37.85441589355469\n",
      "epoch 3600 loss=1236.79150390625\n",
      "epoch 3800 loss=1197.3924560546875\n",
      "epoch 4000 loss=1233.441650390625\n",
      "epoch 4200 loss=1167.5089111328125\n",
      "epoch 4400 loss=1254.239013671875\n",
      "epoch 4600 loss=1152.9490966796875\n",
      "epoch 4800 loss=1264.92724609375\n",
      "epoch 4999 loss=1164.2109375\n",
      "Finished training\n",
      "FINISHED 3 8 32.77260971069336\n",
      "tensor([18275, 12226, 16178, 29074, 21032, 22858, 32154,  3860,  6137, 29727,\n",
      "         7589, 22377,  5412, 27128, 27961, 32835, 29167, 21665,  2548,  9700,\n",
      "        10463, 32654, 29662, 11026, 15366, 26384, 24710, 26811, 10297, 28444,\n",
      "        18429, 29156, 11218, 14820, 26510, 30353,  3627, 10894, 26784,  4994,\n",
      "         6382, 26626, 33026, 26911, 26203, 20217, 11368, 13158, 14378, 34236])\n",
      "tensor([30610,  8079, 31432, 28233, 26493, 15881, 18049, 30022, 16335, 14510,\n",
      "        27246,  1905,  5538, 32853, 13765, 12355, 24520, 15146, 31520, 31817,\n",
      "        18701, 18976, 19934, 22085, 15813, 30949, 16850, 20575, 31627, 14447,\n",
      "        33746, 32993,  2783, 26091,  1245, 25587, 30032, 30947, 22853,  1244,\n",
      "        18866, 13614, 27342, 17135, 25090, 33523,  7708,  3232, 19365, 29465])\n",
      "epoch 0 loss=1515.246826171875\n",
      "New best validation epoch 0 loss=43.69728469848633\n",
      "epoch 200 loss=1363.64794921875\n",
      "New best validation epoch 200 loss=40.38569641113281\n",
      "epoch 400 loss=1307.081787109375\n",
      "New best validation epoch 400 loss=39.59623718261719\n",
      "epoch 600 loss=1239.498046875\n",
      "New best validation epoch 600 loss=39.1041259765625\n",
      "epoch 800 loss=1220.248291015625\n",
      "New best validation epoch 800 loss=38.67074203491211\n",
      "epoch 1000 loss=1161.1971435546875\n",
      "New best validation epoch 1000 loss=38.492645263671875\n",
      "epoch 1200 loss=1184.549072265625\n",
      "New best validation epoch 1200 loss=38.33711624145508\n",
      "epoch 1400 loss=1211.8323974609375\n",
      "New best validation epoch 1400 loss=38.18231201171875\n",
      "epoch 1600 loss=1188.44482421875\n",
      "New best validation epoch 1600 loss=38.10536575317383\n",
      "epoch 1800 loss=1155.177490234375\n",
      "New best validation epoch 1800 loss=38.04722213745117\n",
      "epoch 2000 loss=1195.4747314453125\n",
      "New best validation epoch 2000 loss=38.019432067871094\n",
      "epoch 2200 loss=1212.2130126953125\n",
      "epoch 2400 loss=1154.4990234375\n",
      "epoch 2600 loss=1170.8555908203125\n",
      "New best validation epoch 2600 loss=37.96419906616211\n",
      "epoch 2800 loss=1202.384033203125\n",
      "epoch 3000 loss=1202.251220703125\n",
      "epoch 3200 loss=1220.653564453125\n",
      "epoch 3400 loss=1245.0643310546875\n",
      "New best validation epoch 3400 loss=37.94367980957031\n",
      "epoch 3600 loss=1177.7205810546875\n",
      "epoch 3800 loss=1159.4398193359375\n",
      "epoch 4000 loss=1179.9615478515625\n",
      "epoch 4200 loss=1215.930908203125\n",
      "epoch 4400 loss=1215.3719482421875\n",
      "epoch 4600 loss=1174.11669921875\n",
      "epoch 4800 loss=1209.90966796875\n",
      "epoch 4999 loss=1216.763916015625\n",
      "Finished training\n",
      "FINISHED 3 9 32.377567291259766\n",
      "tensor([31721, 34510,  4947, 18995, 21136])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234])\n",
      "epoch 0 loss=1484.670654296875\n",
      "New best validation epoch 0 loss=44.742088317871094\n",
      "epoch 200 loss=1481.216552734375\n",
      "New best validation epoch 200 loss=44.66378402709961\n",
      "epoch 400 loss=1459.495361328125\n",
      "New best validation epoch 400 loss=44.39877700805664\n",
      "epoch 600 loss=1445.124267578125\n",
      "New best validation epoch 600 loss=43.975833892822266\n",
      "epoch 800 loss=1423.84033203125\n",
      "New best validation epoch 800 loss=43.513370513916016\n",
      "epoch 1000 loss=1410.128173828125\n",
      "New best validation epoch 1000 loss=43.176414489746094\n",
      "epoch 1200 loss=1416.3148193359375\n",
      "New best validation epoch 1200 loss=42.973602294921875\n",
      "epoch 1400 loss=1387.0081787109375\n",
      "New best validation epoch 1400 loss=42.86217498779297\n",
      "epoch 1600 loss=1381.2518310546875\n",
      "New best validation epoch 1600 loss=42.77860641479492\n",
      "epoch 1800 loss=1399.09326171875\n",
      "New best validation epoch 1800 loss=42.76800537109375\n",
      "epoch 2000 loss=1404.77587890625\n",
      "New best validation epoch 2000 loss=42.72350311279297\n",
      "epoch 2200 loss=1380.6419677734375\n",
      "epoch 2400 loss=1389.4417724609375\n",
      "New best validation epoch 2400 loss=42.70880126953125\n",
      "epoch 2600 loss=1393.7806396484375\n",
      "New best validation epoch 2600 loss=42.668399810791016\n",
      "epoch 2800 loss=1398.959716796875\n",
      "New best validation epoch 2800 loss=42.65433883666992\n",
      "epoch 3000 loss=1402.045654296875\n",
      "New best validation epoch 3000 loss=42.632659912109375\n",
      "epoch 3200 loss=1399.8515625\n",
      "New best validation epoch 3200 loss=42.615272521972656\n",
      "epoch 3400 loss=1398.485107421875\n",
      "New best validation epoch 3400 loss=42.602508544921875\n",
      "epoch 3600 loss=1380.250732421875\n",
      "New best validation epoch 3600 loss=42.59579849243164\n",
      "epoch 3800 loss=1405.243896484375\n",
      "New best validation epoch 3800 loss=42.5787239074707\n",
      "epoch 4000 loss=1374.1180419921875\n",
      "epoch 4200 loss=1422.3875732421875\n",
      "epoch 4400 loss=1411.5404052734375\n",
      "epoch 4600 loss=1409.9437255859375\n",
      "epoch 4800 loss=1379.783447265625\n",
      "epoch 4999 loss=1384.7601318359375\n",
      "Finished training\n",
      "FINISHED 4 0 38.30859375\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875])\n",
      "epoch 0 loss=1484.212890625\n",
      "New best validation epoch 0 loss=44.74208068847656\n",
      "epoch 200 loss=1460.115966796875\n",
      "New best validation epoch 200 loss=44.358333587646484\n",
      "epoch 400 loss=1405.663818359375\n",
      "New best validation epoch 400 loss=43.13008117675781\n",
      "epoch 600 loss=1356.1318359375\n",
      "New best validation epoch 600 loss=42.04667282104492\n",
      "epoch 800 loss=1355.8173828125\n",
      "New best validation epoch 800 loss=41.6170654296875\n",
      "epoch 1000 loss=1334.2403564453125\n",
      "New best validation epoch 1000 loss=41.479400634765625\n",
      "epoch 1200 loss=1353.945556640625\n",
      "New best validation epoch 1200 loss=41.34499740600586\n",
      "epoch 1400 loss=1351.580322265625\n",
      "New best validation epoch 1400 loss=41.32746887207031\n",
      "epoch 1600 loss=1351.217041015625\n",
      "New best validation epoch 1600 loss=41.251548767089844\n",
      "epoch 1800 loss=1326.827880859375\n",
      "New best validation epoch 1800 loss=41.21556854248047\n",
      "epoch 2000 loss=1337.9588623046875\n",
      "epoch 2200 loss=1353.889404296875\n",
      "New best validation epoch 2200 loss=41.1745719909668\n",
      "epoch 2400 loss=1337.0743408203125\n",
      "epoch 2600 loss=1363.9248046875\n",
      "New best validation epoch 2600 loss=41.15504455566406\n",
      "epoch 2800 loss=1303.150146484375\n",
      "New best validation epoch 2800 loss=41.123817443847656\n",
      "epoch 3000 loss=1350.264404296875\n",
      "epoch 3200 loss=1332.703857421875\n",
      "epoch 3400 loss=1333.56005859375\n",
      "New best validation epoch 3400 loss=41.10049057006836\n",
      "epoch 3600 loss=1383.330810546875\n",
      "New best validation epoch 3600 loss=41.08985900878906\n",
      "epoch 3800 loss=1352.7708740234375\n",
      "epoch 4000 loss=1310.220703125\n",
      "epoch 4200 loss=1352.83984375\n",
      "epoch 4400 loss=1355.662109375\n",
      "epoch 4600 loss=1322.551513671875\n",
      "epoch 4800 loss=1332.397705078125\n",
      "epoch 4999 loss=1319.13916015625\n",
      "Finished training\n",
      "FINISHED 4 1 37.6302375793457\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134])\n",
      "epoch 0 loss=1485.765380859375\n",
      "New best validation epoch 0 loss=44.7420768737793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1435.9066162109375\n",
      "New best validation epoch 200 loss=44.037784576416016\n",
      "epoch 400 loss=1355.7747802734375\n",
      "New best validation epoch 400 loss=42.15713119506836\n",
      "epoch 600 loss=1333.4814453125\n",
      "New best validation epoch 600 loss=41.34198760986328\n",
      "epoch 800 loss=1330.816162109375\n",
      "New best validation epoch 800 loss=40.991146087646484\n",
      "epoch 1000 loss=1307.376953125\n",
      "New best validation epoch 1000 loss=40.78368377685547\n",
      "epoch 1200 loss=1264.728759765625\n",
      "New best validation epoch 1200 loss=40.644874572753906\n",
      "epoch 1400 loss=1310.4517822265625\n",
      "New best validation epoch 1400 loss=40.545982360839844\n",
      "epoch 1600 loss=1287.42138671875\n",
      "New best validation epoch 1600 loss=40.43585205078125\n",
      "epoch 1800 loss=1298.406494140625\n",
      "New best validation epoch 1800 loss=40.32979202270508\n",
      "epoch 2000 loss=1301.681640625\n",
      "New best validation epoch 2000 loss=40.3065299987793\n",
      "epoch 2200 loss=1280.9154052734375\n",
      "New best validation epoch 2200 loss=40.24665451049805\n",
      "epoch 2400 loss=1295.2064208984375\n",
      "New best validation epoch 2400 loss=40.18195343017578\n",
      "epoch 2600 loss=1318.162109375\n",
      "epoch 2800 loss=1259.16162109375\n",
      "epoch 3000 loss=1277.61181640625\n",
      "New best validation epoch 3000 loss=40.14509963989258\n",
      "epoch 3200 loss=1298.86181640625\n",
      "epoch 3400 loss=1304.634765625\n",
      "New best validation epoch 3400 loss=40.09564971923828\n",
      "epoch 3600 loss=1310.41162109375\n",
      "epoch 3800 loss=1306.4287109375\n",
      "epoch 4000 loss=1281.32275390625\n",
      "New best validation epoch 4000 loss=40.09373474121094\n",
      "epoch 4200 loss=1263.86328125\n",
      "epoch 4400 loss=1293.6068115234375\n",
      "epoch 4600 loss=1287.34326171875\n",
      "epoch 4800 loss=1306.3956298828125\n",
      "epoch 4999 loss=1290.8719482421875\n",
      "Finished training\n",
      "FINISHED 4 2 37.268310546875\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329,  7595,  9493, 12352,  3113, 16189])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134, 16648, 28087, 25335, 24099, 31309])\n",
      "epoch 0 loss=1486.3524169921875\n",
      "New best validation epoch 0 loss=44.7420768737793\n",
      "epoch 200 loss=1418.336181640625\n",
      "New best validation epoch 200 loss=43.71488571166992\n",
      "epoch 400 loss=1332.4296875\n",
      "New best validation epoch 400 loss=41.87888717651367\n",
      "epoch 600 loss=1323.004150390625\n",
      "New best validation epoch 600 loss=41.26129913330078\n",
      "epoch 800 loss=1322.5135498046875\n",
      "New best validation epoch 800 loss=40.955684661865234\n",
      "epoch 1000 loss=1302.3272705078125\n",
      "New best validation epoch 1000 loss=40.65177917480469\n",
      "epoch 1200 loss=1270.8861083984375\n",
      "New best validation epoch 1200 loss=40.48426818847656\n",
      "epoch 1400 loss=1272.478271484375\n",
      "New best validation epoch 1400 loss=40.41432189941406\n",
      "epoch 1600 loss=1304.69140625\n",
      "New best validation epoch 1600 loss=40.238609313964844\n",
      "epoch 1800 loss=1291.45166015625\n",
      "New best validation epoch 1800 loss=40.136741638183594\n",
      "epoch 2000 loss=1259.2689208984375\n",
      "New best validation epoch 2000 loss=40.12743377685547\n",
      "epoch 2200 loss=1296.853515625\n",
      "New best validation epoch 2200 loss=40.070526123046875\n",
      "epoch 2400 loss=1295.961669921875\n",
      "New best validation epoch 2400 loss=40.03700637817383\n",
      "epoch 2600 loss=1218.8978271484375\n",
      "New best validation epoch 2600 loss=40.01624298095703\n",
      "epoch 2800 loss=1317.960693359375\n",
      "epoch 3000 loss=1273.94384765625\n",
      "New best validation epoch 3000 loss=39.996376037597656\n",
      "epoch 3200 loss=1288.506103515625\n",
      "New best validation epoch 3200 loss=39.96495819091797\n",
      "epoch 3400 loss=1267.7552490234375\n",
      "epoch 3600 loss=1303.917724609375\n",
      "epoch 3800 loss=1265.766845703125\n",
      "epoch 4000 loss=1286.1732177734375\n",
      "epoch 4200 loss=1258.66259765625\n",
      "epoch 4400 loss=1269.8336181640625\n",
      "epoch 4600 loss=1295.93896484375\n",
      "epoch 4800 loss=1276.685302734375\n",
      "New best validation epoch 4800 loss=39.961669921875\n",
      "epoch 4999 loss=1272.87744140625\n",
      "Finished training\n",
      "FINISHED 4 3 37.018798828125\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329,  7595,  9493, 12352,  3113, 16189,\n",
      "        11155, 14001, 13686, 15917, 29499])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134, 16648, 28087, 25335, 24099, 31309,\n",
      "        11381,   360, 22128, 13571,  7629])\n",
      "epoch 0 loss=1484.3480224609375\n",
      "New best validation epoch 0 loss=44.742061614990234\n",
      "epoch 200 loss=1380.4951171875\n",
      "New best validation epoch 200 loss=43.189266204833984\n",
      "epoch 400 loss=1351.6339111328125\n",
      "New best validation epoch 400 loss=41.423858642578125\n",
      "epoch 600 loss=1295.124755859375\n",
      "New best validation epoch 600 loss=40.77919387817383\n",
      "epoch 800 loss=1308.77294921875\n",
      "New best validation epoch 800 loss=40.36031723022461\n",
      "epoch 1000 loss=1297.6380615234375\n",
      "New best validation epoch 1000 loss=40.06230163574219\n",
      "epoch 1200 loss=1252.175537109375\n",
      "New best validation epoch 1200 loss=39.74542236328125\n",
      "epoch 1400 loss=1261.112060546875\n",
      "New best validation epoch 1400 loss=39.54852294921875\n",
      "epoch 1600 loss=1253.0625\n",
      "New best validation epoch 1600 loss=39.46767044067383\n",
      "epoch 1800 loss=1239.7618408203125\n",
      "New best validation epoch 1800 loss=39.338951110839844\n",
      "epoch 2000 loss=1258.443603515625\n",
      "New best validation epoch 2000 loss=39.298038482666016\n",
      "epoch 2200 loss=1290.145263671875\n",
      "New best validation epoch 2200 loss=39.27756118774414\n",
      "epoch 2400 loss=1264.38232421875\n",
      "New best validation epoch 2400 loss=39.14215850830078\n",
      "epoch 2600 loss=1254.5645751953125\n",
      "epoch 2800 loss=1261.30419921875\n",
      "epoch 3000 loss=1322.779296875\n",
      "epoch 3200 loss=1241.103271484375\n",
      "epoch 3400 loss=1313.3455810546875\n",
      "epoch 3600 loss=1268.16015625\n",
      "epoch 3800 loss=1275.72314453125\n",
      "epoch 4000 loss=1236.712158203125\n",
      "epoch 4200 loss=1268.124267578125\n",
      "epoch 4400 loss=1244.4383544921875\n",
      "epoch 4600 loss=1292.707763671875\n",
      "epoch 4800 loss=1254.86474609375\n",
      "epoch 4999 loss=1284.882568359375\n",
      "Finished training\n",
      "FINISHED 4 4 36.56648635864258\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329,  7595,  9493, 12352,  3113, 16189,\n",
      "        11155, 14001, 13686, 15917, 29499,  3317,  4498, 33140,  9251, 26634])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134, 16648, 28087, 25335, 24099, 31309,\n",
      "        11381,   360, 22128, 13571,  7629, 31495, 11934, 15384, 32686, 24073])\n",
      "epoch 0 loss=1486.696533203125\n",
      "New best validation epoch 0 loss=44.742042541503906\n",
      "epoch 200 loss=1374.758544921875\n",
      "New best validation epoch 200 loss=42.56564712524414\n",
      "epoch 400 loss=1340.6865234375\n",
      "New best validation epoch 400 loss=41.08063888549805\n",
      "epoch 600 loss=1294.0936279296875\n",
      "New best validation epoch 600 loss=40.482906341552734\n",
      "epoch 800 loss=1267.7548828125\n",
      "New best validation epoch 800 loss=40.05711364746094\n",
      "epoch 1000 loss=1257.056884765625\n",
      "New best validation epoch 1000 loss=39.78213119506836\n",
      "epoch 1200 loss=1284.2255859375\n",
      "New best validation epoch 1200 loss=39.53529357910156\n",
      "epoch 1400 loss=1276.981689453125\n",
      "New best validation epoch 1400 loss=39.37936782836914\n",
      "epoch 1600 loss=1268.326904296875\n",
      "New best validation epoch 1600 loss=39.14488983154297\n",
      "epoch 1800 loss=1235.40380859375\n",
      "New best validation epoch 1800 loss=39.11513137817383\n",
      "epoch 2000 loss=1231.576171875\n",
      "New best validation epoch 2000 loss=39.04887008666992\n",
      "epoch 2200 loss=1214.294921875\n",
      "New best validation epoch 2200 loss=38.96980667114258\n",
      "epoch 2400 loss=1252.939208984375\n",
      "New best validation epoch 2400 loss=38.95045471191406\n",
      "epoch 2600 loss=1235.504150390625\n",
      "epoch 2800 loss=1232.6226806640625\n",
      "epoch 3000 loss=1284.0867919921875\n",
      "epoch 3200 loss=1270.702880859375\n",
      "epoch 3400 loss=1240.503173828125\n",
      "New best validation epoch 3400 loss=38.924617767333984\n",
      "epoch 3600 loss=1318.20556640625\n",
      "epoch 3800 loss=1268.3599853515625\n",
      "epoch 4000 loss=1266.84228515625\n",
      "epoch 4200 loss=1193.4935302734375\n",
      "epoch 4400 loss=1246.740478515625\n",
      "New best validation epoch 4400 loss=38.91819381713867\n",
      "epoch 4600 loss=1237.0750732421875\n",
      "New best validation epoch 4600 loss=38.89048767089844\n",
      "epoch 4800 loss=1272.6578369140625\n",
      "epoch 4999 loss=1303.0047607421875\n",
      "Finished training\n",
      "FINISHED 4 5 36.37795639038086\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329,  7595,  9493, 12352,  3113, 16189,\n",
      "        11155, 14001, 13686, 15917, 29499,  3317,  4498, 33140,  9251, 26634,\n",
      "        22774,  8138, 21223, 34286, 27009])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134, 16648, 28087, 25335, 24099, 31309,\n",
      "        11381,   360, 22128, 13571,  7629, 31495, 11934, 15384, 32686, 24073,\n",
      "        18362, 22993, 28082,  5586, 25637])\n",
      "epoch 0 loss=1485.88720703125\n",
      "New best validation epoch 0 loss=44.742042541503906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1360.552978515625\n",
      "New best validation epoch 200 loss=42.21293640136719\n",
      "epoch 400 loss=1317.9490966796875\n",
      "New best validation epoch 400 loss=40.911808013916016\n",
      "epoch 600 loss=1260.971435546875\n",
      "New best validation epoch 600 loss=40.30553436279297\n",
      "epoch 800 loss=1246.9964599609375\n",
      "New best validation epoch 800 loss=39.829044342041016\n",
      "epoch 1000 loss=1245.515380859375\n",
      "New best validation epoch 1000 loss=39.411861419677734\n",
      "epoch 1200 loss=1206.0587158203125\n",
      "New best validation epoch 1200 loss=39.148197174072266\n",
      "epoch 1400 loss=1201.4013671875\n",
      "New best validation epoch 1400 loss=38.95088577270508\n",
      "epoch 1600 loss=1206.290771484375\n",
      "New best validation epoch 1600 loss=38.75713348388672\n",
      "epoch 1800 loss=1228.64794921875\n",
      "New best validation epoch 1800 loss=38.73020553588867\n",
      "epoch 2000 loss=1218.4432373046875\n",
      "New best validation epoch 2000 loss=38.616119384765625\n",
      "epoch 2200 loss=1239.693359375\n",
      "New best validation epoch 2200 loss=38.580387115478516\n",
      "epoch 2400 loss=1253.6162109375\n",
      "New best validation epoch 2400 loss=38.56998825073242\n",
      "epoch 2600 loss=1212.6741943359375\n",
      "New best validation epoch 2600 loss=38.56892013549805\n",
      "epoch 2800 loss=1209.25537109375\n",
      "New best validation epoch 2800 loss=38.478763580322266\n",
      "epoch 3000 loss=1245.47021484375\n",
      "epoch 3200 loss=1219.987060546875\n",
      "epoch 3400 loss=1289.7528076171875\n",
      "epoch 3600 loss=1219.814453125\n",
      "epoch 3800 loss=1231.9620361328125\n",
      "New best validation epoch 3800 loss=38.46159362792969\n",
      "epoch 4000 loss=1197.5452880859375\n",
      "epoch 4200 loss=1200.227783203125\n",
      "epoch 4400 loss=1208.1351318359375\n",
      "epoch 4600 loss=1212.1011962890625\n",
      "epoch 4800 loss=1244.6337890625\n",
      "epoch 4999 loss=1227.8272705078125\n",
      "Finished training\n",
      "FINISHED 4 6 36.16252517700195\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329,  7595,  9493, 12352,  3113, 16189,\n",
      "        11155, 14001, 13686, 15917, 29499,  3317,  4498, 33140,  9251, 26634,\n",
      "        22774,  8138, 21223, 34286, 27009, 34147, 15099, 12265, 24029, 28515])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134, 16648, 28087, 25335, 24099, 31309,\n",
      "        11381,   360, 22128, 13571,  7629, 31495, 11934, 15384, 32686, 24073,\n",
      "        18362, 22993, 28082,  5586, 25637, 14830, 17827, 19695,  3832, 21441])\n",
      "epoch 0 loss=1484.821044921875\n",
      "New best validation epoch 0 loss=44.74203109741211\n",
      "epoch 200 loss=1354.1209716796875\n",
      "New best validation epoch 200 loss=41.93062973022461\n",
      "epoch 400 loss=1309.5546875\n",
      "New best validation epoch 400 loss=40.76697540283203\n",
      "epoch 600 loss=1273.057861328125\n",
      "New best validation epoch 600 loss=40.060523986816406\n",
      "epoch 800 loss=1254.999755859375\n",
      "New best validation epoch 800 loss=39.52511215209961\n",
      "epoch 1000 loss=1220.3349609375\n",
      "New best validation epoch 1000 loss=39.04456329345703\n",
      "epoch 1200 loss=1230.4609375\n",
      "New best validation epoch 1200 loss=38.75807189941406\n",
      "epoch 1400 loss=1206.8138427734375\n",
      "New best validation epoch 1400 loss=38.49689865112305\n",
      "epoch 1600 loss=1201.3597412109375\n",
      "New best validation epoch 1600 loss=38.38399124145508\n",
      "epoch 1800 loss=1221.009033203125\n",
      "New best validation epoch 1800 loss=38.3358268737793\n",
      "epoch 2000 loss=1218.22998046875\n",
      "New best validation epoch 2000 loss=38.22203063964844\n",
      "epoch 2200 loss=1208.9072265625\n",
      "New best validation epoch 2200 loss=38.15213394165039\n",
      "epoch 2400 loss=1188.4649658203125\n",
      "epoch 2600 loss=1240.641845703125\n",
      "epoch 2800 loss=1223.37841796875\n",
      "New best validation epoch 2800 loss=38.11267852783203\n",
      "epoch 3000 loss=1262.31396484375\n",
      "epoch 3200 loss=1164.474365234375\n",
      "epoch 3400 loss=1193.4921875\n",
      "epoch 3600 loss=1220.196533203125\n",
      "New best validation epoch 3600 loss=38.075950622558594\n",
      "epoch 3800 loss=1219.13037109375\n",
      "epoch 4000 loss=1231.3359375\n",
      "New best validation epoch 4000 loss=38.07459259033203\n",
      "epoch 4200 loss=1256.1785888671875\n",
      "epoch 4400 loss=1200.7999267578125\n",
      "epoch 4600 loss=1237.92529296875\n",
      "epoch 4800 loss=1193.885986328125\n",
      "epoch 4999 loss=1233.5596923828125\n",
      "New best validation epoch 4999 loss=38.01461410522461\n",
      "Finished training\n",
      "FINISHED 4 7 35.85934066772461\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329,  7595,  9493, 12352,  3113, 16189,\n",
      "        11155, 14001, 13686, 15917, 29499,  3317,  4498, 33140,  9251, 26634,\n",
      "        22774,  8138, 21223, 34286, 27009, 34147, 15099, 12265, 24029, 28515,\n",
      "         3218, 24616,  2687, 32317, 11815])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134, 16648, 28087, 25335, 24099, 31309,\n",
      "        11381,   360, 22128, 13571,  7629, 31495, 11934, 15384, 32686, 24073,\n",
      "        18362, 22993, 28082,  5586, 25637, 14830, 17827, 19695,  3832, 21441,\n",
      "         6301, 31195, 19670, 25148, 21576])\n",
      "epoch 0 loss=1484.2197265625\n",
      "New best validation epoch 0 loss=44.74203109741211\n",
      "epoch 200 loss=1350.59619140625\n",
      "New best validation epoch 200 loss=41.737998962402344\n",
      "epoch 400 loss=1272.12744140625\n",
      "New best validation epoch 400 loss=40.59107208251953\n",
      "epoch 600 loss=1229.220458984375\n",
      "New best validation epoch 600 loss=39.75708770751953\n",
      "epoch 800 loss=1214.840087890625\n",
      "New best validation epoch 800 loss=39.23583984375\n",
      "epoch 1000 loss=1213.7305908203125\n",
      "New best validation epoch 1000 loss=38.80563735961914\n",
      "epoch 1200 loss=1212.390380859375\n",
      "New best validation epoch 1200 loss=38.50777816772461\n",
      "epoch 1400 loss=1189.6029052734375\n",
      "New best validation epoch 1400 loss=38.31354904174805\n",
      "epoch 1600 loss=1184.56884765625\n",
      "New best validation epoch 1600 loss=38.1365966796875\n",
      "epoch 1800 loss=1169.9483642578125\n",
      "New best validation epoch 1800 loss=38.09087371826172\n",
      "epoch 2000 loss=1165.24658203125\n",
      "New best validation epoch 2000 loss=38.013423919677734\n",
      "epoch 2200 loss=1170.223388671875\n",
      "New best validation epoch 2200 loss=37.99515151977539\n",
      "epoch 2400 loss=1211.660400390625\n",
      "New best validation epoch 2400 loss=37.98470687866211\n",
      "epoch 2600 loss=1219.778076171875\n",
      "New best validation epoch 2600 loss=37.96613311767578\n",
      "epoch 2800 loss=1200.0928955078125\n",
      "New best validation epoch 2800 loss=37.90616989135742\n",
      "epoch 3000 loss=1221.951904296875\n",
      "New best validation epoch 3000 loss=37.876953125\n",
      "epoch 3200 loss=1201.539794921875\n",
      "epoch 3400 loss=1212.2630615234375\n",
      "New best validation epoch 3400 loss=37.874839782714844\n",
      "epoch 3600 loss=1222.8984375\n",
      "New best validation epoch 3600 loss=37.86810302734375\n",
      "epoch 3800 loss=1239.3369140625\n",
      "epoch 4000 loss=1192.7176513671875\n",
      "epoch 4200 loss=1213.7322998046875\n",
      "New best validation epoch 4200 loss=37.78096389770508\n",
      "epoch 4400 loss=1260.7279052734375\n",
      "epoch 4600 loss=1194.45361328125\n",
      "epoch 4800 loss=1194.19921875\n",
      "epoch 4999 loss=1230.0380859375\n",
      "Finished training\n",
      "FINISHED 4 8 35.83388137817383\n",
      "tensor([31721, 34510,  4947, 18995, 21136, 10245, 18291, 25655, 15830, 19241,\n",
      "         4224, 34132, 16789,  3137, 34329,  7595,  9493, 12352,  3113, 16189,\n",
      "        11155, 14001, 13686, 15917, 29499,  3317,  4498, 33140,  9251, 26634,\n",
      "        22774,  8138, 21223, 34286, 27009, 34147, 15099, 12265, 24029, 28515,\n",
      "         3218, 24616,  2687, 32317, 11815,   194, 19037,  7322,  8515, 21955])\n",
      "tensor([ 9404, 33982, 32566, 23331, 11234, 14940, 10208, 30711, 32900, 10875,\n",
      "         4455, 23415, 15794, 32250, 16134, 16648, 28087, 25335, 24099, 31309,\n",
      "        11381,   360, 22128, 13571,  7629, 31495, 11934, 15384, 32686, 24073,\n",
      "        18362, 22993, 28082,  5586, 25637, 14830, 17827, 19695,  3832, 21441,\n",
      "         6301, 31195, 19670, 25148, 21576, 18961, 25147,  8519,  3117, 21152])\n",
      "epoch 0 loss=1485.0169677734375\n",
      "New best validation epoch 0 loss=44.74201965332031\n",
      "epoch 200 loss=1336.9619140625\n",
      "New best validation epoch 200 loss=41.507789611816406\n",
      "epoch 400 loss=1293.598876953125\n",
      "New best validation epoch 400 loss=40.388553619384766\n",
      "epoch 600 loss=1247.035400390625\n",
      "New best validation epoch 600 loss=39.61530303955078\n",
      "epoch 800 loss=1211.9375\n",
      "New best validation epoch 800 loss=38.99925994873047\n",
      "epoch 1000 loss=1214.7437744140625\n",
      "New best validation epoch 1000 loss=38.59018325805664\n",
      "epoch 1200 loss=1224.2943115234375\n",
      "New best validation epoch 1200 loss=38.357872009277344\n",
      "epoch 1400 loss=1197.10693359375\n",
      "New best validation epoch 1400 loss=38.047122955322266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1600 loss=1172.1878662109375\n",
      "New best validation epoch 1600 loss=37.94197082519531\n",
      "epoch 1800 loss=1185.056640625\n",
      "New best validation epoch 1800 loss=37.79954147338867\n",
      "epoch 2000 loss=1189.845947265625\n",
      "New best validation epoch 2000 loss=37.79930114746094\n",
      "epoch 2200 loss=1221.4073486328125\n",
      "New best validation epoch 2200 loss=37.74287414550781\n",
      "epoch 2400 loss=1214.0755615234375\n",
      "epoch 2600 loss=1174.7010498046875\n",
      "New best validation epoch 2600 loss=37.72951889038086\n",
      "epoch 2800 loss=1205.99755859375\n",
      "New best validation epoch 2800 loss=37.68592834472656\n",
      "epoch 3000 loss=1223.353271484375\n",
      "epoch 3200 loss=1225.6595458984375\n",
      "epoch 3400 loss=1205.547607421875\n",
      "epoch 3600 loss=1234.2789306640625\n",
      "epoch 3800 loss=1153.16259765625\n",
      "New best validation epoch 3800 loss=37.67750930786133\n",
      "epoch 4000 loss=1187.7071533203125\n",
      "epoch 4200 loss=1207.94921875\n",
      "New best validation epoch 4200 loss=37.653324127197266\n",
      "epoch 4400 loss=1168.74462890625\n",
      "epoch 4600 loss=1188.956787109375\n",
      "epoch 4800 loss=1188.568359375\n",
      "epoch 4999 loss=1160.3934326171875\n",
      "Finished training\n",
      "FINISHED 4 9 35.68152618408203\n",
      "tensor([24478, 11443, 25020,   684, 12504])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211])\n",
      "epoch 0 loss=1510.735595703125\n",
      "New best validation epoch 0 loss=42.29330062866211\n",
      "epoch 200 loss=1507.671875\n",
      "New best validation epoch 200 loss=42.264774322509766\n",
      "epoch 400 loss=1497.2303466796875\n",
      "New best validation epoch 400 loss=42.15522003173828\n",
      "epoch 600 loss=1474.923095703125\n",
      "New best validation epoch 600 loss=41.92619323730469\n",
      "epoch 800 loss=1464.953857421875\n",
      "New best validation epoch 800 loss=41.59028625488281\n",
      "epoch 1000 loss=1464.302490234375\n",
      "New best validation epoch 1000 loss=41.30467987060547\n",
      "epoch 1200 loss=1443.517333984375\n",
      "New best validation epoch 1200 loss=41.138057708740234\n",
      "epoch 1400 loss=1450.1259765625\n",
      "New best validation epoch 1400 loss=41.06443405151367\n",
      "epoch 1600 loss=1426.8607177734375\n",
      "New best validation epoch 1600 loss=40.99066925048828\n",
      "epoch 1800 loss=1448.9599609375\n",
      "New best validation epoch 1800 loss=40.90827178955078\n",
      "epoch 2000 loss=1456.666015625\n",
      "New best validation epoch 2000 loss=40.84392166137695\n",
      "epoch 2200 loss=1439.476318359375\n",
      "epoch 2400 loss=1430.715087890625\n",
      "New best validation epoch 2400 loss=40.79033660888672\n",
      "epoch 2600 loss=1448.326904296875\n",
      "New best validation epoch 2600 loss=40.77519226074219\n",
      "epoch 2800 loss=1462.7957763671875\n",
      "New best validation epoch 2800 loss=40.76324462890625\n",
      "epoch 3000 loss=1420.6400146484375\n",
      "New best validation epoch 3000 loss=40.73118591308594\n",
      "epoch 3200 loss=1429.077880859375\n",
      "epoch 3400 loss=1418.7713623046875\n",
      "New best validation epoch 3400 loss=40.71295928955078\n",
      "epoch 3600 loss=1443.4652099609375\n",
      "epoch 3800 loss=1442.734375\n",
      "epoch 4000 loss=1425.3411865234375\n",
      "epoch 4200 loss=1393.17431640625\n",
      "New best validation epoch 4200 loss=40.694583892822266\n",
      "epoch 4400 loss=1442.519775390625\n",
      "New best validation epoch 4400 loss=40.68516540527344\n",
      "epoch 4600 loss=1432.27978515625\n",
      "epoch 4800 loss=1420.1575927734375\n",
      "New best validation epoch 4800 loss=40.67996597290039\n",
      "epoch 4999 loss=1443.424072265625\n",
      "Finished training\n",
      "FINISHED 5 0 38.50659942626953\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603])\n",
      "epoch 0 loss=1512.48876953125\n",
      "New best validation epoch 0 loss=42.29330062866211\n",
      "epoch 200 loss=1498.693115234375\n",
      "New best validation epoch 200 loss=42.15637969970703\n",
      "epoch 400 loss=1458.712646484375\n",
      "New best validation epoch 400 loss=41.5311164855957\n",
      "epoch 600 loss=1408.529052734375\n",
      "New best validation epoch 600 loss=40.704769134521484\n",
      "epoch 800 loss=1401.1463623046875\n",
      "New best validation epoch 800 loss=40.30820846557617\n",
      "epoch 1000 loss=1392.58154296875\n",
      "New best validation epoch 1000 loss=40.09117889404297\n",
      "epoch 1200 loss=1403.3768310546875\n",
      "New best validation epoch 1200 loss=40.044960021972656\n",
      "epoch 1400 loss=1409.9154052734375\n",
      "New best validation epoch 1400 loss=39.960052490234375\n",
      "epoch 1600 loss=1376.87744140625\n",
      "New best validation epoch 1600 loss=39.94083023071289\n",
      "epoch 1800 loss=1398.8330078125\n",
      "New best validation epoch 1800 loss=39.90578079223633\n",
      "epoch 2000 loss=1386.92138671875\n",
      "New best validation epoch 2000 loss=39.89350128173828\n",
      "epoch 2200 loss=1404.7734375\n",
      "New best validation epoch 2200 loss=39.8675651550293\n",
      "epoch 2400 loss=1362.22314453125\n",
      "epoch 2600 loss=1389.46484375\n",
      "epoch 2800 loss=1416.7449951171875\n",
      "epoch 3000 loss=1368.5\n",
      "epoch 3200 loss=1410.9443359375\n",
      "epoch 3400 loss=1385.02685546875\n",
      "epoch 3600 loss=1394.5399169921875\n",
      "epoch 3800 loss=1368.3094482421875\n",
      "epoch 4000 loss=1338.31298828125\n",
      "epoch 4200 loss=1361.888916015625\n",
      "epoch 4400 loss=1371.705078125\n",
      "epoch 4600 loss=1402.65576171875\n",
      "epoch 4800 loss=1391.307373046875\n",
      "epoch 4999 loss=1398.7933349609375\n",
      "Finished training\n",
      "FINISHED 5 1 37.89337158203125\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201])\n",
      "epoch 0 loss=1511.472900390625\n",
      "New best validation epoch 0 loss=42.29330062866211\n",
      "epoch 200 loss=1481.0369873046875\n",
      "New best validation epoch 200 loss=41.912315368652344\n",
      "epoch 400 loss=1413.3148193359375\n",
      "New best validation epoch 400 loss=40.47885513305664\n",
      "epoch 600 loss=1410.5545654296875\n",
      "New best validation epoch 600 loss=39.86899185180664\n",
      "epoch 800 loss=1387.635498046875\n",
      "New best validation epoch 800 loss=39.708248138427734\n",
      "epoch 1000 loss=1370.67138671875\n",
      "New best validation epoch 1000 loss=39.62580490112305\n",
      "epoch 1200 loss=1393.01953125\n",
      "New best validation epoch 1200 loss=39.57620620727539\n",
      "epoch 1400 loss=1409.567626953125\n",
      "New best validation epoch 1400 loss=39.538814544677734\n",
      "epoch 1600 loss=1379.588134765625\n",
      "epoch 1800 loss=1381.09033203125\n",
      "epoch 2000 loss=1384.365234375\n",
      "New best validation epoch 2000 loss=39.517372131347656\n",
      "epoch 2200 loss=1383.0732421875\n",
      "epoch 2400 loss=1391.6619873046875\n",
      "epoch 2600 loss=1363.782470703125\n",
      "epoch 2800 loss=1376.2425537109375\n",
      "epoch 3000 loss=1384.634033203125\n",
      "epoch 3200 loss=1361.67041015625\n",
      "epoch 3400 loss=1384.80322265625\n",
      "epoch 3600 loss=1347.1595458984375\n",
      "epoch 3800 loss=1353.4228515625\n",
      "epoch 4000 loss=1386.9564208984375\n",
      "epoch 4200 loss=1395.4736328125\n",
      "epoch 4400 loss=1389.741943359375\n",
      "epoch 4600 loss=1379.624267578125\n",
      "epoch 4800 loss=1344.535400390625\n",
      "epoch 4999 loss=1409.6810302734375\n",
      "Finished training\n",
      "FINISHED 5 2 37.56321334838867\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774,  9731, 32492, 10354, 30582,  5603])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201, 19849, 15742, 14581, 10487, 31574])\n",
      "epoch 0 loss=1511.826416015625\n",
      "New best validation epoch 0 loss=42.293296813964844\n",
      "epoch 200 loss=1458.76318359375\n",
      "New best validation epoch 200 loss=41.53105545043945\n",
      "epoch 400 loss=1406.9873046875\n",
      "New best validation epoch 400 loss=39.84799575805664\n",
      "epoch 600 loss=1397.725341796875\n",
      "New best validation epoch 600 loss=39.51091766357422\n",
      "epoch 800 loss=1403.363037109375\n",
      "New best validation epoch 800 loss=39.3624382019043\n",
      "epoch 1000 loss=1376.6932373046875\n",
      "New best validation epoch 1000 loss=39.331504821777344\n",
      "epoch 1200 loss=1364.442626953125\n",
      "New best validation epoch 1200 loss=39.257598876953125\n",
      "epoch 1400 loss=1331.780517578125\n",
      "epoch 1600 loss=1377.5380859375\n",
      "New best validation epoch 1600 loss=39.24061965942383\n",
      "epoch 1800 loss=1333.144775390625\n",
      "epoch 2000 loss=1335.5467529296875\n",
      "epoch 2200 loss=1371.3612060546875\n",
      "epoch 2400 loss=1327.191650390625\n",
      "epoch 2600 loss=1325.7884521484375\n",
      "epoch 2800 loss=1335.40283203125\n",
      "epoch 3000 loss=1303.92822265625\n",
      "epoch 3200 loss=1328.19873046875\n",
      "epoch 3400 loss=1342.7523193359375\n",
      "epoch 3600 loss=1362.83056640625\n",
      "epoch 3800 loss=1360.698974609375\n",
      "epoch 4000 loss=1362.418701171875\n",
      "epoch 4200 loss=1349.0770263671875\n",
      "epoch 4400 loss=1303.105224609375\n",
      "epoch 4600 loss=1340.769287109375\n",
      "epoch 4800 loss=1339.2547607421875\n",
      "epoch 4999 loss=1334.4178466796875\n",
      "Finished training\n",
      "FINISHED 5 3 36.80636215209961\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774,  9731, 32492, 10354, 30582,  5603,\n",
      "         8441, 15650, 11786, 20518, 34072])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201, 19849, 15742, 14581, 10487, 31574,\n",
      "        30155,  2099, 12837, 28492, 15089])\n",
      "epoch 0 loss=1510.8359375\n",
      "New best validation epoch 0 loss=42.29328918457031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1432.988525390625\n",
      "New best validation epoch 200 loss=40.877098083496094\n",
      "epoch 400 loss=1381.9881591796875\n",
      "New best validation epoch 400 loss=39.36605453491211\n",
      "epoch 600 loss=1379.635009765625\n",
      "New best validation epoch 600 loss=39.047698974609375\n",
      "epoch 800 loss=1375.594970703125\n",
      "New best validation epoch 800 loss=38.877777099609375\n",
      "epoch 1000 loss=1326.858154296875\n",
      "New best validation epoch 1000 loss=38.78925704956055\n",
      "epoch 1200 loss=1336.911376953125\n",
      "New best validation epoch 1200 loss=38.70464324951172\n",
      "epoch 1400 loss=1343.7064208984375\n",
      "New best validation epoch 1400 loss=38.62533187866211\n",
      "epoch 1600 loss=1312.69091796875\n",
      "New best validation epoch 1600 loss=38.568267822265625\n",
      "epoch 1800 loss=1325.8856201171875\n",
      "epoch 2000 loss=1368.3236083984375\n",
      "New best validation epoch 2000 loss=38.55394744873047\n",
      "epoch 2200 loss=1317.4197998046875\n",
      "epoch 2400 loss=1296.6995849609375\n",
      "epoch 2600 loss=1296.88916015625\n",
      "epoch 2800 loss=1297.658447265625\n",
      "epoch 3000 loss=1332.946044921875\n",
      "New best validation epoch 3000 loss=38.545448303222656\n",
      "epoch 3200 loss=1346.48828125\n",
      "epoch 3400 loss=1336.404296875\n",
      "epoch 3600 loss=1323.6239013671875\n",
      "epoch 3800 loss=1330.9476318359375\n",
      "epoch 4000 loss=1320.49951171875\n",
      "epoch 4200 loss=1322.595458984375\n",
      "epoch 4400 loss=1338.4788818359375\n",
      "epoch 4600 loss=1312.7132568359375\n",
      "epoch 4800 loss=1322.7655029296875\n",
      "epoch 4999 loss=1321.57080078125\n",
      "Finished training\n",
      "FINISHED 5 4 36.06210708618164\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774,  9731, 32492, 10354, 30582,  5603,\n",
      "         8441, 15650, 11786, 20518, 34072,  5808, 12895, 10700,  5974, 18184])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201, 19849, 15742, 14581, 10487, 31574,\n",
      "        30155,  2099, 12837, 28492, 15089, 31135, 22136,  5521, 10050, 19071])\n",
      "epoch 0 loss=1510.2626953125\n",
      "New best validation epoch 0 loss=42.29328155517578\n",
      "epoch 200 loss=1408.55029296875\n",
      "New best validation epoch 200 loss=40.19460678100586\n",
      "epoch 400 loss=1369.3548583984375\n",
      "New best validation epoch 400 loss=38.974239349365234\n",
      "epoch 600 loss=1349.01318359375\n",
      "New best validation epoch 600 loss=38.626747131347656\n",
      "epoch 800 loss=1304.4178466796875\n",
      "New best validation epoch 800 loss=38.39662551879883\n",
      "epoch 1000 loss=1316.8968505859375\n",
      "New best validation epoch 1000 loss=38.24497604370117\n",
      "epoch 1200 loss=1311.148193359375\n",
      "New best validation epoch 1200 loss=38.141845703125\n",
      "epoch 1400 loss=1321.5106201171875\n",
      "New best validation epoch 1400 loss=38.0457649230957\n",
      "epoch 1600 loss=1319.77587890625\n",
      "New best validation epoch 1600 loss=38.00155258178711\n",
      "epoch 1800 loss=1287.166015625\n",
      "New best validation epoch 1800 loss=37.95613479614258\n",
      "epoch 2000 loss=1289.218017578125\n",
      "epoch 2200 loss=1267.798583984375\n",
      "epoch 2400 loss=1280.4044189453125\n",
      "epoch 2600 loss=1290.8795166015625\n",
      "epoch 2800 loss=1295.921630859375\n",
      "epoch 3000 loss=1277.680419921875\n",
      "epoch 3200 loss=1269.595458984375\n",
      "epoch 3400 loss=1274.5943603515625\n",
      "epoch 3600 loss=1332.11962890625\n",
      "epoch 3800 loss=1223.6995849609375\n",
      "epoch 4000 loss=1271.9248046875\n",
      "epoch 4200 loss=1270.7379150390625\n",
      "epoch 4400 loss=1280.9510498046875\n",
      "epoch 4600 loss=1278.0479736328125\n",
      "epoch 4800 loss=1292.504638671875\n",
      "epoch 4999 loss=1285.7703857421875\n",
      "Finished training\n",
      "FINISHED 5 5 35.48633575439453\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774,  9731, 32492, 10354, 30582,  5603,\n",
      "         8441, 15650, 11786, 20518, 34072,  5808, 12895, 10700,  5974, 18184,\n",
      "        17512, 18960,  4741, 17562, 14512])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201, 19849, 15742, 14581, 10487, 31574,\n",
      "        30155,  2099, 12837, 28492, 15089, 31135, 22136,  5521, 10050, 19071,\n",
      "         9020,  8575, 13159,  9286,  6053])\n",
      "epoch 0 loss=1511.2088623046875\n",
      "New best validation epoch 0 loss=42.29326629638672\n",
      "epoch 200 loss=1401.9794921875\n",
      "New best validation epoch 200 loss=39.63497543334961\n",
      "epoch 400 loss=1337.93212890625\n",
      "New best validation epoch 400 loss=38.70218276977539\n",
      "epoch 600 loss=1275.7802734375\n",
      "New best validation epoch 600 loss=38.2465934753418\n",
      "epoch 800 loss=1301.970458984375\n",
      "New best validation epoch 800 loss=38.011329650878906\n",
      "epoch 1000 loss=1251.91552734375\n",
      "New best validation epoch 1000 loss=37.82108688354492\n",
      "epoch 1200 loss=1285.6055908203125\n",
      "New best validation epoch 1200 loss=37.56098175048828\n",
      "epoch 1400 loss=1261.705322265625\n",
      "New best validation epoch 1400 loss=37.50480270385742\n",
      "epoch 1600 loss=1258.797607421875\n",
      "epoch 1800 loss=1231.282958984375\n",
      "New best validation epoch 1800 loss=37.48432922363281\n",
      "epoch 2000 loss=1232.241455078125\n",
      "New best validation epoch 2000 loss=37.4697151184082\n",
      "epoch 2200 loss=1245.501953125\n",
      "New best validation epoch 2200 loss=37.463836669921875\n",
      "epoch 2400 loss=1293.708251953125\n",
      "epoch 2600 loss=1318.3089599609375\n",
      "New best validation epoch 2600 loss=37.46080017089844\n",
      "epoch 2800 loss=1275.174560546875\n",
      "New best validation epoch 2800 loss=37.39599609375\n",
      "epoch 3000 loss=1235.115966796875\n",
      "epoch 3200 loss=1229.1756591796875\n",
      "epoch 3400 loss=1271.334716796875\n",
      "New best validation epoch 3400 loss=37.376861572265625\n",
      "epoch 3600 loss=1270.763427734375\n",
      "New best validation epoch 3600 loss=37.358802795410156\n",
      "epoch 3800 loss=1299.28466796875\n",
      "epoch 4000 loss=1321.849609375\n",
      "epoch 4200 loss=1271.3709716796875\n",
      "epoch 4400 loss=1236.37939453125\n",
      "epoch 4600 loss=1255.47998046875\n",
      "epoch 4800 loss=1251.201904296875\n",
      "epoch 4999 loss=1200.5482177734375\n",
      "Finished training\n",
      "FINISHED 5 6 34.75223922729492\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774,  9731, 32492, 10354, 30582,  5603,\n",
      "         8441, 15650, 11786, 20518, 34072,  5808, 12895, 10700,  5974, 18184,\n",
      "        17512, 18960,  4741, 17562, 14512,  1810,  8282, 21944, 34694, 17981])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201, 19849, 15742, 14581, 10487, 31574,\n",
      "        30155,  2099, 12837, 28492, 15089, 31135, 22136,  5521, 10050, 19071,\n",
      "         9020,  8575, 13159,  9286,  6053, 15054,  8850,  7376, 16594, 13386])\n",
      "epoch 0 loss=1509.5771484375\n",
      "New best validation epoch 0 loss=42.29325485229492\n",
      "epoch 200 loss=1387.861328125\n",
      "New best validation epoch 200 loss=39.210723876953125\n",
      "epoch 400 loss=1323.20703125\n",
      "New best validation epoch 400 loss=38.28416061401367\n",
      "epoch 600 loss=1292.111083984375\n",
      "New best validation epoch 600 loss=37.80508041381836\n",
      "epoch 800 loss=1254.6904296875\n",
      "New best validation epoch 800 loss=37.500179290771484\n",
      "epoch 1000 loss=1237.534912109375\n",
      "New best validation epoch 1000 loss=37.2471809387207\n",
      "epoch 1200 loss=1253.99169921875\n",
      "New best validation epoch 1200 loss=36.97966003417969\n",
      "epoch 1400 loss=1237.052001953125\n",
      "New best validation epoch 1400 loss=36.8663444519043\n",
      "epoch 1600 loss=1223.038818359375\n",
      "New best validation epoch 1600 loss=36.831817626953125\n",
      "epoch 1800 loss=1184.4090576171875\n",
      "epoch 2000 loss=1217.6834716796875\n",
      "epoch 2200 loss=1253.0208740234375\n",
      "New best validation epoch 2200 loss=36.799041748046875\n",
      "epoch 2400 loss=1238.162841796875\n",
      "epoch 2600 loss=1230.6981201171875\n",
      "New best validation epoch 2600 loss=36.70494079589844\n",
      "epoch 2800 loss=1243.8084716796875\n",
      "epoch 3000 loss=1238.92333984375\n",
      "epoch 3200 loss=1225.71923828125\n",
      "epoch 3400 loss=1225.304931640625\n",
      "epoch 3600 loss=1198.630859375\n",
      "epoch 3800 loss=1228.757080078125\n",
      "epoch 4000 loss=1200.5291748046875\n",
      "epoch 4200 loss=1220.90185546875\n",
      "epoch 4400 loss=1230.62744140625\n",
      "epoch 4600 loss=1191.8048095703125\n",
      "epoch 4800 loss=1240.9600830078125\n",
      "epoch 4999 loss=1235.0848388671875\n",
      "Finished training\n",
      "FINISHED 5 7 34.094970703125\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774,  9731, 32492, 10354, 30582,  5603,\n",
      "         8441, 15650, 11786, 20518, 34072,  5808, 12895, 10700,  5974, 18184,\n",
      "        17512, 18960,  4741, 17562, 14512,  1810,  8282, 21944, 34694, 17981,\n",
      "         3340, 18840,  9401, 29668, 21734])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201, 19849, 15742, 14581, 10487, 31574,\n",
      "        30155,  2099, 12837, 28492, 15089, 31135, 22136,  5521, 10050, 19071,\n",
      "         9020,  8575, 13159,  9286,  6053, 15054,  8850,  7376, 16594, 13386,\n",
      "         4425,  5952, 31479, 27928, 17775])\n",
      "epoch 0 loss=1509.374755859375\n",
      "New best validation epoch 0 loss=42.293270111083984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1375.3646240234375\n",
      "New best validation epoch 200 loss=39.20946502685547\n",
      "epoch 400 loss=1341.53076171875\n",
      "New best validation epoch 400 loss=38.34489059448242\n",
      "epoch 600 loss=1286.9515380859375\n",
      "New best validation epoch 600 loss=37.797821044921875\n",
      "epoch 800 loss=1234.125\n",
      "New best validation epoch 800 loss=37.40230941772461\n",
      "epoch 1000 loss=1256.7567138671875\n",
      "New best validation epoch 1000 loss=37.08565139770508\n",
      "epoch 1200 loss=1264.505126953125\n",
      "New best validation epoch 1200 loss=36.99205017089844\n",
      "epoch 1400 loss=1238.516845703125\n",
      "New best validation epoch 1400 loss=36.81235122680664\n",
      "epoch 1600 loss=1247.5208740234375\n",
      "New best validation epoch 1600 loss=36.77625274658203\n",
      "epoch 1800 loss=1249.274658203125\n",
      "New best validation epoch 1800 loss=36.65775680541992\n",
      "epoch 2000 loss=1234.6944580078125\n",
      "New best validation epoch 2000 loss=36.61380386352539\n",
      "epoch 2200 loss=1224.3021240234375\n",
      "New best validation epoch 2200 loss=36.56112289428711\n",
      "epoch 2400 loss=1213.612060546875\n",
      "epoch 2600 loss=1211.824951171875\n",
      "epoch 2800 loss=1245.0970458984375\n",
      "epoch 3000 loss=1243.2587890625\n",
      "epoch 3200 loss=1205.94775390625\n",
      "epoch 3400 loss=1220.975341796875\n",
      "epoch 3600 loss=1284.6112060546875\n",
      "epoch 3800 loss=1233.552978515625\n",
      "epoch 4000 loss=1230.572021484375\n",
      "epoch 4200 loss=1276.9071044921875\n",
      "epoch 4400 loss=1263.327392578125\n",
      "epoch 4600 loss=1192.4969482421875\n",
      "epoch 4800 loss=1242.2647705078125\n",
      "epoch 4999 loss=1249.577392578125\n",
      "Finished training\n",
      "FINISHED 5 8 34.13248062133789\n",
      "tensor([24478, 11443, 25020,   684, 12504, 16375, 28097,  1963, 14876, 11872,\n",
      "        25451, 29020, 11168, 34207, 14774,  9731, 32492, 10354, 30582,  5603,\n",
      "         8441, 15650, 11786, 20518, 34072,  5808, 12895, 10700,  5974, 18184,\n",
      "        17512, 18960,  4741, 17562, 14512,  1810,  8282, 21944, 34694, 17981,\n",
      "         3340, 18840,  9401, 29668, 21734, 19854, 15491, 23029, 20249, 31494])\n",
      "tensor([ 7891, 17150, 22894, 12663, 15211, 27111, 18710, 23753, 24596,  8603,\n",
      "        24856,   482,  5707, 33775, 18201, 19849, 15742, 14581, 10487, 31574,\n",
      "        30155,  2099, 12837, 28492, 15089, 31135, 22136,  5521, 10050, 19071,\n",
      "         9020,  8575, 13159,  9286,  6053, 15054,  8850,  7376, 16594, 13386,\n",
      "         4425,  5952, 31479, 27928, 17775, 22559,  9496, 23637,  4793, 10144])\n",
      "epoch 0 loss=1510.4290771484375\n",
      "New best validation epoch 0 loss=42.293243408203125\n",
      "epoch 200 loss=1339.37841796875\n",
      "New best validation epoch 200 loss=39.06388473510742\n",
      "epoch 400 loss=1302.974853515625\n",
      "New best validation epoch 400 loss=38.09451675415039\n",
      "epoch 600 loss=1292.60791015625\n",
      "New best validation epoch 600 loss=37.37874984741211\n",
      "epoch 800 loss=1225.58935546875\n",
      "New best validation epoch 800 loss=36.8951530456543\n",
      "epoch 1000 loss=1228.366455078125\n",
      "New best validation epoch 1000 loss=36.54624938964844\n",
      "epoch 1200 loss=1225.9755859375\n",
      "New best validation epoch 1200 loss=36.3305778503418\n",
      "epoch 1400 loss=1208.0736083984375\n",
      "New best validation epoch 1400 loss=36.252201080322266\n",
      "epoch 1600 loss=1246.5399169921875\n",
      "New best validation epoch 1600 loss=36.204856872558594\n",
      "epoch 1800 loss=1232.454345703125\n",
      "New best validation epoch 1800 loss=36.16358184814453\n",
      "epoch 2000 loss=1231.396484375\n",
      "New best validation epoch 2000 loss=36.139991760253906\n",
      "epoch 2200 loss=1208.26171875\n",
      "New best validation epoch 2200 loss=36.06900405883789\n",
      "epoch 2400 loss=1179.171875\n",
      "epoch 2600 loss=1209.783935546875\n",
      "epoch 2800 loss=1249.2257080078125\n",
      "epoch 3000 loss=1201.5550537109375\n",
      "New best validation epoch 3000 loss=36.06325149536133\n",
      "epoch 3200 loss=1224.9329833984375\n",
      "New best validation epoch 3200 loss=36.01695251464844\n",
      "epoch 3400 loss=1224.363525390625\n",
      "epoch 3600 loss=1239.0771484375\n",
      "epoch 3800 loss=1200.95654296875\n",
      "epoch 4000 loss=1182.129150390625\n",
      "epoch 4200 loss=1186.607421875\n",
      "epoch 4400 loss=1226.7041015625\n",
      "epoch 4600 loss=1158.6883544921875\n",
      "epoch 4800 loss=1167.3880615234375\n",
      "epoch 4999 loss=1183.5736083984375\n",
      "Finished training\n",
      "FINISHED 5 9 33.797367095947266\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440])\n",
      "epoch 0 loss=1498.864990234375\n",
      "New best validation epoch 0 loss=42.9493522644043\n",
      "epoch 200 loss=1494.474853515625\n",
      "New best validation epoch 200 loss=42.86984634399414\n",
      "epoch 400 loss=1479.2099609375\n",
      "New best validation epoch 400 loss=42.603797912597656\n",
      "epoch 600 loss=1453.7596435546875\n",
      "New best validation epoch 600 loss=42.175071716308594\n",
      "epoch 800 loss=1408.778076171875\n",
      "New best validation epoch 800 loss=41.661529541015625\n",
      "epoch 1000 loss=1426.53173828125\n",
      "New best validation epoch 1000 loss=41.26431655883789\n",
      "epoch 1200 loss=1400.430908203125\n",
      "New best validation epoch 1200 loss=41.03943634033203\n",
      "epoch 1400 loss=1379.7484130859375\n",
      "New best validation epoch 1400 loss=40.91122817993164\n",
      "epoch 1600 loss=1390.18212890625\n",
      "New best validation epoch 1600 loss=40.83465576171875\n",
      "epoch 1800 loss=1390.6702880859375\n",
      "New best validation epoch 1800 loss=40.79432678222656\n",
      "epoch 2000 loss=1420.102783203125\n",
      "New best validation epoch 2000 loss=40.7535514831543\n",
      "epoch 2200 loss=1405.698974609375\n",
      "New best validation epoch 2200 loss=40.71851348876953\n",
      "epoch 2400 loss=1374.01318359375\n",
      "New best validation epoch 2400 loss=40.705352783203125\n",
      "epoch 2600 loss=1402.369873046875\n",
      "New best validation epoch 2600 loss=40.700408935546875\n",
      "epoch 2800 loss=1375.0955810546875\n",
      "New best validation epoch 2800 loss=40.69441604614258\n",
      "epoch 3000 loss=1368.73046875\n",
      "New best validation epoch 3000 loss=40.67156219482422\n",
      "epoch 3200 loss=1404.796142578125\n",
      "epoch 3400 loss=1376.8621826171875\n",
      "epoch 3600 loss=1373.463623046875\n",
      "epoch 3800 loss=1395.0555419921875\n",
      "epoch 4000 loss=1387.989013671875\n",
      "epoch 4200 loss=1364.6768798828125\n",
      "epoch 4400 loss=1405.2156982421875\n",
      "epoch 4600 loss=1348.8455810546875\n",
      "epoch 4800 loss=1405.2314453125\n",
      "epoch 4999 loss=1379.0609130859375\n",
      "Finished training\n",
      "FINISHED 6 0 38.997188568115234\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375])\n",
      "epoch 0 loss=1497.63671875\n",
      "New best validation epoch 0 loss=42.9493522644043\n",
      "epoch 200 loss=1480.275146484375\n",
      "New best validation epoch 200 loss=42.69868850708008\n",
      "epoch 400 loss=1437.207763671875\n",
      "New best validation epoch 400 loss=41.85279083251953\n",
      "epoch 600 loss=1387.144287109375\n",
      "New best validation epoch 600 loss=41.009761810302734\n",
      "epoch 800 loss=1338.4779052734375\n",
      "New best validation epoch 800 loss=40.57890701293945\n",
      "epoch 1000 loss=1354.8935546875\n",
      "New best validation epoch 1000 loss=40.34606170654297\n",
      "epoch 1200 loss=1343.7587890625\n",
      "New best validation epoch 1200 loss=40.212642669677734\n",
      "epoch 1400 loss=1331.224609375\n",
      "New best validation epoch 1400 loss=40.11921310424805\n",
      "epoch 1600 loss=1326.107177734375\n",
      "New best validation epoch 1600 loss=39.99831771850586\n",
      "epoch 1800 loss=1336.718017578125\n",
      "New best validation epoch 1800 loss=39.92808532714844\n",
      "epoch 2000 loss=1320.7318115234375\n",
      "New best validation epoch 2000 loss=39.87593078613281\n",
      "epoch 2200 loss=1343.2001953125\n",
      "New best validation epoch 2200 loss=39.8566780090332\n",
      "epoch 2400 loss=1311.295654296875\n",
      "New best validation epoch 2400 loss=39.79392623901367\n",
      "epoch 2600 loss=1330.195556640625\n",
      "epoch 2800 loss=1362.807861328125\n",
      "New best validation epoch 2800 loss=39.74669647216797\n",
      "epoch 3000 loss=1314.2498779296875\n",
      "New best validation epoch 3000 loss=39.721519470214844\n",
      "epoch 3200 loss=1344.7462158203125\n",
      "New best validation epoch 3200 loss=39.70499801635742\n",
      "epoch 3400 loss=1303.78076171875\n",
      "epoch 3600 loss=1309.2249755859375\n",
      "New best validation epoch 3600 loss=39.69370651245117\n",
      "epoch 3800 loss=1316.113037109375\n",
      "epoch 4000 loss=1333.997314453125\n",
      "New best validation epoch 4000 loss=39.688873291015625\n",
      "epoch 4200 loss=1329.343017578125\n",
      "epoch 4400 loss=1331.400390625\n",
      "New best validation epoch 4400 loss=39.66740417480469\n",
      "epoch 4600 loss=1312.63525390625\n",
      "epoch 4800 loss=1303.915771484375\n",
      "epoch 4999 loss=1310.62109375\n",
      "Finished training\n",
      "FINISHED 6 1 38.22366714477539\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578])\n",
      "epoch 0 loss=1496.83935546875\n",
      "New best validation epoch 0 loss=42.949344635009766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1464.228271484375\n",
      "New best validation epoch 200 loss=42.383766174316406\n",
      "epoch 400 loss=1372.3935546875\n",
      "New best validation epoch 400 loss=40.96744918823242\n",
      "epoch 600 loss=1342.785400390625\n",
      "New best validation epoch 600 loss=40.33351135253906\n",
      "epoch 800 loss=1350.210693359375\n",
      "New best validation epoch 800 loss=40.068668365478516\n",
      "epoch 1000 loss=1313.691162109375\n",
      "New best validation epoch 1000 loss=39.88987731933594\n",
      "epoch 1200 loss=1319.8876953125\n",
      "New best validation epoch 1200 loss=39.717918395996094\n",
      "epoch 1400 loss=1324.076416015625\n",
      "New best validation epoch 1400 loss=39.628719329833984\n",
      "epoch 1600 loss=1325.636474609375\n",
      "New best validation epoch 1600 loss=39.5507698059082\n",
      "epoch 1800 loss=1290.5859375\n",
      "New best validation epoch 1800 loss=39.46400451660156\n",
      "epoch 2000 loss=1315.0665283203125\n",
      "New best validation epoch 2000 loss=39.40301513671875\n",
      "epoch 2200 loss=1313.5535888671875\n",
      "New best validation epoch 2200 loss=39.34571075439453\n",
      "epoch 2400 loss=1309.29248046875\n",
      "New best validation epoch 2400 loss=39.32987594604492\n",
      "epoch 2600 loss=1304.3519287109375\n",
      "New best validation epoch 2600 loss=39.3060417175293\n",
      "epoch 2800 loss=1290.207275390625\n",
      "epoch 3000 loss=1338.837890625\n",
      "New best validation epoch 3000 loss=39.28492736816406\n",
      "epoch 3200 loss=1322.052734375\n",
      "New best validation epoch 3200 loss=39.262691497802734\n",
      "epoch 3400 loss=1296.8607177734375\n",
      "New best validation epoch 3400 loss=39.25115203857422\n",
      "epoch 3600 loss=1314.59423828125\n",
      "epoch 3800 loss=1276.731201171875\n",
      "epoch 4000 loss=1301.5255126953125\n",
      "New best validation epoch 4000 loss=39.20088577270508\n",
      "epoch 4200 loss=1307.508056640625\n",
      "epoch 4400 loss=1305.099609375\n",
      "epoch 4600 loss=1332.01318359375\n",
      "epoch 4800 loss=1329.931396484375\n",
      "epoch 4999 loss=1332.35107421875\n",
      "Finished training\n",
      "FINISHED 6 2 38.33717727661133\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536,  6808,  5951, 30927, 16761, 21873])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578, 32225, 23315, 29560,  3441, 14577])\n",
      "epoch 0 loss=1498.736083984375\n",
      "New best validation epoch 0 loss=42.9493408203125\n",
      "epoch 200 loss=1423.4486083984375\n",
      "New best validation epoch 200 loss=41.809967041015625\n",
      "epoch 400 loss=1337.861328125\n",
      "New best validation epoch 400 loss=40.03142547607422\n",
      "epoch 600 loss=1322.44677734375\n",
      "New best validation epoch 600 loss=39.519100189208984\n",
      "epoch 800 loss=1309.756591796875\n",
      "New best validation epoch 800 loss=39.214080810546875\n",
      "epoch 1000 loss=1299.2869873046875\n",
      "New best validation epoch 1000 loss=39.0075569152832\n",
      "epoch 1200 loss=1299.3416748046875\n",
      "New best validation epoch 1200 loss=38.855369567871094\n",
      "epoch 1400 loss=1298.8995361328125\n",
      "New best validation epoch 1400 loss=38.67280197143555\n",
      "epoch 1600 loss=1259.724609375\n",
      "New best validation epoch 1600 loss=38.63365936279297\n",
      "epoch 1800 loss=1277.66845703125\n",
      "New best validation epoch 1800 loss=38.54695129394531\n",
      "epoch 2000 loss=1275.3251953125\n",
      "New best validation epoch 2000 loss=38.44976806640625\n",
      "epoch 2200 loss=1283.5172119140625\n",
      "epoch 2400 loss=1258.2724609375\n",
      "New best validation epoch 2400 loss=38.44493103027344\n",
      "epoch 2600 loss=1289.62109375\n",
      "New best validation epoch 2600 loss=38.40435028076172\n",
      "epoch 2800 loss=1279.5018310546875\n",
      "New best validation epoch 2800 loss=38.35771942138672\n",
      "epoch 3000 loss=1265.8958740234375\n",
      "epoch 3200 loss=1271.6678466796875\n",
      "New best validation epoch 3200 loss=38.350181579589844\n",
      "epoch 3400 loss=1244.5335693359375\n",
      "epoch 3600 loss=1278.48046875\n",
      "epoch 3800 loss=1254.431640625\n",
      "epoch 4000 loss=1276.86962890625\n",
      "epoch 4200 loss=1255.833740234375\n",
      "New best validation epoch 4200 loss=38.348819732666016\n",
      "epoch 4400 loss=1255.267822265625\n",
      "New best validation epoch 4400 loss=38.342472076416016\n",
      "epoch 4600 loss=1301.4783935546875\n",
      "epoch 4800 loss=1279.578857421875\n",
      "New best validation epoch 4800 loss=38.336509704589844\n",
      "epoch 4999 loss=1257.8994140625\n",
      "Finished training\n",
      "FINISHED 6 3 37.49406433105469\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536,  6808,  5951, 30927, 16761, 21873,\n",
      "        12814, 26825, 13096, 23928,  3836])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578, 32225, 23315, 29560,  3441, 14577,\n",
      "        19341, 23003, 12363, 23655, 24473])\n",
      "epoch 0 loss=1502.412109375\n",
      "New best validation epoch 0 loss=42.94933319091797\n",
      "epoch 200 loss=1375.0804443359375\n",
      "New best validation epoch 200 loss=41.08449935913086\n",
      "epoch 400 loss=1309.802734375\n",
      "New best validation epoch 400 loss=39.426422119140625\n",
      "epoch 600 loss=1296.296630859375\n",
      "New best validation epoch 600 loss=38.89643478393555\n",
      "epoch 800 loss=1280.341552734375\n",
      "New best validation epoch 800 loss=38.558284759521484\n",
      "epoch 1000 loss=1225.5887451171875\n",
      "New best validation epoch 1000 loss=38.29280090332031\n",
      "epoch 1200 loss=1252.187255859375\n",
      "New best validation epoch 1200 loss=38.06984329223633\n",
      "epoch 1400 loss=1264.8076171875\n",
      "New best validation epoch 1400 loss=37.84534454345703\n",
      "epoch 1600 loss=1247.204345703125\n",
      "New best validation epoch 1600 loss=37.7475700378418\n",
      "epoch 1800 loss=1240.03955078125\n",
      "New best validation epoch 1800 loss=37.65298843383789\n",
      "epoch 2000 loss=1228.8695068359375\n",
      "New best validation epoch 2000 loss=37.60514831542969\n",
      "epoch 2200 loss=1233.0458984375\n",
      "New best validation epoch 2200 loss=37.55747985839844\n",
      "epoch 2400 loss=1200.7830810546875\n",
      "New best validation epoch 2400 loss=37.553653717041016\n",
      "epoch 2600 loss=1233.731689453125\n",
      "New best validation epoch 2600 loss=37.47690200805664\n",
      "epoch 2800 loss=1232.55712890625\n",
      "New best validation epoch 2800 loss=37.44289779663086\n",
      "epoch 3000 loss=1255.89697265625\n",
      "epoch 3200 loss=1270.6429443359375\n",
      "epoch 3400 loss=1242.062255859375\n",
      "epoch 3600 loss=1256.304931640625\n",
      "New best validation epoch 3600 loss=37.423614501953125\n",
      "epoch 3800 loss=1237.092041015625\n",
      "New best validation epoch 3800 loss=37.40684509277344\n",
      "epoch 4000 loss=1211.3314208984375\n",
      "epoch 4200 loss=1246.7900390625\n",
      "epoch 4400 loss=1233.382568359375\n",
      "epoch 4600 loss=1234.2091064453125\n",
      "epoch 4800 loss=1214.1195068359375\n",
      "epoch 4999 loss=1244.093505859375\n",
      "Finished training\n",
      "FINISHED 6 4 36.94439697265625\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536,  6808,  5951, 30927, 16761, 21873,\n",
      "        12814, 26825, 13096, 23928,  3836, 34136, 26296, 24754, 18109, 19617])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578, 32225, 23315, 29560,  3441, 14577,\n",
      "        19341, 23003, 12363, 23655, 24473,  9344, 25818,  4712, 20350, 26869])\n",
      "epoch 0 loss=1499.8157958984375\n",
      "New best validation epoch 0 loss=42.949317932128906\n",
      "epoch 200 loss=1364.4505615234375\n",
      "New best validation epoch 200 loss=40.53165054321289\n",
      "epoch 400 loss=1318.127685546875\n",
      "New best validation epoch 400 loss=39.20769500732422\n",
      "epoch 600 loss=1286.2625732421875\n",
      "New best validation epoch 600 loss=38.728633880615234\n",
      "epoch 800 loss=1268.8880615234375\n",
      "New best validation epoch 800 loss=38.3739013671875\n",
      "epoch 1000 loss=1243.4891357421875\n",
      "New best validation epoch 1000 loss=38.09590148925781\n",
      "epoch 1200 loss=1242.962890625\n",
      "New best validation epoch 1200 loss=37.85810852050781\n",
      "epoch 1400 loss=1220.6219482421875\n",
      "New best validation epoch 1400 loss=37.76570510864258\n",
      "epoch 1600 loss=1221.8116455078125\n",
      "New best validation epoch 1600 loss=37.630855560302734\n",
      "epoch 1800 loss=1201.162109375\n",
      "New best validation epoch 1800 loss=37.5776252746582\n",
      "epoch 2000 loss=1219.046875\n",
      "New best validation epoch 2000 loss=37.4431037902832\n",
      "epoch 2200 loss=1233.253173828125\n",
      "New best validation epoch 2200 loss=37.39786911010742\n",
      "epoch 2400 loss=1223.635009765625\n",
      "New best validation epoch 2400 loss=37.37523651123047\n",
      "epoch 2600 loss=1219.8388671875\n",
      "New best validation epoch 2600 loss=37.354347229003906\n",
      "epoch 2800 loss=1236.83447265625\n",
      "epoch 3000 loss=1216.5916748046875\n",
      "epoch 3200 loss=1217.08740234375\n",
      "New best validation epoch 3200 loss=37.28307342529297\n",
      "epoch 3400 loss=1211.8804931640625\n",
      "epoch 3600 loss=1214.7689208984375\n",
      "epoch 3800 loss=1168.89892578125\n",
      "epoch 4000 loss=1166.94580078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4200 loss=1215.37890625\n",
      "New best validation epoch 4200 loss=37.2480354309082\n",
      "epoch 4400 loss=1185.916748046875\n",
      "epoch 4600 loss=1239.197265625\n",
      "epoch 4800 loss=1248.5135498046875\n",
      "epoch 4999 loss=1234.551513671875\n",
      "New best validation epoch 4999 loss=37.220462799072266\n",
      "Finished training\n",
      "FINISHED 6 5 36.71139907836914\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536,  6808,  5951, 30927, 16761, 21873,\n",
      "        12814, 26825, 13096, 23928,  3836, 34136, 26296, 24754, 18109, 19617,\n",
      "        27864,  9032, 18648,  8561, 22146])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578, 32225, 23315, 29560,  3441, 14577,\n",
      "        19341, 23003, 12363, 23655, 24473,  9344, 25818,  4712, 20350, 26869,\n",
      "        25640, 21848, 12388, 34601, 11465])\n",
      "epoch 0 loss=1497.1298828125\n",
      "New best validation epoch 0 loss=42.94930648803711\n",
      "epoch 200 loss=1342.5384521484375\n",
      "New best validation epoch 200 loss=39.975303649902344\n",
      "epoch 400 loss=1282.308837890625\n",
      "New best validation epoch 400 loss=38.950035095214844\n",
      "epoch 600 loss=1264.84765625\n",
      "New best validation epoch 600 loss=38.48543930053711\n",
      "epoch 800 loss=1241.802490234375\n",
      "New best validation epoch 800 loss=38.15813446044922\n",
      "epoch 1000 loss=1210.815185546875\n",
      "New best validation epoch 1000 loss=37.83675765991211\n",
      "epoch 1200 loss=1239.120361328125\n",
      "New best validation epoch 1200 loss=37.617061614990234\n",
      "epoch 1400 loss=1225.5238037109375\n",
      "New best validation epoch 1400 loss=37.44066619873047\n",
      "epoch 1600 loss=1162.7078857421875\n",
      "New best validation epoch 1600 loss=37.37217330932617\n",
      "epoch 1800 loss=1214.5579833984375\n",
      "New best validation epoch 1800 loss=37.29988479614258\n",
      "epoch 2000 loss=1246.39892578125\n",
      "New best validation epoch 2000 loss=37.181358337402344\n",
      "epoch 2200 loss=1207.433837890625\n",
      "epoch 2400 loss=1171.162841796875\n",
      "New best validation epoch 2400 loss=37.099945068359375\n",
      "epoch 2600 loss=1210.243896484375\n",
      "epoch 2800 loss=1219.418212890625\n",
      "epoch 3000 loss=1206.5576171875\n",
      "epoch 3200 loss=1219.453857421875\n",
      "epoch 3400 loss=1195.3905029296875\n",
      "epoch 3600 loss=1234.431640625\n",
      "epoch 3800 loss=1169.4420166015625\n",
      "epoch 4000 loss=1221.3487548828125\n",
      "epoch 4200 loss=1199.8271484375\n",
      "New best validation epoch 4200 loss=37.097923278808594\n",
      "epoch 4400 loss=1200.759033203125\n",
      "New best validation epoch 4400 loss=37.05406951904297\n",
      "epoch 4600 loss=1246.5853271484375\n",
      "epoch 4800 loss=1205.58740234375\n",
      "epoch 4999 loss=1214.9056396484375\n",
      "Finished training\n",
      "FINISHED 6 6 36.778228759765625\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536,  6808,  5951, 30927, 16761, 21873,\n",
      "        12814, 26825, 13096, 23928,  3836, 34136, 26296, 24754, 18109, 19617,\n",
      "        27864,  9032, 18648,  8561, 22146, 10385,   850, 21333, 26664, 33257])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578, 32225, 23315, 29560,  3441, 14577,\n",
      "        19341, 23003, 12363, 23655, 24473,  9344, 25818,  4712, 20350, 26869,\n",
      "        25640, 21848, 12388, 34601, 11465, 24716, 20012, 14032, 22979, 20490])\n",
      "epoch 0 loss=1497.8759765625\n",
      "New best validation epoch 0 loss=42.949275970458984\n",
      "epoch 200 loss=1318.3765869140625\n",
      "New best validation epoch 200 loss=39.68878173828125\n",
      "epoch 400 loss=1277.856201171875\n",
      "New best validation epoch 400 loss=38.8334846496582\n",
      "epoch 600 loss=1250.0419921875\n",
      "New best validation epoch 600 loss=38.30028533935547\n",
      "epoch 800 loss=1222.2020263671875\n",
      "New best validation epoch 800 loss=37.97505569458008\n",
      "epoch 1000 loss=1183.4407958984375\n",
      "New best validation epoch 1000 loss=37.663875579833984\n",
      "epoch 1200 loss=1168.99658203125\n",
      "New best validation epoch 1200 loss=37.418331146240234\n",
      "epoch 1400 loss=1196.65283203125\n",
      "New best validation epoch 1400 loss=37.26637649536133\n",
      "epoch 1600 loss=1139.7679443359375\n",
      "New best validation epoch 1600 loss=37.129268646240234\n",
      "epoch 1800 loss=1203.0302734375\n",
      "New best validation epoch 1800 loss=37.00017166137695\n",
      "epoch 2000 loss=1182.171630859375\n",
      "epoch 2200 loss=1175.751708984375\n",
      "epoch 2400 loss=1189.444091796875\n",
      "New best validation epoch 2400 loss=36.98008728027344\n",
      "epoch 2600 loss=1194.5179443359375\n",
      "New best validation epoch 2600 loss=36.94268035888672\n",
      "epoch 2800 loss=1154.142333984375\n",
      "New best validation epoch 2800 loss=36.923187255859375\n",
      "epoch 3000 loss=1203.3721923828125\n",
      "epoch 3200 loss=1166.73681640625\n",
      "epoch 3400 loss=1176.3284912109375\n",
      "epoch 3600 loss=1209.1474609375\n",
      "New best validation epoch 3600 loss=36.89168167114258\n",
      "epoch 3800 loss=1192.186279296875\n",
      "epoch 4000 loss=1188.39990234375\n",
      "New best validation epoch 4000 loss=36.881446838378906\n",
      "epoch 4200 loss=1192.595947265625\n",
      "epoch 4400 loss=1187.898681640625\n",
      "epoch 4600 loss=1225.8935546875\n",
      "epoch 4800 loss=1133.5936279296875\n",
      "epoch 4999 loss=1177.9630126953125\n",
      "New best validation epoch 4999 loss=36.878299713134766\n",
      "Finished training\n",
      "FINISHED 6 7 36.561466217041016\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536,  6808,  5951, 30927, 16761, 21873,\n",
      "        12814, 26825, 13096, 23928,  3836, 34136, 26296, 24754, 18109, 19617,\n",
      "        27864,  9032, 18648,  8561, 22146, 10385,   850, 21333, 26664, 33257,\n",
      "        26590,   758,   788, 16673,   668])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578, 32225, 23315, 29560,  3441, 14577,\n",
      "        19341, 23003, 12363, 23655, 24473,  9344, 25818,  4712, 20350, 26869,\n",
      "        25640, 21848, 12388, 34601, 11465, 24716, 20012, 14032, 22979, 20490,\n",
      "        15841,  3896,   305, 27025, 20602])\n",
      "epoch 0 loss=1496.578125\n",
      "New best validation epoch 0 loss=42.94926834106445\n",
      "epoch 200 loss=1336.240478515625\n",
      "New best validation epoch 200 loss=39.487789154052734\n",
      "epoch 400 loss=1280.010498046875\n",
      "New best validation epoch 400 loss=38.69508743286133\n",
      "epoch 600 loss=1243.282470703125\n",
      "New best validation epoch 600 loss=38.205169677734375\n",
      "epoch 800 loss=1238.9580078125\n",
      "New best validation epoch 800 loss=37.797271728515625\n",
      "epoch 1000 loss=1191.943359375\n",
      "New best validation epoch 1000 loss=37.50221633911133\n",
      "epoch 1200 loss=1216.288818359375\n",
      "New best validation epoch 1200 loss=37.25003433227539\n",
      "epoch 1400 loss=1219.9267578125\n",
      "New best validation epoch 1400 loss=37.08732986450195\n",
      "epoch 1600 loss=1164.4754638671875\n",
      "New best validation epoch 1600 loss=37.060760498046875\n",
      "epoch 1800 loss=1166.8875732421875\n",
      "New best validation epoch 1800 loss=36.966941833496094\n",
      "epoch 2000 loss=1200.309326171875\n",
      "New best validation epoch 2000 loss=36.84337615966797\n",
      "epoch 2200 loss=1189.81689453125\n",
      "epoch 2400 loss=1191.095458984375\n",
      "New best validation epoch 2400 loss=36.784915924072266\n",
      "epoch 2600 loss=1191.6539306640625\n",
      "New best validation epoch 2600 loss=36.77885055541992\n",
      "epoch 2800 loss=1213.322509765625\n",
      "epoch 3000 loss=1205.628662109375\n",
      "epoch 3200 loss=1197.7481689453125\n",
      "epoch 3400 loss=1207.66259765625\n",
      "epoch 3600 loss=1151.8428955078125\n",
      "epoch 3800 loss=1161.9302978515625\n",
      "epoch 4000 loss=1162.0462646484375\n",
      "epoch 4200 loss=1164.81005859375\n",
      "epoch 4400 loss=1164.1923828125\n",
      "epoch 4600 loss=1160.7718505859375\n",
      "epoch 4800 loss=1167.9388427734375\n",
      "epoch 4999 loss=1202.9969482421875\n",
      "Finished training\n",
      "FINISHED 6 8 36.639835357666016\n",
      "tensor([ 6309, 13991,  9882,  7802, 20195, 17243, 26611, 20569, 21188,  2153,\n",
      "        17926,  9359, 26987, 17457,  3536,  6808,  5951, 30927, 16761, 21873,\n",
      "        12814, 26825, 13096, 23928,  3836, 34136, 26296, 24754, 18109, 19617,\n",
      "        27864,  9032, 18648,  8561, 22146, 10385,   850, 21333, 26664, 33257,\n",
      "        26590,   758,   788, 16673,   668,  7834, 10670, 12182,  2848, 28877])\n",
      "tensor([ 1892,  6702, 30901, 20559, 23440, 23006, 17516,  3566,  9383,  5375,\n",
      "        33046, 13842, 22902,  8703, 16578, 32225, 23315, 29560,  3441, 14577,\n",
      "        19341, 23003, 12363, 23655, 24473,  9344, 25818,  4712, 20350, 26869,\n",
      "        25640, 21848, 12388, 34601, 11465, 24716, 20012, 14032, 22979, 20490,\n",
      "        15841,  3896,   305, 27025, 20602, 13000, 16562, 24894,  9697, 24389])\n",
      "epoch 0 loss=1498.124755859375\n",
      "New best validation epoch 0 loss=42.949256896972656\n",
      "epoch 200 loss=1314.2137451171875\n",
      "New best validation epoch 200 loss=39.398101806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400 loss=1264.2576904296875\n",
      "New best validation epoch 400 loss=38.571083068847656\n",
      "epoch 600 loss=1229.7626953125\n",
      "New best validation epoch 600 loss=37.94147872924805\n",
      "epoch 800 loss=1245.65478515625\n",
      "New best validation epoch 800 loss=37.444793701171875\n",
      "epoch 1000 loss=1150.7347412109375\n",
      "New best validation epoch 1000 loss=37.13764953613281\n",
      "epoch 1200 loss=1197.902587890625\n",
      "New best validation epoch 1200 loss=36.79527282714844\n",
      "epoch 1400 loss=1179.3125\n",
      "New best validation epoch 1400 loss=36.68453598022461\n",
      "epoch 1600 loss=1164.7177734375\n",
      "New best validation epoch 1600 loss=36.55577850341797\n",
      "epoch 1800 loss=1185.468017578125\n",
      "epoch 2000 loss=1166.3792724609375\n",
      "New best validation epoch 2000 loss=36.47029495239258\n",
      "epoch 2200 loss=1147.085205078125\n",
      "New best validation epoch 2200 loss=36.458580017089844\n",
      "epoch 2400 loss=1142.8408203125\n",
      "New best validation epoch 2400 loss=36.41073226928711\n",
      "epoch 2600 loss=1197.2674560546875\n",
      "New best validation epoch 2600 loss=36.40430450439453\n",
      "epoch 2800 loss=1204.2059326171875\n",
      "New best validation epoch 2800 loss=36.34034729003906\n",
      "epoch 3000 loss=1158.530517578125\n",
      "New best validation epoch 3000 loss=36.33089065551758\n",
      "epoch 3200 loss=1175.982177734375\n",
      "epoch 3400 loss=1136.327392578125\n",
      "epoch 3600 loss=1163.2119140625\n",
      "New best validation epoch 3600 loss=36.31420135498047\n",
      "epoch 3800 loss=1095.0751953125\n",
      "epoch 4000 loss=1179.5693359375\n",
      "epoch 4200 loss=1181.065185546875\n",
      "New best validation epoch 4200 loss=36.300071716308594\n",
      "epoch 4400 loss=1147.4779052734375\n",
      "New best validation epoch 4400 loss=36.27396774291992\n",
      "epoch 4600 loss=1174.43505859375\n",
      "New best validation epoch 4600 loss=36.253910064697266\n",
      "epoch 4800 loss=1149.0841064453125\n",
      "epoch 4999 loss=1166.378662109375\n",
      "Finished training\n",
      "FINISHED 6 9 36.24949264526367\n",
      "tensor([31700, 32575,   865, 18832, 25460])\n",
      "tensor([32299,   360, 19822,  9913,  7399])\n",
      "epoch 0 loss=1529.1658935546875\n",
      "New best validation epoch 0 loss=42.341941833496094\n",
      "epoch 200 loss=1523.19287109375\n",
      "New best validation epoch 200 loss=42.288700103759766\n",
      "epoch 400 loss=1507.3447265625\n",
      "New best validation epoch 400 loss=42.100013732910156\n",
      "epoch 600 loss=1464.0433349609375\n",
      "New best validation epoch 600 loss=41.778167724609375\n",
      "epoch 800 loss=1467.5262451171875\n",
      "New best validation epoch 800 loss=41.40631866455078\n",
      "epoch 1000 loss=1452.421875\n",
      "New best validation epoch 1000 loss=41.14830017089844\n",
      "epoch 1200 loss=1447.4798583984375\n",
      "New best validation epoch 1200 loss=41.00723648071289\n",
      "epoch 1400 loss=1450.9046630859375\n",
      "New best validation epoch 1400 loss=40.97846603393555\n",
      "epoch 1600 loss=1429.953369140625\n",
      "New best validation epoch 1600 loss=40.924407958984375\n",
      "epoch 1800 loss=1451.388916015625\n",
      "New best validation epoch 1800 loss=40.87063980102539\n",
      "epoch 2000 loss=1430.455322265625\n",
      "New best validation epoch 2000 loss=40.8481330871582\n",
      "epoch 2200 loss=1459.896240234375\n",
      "epoch 2400 loss=1421.898193359375\n",
      "epoch 2600 loss=1418.50537109375\n",
      "epoch 2800 loss=1429.64794921875\n",
      "New best validation epoch 2800 loss=40.83991241455078\n",
      "epoch 3000 loss=1451.5263671875\n",
      "New best validation epoch 3000 loss=40.82808303833008\n",
      "epoch 3200 loss=1429.668701171875\n",
      "epoch 3400 loss=1414.43701171875\n",
      "epoch 3600 loss=1413.5697021484375\n",
      "epoch 3800 loss=1441.2269287109375\n",
      "epoch 4000 loss=1425.6497802734375\n",
      "epoch 4200 loss=1434.5283203125\n",
      "epoch 4400 loss=1438.170654296875\n",
      "epoch 4600 loss=1451.1068115234375\n",
      "epoch 4800 loss=1432.268798828125\n",
      "epoch 4999 loss=1416.567138671875\n",
      "Finished training\n",
      "FINISHED 7 0 37.79800796508789\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292])\n",
      "epoch 0 loss=1526.1883544921875\n",
      "New best validation epoch 0 loss=42.3419303894043\n",
      "epoch 200 loss=1513.064453125\n",
      "New best validation epoch 200 loss=42.181488037109375\n",
      "epoch 400 loss=1465.3914794921875\n",
      "New best validation epoch 400 loss=41.60042953491211\n",
      "epoch 600 loss=1403.759765625\n",
      "New best validation epoch 600 loss=40.98200988769531\n",
      "epoch 800 loss=1468.3818359375\n",
      "New best validation epoch 800 loss=40.701194763183594\n",
      "epoch 1000 loss=1450.085205078125\n",
      "New best validation epoch 1000 loss=40.536216735839844\n",
      "epoch 1200 loss=1402.505615234375\n",
      "New best validation epoch 1200 loss=40.43584442138672\n",
      "epoch 1400 loss=1411.4925537109375\n",
      "New best validation epoch 1400 loss=40.37512969970703\n",
      "epoch 1600 loss=1406.5198974609375\n",
      "New best validation epoch 1600 loss=40.35105514526367\n",
      "epoch 1800 loss=1422.616943359375\n",
      "New best validation epoch 1800 loss=40.31008529663086\n",
      "epoch 2000 loss=1418.7562255859375\n",
      "New best validation epoch 2000 loss=40.286502838134766\n",
      "epoch 2200 loss=1390.412841796875\n",
      "epoch 2400 loss=1488.147216796875\n",
      "New best validation epoch 2400 loss=40.25274658203125\n",
      "epoch 2600 loss=1396.867431640625\n",
      "epoch 2800 loss=1399.171630859375\n",
      "epoch 3000 loss=1401.3818359375\n",
      "epoch 3200 loss=1391.3382568359375\n",
      "epoch 3400 loss=1401.36181640625\n",
      "epoch 3600 loss=1371.006591796875\n",
      "epoch 3800 loss=1371.439208984375\n",
      "epoch 4000 loss=1441.633544921875\n",
      "epoch 4200 loss=1409.6717529296875\n",
      "epoch 4400 loss=1400.5487060546875\n",
      "epoch 4600 loss=1425.11181640625\n",
      "epoch 4800 loss=1434.373046875\n",
      "epoch 4999 loss=1373.1492919921875\n",
      "Finished training\n",
      "FINISHED 7 1 36.78868865966797\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875])\n",
      "epoch 0 loss=1525.6673583984375\n",
      "New best validation epoch 0 loss=42.3419303894043\n",
      "epoch 200 loss=1493.4658203125\n",
      "New best validation epoch 200 loss=41.970619201660156\n",
      "epoch 400 loss=1420.1572265625\n",
      "New best validation epoch 400 loss=40.940887451171875\n",
      "epoch 600 loss=1433.991943359375\n",
      "New best validation epoch 600 loss=40.449851989746094\n",
      "epoch 800 loss=1390.978759765625\n",
      "New best validation epoch 800 loss=40.236175537109375\n",
      "epoch 1000 loss=1382.091796875\n",
      "New best validation epoch 1000 loss=40.107757568359375\n",
      "epoch 1200 loss=1389.851318359375\n",
      "New best validation epoch 1200 loss=40.01523208618164\n",
      "epoch 1400 loss=1358.806884765625\n",
      "New best validation epoch 1400 loss=39.958011627197266\n",
      "epoch 1600 loss=1382.559326171875\n",
      "New best validation epoch 1600 loss=39.87204360961914\n",
      "epoch 1800 loss=1366.18603515625\n",
      "New best validation epoch 1800 loss=39.79753112792969\n",
      "epoch 2000 loss=1362.1644287109375\n",
      "New best validation epoch 2000 loss=39.79020309448242\n",
      "epoch 2200 loss=1344.5198974609375\n",
      "New best validation epoch 2200 loss=39.774681091308594\n",
      "epoch 2400 loss=1342.737060546875\n",
      "New best validation epoch 2400 loss=39.7646484375\n",
      "epoch 2600 loss=1342.988037109375\n",
      "New best validation epoch 2600 loss=39.72907638549805\n",
      "epoch 2800 loss=1356.634033203125\n",
      "epoch 3000 loss=1355.137451171875\n",
      "epoch 3200 loss=1395.1356201171875\n",
      "epoch 3400 loss=1370.1689453125\n",
      "epoch 3600 loss=1317.294189453125\n",
      "epoch 3800 loss=1367.5540771484375\n",
      "epoch 4000 loss=1346.1219482421875\n",
      "epoch 4200 loss=1355.6865234375\n",
      "epoch 4400 loss=1366.307861328125\n",
      "epoch 4600 loss=1339.9910888671875\n",
      "epoch 4800 loss=1372.6287841796875\n",
      "epoch 4999 loss=1355.17529296875\n",
      "Finished training\n",
      "FINISHED 7 2 36.18726348876953\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846, 27192, 26547,  7189,  2272, 24540])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875, 20936, 17330,  7769,  8709,  6887])\n",
      "epoch 0 loss=1525.4100341796875\n",
      "New best validation epoch 0 loss=42.34193420410156\n",
      "epoch 200 loss=1470.0189208984375\n",
      "New best validation epoch 200 loss=41.760921478271484\n",
      "epoch 400 loss=1388.0111083984375\n",
      "New best validation epoch 400 loss=40.610252380371094\n",
      "epoch 600 loss=1399.531494140625\n",
      "New best validation epoch 600 loss=40.210941314697266\n",
      "epoch 800 loss=1369.327392578125\n",
      "New best validation epoch 800 loss=39.96061325073242\n",
      "epoch 1000 loss=1353.0550537109375\n",
      "New best validation epoch 1000 loss=39.77589797973633\n",
      "epoch 1200 loss=1360.75048828125\n",
      "New best validation epoch 1200 loss=39.604068756103516\n",
      "epoch 1400 loss=1301.4998779296875\n",
      "New best validation epoch 1400 loss=39.46268081665039\n",
      "epoch 1600 loss=1353.5115966796875\n",
      "New best validation epoch 1600 loss=39.353179931640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1800 loss=1330.50634765625\n",
      "New best validation epoch 1800 loss=39.28533172607422\n",
      "epoch 2000 loss=1346.2392578125\n",
      "New best validation epoch 2000 loss=39.19918441772461\n",
      "epoch 2200 loss=1368.781982421875\n",
      "New best validation epoch 2200 loss=39.18470001220703\n",
      "epoch 2400 loss=1318.773681640625\n",
      "New best validation epoch 2400 loss=39.13314437866211\n",
      "epoch 2600 loss=1365.155517578125\n",
      "epoch 2800 loss=1320.3187255859375\n",
      "New best validation epoch 2800 loss=39.131507873535156\n",
      "epoch 3000 loss=1360.6319580078125\n",
      "New best validation epoch 3000 loss=39.11353302001953\n",
      "epoch 3200 loss=1337.415771484375\n",
      "epoch 3400 loss=1327.564208984375\n",
      "New best validation epoch 3400 loss=39.088111877441406\n",
      "epoch 3600 loss=1350.084228515625\n",
      "epoch 3800 loss=1349.611328125\n",
      "epoch 4000 loss=1314.250244140625\n",
      "New best validation epoch 4000 loss=39.079078674316406\n",
      "epoch 4200 loss=1361.22509765625\n",
      "epoch 4400 loss=1315.5367431640625\n",
      "epoch 4600 loss=1348.656494140625\n",
      "epoch 4800 loss=1360.740234375\n",
      "New best validation epoch 4800 loss=39.05845260620117\n",
      "epoch 4999 loss=1360.3009033203125\n",
      "Finished training\n",
      "FINISHED 7 3 35.38274002075195\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846, 27192, 26547,  7189,  2272, 24540,\n",
      "        18396, 25846, 23803, 16370, 29639])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875, 20936, 17330,  7769,  8709,  6887,\n",
      "        17793, 28629,  4686,  8977, 18724])\n",
      "epoch 0 loss=1523.7412109375\n",
      "New best validation epoch 0 loss=42.3419303894043\n",
      "epoch 200 loss=1427.8612060546875\n",
      "New best validation epoch 200 loss=41.218727111816406\n",
      "epoch 400 loss=1379.544677734375\n",
      "New best validation epoch 400 loss=39.920684814453125\n",
      "epoch 600 loss=1348.6534423828125\n",
      "New best validation epoch 600 loss=39.477561950683594\n",
      "epoch 800 loss=1309.106201171875\n",
      "New best validation epoch 800 loss=39.10470199584961\n",
      "epoch 1000 loss=1311.7845458984375\n",
      "New best validation epoch 1000 loss=38.823875427246094\n",
      "epoch 1200 loss=1311.892822265625\n",
      "New best validation epoch 1200 loss=38.558250427246094\n",
      "epoch 1400 loss=1295.6160888671875\n",
      "New best validation epoch 1400 loss=38.33495330810547\n",
      "epoch 1600 loss=1266.298583984375\n",
      "New best validation epoch 1600 loss=38.21442794799805\n",
      "epoch 1800 loss=1270.54296875\n",
      "New best validation epoch 1800 loss=38.07508087158203\n",
      "epoch 2000 loss=1259.09375\n",
      "New best validation epoch 2000 loss=37.997657775878906\n",
      "epoch 2200 loss=1311.419677734375\n",
      "New best validation epoch 2200 loss=37.94015884399414\n",
      "epoch 2400 loss=1309.2650146484375\n",
      "New best validation epoch 2400 loss=37.85903549194336\n",
      "epoch 2600 loss=1296.2420654296875\n",
      "epoch 2800 loss=1289.727783203125\n",
      "New best validation epoch 2800 loss=37.85438919067383\n",
      "epoch 3000 loss=1262.764892578125\n",
      "epoch 3200 loss=1264.816650390625\n",
      "New best validation epoch 3200 loss=37.84859848022461\n",
      "epoch 3400 loss=1282.927734375\n",
      "New best validation epoch 3400 loss=37.81591033935547\n",
      "epoch 3600 loss=1302.508544921875\n",
      "New best validation epoch 3600 loss=37.77838134765625\n",
      "epoch 3800 loss=1307.870361328125\n",
      "epoch 4000 loss=1273.3828125\n",
      "epoch 4200 loss=1293.2701416015625\n",
      "epoch 4400 loss=1285.6893310546875\n",
      "epoch 4600 loss=1296.90087890625\n",
      "epoch 4800 loss=1317.19873046875\n",
      "epoch 4999 loss=1246.822509765625\n",
      "Finished training\n",
      "FINISHED 7 4 35.094688415527344\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846, 27192, 26547,  7189,  2272, 24540,\n",
      "        18396, 25846, 23803, 16370, 29639,  5777, 32546, 22767, 10718, 30817])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875, 20936, 17330,  7769,  8709,  6887,\n",
      "        17793, 28629,  4686,  8977, 18724, 13480, 18891,  1562, 23677,  2655])\n",
      "epoch 0 loss=1527.18359375\n",
      "New best validation epoch 0 loss=42.3419189453125\n",
      "epoch 200 loss=1419.327880859375\n",
      "New best validation epoch 200 loss=40.92218017578125\n",
      "epoch 400 loss=1374.8515625\n",
      "New best validation epoch 400 loss=39.890254974365234\n",
      "epoch 600 loss=1339.5673828125\n",
      "New best validation epoch 600 loss=39.432437896728516\n",
      "epoch 800 loss=1321.616943359375\n",
      "New best validation epoch 800 loss=39.025474548339844\n",
      "epoch 1000 loss=1298.4681396484375\n",
      "New best validation epoch 1000 loss=38.72415542602539\n",
      "epoch 1200 loss=1322.316650390625\n",
      "New best validation epoch 1200 loss=38.4567985534668\n",
      "epoch 1400 loss=1303.8740234375\n",
      "New best validation epoch 1400 loss=38.2401237487793\n",
      "epoch 1600 loss=1249.3680419921875\n",
      "New best validation epoch 1600 loss=38.073333740234375\n",
      "epoch 1800 loss=1301.33935546875\n",
      "New best validation epoch 1800 loss=37.93056869506836\n",
      "epoch 2000 loss=1275.0478515625\n",
      "New best validation epoch 2000 loss=37.886539459228516\n",
      "epoch 2200 loss=1275.00439453125\n",
      "New best validation epoch 2200 loss=37.80302047729492\n",
      "epoch 2400 loss=1284.349609375\n",
      "New best validation epoch 2400 loss=37.75674819946289\n",
      "epoch 2600 loss=1252.8515625\n",
      "New best validation epoch 2600 loss=37.742469787597656\n",
      "epoch 2800 loss=1276.343017578125\n",
      "New best validation epoch 2800 loss=37.68920135498047\n",
      "epoch 3000 loss=1273.9056396484375\n",
      "epoch 3200 loss=1259.0169677734375\n",
      "epoch 3400 loss=1285.53271484375\n",
      "New best validation epoch 3400 loss=37.660736083984375\n",
      "epoch 3600 loss=1220.8607177734375\n",
      "New best validation epoch 3600 loss=37.64999008178711\n",
      "epoch 3800 loss=1259.6583251953125\n",
      "epoch 4000 loss=1269.869384765625\n",
      "epoch 4200 loss=1268.5615234375\n",
      "epoch 4400 loss=1272.9842529296875\n",
      "New best validation epoch 4400 loss=37.63414764404297\n",
      "epoch 4600 loss=1257.7236328125\n",
      "epoch 4800 loss=1259.4061279296875\n",
      "epoch 4999 loss=1272.1591796875\n",
      "Finished training\n",
      "FINISHED 7 5 35.093414306640625\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846, 27192, 26547,  7189,  2272, 24540,\n",
      "        18396, 25846, 23803, 16370, 29639,  5777, 32546, 22767, 10718, 30817,\n",
      "         1447, 21988, 30525, 28922, 32570])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875, 20936, 17330,  7769,  8709,  6887,\n",
      "        17793, 28629,  4686,  8977, 18724, 13480, 18891,  1562, 23677,  2655,\n",
      "        23919, 23989, 32059, 34405, 33309])\n",
      "epoch 0 loss=1526.743408203125\n",
      "New best validation epoch 0 loss=42.341915130615234\n",
      "epoch 200 loss=1401.384765625\n",
      "New best validation epoch 200 loss=40.72064208984375\n",
      "epoch 400 loss=1373.23193359375\n",
      "New best validation epoch 400 loss=39.88892364501953\n",
      "epoch 600 loss=1325.384521484375\n",
      "New best validation epoch 600 loss=39.40837478637695\n",
      "epoch 800 loss=1306.8948974609375\n",
      "New best validation epoch 800 loss=38.96315002441406\n",
      "epoch 1000 loss=1283.0440673828125\n",
      "New best validation epoch 1000 loss=38.61945724487305\n",
      "epoch 1200 loss=1306.3197021484375\n",
      "New best validation epoch 1200 loss=38.3270149230957\n",
      "epoch 1400 loss=1245.981689453125\n",
      "New best validation epoch 1400 loss=38.10437774658203\n",
      "epoch 1600 loss=1301.576416015625\n",
      "New best validation epoch 1600 loss=37.98960494995117\n",
      "epoch 1800 loss=1259.4940185546875\n",
      "New best validation epoch 1800 loss=37.89055252075195\n",
      "epoch 2000 loss=1290.3538818359375\n",
      "New best validation epoch 2000 loss=37.824283599853516\n",
      "epoch 2200 loss=1253.8115234375\n",
      "New best validation epoch 2200 loss=37.75323486328125\n",
      "epoch 2400 loss=1271.5657958984375\n",
      "epoch 2600 loss=1245.787109375\n",
      "New best validation epoch 2600 loss=37.70240783691406\n",
      "epoch 2800 loss=1264.9857177734375\n",
      "New best validation epoch 2800 loss=37.6578483581543\n",
      "epoch 3000 loss=1285.792236328125\n",
      "epoch 3200 loss=1276.9539794921875\n",
      "New best validation epoch 3200 loss=37.6216926574707\n",
      "epoch 3400 loss=1300.576904296875\n",
      "New best validation epoch 3400 loss=37.6009635925293\n",
      "epoch 3600 loss=1297.3662109375\n",
      "epoch 3800 loss=1268.9749755859375\n",
      "epoch 4000 loss=1277.52294921875\n",
      "New best validation epoch 4000 loss=37.54099655151367\n",
      "epoch 4200 loss=1285.173095703125\n",
      "epoch 4400 loss=1255.9241943359375\n",
      "epoch 4600 loss=1251.617431640625\n",
      "epoch 4800 loss=1245.2144775390625\n",
      "epoch 4999 loss=1309.074462890625\n",
      "Finished training\n",
      "FINISHED 7 6 34.98046112060547\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846, 27192, 26547,  7189,  2272, 24540,\n",
      "        18396, 25846, 23803, 16370, 29639,  5777, 32546, 22767, 10718, 30817,\n",
      "         1447, 21988, 30525, 28922, 32570,  2122, 33099, 15677,  9522, 33390])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875, 20936, 17330,  7769,  8709,  6887,\n",
      "        17793, 28629,  4686,  8977, 18724, 13480, 18891,  1562, 23677,  2655,\n",
      "        23919, 23989, 32059, 34405, 33309,  2798,  5051,  5855, 19860, 24323])\n",
      "epoch 0 loss=1526.650390625\n",
      "New best validation epoch 0 loss=42.341896057128906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 loss=1386.3480224609375\n",
      "New best validation epoch 200 loss=40.45138168334961\n",
      "epoch 400 loss=1342.784423828125\n",
      "New best validation epoch 400 loss=39.655494689941406\n",
      "epoch 600 loss=1312.632080078125\n",
      "New best validation epoch 600 loss=39.057865142822266\n",
      "epoch 800 loss=1289.2930908203125\n",
      "New best validation epoch 800 loss=38.531185150146484\n",
      "epoch 1000 loss=1236.1939697265625\n",
      "New best validation epoch 1000 loss=38.11051559448242\n",
      "epoch 1200 loss=1256.253662109375\n",
      "New best validation epoch 1200 loss=37.80494689941406\n",
      "epoch 1400 loss=1231.2786865234375\n",
      "New best validation epoch 1400 loss=37.615291595458984\n",
      "epoch 1600 loss=1207.858642578125\n",
      "New best validation epoch 1600 loss=37.41252899169922\n",
      "epoch 1800 loss=1233.776123046875\n",
      "New best validation epoch 1800 loss=37.381404876708984\n",
      "epoch 2000 loss=1254.6978759765625\n",
      "New best validation epoch 2000 loss=37.34765625\n",
      "epoch 2200 loss=1239.207763671875\n",
      "New best validation epoch 2200 loss=37.239681243896484\n",
      "epoch 2400 loss=1259.9798583984375\n",
      "New best validation epoch 2400 loss=37.21971130371094\n",
      "epoch 2600 loss=1221.614501953125\n",
      "New best validation epoch 2600 loss=37.20914077758789\n",
      "epoch 2800 loss=1242.39306640625\n",
      "New best validation epoch 2800 loss=37.19539260864258\n",
      "epoch 3000 loss=1214.509765625\n",
      "New best validation epoch 3000 loss=37.17110061645508\n",
      "epoch 3200 loss=1266.8289794921875\n",
      "epoch 3400 loss=1249.63037109375\n",
      "epoch 3600 loss=1225.734375\n",
      "New best validation epoch 3600 loss=37.13846206665039\n",
      "epoch 3800 loss=1208.61865234375\n",
      "epoch 4000 loss=1240.39013671875\n",
      "New best validation epoch 4000 loss=37.08646774291992\n",
      "epoch 4200 loss=1274.04638671875\n",
      "epoch 4400 loss=1224.89697265625\n",
      "epoch 4600 loss=1236.261962890625\n",
      "epoch 4800 loss=1272.9188232421875\n",
      "epoch 4999 loss=1165.967041015625\n",
      "Finished training\n",
      "FINISHED 7 7 35.00347137451172\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846, 27192, 26547,  7189,  2272, 24540,\n",
      "        18396, 25846, 23803, 16370, 29639,  5777, 32546, 22767, 10718, 30817,\n",
      "         1447, 21988, 30525, 28922, 32570,  2122, 33099, 15677,  9522, 33390,\n",
      "        19537, 27996, 12524,  7054, 18978])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875, 20936, 17330,  7769,  8709,  6887,\n",
      "        17793, 28629,  4686,  8977, 18724, 13480, 18891,  1562, 23677,  2655,\n",
      "        23919, 23989, 32059, 34405, 33309,  2798,  5051,  5855, 19860, 24323,\n",
      "        30017, 34485, 21756,  4851, 17120])\n",
      "epoch 0 loss=1525.6107177734375\n",
      "New best validation epoch 0 loss=42.34189224243164\n",
      "epoch 200 loss=1383.617431640625\n",
      "New best validation epoch 200 loss=40.24002456665039\n",
      "epoch 400 loss=1314.294677734375\n",
      "New best validation epoch 400 loss=39.40869903564453\n",
      "epoch 600 loss=1268.0771484375\n",
      "New best validation epoch 600 loss=38.72207260131836\n",
      "epoch 800 loss=1269.740478515625\n",
      "New best validation epoch 800 loss=38.1737174987793\n",
      "epoch 1000 loss=1233.29931640625\n",
      "New best validation epoch 1000 loss=37.750858306884766\n",
      "epoch 1200 loss=1195.97607421875\n",
      "New best validation epoch 1200 loss=37.37614059448242\n",
      "epoch 1400 loss=1248.8583984375\n",
      "New best validation epoch 1400 loss=37.273738861083984\n",
      "epoch 1600 loss=1205.951171875\n",
      "New best validation epoch 1600 loss=37.11286163330078\n",
      "epoch 1800 loss=1194.84521484375\n",
      "New best validation epoch 1800 loss=36.96235656738281\n",
      "epoch 2000 loss=1203.14306640625\n",
      "New best validation epoch 2000 loss=36.897640228271484\n",
      "epoch 2200 loss=1252.117919921875\n",
      "epoch 2400 loss=1204.93994140625\n",
      "New best validation epoch 2400 loss=36.8922233581543\n",
      "epoch 2600 loss=1237.6834716796875\n",
      "epoch 2800 loss=1240.4075927734375\n",
      "New best validation epoch 2800 loss=36.82966613769531\n",
      "epoch 3000 loss=1173.692626953125\n",
      "New best validation epoch 3000 loss=36.78362274169922\n",
      "epoch 3200 loss=1194.0943603515625\n",
      "epoch 3400 loss=1237.5611572265625\n",
      "epoch 3600 loss=1230.227783203125\n",
      "epoch 3800 loss=1188.489501953125\n",
      "New best validation epoch 3800 loss=36.76993942260742\n",
      "epoch 4000 loss=1216.7607421875\n",
      "New best validation epoch 4000 loss=36.72152328491211\n",
      "epoch 4200 loss=1241.43505859375\n",
      "epoch 4400 loss=1239.6090087890625\n",
      "epoch 4600 loss=1263.897705078125\n",
      "epoch 4800 loss=1219.427001953125\n",
      "epoch 4999 loss=1200.857421875\n",
      "Finished training\n",
      "FINISHED 7 8 34.78618621826172\n",
      "tensor([31700, 32575,   865, 18832, 25460,  3646, 26704,  9518, 16406, 34518,\n",
      "        14995, 23563, 21019,  7524,  2846, 27192, 26547,  7189,  2272, 24540,\n",
      "        18396, 25846, 23803, 16370, 29639,  5777, 32546, 22767, 10718, 30817,\n",
      "         1447, 21988, 30525, 28922, 32570,  2122, 33099, 15677,  9522, 33390,\n",
      "        19537, 27996, 12524,  7054, 18978,  3296, 14016, 31330,  1694,  3335])\n",
      "tensor([32299,   360, 19822,  9913,  7399,  4863, 16876, 28071, 16417, 14292,\n",
      "        19748, 26817, 17534, 28400, 25875, 20936, 17330,  7769,  8709,  6887,\n",
      "        17793, 28629,  4686,  8977, 18724, 13480, 18891,  1562, 23677,  2655,\n",
      "        23919, 23989, 32059, 34405, 33309,  2798,  5051,  5855, 19860, 24323,\n",
      "        30017, 34485, 21756,  4851, 17120, 22327, 11748, 12677, 19172,    47])\n",
      "epoch 0 loss=1530.0379638671875\n",
      "New best validation epoch 0 loss=42.34187698364258\n",
      "epoch 200 loss=1379.45458984375\n",
      "New best validation epoch 200 loss=40.05214309692383\n",
      "epoch 400 loss=1309.990478515625\n",
      "New best validation epoch 400 loss=39.20170974731445\n",
      "epoch 600 loss=1281.590576171875\n",
      "New best validation epoch 600 loss=38.39234924316406\n",
      "epoch 800 loss=1263.0234375\n",
      "New best validation epoch 800 loss=37.8001594543457\n",
      "epoch 1000 loss=1224.0560302734375\n",
      "New best validation epoch 1000 loss=37.341583251953125\n",
      "epoch 1200 loss=1246.0965576171875\n",
      "New best validation epoch 1200 loss=37.050025939941406\n",
      "epoch 1400 loss=1213.31982421875\n",
      "New best validation epoch 1400 loss=36.83074188232422\n",
      "epoch 1600 loss=1256.0814208984375\n",
      "New best validation epoch 1600 loss=36.77949142456055\n",
      "epoch 1800 loss=1193.0958251953125\n",
      "New best validation epoch 1800 loss=36.654659271240234\n",
      "epoch 2000 loss=1246.1151123046875\n",
      "New best validation epoch 2000 loss=36.543277740478516\n",
      "epoch 2200 loss=1202.8587646484375\n",
      "epoch 2400 loss=1214.0516357421875\n",
      "epoch 2600 loss=1188.3238525390625\n",
      "New best validation epoch 2600 loss=36.490440368652344\n",
      "epoch 2800 loss=1223.99072265625\n",
      "New best validation epoch 2800 loss=36.463661193847656\n",
      "epoch 3000 loss=1196.2174072265625\n",
      "New best validation epoch 3000 loss=36.46183776855469\n",
      "epoch 3200 loss=1215.389404296875\n",
      "epoch 3400 loss=1236.629638671875\n",
      "New best validation epoch 3400 loss=36.442115783691406\n",
      "epoch 3600 loss=1154.2547607421875\n",
      "New best validation epoch 3600 loss=36.37568283081055\n",
      "epoch 3800 loss=1201.1292724609375\n",
      "epoch 4000 loss=1170.462646484375\n",
      "New best validation epoch 4000 loss=36.324764251708984\n",
      "epoch 4200 loss=1210.2034912109375\n",
      "epoch 4400 loss=1227.444580078125\n",
      "epoch 4600 loss=1204.49267578125\n",
      "epoch 4800 loss=1154.797119140625\n",
      "epoch 4999 loss=1228.84521484375\n",
      "Finished training\n",
      "FINISHED 7 9 34.53012466430664\n",
      "tensor([28717, 27567, 24025, 13064, 28823])\n",
      "tensor([18317, 24668, 14626, 21148, 20715])\n",
      "epoch 0 loss=1551.1737060546875\n",
      "New best validation epoch 0 loss=43.5712776184082\n",
      "epoch 200 loss=1550.3294677734375\n",
      "New best validation epoch 200 loss=43.53642654418945\n",
      "epoch 400 loss=1540.18505859375\n",
      "New best validation epoch 400 loss=43.41399002075195\n",
      "epoch 600 loss=1519.399658203125\n",
      "New best validation epoch 600 loss=43.176780700683594\n",
      "epoch 800 loss=1500.4520263671875\n",
      "New best validation epoch 800 loss=42.85634231567383\n",
      "epoch 1000 loss=1490.99853515625\n",
      "New best validation epoch 1000 loss=42.53363800048828\n",
      "epoch 1200 loss=1469.19580078125\n",
      "New best validation epoch 1200 loss=42.31943130493164\n",
      "epoch 1400 loss=1495.13623046875\n",
      "New best validation epoch 1400 loss=42.18873596191406\n",
      "epoch 1600 loss=1477.2890625\n",
      "New best validation epoch 1600 loss=42.10358428955078\n",
      "epoch 1800 loss=1472.421142578125\n",
      "New best validation epoch 1800 loss=42.033809661865234\n",
      "epoch 2000 loss=1476.51318359375\n",
      "New best validation epoch 2000 loss=42.02739715576172\n",
      "epoch 2200 loss=1467.9642333984375\n",
      "New best validation epoch 2200 loss=42.00075912475586\n",
      "epoch 2400 loss=1477.1875\n",
      "New best validation epoch 2400 loss=41.97959518432617\n",
      "epoch 2600 loss=1472.7645263671875\n",
      "epoch 2800 loss=1472.0638427734375\n",
      "epoch 3000 loss=1469.01171875\n",
      "New best validation epoch 3000 loss=41.95794677734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3200 loss=1448.9354248046875\n",
      "New best validation epoch 3200 loss=41.95342254638672\n",
      "epoch 3400 loss=1463.6771240234375\n",
      "epoch 3600 loss=1472.0184326171875\n",
      "New best validation epoch 3600 loss=41.93972396850586\n",
      "epoch 3800 loss=1464.0828857421875\n",
      "epoch 4000 loss=1466.1702880859375\n",
      "epoch 4200 loss=1449.4114990234375\n",
      "New best validation epoch 4200 loss=41.92742156982422\n",
      "epoch 4400 loss=1492.2529296875\n",
      "epoch 4600 loss=1492.7908935546875\n",
      "epoch 4800 loss=1467.7470703125\n",
      "epoch 4999 loss=1468.92724609375\n",
      "New best validation epoch 4999 loss=41.9215087890625\n",
      "Finished training\n",
      "FINISHED 8 0 33.14404296875\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063])\n",
      "epoch 0 loss=1551.57861328125\n",
      "New best validation epoch 0 loss=43.57128143310547\n",
      "epoch 200 loss=1540.8236083984375\n",
      "New best validation epoch 200 loss=43.381507873535156\n",
      "epoch 400 loss=1488.21240234375\n",
      "New best validation epoch 400 loss=42.69419860839844\n",
      "epoch 600 loss=1458.6787109375\n",
      "New best validation epoch 600 loss=41.887794494628906\n",
      "epoch 800 loss=1437.9501953125\n",
      "New best validation epoch 800 loss=41.4947395324707\n",
      "epoch 1000 loss=1441.5897216796875\n",
      "New best validation epoch 1000 loss=41.341026306152344\n",
      "epoch 1200 loss=1413.781494140625\n",
      "New best validation epoch 1200 loss=41.272090911865234\n",
      "epoch 1400 loss=1432.401611328125\n",
      "New best validation epoch 1400 loss=41.247718811035156\n",
      "epoch 1600 loss=1457.988037109375\n",
      "New best validation epoch 1600 loss=41.21661376953125\n",
      "epoch 1800 loss=1447.52685546875\n",
      "epoch 2000 loss=1469.1357421875\n",
      "epoch 2200 loss=1416.1405029296875\n",
      "New best validation epoch 2200 loss=41.18804168701172\n",
      "epoch 2400 loss=1423.9365234375\n",
      "New best validation epoch 2400 loss=41.1615104675293\n",
      "epoch 2600 loss=1435.1259765625\n",
      "epoch 2800 loss=1434.0423583984375\n",
      "epoch 3000 loss=1426.7581787109375\n",
      "epoch 3200 loss=1448.308349609375\n",
      "epoch 3400 loss=1438.999267578125\n",
      "epoch 3600 loss=1448.12451171875\n",
      "epoch 3800 loss=1410.987060546875\n",
      "epoch 4000 loss=1417.337158203125\n",
      "epoch 4200 loss=1436.090087890625\n",
      "epoch 4400 loss=1419.18310546875\n",
      "epoch 4600 loss=1448.795166015625\n",
      "epoch 4800 loss=1457.43505859375\n",
      "epoch 4999 loss=1462.264404296875\n",
      "Finished training\n",
      "FINISHED 8 1 32.76079177856445\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100])\n",
      "epoch 0 loss=1551.6566162109375\n",
      "New best validation epoch 0 loss=43.57127380371094\n",
      "epoch 200 loss=1526.119873046875\n",
      "New best validation epoch 200 loss=43.08636474609375\n",
      "epoch 400 loss=1474.7342529296875\n",
      "New best validation epoch 400 loss=41.600738525390625\n",
      "epoch 600 loss=1435.7254638671875\n",
      "New best validation epoch 600 loss=40.712486267089844\n",
      "epoch 800 loss=1428.916748046875\n",
      "New best validation epoch 800 loss=40.40948486328125\n",
      "epoch 1000 loss=1417.53955078125\n",
      "New best validation epoch 1000 loss=40.279258728027344\n",
      "epoch 1200 loss=1418.0335693359375\n",
      "New best validation epoch 1200 loss=40.185829162597656\n",
      "epoch 1400 loss=1399.14453125\n",
      "New best validation epoch 1400 loss=40.103126525878906\n",
      "epoch 1600 loss=1426.461669921875\n",
      "epoch 1800 loss=1396.384521484375\n",
      "New best validation epoch 1800 loss=40.044044494628906\n",
      "epoch 2000 loss=1409.922119140625\n",
      "New best validation epoch 2000 loss=39.991146087646484\n",
      "epoch 2200 loss=1406.7098388671875\n",
      "New best validation epoch 2200 loss=39.98817443847656\n",
      "epoch 2400 loss=1429.168212890625\n",
      "epoch 2600 loss=1396.698974609375\n",
      "epoch 2800 loss=1403.829833984375\n",
      "epoch 3000 loss=1378.780517578125\n",
      "New best validation epoch 3000 loss=39.98182678222656\n",
      "epoch 3200 loss=1395.493896484375\n",
      "New best validation epoch 3200 loss=39.97685623168945\n",
      "epoch 3400 loss=1371.5032958984375\n",
      "New best validation epoch 3400 loss=39.948699951171875\n",
      "epoch 3600 loss=1408.29345703125\n",
      "New best validation epoch 3600 loss=39.92658996582031\n",
      "epoch 3800 loss=1387.9583740234375\n",
      "epoch 4000 loss=1397.81298828125\n",
      "epoch 4200 loss=1372.6307373046875\n",
      "epoch 4400 loss=1390.435546875\n",
      "epoch 4600 loss=1408.517333984375\n",
      "epoch 4800 loss=1386.5687255859375\n",
      "epoch 4999 loss=1424.9169921875\n",
      "New best validation epoch 4999 loss=39.88026428222656\n",
      "Finished training\n",
      "FINISHED 8 2 32.316978454589844\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292,  7178, 15495, 21184, 18055, 22822])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100, 24402,  6793,  1450,  8455, 33024])\n",
      "epoch 0 loss=1551.55908203125\n",
      "New best validation epoch 0 loss=43.57126998901367\n",
      "epoch 200 loss=1498.17236328125\n",
      "New best validation epoch 200 loss=42.67954635620117\n",
      "epoch 400 loss=1446.056640625\n",
      "New best validation epoch 400 loss=40.83845520019531\n",
      "epoch 600 loss=1420.2952880859375\n",
      "New best validation epoch 600 loss=40.26555633544922\n",
      "epoch 800 loss=1388.3577880859375\n",
      "New best validation epoch 800 loss=39.933956146240234\n",
      "epoch 1000 loss=1415.4462890625\n",
      "New best validation epoch 1000 loss=39.7236328125\n",
      "epoch 1200 loss=1377.935302734375\n",
      "New best validation epoch 1200 loss=39.59812545776367\n",
      "epoch 1400 loss=1396.794921875\n",
      "New best validation epoch 1400 loss=39.4692497253418\n",
      "epoch 1600 loss=1396.65087890625\n",
      "New best validation epoch 1600 loss=39.39362335205078\n",
      "epoch 1800 loss=1354.117431640625\n",
      "New best validation epoch 1800 loss=39.28959655761719\n",
      "epoch 2000 loss=1374.0169677734375\n",
      "New best validation epoch 2000 loss=39.275596618652344\n",
      "epoch 2200 loss=1395.341064453125\n",
      "epoch 2400 loss=1386.873046875\n",
      "New best validation epoch 2400 loss=39.26820373535156\n",
      "epoch 2600 loss=1393.0941162109375\n",
      "New best validation epoch 2600 loss=39.24970245361328\n",
      "epoch 2800 loss=1348.821044921875\n",
      "New best validation epoch 2800 loss=39.19261932373047\n",
      "epoch 3000 loss=1392.14990234375\n",
      "epoch 3200 loss=1405.480224609375\n",
      "New best validation epoch 3200 loss=39.17053985595703\n",
      "epoch 3400 loss=1386.3128662109375\n",
      "epoch 3600 loss=1379.8348388671875\n",
      "epoch 3800 loss=1338.9822998046875\n",
      "New best validation epoch 3800 loss=39.157249450683594\n",
      "epoch 4000 loss=1382.7841796875\n",
      "epoch 4200 loss=1373.4920654296875\n",
      "New best validation epoch 4200 loss=39.130767822265625\n",
      "epoch 4400 loss=1393.405517578125\n",
      "epoch 4600 loss=1367.3118896484375\n",
      "epoch 4800 loss=1379.690185546875\n",
      "epoch 4999 loss=1383.470458984375\n",
      "New best validation epoch 4999 loss=39.11906814575195\n",
      "Finished training\n",
      "FINISHED 8 3 32.02396774291992\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292,  7178, 15495, 21184, 18055, 22822,\n",
      "        17143, 24825,  7721, 32118,  6863])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100, 24402,  6793,  1450,  8455, 33024,\n",
      "        34005,  8620,  5345, 10294, 19694])\n",
      "epoch 0 loss=1553.2967529296875\n",
      "New best validation epoch 0 loss=43.571266174316406\n",
      "epoch 200 loss=1490.631103515625\n",
      "New best validation epoch 200 loss=42.290950775146484\n",
      "epoch 400 loss=1407.896240234375\n",
      "New best validation epoch 400 loss=40.38033676147461\n",
      "epoch 600 loss=1363.27685546875\n",
      "New best validation epoch 600 loss=39.847904205322266\n",
      "epoch 800 loss=1375.967529296875\n",
      "New best validation epoch 800 loss=39.44533157348633\n",
      "epoch 1000 loss=1373.1097412109375\n",
      "New best validation epoch 1000 loss=39.193363189697266\n",
      "epoch 1200 loss=1385.641845703125\n",
      "New best validation epoch 1200 loss=38.9652099609375\n",
      "epoch 1400 loss=1320.261474609375\n",
      "New best validation epoch 1400 loss=38.82379913330078\n",
      "epoch 1600 loss=1380.68505859375\n",
      "New best validation epoch 1600 loss=38.7635383605957\n",
      "epoch 1800 loss=1350.121337890625\n",
      "New best validation epoch 1800 loss=38.71421813964844\n",
      "epoch 2000 loss=1340.06591796875\n",
      "New best validation epoch 2000 loss=38.601531982421875\n",
      "epoch 2200 loss=1386.7991943359375\n",
      "epoch 2400 loss=1376.197998046875\n",
      "New best validation epoch 2400 loss=38.58029556274414\n",
      "epoch 2600 loss=1373.826171875\n",
      "epoch 2800 loss=1379.9007568359375\n",
      "New best validation epoch 2800 loss=38.57605743408203\n",
      "epoch 3000 loss=1352.3046875\n",
      "New best validation epoch 3000 loss=38.507965087890625\n",
      "epoch 3200 loss=1333.922119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3400 loss=1359.0213623046875\n",
      "New best validation epoch 3400 loss=38.459903717041016\n",
      "epoch 3600 loss=1315.7021484375\n",
      "epoch 3800 loss=1357.03173828125\n",
      "New best validation epoch 3800 loss=38.45508575439453\n",
      "epoch 4000 loss=1291.1766357421875\n",
      "epoch 4200 loss=1337.218505859375\n",
      "epoch 4400 loss=1349.1614990234375\n",
      "epoch 4600 loss=1365.2855224609375\n",
      "epoch 4800 loss=1341.082763671875\n",
      "epoch 4999 loss=1361.269775390625\n",
      "Finished training\n",
      "FINISHED 8 4 31.614221572875977\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292,  7178, 15495, 21184, 18055, 22822,\n",
      "        17143, 24825,  7721, 32118,  6863,   220, 28511,  9755, 18345, 24350])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100, 24402,  6793,  1450,  8455, 33024,\n",
      "        34005,  8620,  5345, 10294, 19694, 24911, 29084, 19533, 23028, 31891])\n",
      "epoch 0 loss=1553.9013671875\n",
      "New best validation epoch 0 loss=43.57124710083008\n",
      "epoch 200 loss=1448.7103271484375\n",
      "New best validation epoch 200 loss=41.682640075683594\n",
      "epoch 400 loss=1399.2109375\n",
      "New best validation epoch 400 loss=40.10429763793945\n",
      "epoch 600 loss=1382.3045654296875\n",
      "New best validation epoch 600 loss=39.56816101074219\n",
      "epoch 800 loss=1340.7828369140625\n",
      "New best validation epoch 800 loss=39.16865158081055\n",
      "epoch 1000 loss=1337.8758544921875\n",
      "New best validation epoch 1000 loss=38.85219955444336\n",
      "epoch 1200 loss=1361.1787109375\n",
      "New best validation epoch 1200 loss=38.61483383178711\n",
      "epoch 1400 loss=1313.607177734375\n",
      "New best validation epoch 1400 loss=38.468109130859375\n",
      "epoch 1600 loss=1332.9991455078125\n",
      "New best validation epoch 1600 loss=38.367740631103516\n",
      "epoch 1800 loss=1365.62646484375\n",
      "New best validation epoch 1800 loss=38.26936721801758\n",
      "epoch 2000 loss=1328.1865234375\n",
      "New best validation epoch 2000 loss=38.25162887573242\n",
      "epoch 2200 loss=1332.72705078125\n",
      "New best validation epoch 2200 loss=38.13827896118164\n",
      "epoch 2400 loss=1376.4129638671875\n",
      "epoch 2600 loss=1344.0179443359375\n",
      "epoch 2800 loss=1322.11767578125\n",
      "New best validation epoch 2800 loss=38.0936393737793\n",
      "epoch 3000 loss=1307.5472412109375\n",
      "epoch 3200 loss=1311.051513671875\n",
      "epoch 3400 loss=1317.18115234375\n",
      "epoch 3600 loss=1337.1854248046875\n",
      "New best validation epoch 3600 loss=38.041011810302734\n",
      "epoch 3800 loss=1361.056640625\n",
      "New best validation epoch 3800 loss=38.025047302246094\n",
      "epoch 4000 loss=1287.036865234375\n",
      "epoch 4200 loss=1338.447509765625\n",
      "epoch 4400 loss=1341.30615234375\n",
      "epoch 4600 loss=1315.3836669921875\n",
      "epoch 4800 loss=1300.739013671875\n",
      "epoch 4999 loss=1326.0760498046875\n",
      "Finished training\n",
      "FINISHED 8 5 31.39129066467285\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292,  7178, 15495, 21184, 18055, 22822,\n",
      "        17143, 24825,  7721, 32118,  6863,   220, 28511,  9755, 18345, 24350,\n",
      "         7404, 34240, 18656, 33856, 16678])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100, 24402,  6793,  1450,  8455, 33024,\n",
      "        34005,  8620,  5345, 10294, 19694, 24911, 29084, 19533, 23028, 31891,\n",
      "        10289, 15394,  2910,  1184,  1553])\n",
      "epoch 0 loss=1553.696044921875\n",
      "New best validation epoch 0 loss=43.57123947143555\n",
      "epoch 200 loss=1455.4619140625\n",
      "New best validation epoch 200 loss=41.14060592651367\n",
      "epoch 400 loss=1391.635986328125\n",
      "New best validation epoch 400 loss=39.84292221069336\n",
      "epoch 600 loss=1392.977294921875\n",
      "New best validation epoch 600 loss=39.2675895690918\n",
      "epoch 800 loss=1326.9827880859375\n",
      "New best validation epoch 800 loss=38.80292510986328\n",
      "epoch 1000 loss=1315.9677734375\n",
      "New best validation epoch 1000 loss=38.47181701660156\n",
      "epoch 1200 loss=1301.054931640625\n",
      "New best validation epoch 1200 loss=38.21207809448242\n",
      "epoch 1400 loss=1307.3299560546875\n",
      "New best validation epoch 1400 loss=38.11459732055664\n",
      "epoch 1600 loss=1325.986572265625\n",
      "epoch 1800 loss=1282.9154052734375\n",
      "New best validation epoch 1800 loss=38.047916412353516\n",
      "epoch 2000 loss=1297.553466796875\n",
      "New best validation epoch 2000 loss=37.91335678100586\n",
      "epoch 2200 loss=1308.9949951171875\n",
      "New best validation epoch 2200 loss=37.87710189819336\n",
      "epoch 2400 loss=1299.1923828125\n",
      "epoch 2600 loss=1302.1483154296875\n",
      "New best validation epoch 2600 loss=37.8125114440918\n",
      "epoch 2800 loss=1345.13525390625\n",
      "epoch 3000 loss=1304.757568359375\n",
      "epoch 3200 loss=1342.70751953125\n",
      "epoch 3400 loss=1344.1285400390625\n",
      "New best validation epoch 3400 loss=37.796234130859375\n",
      "epoch 3600 loss=1367.61669921875\n",
      "epoch 3800 loss=1273.643798828125\n",
      "epoch 4000 loss=1355.8636474609375\n",
      "New best validation epoch 4000 loss=37.79085922241211\n",
      "epoch 4200 loss=1316.92431640625\n",
      "epoch 4400 loss=1305.8905029296875\n",
      "epoch 4600 loss=1322.630859375\n",
      "epoch 4800 loss=1330.85791015625\n",
      "epoch 4999 loss=1324.5892333984375\n",
      "Finished training\n",
      "FINISHED 8 6 31.69978141784668\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292,  7178, 15495, 21184, 18055, 22822,\n",
      "        17143, 24825,  7721, 32118,  6863,   220, 28511,  9755, 18345, 24350,\n",
      "         7404, 34240, 18656, 33856, 16678,  4666, 10951, 27318, 21689,  9338])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100, 24402,  6793,  1450,  8455, 33024,\n",
      "        34005,  8620,  5345, 10294, 19694, 24911, 29084, 19533, 23028, 31891,\n",
      "        10289, 15394,  2910,  1184,  1553, 28963,  5275,   555, 21717,   619])\n",
      "epoch 0 loss=1550.902099609375\n",
      "New best validation epoch 0 loss=43.57124328613281\n",
      "epoch 200 loss=1430.697998046875\n",
      "New best validation epoch 200 loss=40.67802047729492\n",
      "epoch 400 loss=1398.14208984375\n",
      "New best validation epoch 400 loss=39.50537872314453\n",
      "epoch 600 loss=1321.176025390625\n",
      "New best validation epoch 600 loss=38.85857391357422\n",
      "epoch 800 loss=1325.9700927734375\n",
      "New best validation epoch 800 loss=38.35865783691406\n",
      "epoch 1000 loss=1304.6639404296875\n",
      "New best validation epoch 1000 loss=38.082271575927734\n",
      "epoch 1200 loss=1335.164794921875\n",
      "New best validation epoch 1200 loss=37.929405212402344\n",
      "epoch 1400 loss=1295.37548828125\n",
      "New best validation epoch 1400 loss=37.743568420410156\n",
      "epoch 1600 loss=1328.85302734375\n",
      "New best validation epoch 1600 loss=37.67733383178711\n",
      "epoch 1800 loss=1300.458251953125\n",
      "New best validation epoch 1800 loss=37.60426330566406\n",
      "epoch 2000 loss=1295.264404296875\n",
      "epoch 2200 loss=1316.8626708984375\n",
      "New best validation epoch 2200 loss=37.56304168701172\n",
      "epoch 2400 loss=1293.455322265625\n",
      "New best validation epoch 2400 loss=37.5185546875\n",
      "epoch 2600 loss=1291.8271484375\n",
      "epoch 2800 loss=1297.073486328125\n",
      "epoch 3000 loss=1259.2666015625\n",
      "New best validation epoch 3000 loss=37.501285552978516\n",
      "epoch 3200 loss=1284.7178955078125\n",
      "epoch 3400 loss=1302.184814453125\n",
      "New best validation epoch 3400 loss=37.497493743896484\n",
      "epoch 3600 loss=1304.240478515625\n",
      "New best validation epoch 3600 loss=37.4698486328125\n",
      "epoch 3800 loss=1278.3782958984375\n",
      "epoch 4000 loss=1309.7073974609375\n",
      "New best validation epoch 4000 loss=37.45189666748047\n",
      "epoch 4200 loss=1285.974853515625\n",
      "epoch 4400 loss=1248.955322265625\n",
      "epoch 4600 loss=1276.7322998046875\n",
      "epoch 4800 loss=1282.218994140625\n",
      "epoch 4999 loss=1308.269287109375\n",
      "Finished training\n",
      "FINISHED 8 7 31.737524032592773\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292,  7178, 15495, 21184, 18055, 22822,\n",
      "        17143, 24825,  7721, 32118,  6863,   220, 28511,  9755, 18345, 24350,\n",
      "         7404, 34240, 18656, 33856, 16678,  4666, 10951, 27318, 21689,  9338,\n",
      "         6550,  3269, 16315, 28322, 15166])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100, 24402,  6793,  1450,  8455, 33024,\n",
      "        34005,  8620,  5345, 10294, 19694, 24911, 29084, 19533, 23028, 31891,\n",
      "        10289, 15394,  2910,  1184,  1553, 28963,  5275,   555, 21717,   619,\n",
      "        26839, 22599,  2243, 32844,  9220])\n",
      "epoch 0 loss=1549.947509765625\n",
      "New best validation epoch 0 loss=43.57121658325195\n",
      "epoch 200 loss=1410.586669921875\n",
      "New best validation epoch 200 loss=40.3053092956543\n",
      "epoch 400 loss=1368.6868896484375\n",
      "New best validation epoch 400 loss=39.28301239013672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600 loss=1333.8323974609375\n",
      "New best validation epoch 600 loss=38.671661376953125\n",
      "epoch 800 loss=1331.638427734375\n",
      "New best validation epoch 800 loss=38.13642883300781\n",
      "epoch 1000 loss=1282.4627685546875\n",
      "New best validation epoch 1000 loss=37.877952575683594\n",
      "epoch 1200 loss=1260.2308349609375\n",
      "New best validation epoch 1200 loss=37.68223190307617\n",
      "epoch 1400 loss=1222.8377685546875\n",
      "New best validation epoch 1400 loss=37.582149505615234\n",
      "epoch 1600 loss=1270.7923583984375\n",
      "New best validation epoch 1600 loss=37.440853118896484\n",
      "epoch 1800 loss=1283.7080078125\n",
      "epoch 2000 loss=1256.56396484375\n",
      "New best validation epoch 2000 loss=37.36430358886719\n",
      "epoch 2200 loss=1262.51806640625\n",
      "epoch 2400 loss=1272.947998046875\n",
      "New best validation epoch 2400 loss=37.28377151489258\n",
      "epoch 2600 loss=1283.56591796875\n",
      "epoch 2800 loss=1240.0927734375\n",
      "epoch 3000 loss=1312.8231201171875\n",
      "epoch 3200 loss=1282.1766357421875\n",
      "epoch 3400 loss=1282.2257080078125\n",
      "epoch 3600 loss=1225.833984375\n",
      "epoch 3800 loss=1298.5164794921875\n",
      "epoch 4000 loss=1299.29443359375\n",
      "New best validation epoch 4000 loss=37.25452423095703\n",
      "epoch 4200 loss=1307.1412353515625\n",
      "epoch 4400 loss=1320.575439453125\n",
      "epoch 4600 loss=1318.1796875\n",
      "epoch 4800 loss=1221.455810546875\n",
      "epoch 4999 loss=1251.9705810546875\n",
      "Finished training\n",
      "FINISHED 8 8 31.585603713989258\n",
      "tensor([28717, 27567, 24025, 13064, 28823, 31050, 16679,  4702, 27217, 29467,\n",
      "         1922,  1842, 28967, 31465, 21292,  7178, 15495, 21184, 18055, 22822,\n",
      "        17143, 24825,  7721, 32118,  6863,   220, 28511,  9755, 18345, 24350,\n",
      "         7404, 34240, 18656, 33856, 16678,  4666, 10951, 27318, 21689,  9338,\n",
      "         6550,  3269, 16315, 28322, 15166, 31728,  4618, 26149,  9958,  7341])\n",
      "tensor([18317, 24668, 14626, 21148, 20715,  2067,  3211, 25175, 22394, 14063,\n",
      "         4076, 25320,  8988, 21791, 10100, 24402,  6793,  1450,  8455, 33024,\n",
      "        34005,  8620,  5345, 10294, 19694, 24911, 29084, 19533, 23028, 31891,\n",
      "        10289, 15394,  2910,  1184,  1553, 28963,  5275,   555, 21717,   619,\n",
      "        26839, 22599,  2243, 32844,  9220, 27696,  9292, 12599,  6654, 11543])\n",
      "epoch 0 loss=1552.4749755859375\n",
      "New best validation epoch 0 loss=43.57120895385742\n",
      "epoch 200 loss=1412.7655029296875\n",
      "New best validation epoch 200 loss=40.17007827758789\n",
      "epoch 400 loss=1345.9130859375\n",
      "New best validation epoch 400 loss=39.2392463684082\n",
      "epoch 600 loss=1310.2486572265625\n",
      "New best validation epoch 600 loss=38.58683776855469\n",
      "epoch 800 loss=1296.5428466796875\n",
      "New best validation epoch 800 loss=38.17218780517578\n",
      "epoch 1000 loss=1278.953125\n",
      "New best validation epoch 1000 loss=37.96956253051758\n",
      "epoch 1200 loss=1235.4388427734375\n",
      "New best validation epoch 1200 loss=37.72631072998047\n",
      "epoch 1400 loss=1255.2158203125\n",
      "New best validation epoch 1400 loss=37.71339416503906\n",
      "epoch 1600 loss=1270.5087890625\n",
      "New best validation epoch 1600 loss=37.591026306152344\n",
      "epoch 1800 loss=1268.739013671875\n",
      "New best validation epoch 1800 loss=37.47407150268555\n",
      "epoch 2000 loss=1316.340576171875\n",
      "epoch 2200 loss=1239.1229248046875\n",
      "New best validation epoch 2200 loss=37.40939712524414\n",
      "epoch 2400 loss=1228.6220703125\n",
      "epoch 2600 loss=1258.702880859375\n",
      "epoch 2800 loss=1275.78076171875\n",
      "epoch 3000 loss=1219.416748046875\n",
      "New best validation epoch 3000 loss=37.40191650390625\n",
      "epoch 3200 loss=1257.66650390625\n",
      "New best validation epoch 3200 loss=37.37477111816406\n",
      "epoch 3400 loss=1240.142333984375\n",
      "epoch 3600 loss=1277.54638671875\n",
      "epoch 3800 loss=1261.6588134765625\n",
      "epoch 4000 loss=1245.1629638671875\n",
      "epoch 4200 loss=1275.4393310546875\n",
      "New best validation epoch 4200 loss=37.32862854003906\n",
      "epoch 4400 loss=1270.1595458984375\n",
      "epoch 4600 loss=1252.8175048828125\n",
      "epoch 4800 loss=1252.88525390625\n",
      "epoch 4999 loss=1260.4658203125\n",
      "Finished training\n",
      "FINISHED 8 9 31.326242446899414\n",
      "tensor([31345, 27226,  6901,  8783, 17682])\n",
      "tensor([10693, 24508, 34143, 30005, 17636])\n",
      "epoch 0 loss=1461.90234375\n",
      "New best validation epoch 0 loss=44.954627990722656\n",
      "epoch 200 loss=1460.363525390625\n",
      "New best validation epoch 200 loss=44.90938949584961\n",
      "epoch 400 loss=1452.76220703125\n",
      "New best validation epoch 400 loss=44.75402069091797\n",
      "epoch 600 loss=1432.62890625\n",
      "New best validation epoch 600 loss=44.4903564453125\n",
      "epoch 800 loss=1436.913330078125\n",
      "New best validation epoch 800 loss=44.16754150390625\n",
      "epoch 1000 loss=1410.25537109375\n",
      "New best validation epoch 1000 loss=43.913021087646484\n",
      "epoch 1200 loss=1405.662109375\n",
      "New best validation epoch 1200 loss=43.73572540283203\n",
      "epoch 1400 loss=1407.547119140625\n",
      "New best validation epoch 1400 loss=43.664527893066406\n",
      "epoch 1600 loss=1427.79833984375\n",
      "New best validation epoch 1600 loss=43.60993194580078\n",
      "epoch 1800 loss=1408.375244140625\n",
      "New best validation epoch 1800 loss=43.58946990966797\n",
      "epoch 2000 loss=1400.929443359375\n",
      "New best validation epoch 2000 loss=43.588836669921875\n",
      "epoch 2200 loss=1420.8895263671875\n",
      "New best validation epoch 2200 loss=43.5870361328125\n",
      "epoch 2400 loss=1411.591552734375\n",
      "New best validation epoch 2400 loss=43.585575103759766\n",
      "epoch 2600 loss=1396.5780029296875\n",
      "New best validation epoch 2600 loss=43.57452392578125\n",
      "epoch 2800 loss=1390.4150390625\n",
      "epoch 3000 loss=1388.404296875\n",
      "epoch 3200 loss=1412.992919921875\n",
      "epoch 3400 loss=1399.92529296875\n",
      "epoch 3600 loss=1403.4759521484375\n",
      "epoch 3800 loss=1408.4892578125\n",
      "epoch 4000 loss=1410.163818359375\n",
      "epoch 4200 loss=1418.1370849609375\n",
      "epoch 4400 loss=1366.6839599609375\n",
      "epoch 4600 loss=1402.7923583984375\n",
      "epoch 4800 loss=1417.156982421875\n",
      "epoch 4999 loss=1390.05322265625\n",
      "Finished training\n",
      "FINISHED 9 0 41.77410888671875\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334])\n",
      "epoch 0 loss=1465.26220703125\n",
      "New best validation epoch 0 loss=44.954627990722656\n",
      "epoch 200 loss=1450.8802490234375\n",
      "New best validation epoch 200 loss=44.77761459350586\n",
      "epoch 400 loss=1420.4339599609375\n",
      "New best validation epoch 400 loss=44.151390075683594\n",
      "epoch 600 loss=1400.8504638671875\n",
      "New best validation epoch 600 loss=43.50895690917969\n",
      "epoch 800 loss=1377.031982421875\n",
      "New best validation epoch 800 loss=43.24269104003906\n",
      "epoch 1000 loss=1369.9080810546875\n",
      "New best validation epoch 1000 loss=43.15685272216797\n",
      "epoch 1200 loss=1395.3876953125\n",
      "New best validation epoch 1200 loss=43.114280700683594\n",
      "epoch 1400 loss=1387.905029296875\n",
      "New best validation epoch 1400 loss=43.09330749511719\n",
      "epoch 1600 loss=1402.8997802734375\n",
      "epoch 1800 loss=1368.3916015625\n",
      "epoch 2000 loss=1382.931884765625\n",
      "New best validation epoch 2000 loss=43.0910530090332\n",
      "epoch 2200 loss=1376.1058349609375\n",
      "epoch 2400 loss=1381.2591552734375\n",
      "epoch 2600 loss=1362.7950439453125\n",
      "epoch 2800 loss=1370.672607421875\n",
      "epoch 3000 loss=1373.493896484375\n",
      "epoch 3200 loss=1385.8436279296875\n",
      "epoch 3400 loss=1366.0814208984375\n",
      "epoch 3600 loss=1375.615966796875\n",
      "epoch 3800 loss=1387.4388427734375\n",
      "epoch 4000 loss=1368.1087646484375\n",
      "epoch 4200 loss=1413.536865234375\n",
      "epoch 4400 loss=1378.3475341796875\n",
      "epoch 4600 loss=1365.7998046875\n",
      "epoch 4800 loss=1369.359375\n",
      "epoch 4999 loss=1385.41552734375\n",
      "Finished training\n",
      "FINISHED 9 1 41.49631118774414\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096])\n",
      "epoch 0 loss=1465.5169677734375\n",
      "New best validation epoch 0 loss=44.954620361328125\n",
      "epoch 200 loss=1431.580078125\n",
      "New best validation epoch 200 loss=44.38566589355469\n",
      "epoch 400 loss=1375.4925537109375\n",
      "New best validation epoch 400 loss=42.64170837402344\n",
      "epoch 600 loss=1345.87890625\n",
      "New best validation epoch 600 loss=42.04329299926758\n",
      "epoch 800 loss=1330.35205078125\n",
      "New best validation epoch 800 loss=41.85940933227539\n",
      "epoch 1000 loss=1337.8558349609375\n",
      "New best validation epoch 1000 loss=41.758853912353516\n",
      "epoch 1200 loss=1310.5145263671875\n",
      "New best validation epoch 1200 loss=41.633338928222656\n",
      "epoch 1400 loss=1303.4940185546875\n",
      "New best validation epoch 1400 loss=41.58478927612305\n",
      "epoch 1600 loss=1301.1195068359375\n",
      "New best validation epoch 1600 loss=41.5786018371582\n",
      "epoch 1800 loss=1295.07958984375\n",
      "New best validation epoch 1800 loss=41.55167770385742\n",
      "epoch 2000 loss=1347.5048828125\n",
      "New best validation epoch 2000 loss=41.53112030029297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2200 loss=1372.902099609375\n",
      "New best validation epoch 2200 loss=41.498722076416016\n",
      "epoch 2400 loss=1277.471435546875\n",
      "epoch 2600 loss=1315.16552734375\n",
      "New best validation epoch 2600 loss=41.49229049682617\n",
      "epoch 2800 loss=1341.376708984375\n",
      "epoch 3000 loss=1264.405029296875\n",
      "New best validation epoch 3000 loss=41.4766731262207\n",
      "epoch 3200 loss=1282.437255859375\n",
      "New best validation epoch 3200 loss=41.471519470214844\n",
      "epoch 3400 loss=1260.62744140625\n",
      "epoch 3600 loss=1324.31787109375\n",
      "epoch 3800 loss=1322.0927734375\n",
      "epoch 4000 loss=1297.16357421875\n",
      "New best validation epoch 4000 loss=41.45794677734375\n",
      "epoch 4200 loss=1304.441650390625\n",
      "epoch 4400 loss=1276.9373779296875\n",
      "epoch 4600 loss=1323.0693359375\n",
      "epoch 4800 loss=1292.6798095703125\n",
      "epoch 4999 loss=1296.3270263671875\n",
      "Finished training\n",
      "FINISHED 9 2 40.84603500366211\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064,  1529, 12699, 34380, 14812, 28906])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096, 22538,  9133, 32298,   970, 25601])\n",
      "epoch 0 loss=1464.8983154296875\n",
      "New best validation epoch 0 loss=44.954612731933594\n",
      "epoch 200 loss=1411.2845458984375\n",
      "New best validation epoch 200 loss=43.9251708984375\n",
      "epoch 400 loss=1335.9466552734375\n",
      "New best validation epoch 400 loss=42.03572082519531\n",
      "epoch 600 loss=1310.97021484375\n",
      "New best validation epoch 600 loss=41.549339294433594\n",
      "epoch 800 loss=1298.3406982421875\n",
      "New best validation epoch 800 loss=41.30636215209961\n",
      "epoch 1000 loss=1292.6591796875\n",
      "New best validation epoch 1000 loss=41.17647933959961\n",
      "epoch 1200 loss=1287.375732421875\n",
      "New best validation epoch 1200 loss=41.08346176147461\n",
      "epoch 1400 loss=1299.1595458984375\n",
      "New best validation epoch 1400 loss=41.005836486816406\n",
      "epoch 1600 loss=1309.4735107421875\n",
      "New best validation epoch 1600 loss=40.909786224365234\n",
      "epoch 1800 loss=1305.591552734375\n",
      "epoch 2000 loss=1276.0242919921875\n",
      "epoch 2200 loss=1305.110107421875\n",
      "epoch 2400 loss=1281.53564453125\n",
      "New best validation epoch 2400 loss=40.88129425048828\n",
      "epoch 2600 loss=1239.53369140625\n",
      "New best validation epoch 2600 loss=40.88100051879883\n",
      "epoch 2800 loss=1267.888671875\n",
      "epoch 3000 loss=1238.1337890625\n",
      "New best validation epoch 3000 loss=40.848876953125\n",
      "epoch 3200 loss=1242.01953125\n",
      "epoch 3400 loss=1263.325439453125\n",
      "epoch 3600 loss=1243.7701416015625\n",
      "epoch 3800 loss=1263.002685546875\n",
      "epoch 4000 loss=1274.5888671875\n",
      "epoch 4200 loss=1275.531494140625\n",
      "New best validation epoch 4200 loss=40.76580810546875\n",
      "epoch 4400 loss=1306.22216796875\n",
      "epoch 4600 loss=1281.784423828125\n",
      "epoch 4800 loss=1286.4658203125\n",
      "epoch 4999 loss=1281.36865234375\n",
      "Finished training\n",
      "FINISHED 9 3 39.99652862548828\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064,  1529, 12699, 34380, 14812, 28906,\n",
      "        20897,  1454,  9698,  8963,  3794])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096, 22538,  9133, 32298,   970, 25601,\n",
      "          573,  2992, 12167, 24480, 24752])\n",
      "epoch 0 loss=1463.2757568359375\n",
      "New best validation epoch 0 loss=44.95460891723633\n",
      "epoch 200 loss=1386.237548828125\n",
      "New best validation epoch 200 loss=43.37098693847656\n",
      "epoch 400 loss=1317.92236328125\n",
      "New best validation epoch 400 loss=41.593990325927734\n",
      "epoch 600 loss=1337.4027099609375\n",
      "New best validation epoch 600 loss=41.183876037597656\n",
      "epoch 800 loss=1309.97314453125\n",
      "New best validation epoch 800 loss=40.91152572631836\n",
      "epoch 1000 loss=1275.036865234375\n",
      "New best validation epoch 1000 loss=40.85253143310547\n",
      "epoch 1200 loss=1260.4365234375\n",
      "New best validation epoch 1200 loss=40.65830993652344\n",
      "epoch 1400 loss=1225.727294921875\n",
      "epoch 1600 loss=1260.120361328125\n",
      "New best validation epoch 1600 loss=40.6332893371582\n",
      "epoch 1800 loss=1267.75048828125\n",
      "New best validation epoch 1800 loss=40.586669921875\n",
      "epoch 2000 loss=1270.37890625\n",
      "New best validation epoch 2000 loss=40.497589111328125\n",
      "epoch 2200 loss=1259.7303466796875\n",
      "New best validation epoch 2200 loss=40.46945571899414\n",
      "epoch 2400 loss=1244.28759765625\n",
      "New best validation epoch 2400 loss=40.45424270629883\n",
      "epoch 2600 loss=1249.67724609375\n",
      "epoch 2800 loss=1227.966552734375\n",
      "epoch 3000 loss=1281.177490234375\n",
      "New best validation epoch 3000 loss=40.407142639160156\n",
      "epoch 3200 loss=1293.713623046875\n",
      "epoch 3400 loss=1269.4066162109375\n",
      "epoch 3600 loss=1265.501708984375\n",
      "epoch 3800 loss=1245.1600341796875\n",
      "New best validation epoch 3800 loss=40.40604782104492\n",
      "epoch 4000 loss=1257.8704833984375\n",
      "epoch 4200 loss=1242.87353515625\n",
      "epoch 4400 loss=1268.0252685546875\n",
      "epoch 4600 loss=1238.833984375\n",
      "epoch 4800 loss=1258.858154296875\n",
      "epoch 4999 loss=1261.23486328125\n",
      "Finished training\n",
      "FINISHED 9 4 39.27883529663086\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064,  1529, 12699, 34380, 14812, 28906,\n",
      "        20897,  1454,  9698,  8963,  3794, 14524, 13464, 21467, 26598, 31935])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096, 22538,  9133, 32298,   970, 25601,\n",
      "          573,  2992, 12167, 24480, 24752, 12765, 12689,   337, 19749, 25598])\n",
      "epoch 0 loss=1463.825927734375\n",
      "New best validation epoch 0 loss=44.95460510253906\n",
      "epoch 200 loss=1379.2841796875\n",
      "New best validation epoch 200 loss=42.854469299316406\n",
      "epoch 400 loss=1328.385498046875\n",
      "New best validation epoch 400 loss=41.44587707519531\n",
      "epoch 600 loss=1316.6826171875\n",
      "New best validation epoch 600 loss=41.095455169677734\n",
      "epoch 800 loss=1300.3262939453125\n",
      "New best validation epoch 800 loss=40.83881378173828\n",
      "epoch 1000 loss=1250.0048828125\n",
      "New best validation epoch 1000 loss=40.749717712402344\n",
      "epoch 1200 loss=1224.81494140625\n",
      "New best validation epoch 1200 loss=40.604896545410156\n",
      "epoch 1400 loss=1235.1292724609375\n",
      "New best validation epoch 1400 loss=40.593162536621094\n",
      "epoch 1600 loss=1216.78271484375\n",
      "New best validation epoch 1600 loss=40.54586410522461\n",
      "epoch 1800 loss=1223.9755859375\n",
      "New best validation epoch 1800 loss=40.50155258178711\n",
      "epoch 2000 loss=1252.7347412109375\n",
      "New best validation epoch 2000 loss=40.40370178222656\n",
      "epoch 2200 loss=1235.72314453125\n",
      "epoch 2400 loss=1223.4481201171875\n",
      "epoch 2600 loss=1210.42236328125\n",
      "New best validation epoch 2600 loss=40.40191650390625\n",
      "epoch 2800 loss=1220.9700927734375\n",
      "epoch 3000 loss=1239.968017578125\n",
      "epoch 3200 loss=1217.87451171875\n",
      "New best validation epoch 3200 loss=40.38405990600586\n",
      "epoch 3400 loss=1201.6790771484375\n",
      "epoch 3600 loss=1197.6756591796875\n",
      "epoch 3800 loss=1201.237060546875\n",
      "epoch 4000 loss=1280.6226806640625\n",
      "epoch 4200 loss=1189.0908203125\n",
      "epoch 4400 loss=1249.5306396484375\n",
      "epoch 4600 loss=1231.6697998046875\n",
      "epoch 4800 loss=1237.9691162109375\n",
      "epoch 4999 loss=1206.3033447265625\n",
      "New best validation epoch 4999 loss=40.38018035888672\n",
      "Finished training\n",
      "FINISHED 9 5 38.79594802856445\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064,  1529, 12699, 34380, 14812, 28906,\n",
      "        20897,  1454,  9698,  8963,  3794, 14524, 13464, 21467, 26598, 31935,\n",
      "         1247, 15662, 24599, 11836, 11614])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096, 22538,  9133, 32298,   970, 25601,\n",
      "          573,  2992, 12167, 24480, 24752, 12765, 12689,   337, 19749, 25598,\n",
      "        20739,  2821, 21702, 25284, 20867])\n",
      "epoch 0 loss=1466.869873046875\n",
      "New best validation epoch 0 loss=44.954593658447266\n",
      "epoch 200 loss=1367.95458984375\n",
      "New best validation epoch 200 loss=42.37825393676758\n",
      "epoch 400 loss=1311.2630615234375\n",
      "New best validation epoch 400 loss=41.30437088012695\n",
      "epoch 600 loss=1288.531005859375\n",
      "New best validation epoch 600 loss=40.97841262817383\n",
      "epoch 800 loss=1231.956298828125\n",
      "New best validation epoch 800 loss=40.753273010253906\n",
      "epoch 1000 loss=1236.2230224609375\n",
      "New best validation epoch 1000 loss=40.620052337646484\n",
      "epoch 1200 loss=1242.692626953125\n",
      "New best validation epoch 1200 loss=40.5947380065918\n",
      "epoch 1400 loss=1241.0521240234375\n",
      "New best validation epoch 1400 loss=40.454158782958984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1600 loss=1172.056396484375\n",
      "New best validation epoch 1600 loss=40.41872787475586\n",
      "epoch 1800 loss=1201.7122802734375\n",
      "New best validation epoch 1800 loss=40.39601516723633\n",
      "epoch 2000 loss=1220.6981201171875\n",
      "epoch 2200 loss=1236.0064697265625\n",
      "epoch 2400 loss=1200.822509765625\n",
      "New best validation epoch 2400 loss=40.36540603637695\n",
      "epoch 2600 loss=1226.0233154296875\n",
      "New best validation epoch 2600 loss=40.29677963256836\n",
      "epoch 2800 loss=1233.970458984375\n",
      "epoch 3000 loss=1232.986328125\n",
      "epoch 3200 loss=1213.130126953125\n",
      "epoch 3400 loss=1227.11865234375\n",
      "epoch 3600 loss=1184.7230224609375\n",
      "epoch 3800 loss=1214.128173828125\n",
      "epoch 4000 loss=1213.274169921875\n",
      "epoch 4200 loss=1225.337890625\n",
      "epoch 4400 loss=1186.519287109375\n",
      "epoch 4600 loss=1214.255126953125\n",
      "epoch 4800 loss=1212.2901611328125\n",
      "epoch 4999 loss=1399.293212890625\n",
      "Finished training\n",
      "FINISHED 9 6 38.428794860839844\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064,  1529, 12699, 34380, 14812, 28906,\n",
      "        20897,  1454,  9698,  8963,  3794, 14524, 13464, 21467, 26598, 31935,\n",
      "         1247, 15662, 24599, 11836, 11614, 23428, 31324, 34492,  3614, 33416])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096, 22538,  9133, 32298,   970, 25601,\n",
      "          573,  2992, 12167, 24480, 24752, 12765, 12689,   337, 19749, 25598,\n",
      "        20739,  2821, 21702, 25284, 20867,  8450, 19849, 29082,  6597,  1961])\n",
      "epoch 0 loss=1461.376953125\n",
      "New best validation epoch 0 loss=44.95458984375\n",
      "epoch 200 loss=1332.8953857421875\n",
      "New best validation epoch 200 loss=42.055362701416016\n",
      "epoch 400 loss=1290.4375\n",
      "New best validation epoch 400 loss=41.14856719970703\n",
      "epoch 600 loss=1273.456787109375\n",
      "New best validation epoch 600 loss=40.729957580566406\n",
      "epoch 800 loss=1245.853515625\n",
      "New best validation epoch 800 loss=40.45030975341797\n",
      "epoch 1000 loss=1210.706298828125\n",
      "New best validation epoch 1000 loss=40.27704620361328\n",
      "epoch 1200 loss=1204.816650390625\n",
      "New best validation epoch 1200 loss=40.14967346191406\n",
      "epoch 1400 loss=1220.166748046875\n",
      "New best validation epoch 1400 loss=40.0391960144043\n",
      "epoch 1600 loss=1212.255615234375\n",
      "New best validation epoch 1600 loss=40.012142181396484\n",
      "epoch 1800 loss=1223.337890625\n",
      "New best validation epoch 1800 loss=39.97745895385742\n",
      "epoch 2000 loss=1215.01220703125\n",
      "New best validation epoch 2000 loss=39.9178466796875\n",
      "epoch 2200 loss=1151.2530517578125\n",
      "New best validation epoch 2200 loss=39.85879135131836\n",
      "epoch 2400 loss=1194.099609375\n",
      "epoch 2600 loss=1152.984619140625\n",
      "New best validation epoch 2600 loss=39.83415603637695\n",
      "epoch 2800 loss=1217.618408203125\n",
      "epoch 3000 loss=1207.6380615234375\n",
      "epoch 3200 loss=1192.70556640625\n",
      "New best validation epoch 3200 loss=39.81728744506836\n",
      "epoch 3400 loss=1255.996826171875\n",
      "epoch 3600 loss=1186.2537841796875\n",
      "New best validation epoch 3600 loss=39.79472732543945\n",
      "epoch 3800 loss=1202.365966796875\n",
      "epoch 4000 loss=1172.7122802734375\n",
      "epoch 4200 loss=1244.8665771484375\n",
      "epoch 4400 loss=1319.250244140625\n",
      "epoch 4600 loss=1199.9842529296875\n",
      "New best validation epoch 4600 loss=39.787479400634766\n",
      "epoch 4800 loss=1233.880859375\n",
      "epoch 4999 loss=1230.237548828125\n",
      "Finished training\n",
      "FINISHED 9 7 37.852989196777344\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064,  1529, 12699, 34380, 14812, 28906,\n",
      "        20897,  1454,  9698,  8963,  3794, 14524, 13464, 21467, 26598, 31935,\n",
      "         1247, 15662, 24599, 11836, 11614, 23428, 31324, 34492,  3614, 33416,\n",
      "         4648,  9478, 30395, 32855, 28222])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096, 22538,  9133, 32298,   970, 25601,\n",
      "          573,  2992, 12167, 24480, 24752, 12765, 12689,   337, 19749, 25598,\n",
      "        20739,  2821, 21702, 25284, 20867,  8450, 19849, 29082,  6597,  1961,\n",
      "        25411,  6238, 18480, 20203, 12790])\n",
      "epoch 0 loss=1462.9320068359375\n",
      "New best validation epoch 0 loss=44.954559326171875\n",
      "epoch 200 loss=1333.158203125\n",
      "New best validation epoch 200 loss=41.814510345458984\n",
      "epoch 400 loss=1269.9503173828125\n",
      "New best validation epoch 400 loss=40.95402908325195\n",
      "epoch 600 loss=1258.222412109375\n",
      "New best validation epoch 600 loss=40.47579574584961\n",
      "epoch 800 loss=1235.3131103515625\n",
      "New best validation epoch 800 loss=40.14011001586914\n",
      "epoch 1000 loss=1199.919189453125\n",
      "New best validation epoch 1000 loss=39.940025329589844\n",
      "epoch 1200 loss=1198.75048828125\n",
      "New best validation epoch 1200 loss=39.8259162902832\n",
      "epoch 1400 loss=1221.2982177734375\n",
      "New best validation epoch 1400 loss=39.76133346557617\n",
      "epoch 1600 loss=1192.3663330078125\n",
      "New best validation epoch 1600 loss=39.632877349853516\n",
      "epoch 1800 loss=1178.766357421875\n",
      "New best validation epoch 1800 loss=39.56644058227539\n",
      "epoch 2000 loss=1165.5692138671875\n",
      "epoch 2200 loss=1174.544921875\n",
      "New best validation epoch 2200 loss=39.56024932861328\n",
      "epoch 2400 loss=1207.7481689453125\n",
      "epoch 2600 loss=1176.394287109375\n",
      "New best validation epoch 2600 loss=39.511260986328125\n",
      "epoch 2800 loss=1289.25390625\n",
      "epoch 3000 loss=1229.98388671875\n",
      "New best validation epoch 3000 loss=39.46501922607422\n",
      "epoch 3200 loss=1162.29150390625\n",
      "epoch 3400 loss=1286.23291015625\n",
      "epoch 3600 loss=1186.0517578125\n",
      "epoch 3800 loss=1166.1365966796875\n",
      "epoch 4000 loss=1196.0067138671875\n",
      "New best validation epoch 4000 loss=39.461334228515625\n",
      "epoch 4200 loss=1171.881103515625\n",
      "epoch 4400 loss=1237.5758056640625\n",
      "epoch 4600 loss=1202.70947265625\n",
      "epoch 4800 loss=1178.9580078125\n",
      "New best validation epoch 4800 loss=39.41750717163086\n",
      "epoch 4999 loss=1218.6939697265625\n",
      "Finished training\n",
      "FINISHED 9 8 37.5861930847168\n",
      "tensor([31345, 27226,  6901,  8783, 17682, 31858, 11551,  4455, 30339, 26159,\n",
      "        12610,  6855, 16857, 29492, 20064,  1529, 12699, 34380, 14812, 28906,\n",
      "        20897,  1454,  9698,  8963,  3794, 14524, 13464, 21467, 26598, 31935,\n",
      "         1247, 15662, 24599, 11836, 11614, 23428, 31324, 34492,  3614, 33416,\n",
      "         4648,  9478, 30395, 32855, 28222, 29051, 18430, 17898, 33581, 34011])\n",
      "tensor([10693, 24508, 34143, 30005, 17636,  7671,  1862, 15750, 28181, 32334,\n",
      "         6142, 16849,  8901,  6530, 21096, 22538,  9133, 32298,   970, 25601,\n",
      "          573,  2992, 12167, 24480, 24752, 12765, 12689,   337, 19749, 25598,\n",
      "        20739,  2821, 21702, 25284, 20867,  8450, 19849, 29082,  6597,  1961,\n",
      "        25411,  6238, 18480, 20203, 12790, 19873, 34367, 14836,   951, 14854])\n",
      "epoch 0 loss=1465.3929443359375\n",
      "New best validation epoch 0 loss=44.954551696777344\n",
      "epoch 200 loss=1348.5145263671875\n",
      "New best validation epoch 200 loss=41.700130462646484\n",
      "epoch 400 loss=1286.080322265625\n",
      "New best validation epoch 400 loss=40.830833435058594\n",
      "epoch 600 loss=1214.7598876953125\n",
      "New best validation epoch 600 loss=40.35441207885742\n",
      "epoch 800 loss=1207.8447265625\n",
      "New best validation epoch 800 loss=40.041812896728516\n",
      "epoch 1000 loss=1147.0703125\n",
      "New best validation epoch 1000 loss=39.77366256713867\n",
      "epoch 1200 loss=1182.88134765625\n",
      "New best validation epoch 1200 loss=39.71977996826172\n",
      "epoch 1400 loss=1196.0079345703125\n",
      "New best validation epoch 1400 loss=39.55219268798828\n",
      "epoch 1600 loss=1204.8408203125\n",
      "New best validation epoch 1600 loss=39.528804779052734\n",
      "epoch 1800 loss=1194.535888671875\n",
      "New best validation epoch 1800 loss=39.5272216796875\n",
      "epoch 2000 loss=1185.6546630859375\n",
      "New best validation epoch 2000 loss=39.38029479980469\n",
      "epoch 2200 loss=1184.52587890625\n",
      "New best validation epoch 2200 loss=39.3761100769043\n",
      "epoch 2400 loss=1159.5194091796875\n",
      "epoch 2600 loss=1195.50439453125\n",
      "epoch 2800 loss=1138.0657958984375\n",
      "New best validation epoch 2800 loss=39.33638381958008\n",
      "epoch 3000 loss=1215.846435546875\n",
      "epoch 3200 loss=1171.10400390625\n",
      "epoch 3400 loss=1174.0025634765625\n",
      "epoch 3600 loss=1136.5067138671875\n",
      "epoch 3800 loss=1175.907958984375\n",
      "epoch 4000 loss=1208.92724609375\n",
      "epoch 4200 loss=1184.9466552734375\n",
      "epoch 4400 loss=1156.09423828125\n",
      "epoch 4600 loss=1164.1204833984375\n",
      "epoch 4800 loss=1203.4525146484375\n",
      "epoch 4999 loss=1189.378173828125\n",
      "Finished training\n",
      "FINISHED 9 9 37.73685073852539\n",
      "ALL DONE\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for grp in range(10):\n",
    "    trainIdcs = groups[grp][0][0:496]\n",
    "    validIdcs = groups[grp][0]\n",
    "    testIdcs = groups[grp][1]\n",
    "    \n",
    "    for n in range(10):\n",
    "        if n == 0:\n",
    "            varArr = age_t[trainIdcs]\n",
    "            varArr = [varArr, varArr]\n",
    "            regs = [[], []]\n",
    "        else:\n",
    "            varArr = [ynback, yemoid]\n",
    "\n",
    "        for i,var in enumerate(varArr):\n",
    "#             idcs = torch.argsort(var)\n",
    "#             mat = torch.cdist(var[idcs].unsqueeze(1), var[idcs].unsqueeze(1))\n",
    "#             mat = torch.mean(mat) - mat\n",
    "            \n",
    "#             step = 200\n",
    "#             Y = [nback_p_t[trainIdcs][idcs], emoid_p_t[trainIdcs][idcs]][i]\n",
    "\n",
    "#             parts = []\n",
    "#             for j in range(0,40000,step):\n",
    "#                 if j >= Y.shape[1]:\n",
    "#                     break\n",
    "#                 part = Y[:,j:j+step]\n",
    "#                 corrSim = torch.einsum('ab,db->adb', part, part)\n",
    "#                 corr2 = torch.einsum('adb,ad->b', corrSim, mat)\n",
    "#                 parts.append(corr2.detach().cpu().numpy())\n",
    "\n",
    "#             parts = np.concatenate(parts)\n",
    "#             idcs = np.argsort(parts)\n",
    "            \n",
    "#             regs[i] += [idx for idx in idcs[-5:]]\n",
    "#             topRegions[grp,n,i,:,0] = idcs[-5:]\n",
    "#             topRegions[grp,n,i,:,1] = parts[idcs[-5:]]\n",
    "            r = None\n",
    "            count = 0\n",
    "            while r is None or r in regs[i]:\n",
    "                if count == 5:\n",
    "                    break\n",
    "                r = random.randint(0,arith(263)-1)\n",
    "                if r not in regs[i]:\n",
    "                    count += 1\n",
    "                    regs[i] += [r]\n",
    "                    \n",
    "            topRegions[grp,n,i,4,0] = r\n",
    "            \n",
    "        rnback = torch.tensor(regs[0], dtype=int)\n",
    "        remoid = torch.tensor(regs[1], dtype=int)\n",
    "\n",
    "        X0 = nback_p_t[:,rnback]\n",
    "        X1 = emoid_p_t[:,remoid]\n",
    "        Xreg = torch.stack([X0,X1], dim=1)\n",
    "\n",
    "        print(rnback)\n",
    "        print(remoid)\n",
    "\n",
    "        nEpochs = 5000\n",
    "        pPeriod = 200\n",
    "        thresh = 50\n",
    "\n",
    "        sim = LatSim(2, Xreg, 0.5, 0.1) # 0.2 wrat, 0.1 other\n",
    "        optim = torch.optim.Adam(sim.parameters(), lr=1e-4, weight_decay=1e-4) \n",
    "\n",
    "        Xt = Xreg[trainIdcs]\n",
    "        Xv = Xreg[validIdcs]\n",
    "\n",
    "        trainLoss = []\n",
    "        validLoss = []\n",
    "\n",
    "        vIdcs1 = np.arange(496,len(validIdcs))\n",
    "        vIdcs2 = validIdcs[496:]\n",
    "        vIdcs3 = np.concatenate([testIdcs, vIdcs2])\n",
    "\n",
    "        var = age_t\n",
    "\n",
    "        for epoch in range(nEpochs):\n",
    "            optim.zero_grad()\n",
    "            res, _ = sim(Xt, var[trainIdcs])\n",
    "            avg = torch.mean(torch.stack(res), dim=0)\n",
    "            loss = 0\n",
    "            for r in res + [avg]:\n",
    "                loss += mseLoss(r, var[trainIdcs])\n",
    "            loss = torch.stack([loss/(len(res)+1)])\n",
    "            torch.sum(loss).backward()\n",
    "            optim.step()\n",
    "            if epoch % pPeriod == 0 or epoch == nEpochs-1 or torch.all(loss[0:3] < thresh):\n",
    "                print(f'epoch {epoch} loss={(float(loss))}')\n",
    "                lossV = validate(sim, Xv, var[validIdcs], vIdcs1)\n",
    "                if len(validLoss) == 0 or lossV < min(validLoss):\n",
    "                    print(f'New best validation epoch {epoch} loss={lossV}')\n",
    "                    topRMSE[grp,n,1] = lossV\n",
    "                    torch.save(sim.state_dict(), '../../Work/LatentSim/sim.pyt')\n",
    "                validLoss.append(lossV)\n",
    "                if torch.all(loss[0:3] < thresh):\n",
    "                    print('Early stopping')\n",
    "                    break\n",
    "        \n",
    "        topRMSE[grp,n,0] = torch.sum(loss).detach().cpu().numpy()\n",
    "        print('Finished training')\n",
    "\n",
    "        sim.load_state_dict(torch.load('../../Work/LatentSim/sim.pyt'))\n",
    "        loss = validate(sim, Xreg, var, testIdcs)\n",
    "        topRMSE[grp,n,2] = loss\n",
    "        print(f'FINISHED {grp} {n} {loss}')\n",
    "        \n",
    "        ynback = var[trainIdcs]-res[0]\n",
    "        yemoid = var[trainIdcs]-res[1]\n",
    "        yavg = var[trainIdcs]-avg\n",
    "        \n",
    "print('ALL DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d4e1067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/.conda/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = (np.sum(topRMSE[:,:,0], axis=0)/10)**0.5/12\n",
    "bestVal = np.sum(topRMSE[:,:,1], axis=0)/10/12\n",
    "testNoVal = np.sum(topRMSE[:,:,2], axis=0)/10/12\n",
    "\n",
    "idcs = 5*np.arange(1,11)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "ax.plot(idcs, train, label='Training', marker='.', markersize=10)\n",
    "ax.plot(idcs, bestVal, label='Validation', marker='.', markersize=10)\n",
    "ax.plot(idcs, testNoVal, label='Test', marker='.', markersize=10)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('Age Prediction Random Feature Selection')\n",
    "ax.set_xlabel('Number of Features')\n",
    "ax.set_ylabel('RMSE (Age)')\n",
    "\n",
    "fig.show()\n",
    "fig.savefig('../../Work/LatentSim/RandomValidation50FeatDP5DP2.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96f91db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "with open('../../Work/LatentSim/Greed/RandomValidation50FeatDP5DP2.pkl', 'wb') as f:\n",
    "    pickle.dump([topRegions, topRMSE], f)\n",
    "    \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34c98496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "allReg = topRegions[:,0:3,:,4,0].flatten()\n",
    "\n",
    "print(len(allReg))\n",
    "print(len(np.unique(allReg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4db4d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "with open('../../Work/LatentSim/Greed/WratValidationDP2.pkl', 'rb') as f:\n",
    "    topRegions, topRMSE = pickle.load(f)\n",
    "    \n",
    "print(topRMSE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cddea9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
