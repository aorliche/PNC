{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb5a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../PNC_Good/MegaMeta3.pkl', 'rb') as f: \n",
    "    meta = pickle.load(f)\n",
    "    \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dae02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620\n",
      "620\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "with open('../../Work/LatentSim/Splits.pkl', 'rb') as f:\n",
    "    keys, groups = pickle.load(f)\n",
    "    \n",
    "print(len(keys))\n",
    "print(len(groups[0][0])+len(groups[0][1]))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93da8c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 264, 231)\n",
      "(620, 264, 210)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "nback = np.stack([meta[key]['nback'] for key in keys])\n",
    "emoid = np.stack([meta[key]['emoid'] for key in keys])\n",
    "\n",
    "print(nback.shape)\n",
    "print(emoid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e8625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 264, 264)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "def getFC(timeSeries, kind='correlation', transpose=True):\n",
    "    connMeasure = ConnectivityMeasure(kind=kind)\n",
    "    if transpose:\n",
    "        timeSeries = np.transpose(timeSeries, axes=(0,2,1))\n",
    "    return connMeasure.fit_transform(timeSeries)\n",
    "\n",
    "nback_p = getFC(nback)\n",
    "emoid_p = getFC(emoid)\n",
    "\n",
    "print(nback_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6334fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([620, 34716])\n",
      "torch.Size([620, 34716])\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def convertTorch(p):\n",
    "    t = torch.from_numpy(p).float()\n",
    "    u = []\n",
    "    for i in range(t.shape[0]):\n",
    "        u.append(t[i][torch.triu_indices(264,264,offset=1).unbind()])\n",
    "    return torch.stack(u).cuda()\n",
    "\n",
    "nback_p_t = convertTorch(nback_p)\n",
    "emoid_p_t = convertTorch(emoid_p)\n",
    "\n",
    "print(nback_p_t.shape)\n",
    "print(emoid_p_t.shape)\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1920e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm complete\n"
     ]
    }
   ],
   "source": [
    "mu_nback = torch.mean(nback_p_t, dim=0, keepdim=True)\n",
    "mu_emoid = torch.mean(emoid_p_t, dim=0, keepdim=True)\n",
    "std_nback = torch.std(nback_p_t, dim=0, keepdim=True)\n",
    "std_emoid = torch.std(emoid_p_t, dim=0, keepdim=True)\n",
    "\n",
    "nback_p_t = (nback_p_t - mu_nback)/std_nback\n",
    "emoid_p_t = (emoid_p_t - mu_emoid)/std_emoid\n",
    "\n",
    "print('Norm complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cdef694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([-2.2998, -3.0133], device='cuda:0'),\n",
      "indices=tensor([603, 350], device='cuda:0'))\n",
      "torch.return_types.min(\n",
      "values=tensor([-2.7284, -3.0616], device='cuda:0'),\n",
      "indices=tensor([351,  33], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(nback_p_t[:,420:422],dim=0))\n",
    "print(torch.min(emoid_p_t[:,420:422],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca3a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620,)\n",
      "(620, 2)\n",
      "(620,)\n"
     ]
    }
   ],
   "source": [
    "age = np.stack([meta[key]['AgeInMonths'] for key in keys])\n",
    "gen = np.stack([np.array([meta[key]['Gender'] == 'M', meta[key]['Gender'] == 'F']) for key in keys]).astype(int)\n",
    "wrt = np.stack([meta[key]['wratStd'] for key in keys])\n",
    "\n",
    "print(age.shape)\n",
    "print(gen.shape)\n",
    "print(wrt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de275285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "age_t = torch.from_numpy(age).float().cuda()\n",
    "gen_t = torch.from_numpy(gen).float().cuda()\n",
    "wrt_t = torch.from_numpy(wrt).float().cuda()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c3e8380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss=1509.39990234375 pairLoss=149.38162231445312\n",
      "New best validation epoch 0 loss=61.67731475830078\n",
      "epoch 20 loss=2595.137939453125 pairLoss=1974.8973388671875\n",
      "New best validation epoch 20 loss=43.525787353515625\n",
      "epoch 40 loss=1277.4820556640625 pairLoss=192.2421112060547\n",
      "New best validation epoch 40 loss=42.831233978271484\n",
      "epoch 60 loss=684.9138793945312 pairLoss=173.40145874023438\n",
      "New best validation epoch 60 loss=31.14763832092285\n",
      "epoch 80 loss=400.3998718261719 pairLoss=165.91326904296875\n",
      "New best validation epoch 80 loss=29.267398834228516\n",
      "epoch 100 loss=241.87049865722656 pairLoss=163.2947540283203\n",
      "New best validation epoch 100 loss=28.22511863708496\n",
      "epoch 120 loss=146.8122100830078 pairLoss=161.85472106933594\n",
      "New best validation epoch 120 loss=27.827346801757812\n",
      "epoch 140 loss=108.25006103515625 pairLoss=161.46888732910156\n",
      "New best validation epoch 140 loss=27.363027572631836\n",
      "epoch 160 loss=81.6581039428711 pairLoss=161.38095092773438\n",
      "New best validation epoch 160 loss=27.170276641845703\n",
      "epoch 180 loss=64.53184509277344 pairLoss=161.91909790039062\n",
      "New best validation epoch 180 loss=26.951629638671875\n",
      "epoch 200 loss=52.74809265136719 pairLoss=161.83181762695312\n",
      "epoch 220 loss=44.783512115478516 pairLoss=161.1123046875\n",
      "New best validation epoch 220 loss=26.860254287719727\n",
      "epoch 240 loss=44.0846061706543 pairLoss=162.17886352539062\n",
      "epoch 260 loss=36.95054244995117 pairLoss=161.5736541748047\n",
      "epoch 280 loss=37.08164596557617 pairLoss=160.868896484375\n",
      "New best validation epoch 280 loss=26.759061813354492\n",
      "epoch 300 loss=32.99617004394531 pairLoss=161.65106201171875\n",
      "New best validation epoch 300 loss=26.73265838623047\n",
      "epoch 320 loss=39.88330841064453 pairLoss=161.2445831298828\n",
      "New best validation epoch 320 loss=26.45121955871582\n",
      "epoch 340 loss=36.25123596191406 pairLoss=161.76364135742188\n",
      "epoch 360 loss=32.961856842041016 pairLoss=161.91366577148438\n",
      "epoch 380 loss=31.056812286376953 pairLoss=161.1435089111328\n",
      "epoch 400 loss=35.221099853515625 pairLoss=161.1976776123047\n",
      "epoch 420 loss=31.419971466064453 pairLoss=161.7506103515625\n",
      "epoch 440 loss=30.943370819091797 pairLoss=161.78338623046875\n",
      "New best validation epoch 440 loss=26.399879455566406\n",
      "epoch 460 loss=31.634614944458008 pairLoss=160.64956665039062\n",
      "New best validation epoch 460 loss=26.307462692260742\n",
      "epoch 480 loss=31.734527587890625 pairLoss=160.95596313476562\n",
      "epoch 500 loss=32.13226318359375 pairLoss=160.7555389404297\n",
      "epoch 520 loss=29.146955490112305 pairLoss=160.9825897216797\n",
      "New best validation epoch 520 loss=26.27849578857422\n",
      "epoch 540 loss=26.53209114074707 pairLoss=161.21873474121094\n",
      "New best validation epoch 540 loss=26.094207763671875\n",
      "epoch 560 loss=29.66594696044922 pairLoss=161.12335205078125\n",
      "epoch 580 loss=26.197826385498047 pairLoss=161.11837768554688\n",
      "epoch 600 loss=33.364437103271484 pairLoss=159.8782501220703\n",
      "New best validation epoch 600 loss=25.839710235595703\n",
      "epoch 620 loss=28.060993194580078 pairLoss=159.89576721191406\n",
      "New best validation epoch 620 loss=25.474117279052734\n",
      "epoch 640 loss=26.061643600463867 pairLoss=162.33004760742188\n",
      "epoch 660 loss=28.409624099731445 pairLoss=160.23497009277344\n",
      "epoch 680 loss=25.79709815979004 pairLoss=161.707763671875\n",
      "epoch 700 loss=26.743940353393555 pairLoss=161.63682556152344\n",
      "epoch 720 loss=24.511764526367188 pairLoss=160.3715362548828\n",
      "epoch 740 loss=24.34712791442871 pairLoss=161.1559295654297\n",
      "epoch 760 loss=25.979248046875 pairLoss=160.7181396484375\n",
      "epoch 780 loss=21.78777313232422 pairLoss=160.27093505859375\n",
      "epoch 800 loss=19.750446319580078 pairLoss=161.69920349121094\n",
      "epoch 820 loss=21.609426498413086 pairLoss=160.1770782470703\n",
      "epoch 840 loss=22.57721519470215 pairLoss=159.96875\n",
      "epoch 860 loss=20.397235870361328 pairLoss=159.3479766845703\n",
      "epoch 880 loss=20.719383239746094 pairLoss=160.14376831054688\n",
      "epoch 900 loss=22.343177795410156 pairLoss=160.1968231201172\n",
      "epoch 920 loss=22.464693069458008 pairLoss=159.48477172851562\n",
      "epoch 940 loss=22.47857093811035 pairLoss=160.67564392089844\n",
      "epoch 960 loss=18.95337677001953 pairLoss=159.57064819335938\n",
      "epoch 980 loss=19.029075622558594 pairLoss=159.60740661621094\n",
      "epoch 999 loss=18.251920700073242 pairLoss=159.4718017578125\n",
      "Finished training\n",
      "FINISHED 0 26.237201690673828\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "ceLoss = torch.nn.CrossEntropyLoss()\n",
    "mseLoss = torch.nn.MSELoss()\n",
    "\n",
    "rmse = []\n",
    "\n",
    "def arith(n):\n",
    "    return int(n*(n+1)/2)\n",
    "\n",
    "def mask(e):\n",
    "    return e - torch.diag(torch.diag(e.detach()))\n",
    "\n",
    "def makeEdgeTarget(y, rng):\n",
    "    e = torch.cdist(y.unsqueeze(1), y.unsqueeze(1))\n",
    "    e[e == 0] = 1\n",
    "    e = 1/e\n",
    "    return e\n",
    "\n",
    "class LatSim(nn.Module):\n",
    "    def __init__(self, nTgts, inp, dp=0.5, edp=0.1, wInit=1e-4, dim=2, temp=1):\n",
    "        super(LatSim, self).__init__()\n",
    "        self.active = nn.Parameter(wInit*torch.randn(nTgts,inp.shape[-1],dim).float().cuda())\n",
    "        self.dp = nn.Dropout(p=dp)\n",
    "        self.edp = nn.Dropout(p=edp)\n",
    "        self.temp = temp\n",
    "    \n",
    "    def getLatentsAndEdges(self, x, i):\n",
    "        e = 1e-10\n",
    "        y = torch.einsum('ac,ce->ae', x, self.active[i])\n",
    "        e = e+y@y.T\n",
    "        return y, y, e\n",
    "        \n",
    "    def forward(self, x, y, testIdcs=None):\n",
    "        x = self.dp(x)\n",
    "        res = []\n",
    "        es = []\n",
    "        for i in range(self.active.shape[0]):\n",
    "            _, _, e = self.getLatentsAndEdges(x[:,i,:], i)\n",
    "            if testIdcs is not None:\n",
    "                e[:,testIdcs] = 0\n",
    "            es.append(e.clone())\n",
    "            e = self.edp(e)\n",
    "            e = mask(e)\n",
    "            e[e == 0] = float('-inf')\n",
    "            e = F.softmax(e/self.temp, dim=1)\n",
    "            res.append(e@y)\n",
    "        return res, es\n",
    "\n",
    "def validate(model, X, y, testIdcs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        res, _ = model(X, y, testIdcs)\n",
    "        avg = torch.mean(torch.stack(res), dim=0)\n",
    "        if res[0].dim() == 1:\n",
    "            loss = mseLoss(avg[testIdcs], y[testIdcs]).cpu().numpy()**0.5\n",
    "        else:\n",
    "            corr = (torch.argmax(avg, dim=1) == torch.argmax(y, dim=1))[testIdcs]\n",
    "            loss = torch.sum(corr)/len(testIdcs)\n",
    "    model.train()\n",
    "    return loss, avg.detach().cpu().numpy()\n",
    "\n",
    "for grp in range(1):\n",
    "    trainIdcs = groups[grp][0][0:496]\n",
    "    validIdcs = groups[grp][0]\n",
    "    testIdcs = groups[grp][1]\n",
    "\n",
    "    X0 = nback_p_t\n",
    "    X1 = emoid_p_t\n",
    "    Xreg = torch.stack([X0], dim=1)\n",
    "\n",
    "    nEpochs = 1000\n",
    "    pPeriod = 20\n",
    "    thresh = 20\n",
    "\n",
    "    sim = LatSim(1, Xreg, 0.5, 0.1, dim=20) # 0.2 wrat, 0.1 other\n",
    "    optim = torch.optim.Adam(sim.parameters(), lr=1e-4, weight_decay=1e-4) \n",
    "\n",
    "    Xt = Xreg[trainIdcs]\n",
    "    Xv = Xreg[validIdcs]\n",
    "\n",
    "    trainLoss = []\n",
    "    validLoss = []\n",
    "\n",
    "    vIdcs1 = np.arange(496,len(validIdcs))\n",
    "    vIdcs2 = validIdcs[496:]\n",
    "    vIdcs3 = np.concatenate([testIdcs, vIdcs2])\n",
    "\n",
    "    var = age_t\n",
    "    etgt = makeEdgeTarget(var[trainIdcs], mult=6)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        res, es = sim(Xt, var[trainIdcs])\n",
    "        avg = torch.mean(torch.stack(res), dim=0)\n",
    "        loss = 0\n",
    "        pairLoss = 0\n",
    "        for r,e in zip(res + [avg], es + [es[0]]):\n",
    "            loss += mseLoss(r, var[trainIdcs])\n",
    "            pairLoss += 10*mseLoss(e, etgt)\n",
    "        loss = torch.stack([loss, pairLoss])/(len(res)+1)\n",
    "        torch.sum(loss).backward()\n",
    "        optim.step()\n",
    "        if epoch % pPeriod == 0 or epoch == nEpochs-1 or torch.all(loss[0:3] < thresh):\n",
    "            print(f'epoch {epoch} loss={(float(loss[0]))} pairLoss={float(pairLoss)}')\n",
    "            lossV, _ = validate(sim, Xv, var[validIdcs], vIdcs1)\n",
    "            if len(validLoss) == 0 or lossV < min(validLoss):\n",
    "                print(f'New best validation epoch {epoch} loss={lossV}')\n",
    "                torch.save(sim.state_dict(), '../../Work/LatentSim/sim.pyt')\n",
    "            validLoss.append(lossV)\n",
    "            if torch.all(loss[0:3] < thresh):\n",
    "                print('Early stopping')\n",
    "                break\n",
    "\n",
    "    print('Finished training')\n",
    "\n",
    "    sim.load_state_dict(torch.load('../../Work/LatentSim/sim.pyt'))\n",
    "    loss, avg = validate(sim, Xreg, var, testIdcs)\n",
    "    rmse.append(loss)\n",
    "    \n",
    "#     yhat[testIdcs] = avg[testIdcs]\n",
    "    print(f'FINISHED {grp} {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45b1d1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5740, -1.2658, -1.4777,  ..., -0.7391, -0.5673, -2.1394],\n",
      "        [-1.2658,  1.3484, -0.4048,  ..., -0.3890,  0.0381, -0.0918],\n",
      "        [-1.4777, -0.4048,  2.7334,  ...,  1.8170,  0.8971,  3.1629],\n",
      "        ...,\n",
      "        [-0.7391, -0.3890,  1.8170,  ...,  1.5781,  0.9526,  2.1489],\n",
      "        [-0.5673,  0.0381,  0.8971,  ...,  0.9526,  0.7275,  1.1542],\n",
      "        [-2.1394, -0.0918,  3.1629,  ...,  2.1489,  1.1542,  3.9868]],\n",
      "       device='cuda:0', grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911afe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
