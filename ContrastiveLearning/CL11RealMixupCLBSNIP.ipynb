{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fcadd1c-e9ff-40c7-8bfc-96c43b52a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(405,), (405,), (405,), (405,), (405, 34716), (405, 34716), (405, 34716)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "bsnipdir = '/home/anton/Documents/Tulane/Research/ImageNomer/data/anton/cohorts/BSNIP/'\n",
    "bsnipdemo = pickle.load(open(f'{bsnipdir}/demographics.pkl', 'rb'))\n",
    "bsniptopdir = '/home/anton/Documents/Tulane/Research/Work/ContrastiveLearning/BSNIP/'\n",
    "\n",
    "fc = []\n",
    "aps20 = []\n",
    "aps15 = []\n",
    "aps10 = []\n",
    "aps5 = []\n",
    "aps3 = []\n",
    "aps1 = []\n",
    "age = []\n",
    "sex = []\n",
    "race = []\n",
    "sz = []\n",
    "\n",
    "for sub in bsnipdemo['Age_cal']:\n",
    "    try:\n",
    "        a = bsnipdemo['Age_cal'][sub]\n",
    "        s = bsnipdemo['sex'][sub]\n",
    "        r = bsnipdemo['Race'][sub]\n",
    "        d = bsnipdemo['DXGROUP_1'][sub]\n",
    "        if d not in ['NC', 'SZP']:\n",
    "            continue\n",
    "        if r not in ['AA', 'CA']:\n",
    "            continue\n",
    "        s = s == 's1.0'\n",
    "        r = r == 'AA'\n",
    "        d = d == 'SZP'\n",
    "        age.append(a)\n",
    "        sex.append(s)\n",
    "        race.append(r)\n",
    "        sz.append(d)\n",
    "        fc.append(np.load(f'{bsnipdir}/fc/{sub}_task-unk_fc.npy'))\n",
    "        aps20.append(np.load(f'{bsniptopdir}/Top20/{sub}_task-unktop20_fc.npy'))\n",
    "        aps3.append(np.load(f'{bsniptopdir}/Top3/{sub}_task-unktop3_fc.npy'))\n",
    "        aps1.append(np.load(f'{bsniptopdir}/Top1/{sub}_task-unktop1_fc.npy'))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "age = np.stack(age)\n",
    "sex = np.stack(sex).astype('int')\n",
    "race = np.stack(race).astype('int')\n",
    "sz = np.stack(sz).astype('int')\n",
    "fc = np.stack(fc)\n",
    "aps20 = np.stack(aps20)\n",
    "aps1 = np.stack(aps1)\n",
    "\n",
    "print([x.shape for x in [age, sex, race, sz, fc, aps20, aps1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6c4dd4d2-250c-4750-8e77-59728c22b3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.04\n",
      "20 1.04\n",
      "40 1.04\n",
      "60 1.04\n",
      "80 1.04\n",
      "100 1.04\n",
      "120 1.04\n",
      "140 1.04\n",
      "160 1.04\n",
      "180 1.04\n",
      "200 1.04\n",
      "220 1.04\n",
      "240 1.04\n",
      "260 1.04\n",
      "280 1.04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nepochs):\n\u001b[1;32m     82\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 83\u001b[0m     x, xsamp \u001b[38;5;241m=\u001b[39m \u001b[43mmake_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxaps20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxaps1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     yhat \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n",
      "Cell \u001b[0;32mIn[131], line 44\u001b[0m, in \u001b[0;36mmake_samples\u001b[0;34m(xaps20, xaps1)\u001b[0m\n\u001b[1;32m     42\u001b[0m     idcs[idcs \u001b[38;5;241m==\u001b[39m bad] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     43\u001b[0m     idcs[idcs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 44\u001b[0m     xsamp\u001b[38;5;241m.\u001b[39mappend(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxaps20\u001b[49m\u001b[43m[\u001b[49m\u001b[43midcs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     45\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(f(xaps20))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x,xsamp\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/torch/nn/modules/module.py:1494\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1495\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "\n",
    "def decim(v):\n",
    "    return '{:.2f}'.format(float(v))\n",
    "\n",
    "# Assume xb has already had first component removed\n",
    "def make_pos_samples(xb, aps1):\n",
    "    x = []\n",
    "    xpos = []\n",
    "    for n in range(5):\n",
    "        idcs = np.random.permutation(len(xb))\n",
    "        xpart = xb+aps1[idcs]\n",
    "        x.append(xb)\n",
    "        xpos.append(xpart)\n",
    "    x = torch.cat(x)\n",
    "    xpos = torch.cat(xpos)\n",
    "    return x, xpos\n",
    "\n",
    "# First component has not been removed\n",
    "def make_neg_samples(x):\n",
    "    xneg = []\n",
    "    for n in range(5):\n",
    "        idcs = np.random.permutation(len(x))\n",
    "        bad = np.arange(len(x))\n",
    "        idcs[idcs == bad] -= 1\n",
    "        idcs[idcs < 0] += 2\n",
    "        xpart = x[idcs]\n",
    "        xneg.append(xpart)\n",
    "    xneg = torch.cat(xneg)\n",
    "    return xneg\n",
    "\n",
    "def make_samples(xaps20, xaps1):\n",
    "    x = [f(xaps20)]\n",
    "    xpos = xaps20-xaps1\n",
    "    idcs = np.random.permutation(len(xaps1))\n",
    "    xsamp = [f(xpos+xaps1[idcs])]\n",
    "    for n in range(5):\n",
    "        idcs = np.random.permutation(len(xaps20))\n",
    "        bad = np.arange(len(xaps20))\n",
    "        idcs[idcs == bad] -= 1\n",
    "        idcs[idcs < 0] += 2\n",
    "        xsamp.append(f(xaps20[idcs]))\n",
    "        x.append(f(xaps20))\n",
    "    return x,xsamp\n",
    "    \n",
    "xaps20 = torch.from_numpy(aps20).float().cuda()\n",
    "xaps1 = torch.from_numpy(aps1).float().cuda()\n",
    "y = torch.zeros(6).float().cuda()\n",
    "y[0] = 1\n",
    "\n",
    "class F(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F, self).__init__()\n",
    "        self.fc1 = nn.Linear(34716,20).float().cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x).squeeze()\n",
    "\n",
    "class Same(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Same, self).__init__()\n",
    "        self.fc1 = nn.Linear(20*2,50).float().cuda()\n",
    "        self.fc2 = nn.Linear(50,2).float().cuda()\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], axis=1)\n",
    "        x = Func.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "f = F()\n",
    "same = Same()\n",
    "optim = torch.optim.Adam(list(f.parameters()) + list(same.parameters()), lr=1e-4, weight_decay=0)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "nepochs = 1000\n",
    "pperiod = 20\n",
    "\n",
    "for e in range(nepochs):\n",
    "    optim.zero_grad()\n",
    "    x, xsamp = make_samples(xaps20, xaps1)\n",
    "    yhat = []\n",
    "    for i in range(6):\n",
    "        yhat.append(torch.sum(x[i]*xsamp[i]))\n",
    "    yhat = torch.stack(yhat)\n",
    "    yhat = Func.softmax(yhat, dim=0)\n",
    "    loss = ce(yhat, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if e % pperiod == 0 or e == nepochs-1:\n",
    "        print(f'{e} {decim(loss)}')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aac12773-9f7c-45b2-80f8-0a52dc78f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.583522000308596 12.472301272811706\n",
      "10.250557171784562 12.36864530491759\n",
      "8.830976716847966 11.708404015264717\n",
      "10.703622099723177 12.612076430123894\n",
      "10.766776331953832 11.96929975247291\n",
      "10.639522709654642 11.100488749605114\n",
      "11.211795314966448 12.40845766699171\n",
      "11.118532887069366 11.939261005638839\n",
      "10.647001176635744 11.329432610951196\n",
      "11.08030136403556 12.420612099984107\n",
      "10.156131023177883 11.903603575498023\n",
      "10.918270747328005 12.535941317740809\n",
      "10.191922407513177 12.27606298038708\n",
      "10.533554709972426 13.216716816748162\n",
      "11.200853042776817 12.157178215661418\n",
      "10.513380404240316 11.240169543659828\n",
      "11.911739727165163 13.669928347108817\n",
      "10.25840283107512 12.16918283293998\n",
      "9.799373465674545 12.840693202488678\n",
      "10.61628461764953 12.718446376023431\n",
      "10.596626037477645\n"
     ]
    }
   ],
   "source": [
    "# Train using features\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    return np.mean((yhat-y)**2)**0.5\n",
    "\n",
    "def make_pos_samples(xb, aps1, yb):\n",
    "    x = []\n",
    "    xpos = []\n",
    "    y = []\n",
    "    for n in range(1):\n",
    "        idcs = np.random.permutation(len(aps1))\n",
    "        xpart = xb+aps1[idcs][:len(xb)]\n",
    "        x.append(xb)\n",
    "        xpos.append(xpart)\n",
    "        y.append(yb)\n",
    "    x = np.concatenate(x)\n",
    "    xpos = np.concatenate(xpos)\n",
    "    y = np.concatenate(y)\n",
    "    return x, xpos, y\n",
    "\n",
    "losses = []\n",
    "\n",
    "for _ in range(20):\n",
    "    x1tr, x1t, x20tr, x20t, ytr, yt = train_test_split(aps1, fc, age, train_size=0.8)\n",
    "\n",
    "    _, xtr, ytr = make_pos_samples(x20tr-x1tr, x1tr, ytr)\n",
    "    # _, xt, yt = make_pos_samples(x20t-x1t, x1tr, yt)\n",
    "    xt, yt = x20t, yt\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    #     x1tr = torch.from_numpy(x1tr).float().cuda()\n",
    "    #     x1t = torch.from_numpy(x1t).float().cuda()\n",
    "    #     x20tr = torch.from_numpy(x20tr).float().cuda()\n",
    "    #     x20t = torch.from_numpy(x20t).float().cuda()\n",
    "\n",
    "    #     aa, bb = make_pos_samples(x20tr-x1tr, x1tr)\n",
    "    #     bb = bb.detach().cpu().numpy()\n",
    "        \n",
    "    reg = Ridge(alpha=1).fit(xtr, ytr)\n",
    "    yhat = reg.predict(xt)\n",
    "    loss = rmse(yhat, yt)\n",
    "    null = rmse(np.mean(yt), yt)\n",
    "    print(loss, null)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # reg = LogisticRegression(C=1, max_iter=300).fit(xtr, ytr)\n",
    "    # yhat = reg.predict(xt)\n",
    "    # loss = np.mean(yhat == yt)\n",
    "    # null = np.mean(yt)\n",
    "    # if null < 0.5:\n",
    "    #     null = 1-null\n",
    "    # print(loss, null)\n",
    "    # losses.append(loss)\n",
    "\n",
    "print(np.mean(losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afaa75b1-f5c1-4ddf-b321-24e92b37d41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "ours2orig = [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
    "28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 254, 41, 42, 43, 44, 45,\n",
    "46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
    "65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85,\n",
    "86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103,\n",
    "104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
    "119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 136, 138, 132,\n",
    "133, 134, 135, 220, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
    "153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
    "168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 185, 186,\n",
    "187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
    "202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n",
    "217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
    "233, 137, 234, 235, 236, 237, 238, 239, 240, 241, 250, 251, 255, 256, 257,\n",
    "258, 259, 260, 261, 262, 263, 242, 243, 244, 245, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
    "9, 10, 11, 83, 84, 131, 139, 140, 141, 181, 182, 183, 184, 246, 247, 248,\n",
    "249, 252, 253]\n",
    "\n",
    "def vec2mat(v):\n",
    "    a,b = np.triu_indices(264,1)\n",
    "    m = np.zeros((264,264))\n",
    "    m[a,b] = v\n",
    "    return m+m.T\n",
    "\n",
    "def remap(fc, roimap=ours2orig):\n",
    "    fc = fc[roimap,:]\n",
    "    fc = fc[:,roimap]\n",
    "    return fc\n",
    "\n",
    "def numpy(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23160d7-a717-449e-a961-0921c0304094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
