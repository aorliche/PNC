{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87783615",
   "metadata": {},
   "source": [
    "# Calculate low-rank dynamic FC and use it to approximate static FC\n",
    "We can approximate static FC with \\~120 rank-\\~120 dictionary entries<br>\n",
    "We can also approximate dynamic FC with >300 rank-1 dictionary entries<br>\n",
    "Can the rank-1 entries sum together to approximate a static FC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cd3b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'wrat', 'missingage', 'missingsex', 'missingwrat', 'failedqc']\n",
      "['emoid', 'nback', 'rest']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Using newly preprocessed subjects\n",
    "\n",
    "import pickle\n",
    "\n",
    "metadictname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_agesexwrat.pkl'\n",
    "alltsname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_PowerTS_float2.pkl'\n",
    "\n",
    "with open(metadictname, 'rb') as f:\n",
    "    metadict = pickle.load(f)\n",
    "\n",
    "with open(alltsname, 'rb') as f:\n",
    "    allts = pickle.load(f)\n",
    "    \n",
    "print(list(metadict.keys()))\n",
    "print(list(allts.keys()))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d995126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n",
      "(847, 264, 124)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get subjects that have all tasks and paras specified\n",
    "Functions for creating independent and response variables\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_subs(allts, metadict, tasks, paras):\n",
    "    # Get subs for all paras\n",
    "    for i,para in enumerate(paras):\n",
    "        tmpset = set([int(sub[4:]) for sub in allts[para].keys()])\n",
    "        if i == 0:\n",
    "            paraset = tmpset\n",
    "        else:\n",
    "            paraset = paraset.intersection(tmpset)\n",
    "    # Get subs for all tasks\n",
    "    for i,task in enumerate(tasks):\n",
    "        tmpset = set([sub for sub in metadict[task].keys()])\n",
    "        if i == 0:\n",
    "            taskset = tmpset\n",
    "        else:\n",
    "            taskset = paraset.intersection(tmpset)\n",
    "    # Remove QC failures\n",
    "    allsubs = taskset.intersection(paraset)\n",
    "    for badsub in metadict['failedqc']:\n",
    "        try:\n",
    "            allsubs.remove(int(badsub[4:]))\n",
    "        except:\n",
    "            pass\n",
    "    return allsubs\n",
    "\n",
    "def get_X(allts, paras, subs):\n",
    "    X = []\n",
    "    for para in paras:\n",
    "        pX = [allts[para][f'sub-{sub}'] for sub in subs]\n",
    "        pX = np.stack(pX)\n",
    "        X.append(pX)\n",
    "    return X\n",
    "\n",
    "def get_y(metadict, tasks, subs):\n",
    "    y = []\n",
    "    for task in tasks:\n",
    "        if task == 'age' or task == 'wrat':\n",
    "            var = [metadict[task][sub] for sub in subs]\n",
    "            var = np.array(var)\n",
    "            y.append(var)\n",
    "        if task == 'sex':\n",
    "            maleness = [metadict[task][sub] == 'M' for sub in subs]\n",
    "            maleness = np.array(maleness)\n",
    "            sex = np.stack([maleness, 1-maleness], axis=1)\n",
    "            y.append(sex)\n",
    "    return y\n",
    "\n",
    "subs = get_subs(allts, metadict, ['age'], ['rest', 'nback', 'emoid'])\n",
    "print(len(subs))\n",
    "\n",
    "X = get_X(allts, ['rest', 'nback', 'emoid'], subs)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807e832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 264, 124)\n"
     ]
    }
   ],
   "source": [
    "# TS to condensed FC\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = [cutoff[0] / nyq, cutoff[1] / nyq]\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_bandpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "tr = 1.83\n",
    "\n",
    "def filter_design_ts(X):\n",
    "    Xs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        nX = butter_bandpass_filter(X[i], [0.01, 0.2], 1/tr)\n",
    "        Xs.append(nX)\n",
    "    return np.stack(Xs)\n",
    "\n",
    "def ts_to_flat_fc(X):\n",
    "    p = np.corrcoef(X)\n",
    "    a,b = np.triu_indices(p[0].shape[0], 1)\n",
    "    p = p[a,b]\n",
    "    return p\n",
    "\n",
    "ts = [np.stack([ts for ts in filter_design_ts(Xp)]) for Xp in X]\n",
    "ts = [tsmod/np.linalg.norm(tsmod, axis=-1, keepdims=True) for tsmod in ts]\n",
    "print(ts[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7893693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 recon: [0.011949059217210473, 1.296255454723844e-06] lr: [0.01]\n",
      "0 30 recon: [0.011827931935633564, 1.305218103184779e-06] lr: [0.01]\n",
      "0 60 recon: [0.012338877569601071, 1.310397918217625e-06] lr: [0.01]\n",
      "0 90 recon: [0.01201671417963237, 1.3160995516054654e-06] lr: [0.01]\n",
      "0 120 recon: [0.013905218289878982, 1.3256684555004354e-06] lr: [0.01]\n",
      "0 150 recon: [0.012890260571147387, 1.34038213368106e-06] lr: [0.01]\n",
      "0 180 recon: [0.011782472308924237, 1.3496743974229167e-06] lr: [0.01]\n",
      "0 210 recon: [0.012283084701174056, 1.3680592101576008e-06] lr: [0.01]\n",
      "0 240 recon: [0.012493818424467389, 1.3807224667126702e-06] lr: [0.01]\n",
      "0 270 recon: [0.012844406885266967, 1.4054761585890162e-06] lr: [0.01]\n",
      "0 300 recon: [0.011863007478762753, 1.4331407570075352e-06] lr: [0.01]\n",
      "0 330 recon: [0.012544688073430494, 1.4632368459082526e-06] lr: [0.01]\n",
      "0 360 recon: [0.012000584093608447, 1.5065754739418786e-06] lr: [0.01]\n",
      "0 390 recon: [0.014794181932698325, 1.5549148592322939e-06] lr: [0.01]\n",
      "1 0 recon: [0.01194705084780254, 1.6184774001382932e-06] lr: [0.01]\n",
      "1 30 recon: [0.011825283416431178, 1.7013246600066403e-06] lr: [0.01]\n",
      "1 60 recon: [0.01233591467445755, 1.7967740955130252e-06] lr: [0.01]\n",
      "1 90 recon: [0.012012928687580108, 1.9199833225077875e-06] lr: [0.01]\n",
      "1 120 recon: [0.013900897112242228, 2.073691615766592e-06] lr: [0.01]\n",
      "1 150 recon: [0.012884396819429116, 2.2539718796609014e-06] lr: [0.01]\n",
      "1 180 recon: [0.011774562260910901, 2.487197066801188e-06] lr: [0.01]\n",
      "1 210 recon: [0.012274740903900397, 2.8014317726729508e-06] lr: [0.01]\n",
      "1 240 recon: [0.01248406933151724, 3.1499584724478666e-06] lr: [0.01]\n",
      "1 270 recon: [0.01283128189158959, 3.5922453004530124e-06] lr: [0.01]\n",
      "1 300 recon: [0.011847338160679198, 4.120275274177725e-06] lr: [0.01]\n",
      "1 330 recon: [0.01252378358518165, 4.741861790759574e-06] lr: [0.01]\n",
      "1 360 recon: [0.011978458594930195, 5.49373980108652e-06] lr: [0.01]\n",
      "1 390 recon: [0.014763500880640098, 7.625635345648162e-06] lr: [0.01]\n",
      "2 0 recon: [0.011912836608783957, 7.6219906076773786e-06] lr: [0.01]\n",
      "2 30 recon: [0.011780696794090106, 9.095200327236507e-06] lr: [0.01]\n",
      "2 60 recon: [0.012286860981866451, 1.0900187954779291e-05] lr: [0.01]\n",
      "2 90 recon: [0.011951493410176218, 1.3199191917326203e-05] lr: [0.01]\n",
      "2 120 recon: [0.013829278317776474, 1.657628271593242e-05] lr: [0.01]\n",
      "2 150 recon: [0.012789006839117243, 1.9475048807448225e-05] lr: [0.01]\n",
      "2 180 recon: [0.011649334726583915, 2.3546468177769225e-05] lr: [0.01]\n",
      "2 210 recon: [0.012143834559118726, 2.9413836301350143e-05] lr: [0.01]\n",
      "2 240 recon: [0.012332601805765668, 3.707285525194713e-05] lr: [0.01]\n",
      "2 270 recon: [0.012621655586483175, 5.1224535672240576e-05] lr: [0.01]\n",
      "2 300 recon: [0.011613072554239726, 6.021577675873062e-05] lr: [0.01]\n",
      "2 330 recon: [0.012181180762271069, 8.215864918041715e-05] lr: [0.01]\n",
      "2 360 recon: [0.011645532903904144, 0.00010455373390814282] lr: [0.01]\n",
      "2 390 recon: [0.013978465083667688, 0.00032524943369004015] lr: [0.01]\n",
      "3 0 recon: [0.011407122981740368, 0.00017781165480918395] lr: [0.01]\n",
      "3 30 recon: [0.011111378924888518, 0.00024155855780074123] lr: [0.01]\n",
      "3 60 recon: [0.011585014524539292, 0.0003204959651977898] lr: [0.01]\n",
      "3 90 recon: [0.011170783247988666, 0.00038138915865166547] lr: [0.01]\n",
      "3 120 recon: [0.012859960069975427, 0.0005482654640757359] lr: [0.01]\n",
      "3 150 recon: [0.011611103824890572, 0.0006634227987724137] lr: [0.01]\n",
      "3 180 recon: [0.010401181853558171, 0.0008045788827258858] lr: [0.01]\n",
      "3 210 recon: [0.011078559970269292, 0.0009241178862148452] lr: [0.01]\n",
      "3 240 recon: [0.011348210812016424, 0.0011460761010120835] lr: [0.01]\n",
      "3 270 recon: [0.011394920890527627, 0.0015656124476423905] lr: [0.01]\n",
      "3 300 recon: [0.010835235452225837, 0.0015307199157877287] lr: [0.01]\n",
      "3 330 recon: [0.010903296691097634, 0.0017479486381034592] lr: [0.01]\n",
      "3 360 recon: [0.01072302342949614, 0.001766034637143876] lr: [0.01]\n",
      "3 390 recon: [0.01321249626015904, 0.0032621256309429735] lr: [0.01]\n",
      "4 0 recon: [0.010369299395064764, 0.0018690455259586425] lr: [0.01]\n",
      "4 30 recon: [0.009963520076974234, 0.0018748848383300467] lr: [0.01]\n",
      "4 60 recon: [0.01066097670097767, 0.001775223434115248] lr: [0.01]\n",
      "4 90 recon: [0.01055192394679651, 0.0016132446884366569] lr: [0.01]\n",
      "4 120 recon: [0.01239739402799516, 0.0016190490137271735] lr: [0.01]\n",
      "4 150 recon: [0.011472076532146035, 0.0014488791014589642] lr: [0.01]\n",
      "4 180 recon: [0.01074993466488049, 0.0012485971199499449] lr: [0.01]\n",
      "4 210 recon: [0.01178251244790585, 0.0009639746995605593] lr: [0.01]\n",
      "4 240 recon: [0.01228879131694231, 0.000850294651391496] lr: [0.01]\n",
      "4 270 recon: [0.0126409432430222, 0.0007965639656945321] lr: [0.01]\n",
      "4 300 recon: [0.0120035079237244, 0.0005486144908077161] lr: [0.01]\n",
      "4 330 recon: [0.0122861805552871, 0.0005258639436732645] lr: [0.01]\n",
      "4 360 recon: [0.011731174086905672, 0.0004977600408306706] lr: [0.01]\n",
      "4 390 recon: [0.014366604194609497, 0.001611166924754276] lr: [0.01]\n",
      "5 0 recon: [0.011384773380615896, 0.00045098290672010454] lr: [0.01]\n",
      "5 30 recon: [0.0110682920198005, 0.00042411713366103277] lr: [0.01]\n",
      "5 60 recon: [0.01153904622497457, 0.00041870024220768125] lr: [0.01]\n",
      "5 90 recon: [0.011157145672052088, 0.0004072053403674037] lr: [0.01]\n",
      "5 120 recon: [0.012822315424969866, 0.0005557894030431992] lr: [0.01]\n",
      "5 150 recon: [0.011551827352191789, 0.0006575811761158192] lr: [0.01]\n",
      "5 180 recon: [0.010293464549739428, 0.0007425221583651896] lr: [0.0075]\n",
      "5 210 recon: [0.01088619395091863, 0.0008234627403689154] lr: [0.0075]\n",
      "5 240 recon: [0.01120961821893988, 0.0009513767102645557] lr: [0.0075]\n",
      "5 270 recon: [0.011399272893807513, 0.0011641154757103557] lr: [0.0075]\n",
      "5 300 recon: [0.010917728885052757, 0.0010130947169925757] lr: [0.0075]\n",
      "5 330 recon: [0.010894573701332658, 0.0012194123279455921] lr: [0.0075]\n",
      "5 360 recon: [0.010611091469804044, 0.0013732387777830699] lr: [0.0075]\n",
      "5 390 recon: [0.014725845670297333, 0.0042238611214043785] lr: [0.0075]\n",
      "6 0 recon: [0.010086259031992636, 0.0015253219482091096] lr: [0.0075]\n",
      "6 30 recon: [0.009726326444190601, 0.0016581324330645572] lr: [0.0075]\n",
      "6 60 recon: [0.010513626434238426, 0.0017909650728040918] lr: [0.0075]\n",
      "6 90 recon: [0.01027990915608442, 0.0016923815317391217] lr: [0.0075]\n",
      "6 120 recon: [0.011843001518701806, 0.0020610253449928682] lr: [0.0075]\n",
      "6 150 recon: [0.010695166590252108, 0.0020065460594304823] lr: [0.0075]\n",
      "6 180 recon: [0.009490884384950469, 0.0018122152127188632] lr: [0.0075]\n",
      "6 210 recon: [0.010209175449761335, 0.0015991017590920918] lr: [0.0075]\n",
      "6 240 recon: [0.010552543478934846, 0.0015574656406902527] lr: [0.0075]\n",
      "6 270 recon: [0.01057800625772475, 0.0016919518216969185] lr: [0.0075]\n",
      "6 300 recon: [0.010068048838105543, 0.0013410872352335556] lr: [0.0075]\n",
      "6 330 recon: [0.010099128416608644, 0.001482144586536938] lr: [0.0075]\n",
      "6 360 recon: [0.010242315820540098, 0.0015623364832140344] lr: [0.0075]\n",
      "6 390 recon: [0.01528671094138318, 0.004564808713084772] lr: [0.0075]\n",
      "7 0 recon: [0.010260796786230464, 0.001554561317850845] lr: [0.0075]\n",
      "7 30 recon: [0.010106740026695097, 0.0013234471226002032] lr: [0.0075]\n",
      "7 60 recon: [0.01095585072597691, 0.0010203426090616924] lr: [0.0075]\n",
      "7 90 recon: [0.010769222793556549, 0.0008130718510458715] lr: [0.0075]\n",
      "7 120 recon: [0.01240139541323122, 0.0009518026522500251] lr: [0.0075]\n",
      "7 150 recon: [0.011222949568818665, 0.0008783642678751147] lr: [0.0075]\n",
      "7 180 recon: [0.009978923952748587, 0.0008860662503843935] lr: [0.0075]\n",
      "7 210 recon: [0.010560867952348356, 0.0009504573326928725] lr: [0.0075]\n",
      "7 240 recon: [0.010794367568997477, 0.0010906464090136014] lr: [0.0075]\n",
      "7 270 recon: [0.010782939382891949, 0.001373762390909721] lr: [0.0075]\n",
      "7 300 recon: [0.010161193933284782, 0.0011786844049153577] lr: [0.0075]\n",
      "7 330 recon: [0.01013229409296494, 0.0013379693366410248] lr: [0.005625]\n",
      "7 360 recon: [0.010128920276344707, 0.0013530814163458067] lr: [0.005625]\n",
      "7 390 recon: [0.011335967130329808, 0.0022796478934847806] lr: [0.005625]\n",
      "8 0 recon: [0.009880611227886374, 0.0014318748176362069] lr: [0.005625]\n",
      "8 30 recon: [0.00948360938359654, 0.0015955678145489899] lr: [0.005625]\n",
      "8 60 recon: [0.010226088494756855, 0.001641871721786544] lr: [0.005625]\n",
      "8 90 recon: [0.009951103766955113, 0.001528508855426893] lr: [0.005625]\n",
      "8 120 recon: [0.011553747615573816, 0.0019221902032235474] lr: [0.005625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 150 recon: [0.010473221296171106, 0.0019231177189245553] lr: [0.005625]\n",
      "8 180 recon: [0.009426010807417038, 0.001954720984064582] lr: [0.005625]\n",
      "8 210 recon: [0.010256674653951452, 0.0019814079792828446] lr: [0.005625]\n",
      "8 240 recon: [0.010650519996177723, 0.0021208612581366565] lr: [0.005625]\n",
      "8 270 recon: [0.010598657016099109, 0.0024617710162817053] lr: [0.005625]\n",
      "8 300 recon: [0.00994010343544658, 0.0019291546180557739] lr: [0.005625]\n",
      "8 330 recon: [0.009740898000619119, 0.002014837932159085] lr: [0.005625]\n",
      "8 360 recon: [0.009920665731103109, 0.0018705796009021178] lr: [0.005625]\n",
      "8 390 recon: [0.010862697599120709, 0.0028154822447333107] lr: [0.005625]\n",
      "9 0 recon: [0.009713608446876548, 0.0017150687178671957] lr: [0.005625]\n",
      "9 30 recon: [0.009361293904608863, 0.0017865230248876624] lr: [0.005625]\n",
      "9 60 recon: [0.010139238571719842, 0.0017284424198117142] lr: [0.005625]\n",
      "9 90 recon: [0.00988760516926212, 0.001505458431929508] lr: [0.005625]\n",
      "9 120 recon: [0.011537790098929905, 0.0017785205898860294] lr: [0.005625]\n",
      "9 150 recon: [0.010460619480860325, 0.001597920946354368] lr: [0.005625]\n",
      "9 180 recon: [0.009360967070132953, 0.0014705691974565918] lr: [0.005625]\n",
      "9 210 recon: [0.010142782198369654, 0.0014133621483805531] lr: [0.005625]\n",
      "9 240 recon: [0.010482704795273298, 0.0014655074774063092] lr: [0.005625]\n",
      "9 270 recon: [0.010429397323474828, 0.0017162816070685892] lr: [0.005625]\n",
      "9 300 recon: [0.009840833618883407, 0.0014369432973939213] lr: [0.005625]\n",
      "9 330 recon: [0.009657668773562068, 0.001602666500653722] lr: [0.005625]\n",
      "9 360 recon: [0.009853380020841759, 0.001580355964454682] lr: [0.005625]\n",
      "9 390 recon: [0.010718088998037632, 0.0026438207748450027] lr: [0.005625]\n",
      "10 0 recon: [0.009663041185421896, 0.001626987180455915] lr: [0.005625]\n",
      "10 30 recon: [0.009313669503130317, 0.0017818071781502858] lr: [0.005625]\n",
      "10 60 recon: [0.010079045244460044, 0.0017963179788156587] lr: [0.005625]\n",
      "10 90 recon: [0.009778261577086349, 0.0016346448632250299] lr: [0.005625]\n",
      "10 120 recon: [0.01141399431220509, 0.0019978141967676413] lr: [0.005625]\n",
      "10 150 recon: [0.010330786188316184, 0.001807222202749781] lr: [0.005625]\n",
      "10 180 recon: [0.00924751386194052, 0.0016904893449118743] lr: [0.005625]\n",
      "10 210 recon: [0.01004860194223239, 0.0016155076138649976] lr: [0.005625]\n",
      "10 240 recon: [0.01039774483564722, 0.0016619909989455679] lr: [0.005625]\n",
      "10 270 recon: [0.010314777756696349, 0.0019371808709989077] lr: [0.005625]\n",
      "10 300 recon: [0.009745849763275896, 0.001629276164995546] lr: [0.005625]\n",
      "10 330 recon: [0.009474377223872352, 0.001800917364534996] lr: [0.005625]\n",
      "10 360 recon: [0.00975235506826084, 0.0017521108049530958] lr: [0.005625]\n",
      "10 390 recon: [0.010544703387500623, 0.002939669020293093] lr: [0.005625]\n",
      "11 0 recon: [0.009560729189806026, 0.0017459620936982445] lr: [0.005625]\n",
      "11 30 recon: [0.009239551937418131, 0.001877687857605615] lr: [0.005625]\n",
      "11 60 recon: [0.010001683024854784, 0.0018572563688861949] lr: [0.005625]\n",
      "11 90 recon: [0.00967668887531122, 0.0016854882357912027] lr: [0.005625]\n",
      "11 120 recon: [0.01132049768789529, 0.002041251488732303] lr: [0.005625]\n",
      "11 150 recon: [0.010227434581859254, 0.001810311125025593] lr: [0.005625]\n",
      "11 180 recon: [0.00917570060529709, 0.0016977737968008626] lr: [0.005625]\n",
      "11 210 recon: [0.009979033322021916, 0.0016052057023530427] lr: [0.005625]\n",
      "11 240 recon: [0.010317240690127143, 0.0016350323406549322] lr: [0.005625]\n",
      "11 270 recon: [0.01019774394711809, 0.0018906589113598196] lr: [0.005625]\n",
      "11 300 recon: [0.009669208281582615, 0.00159270784650492] lr: [0.005625]\n",
      "11 330 recon: [0.009368921335790025, 0.0017476070138633313] lr: [0.005625]\n",
      "11 360 recon: [0.00964977080661286, 0.0016805932002873854] lr: [0.005625]\n",
      "11 390 recon: [0.010421581532198528, 0.002819568074862514] lr: [0.005625]\n",
      "12 0 recon: [0.009468271882131065, 0.0016958351357973058] lr: [0.005625]\n",
      "12 30 recon: [0.009160803078627032, 0.0018452912325280727] lr: [0.005625]\n",
      "12 60 recon: [0.009908781702766259, 0.001845010273381954] lr: [0.005625]\n",
      "12 90 recon: [0.009556779413206573, 0.0017306535165362055] lr: [0.005625]\n",
      "12 120 recon: [0.011192958192212268, 0.002112290765463867] lr: [0.005625]\n",
      "12 150 recon: [0.010076968154150366, 0.00187444644434033] lr: [0.005625]\n",
      "12 180 recon: [0.009072168183393703, 0.0017768321161183173] lr: [0.005625]\n",
      "12 210 recon: [0.009875112565913086, 0.0016920098080169122] lr: [0.005625]\n",
      "12 240 recon: [0.01020647150946843, 0.001736217918075022] lr: [0.005625]\n",
      "12 270 recon: [0.010022740125600659, 0.0020198879430975663] lr: [0.005625]\n",
      "12 300 recon: [0.009559990586139709, 0.0017209829913811005] lr: [0.005625]\n",
      "12 330 recon: [0.00917998872044621, 0.0018972313294840797] lr: [0.005625]\n",
      "12 360 recon: [0.009505593353849835, 0.0018047493371710472] lr: [0.005625]\n",
      "12 390 recon: [0.010206525331531319, 0.0029863270807393054] lr: [0.005625]\n",
      "13 0 recon: [0.009339033755236373, 0.0018041743071232235] lr: [0.005625]\n",
      "13 30 recon: [0.009052964211321951, 0.0019311915503604949] lr: [0.005625]\n",
      "13 60 recon: [0.009788736547477144, 0.0019089840791590247] lr: [0.005625]\n",
      "13 90 recon: [0.009417913549954457, 0.0018234183099844429] lr: [0.005625]\n",
      "13 120 recon: [0.011048945819407593, 0.0021811881605301197] lr: [0.005625]\n",
      "13 150 recon: [0.009904554205466338, 0.0019068919469556061] lr: [0.005625]\n",
      "13 180 recon: [0.008965338813289273, 0.001784849000624887] lr: [0.005625]\n",
      "13 210 recon: [0.009759321264392492, 0.0016948507197535598] lr: [0.005625]\n",
      "13 240 recon: [0.010097930951043518, 0.0017393016255412561] lr: [0.005625]\n",
      "13 270 recon: [0.009850639723067161, 0.002034050610040084] lr: [0.005625]\n",
      "13 300 recon: [0.00946150512340167, 0.0017467234376871074] lr: [0.005625]\n",
      "13 330 recon: [0.009025470139722403, 0.0019636411234436124] lr: [0.005625]\n",
      "13 360 recon: [0.009371616158273961, 0.0018538481267220293] lr: [0.005625]\n",
      "13 390 recon: [0.010016040681396327, 0.003010954470803462] lr: [0.005625]\n",
      "14 0 recon: [0.009219738972379456, 0.0018551423025237334] lr: [0.005625]\n",
      "14 30 recon: [0.008947199427636254, 0.0019637248391802717] lr: [0.005625]\n",
      "14 60 recon: [0.009668608530506797, 0.0019532445548764137] lr: [0.005625]\n",
      "14 90 recon: [0.009284997045130439, 0.0019315792210546894] lr: [0.005625]\n",
      "14 120 recon: [0.010904040390773626, 0.0022771227560344914] lr: [0.005625]\n",
      "14 150 recon: [0.009725860760453633, 0.0020007258698991554] lr: [0.005625]\n",
      "14 180 recon: [0.008850060249118016, 0.00185514267021572] lr: [0.005625]\n",
      "14 210 recon: [0.009625832050489138, 0.0017680887135344135] lr: [0.005625]\n",
      "14 240 recon: [0.009981027642789641, 0.0018135631707672402] lr: [0.005625]\n",
      "14 270 recon: [0.009676519695047675, 0.002135749745775296] lr: [0.005625]\n",
      "14 300 recon: [0.009352039804304293, 0.0018204874598993957] lr: [0.005625]\n",
      "14 330 recon: [0.008863134072773754, 0.002097982382505295] lr: [0.005625]\n",
      "14 360 recon: [0.00924416423478145, 0.0019476073855515374] lr: [0.005625]\n",
      "14 390 recon: [0.009841149322225955, 0.0030813305712106003] lr: [0.005625]\n",
      "15 0 recon: [0.009102339704349312, 0.00193471528030016] lr: [0.005625]\n",
      "15 30 recon: [0.00884085410906565, 0.002005586497148251] lr: [0.005625]\n",
      "15 60 recon: [0.009548984681747157, 0.0020040369219373752] lr: [0.005625]\n",
      "15 90 recon: [0.009168098923461373, 0.002021133905840959] lr: [0.005625]\n",
      "15 120 recon: [0.010769535941254214, 0.002336905405693912] lr: [0.005625]\n",
      "15 150 recon: [0.00957221415539346, 0.0020651632905751916] lr: [0.005625]\n",
      "15 180 recon: [0.008742494697101576, 0.0018815911486676092] lr: [0.005625]\n",
      "15 210 recon: [0.009499367908550016, 0.0018014684436436766] lr: [0.005625]\n",
      "15 240 recon: [0.00986969303883473, 0.0018467001889293682] lr: [0.005625]\n",
      "15 270 recon: [0.009529363447206205, 0.002187045842129617] lr: [0.005625]\n",
      "15 300 recon: [0.00924434054049415, 0.0018507104257324452] lr: [0.005625]\n",
      "15 330 recon: [0.008726770553935798, 0.002205667888258782] lr: [0.005625]\n",
      "15 360 recon: [0.009132930194399853, 0.001998498085159244] lr: [0.005625]\n",
      "15 390 recon: [0.009765389931352994, 0.0031885186229749568] lr: [0.005625]\n",
      "16 0 recon: [0.008991106313111433, 0.0019868986750551975] lr: [0.005625]\n",
      "16 30 recon: [0.008736728619110103, 0.002029252897008967] lr: [0.005625]\n",
      "16 60 recon: [0.009428297290094687, 0.0020466574072168313] lr: [0.005625]\n",
      "16 90 recon: [0.009061786255728723, 0.0020871691319067623] lr: [0.005625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 120 recon: [0.010627894458714118, 0.0023767125306497303] lr: [0.005625]\n",
      "16 150 recon: [0.009433159769458674, 0.002122758423223212] lr: [0.005625]\n",
      "16 180 recon: [0.008634013408259048, 0.0019123916119617311] lr: [0.005625]\n",
      "16 210 recon: [0.009371311035033298, 0.0018375829212847808] lr: [0.005625]\n",
      "16 240 recon: [0.009755961658778803, 0.0018863775611755922] lr: [0.005625]\n",
      "16 270 recon: [0.009389711688880515, 0.00223474799861571] lr: [0.005625]\n",
      "16 300 recon: [0.009133093112546523, 0.0018848953078343645] lr: [0.005625]\n",
      "16 330 recon: [0.00860980088377323, 0.00230946546296658] lr: [0.005625]\n",
      "16 360 recon: [0.009028104683594705, 0.0020363934764430665] lr: [0.005625]\n",
      "16 390 recon: [0.01002667506373554, 0.003625560082060172] lr: [0.005625]\n",
      "17 0 recon: [0.008885947327615103, 0.0020164182226179335] lr: [0.005625]\n",
      "17 30 recon: [0.0086428497428023, 0.0020321007268690526] lr: [0.005625]\n",
      "17 60 recon: [0.00931821778517073, 0.002057749306720201] lr: [0.005625]\n",
      "17 90 recon: [0.008971623400945207, 0.0021010517667876295] lr: [0.005625]\n",
      "17 120 recon: [0.010487407599323506, 0.0023676279171731727] lr: [0.005625]\n",
      "17 150 recon: [0.009315942945446364, 0.002144662784758763] lr: [0.005625]\n",
      "17 180 recon: [0.008538030928241807, 0.0019221553076950028] lr: [0.005625]\n",
      "17 210 recon: [0.009252529541386816, 0.0018554336755701596] lr: [0.005625]\n",
      "17 240 recon: [0.009654234980677662, 0.001912039650567677] lr: [0.005625]\n",
      "17 270 recon: [0.009269536962499358, 0.0022624876502602854] lr: [0.005625]\n",
      "17 300 recon: [0.009034616611054149, 0.0018965208152439425] lr: [0.005625]\n",
      "17 330 recon: [0.008527805009979851, 0.0023459595379963457] lr: [0.005625]\n",
      "17 360 recon: [0.008938659486729538, 0.002045416653971233] lr: [0.005625]\n",
      "17 390 recon: [0.011312096736559, 0.004771622693868729] lr: [0.005625]\n",
      "18 0 recon: [0.008799530954107201, 0.0020257866457627604] lr: [0.005625]\n",
      "18 30 recon: [0.00856898360057865, 0.0020275542110296217] lr: [0.005625]\n",
      "18 60 recon: [0.009233350423958349, 0.00204832104724312] lr: [0.005625]\n",
      "18 90 recon: [0.008911742718609518, 0.0020587768866891366] lr: [0.005625]\n",
      "18 120 recon: [0.010379789507331967, 0.002310510895072604] lr: [0.005625]\n",
      "18 150 recon: [0.009249779179347047, 0.002107638902711008] lr: [0.005625]\n",
      "18 180 recon: [0.008484754586597879, 0.0018818089522701995] lr: [0.005625]\n",
      "18 210 recon: [0.009181163262130136, 0.0018204098971237365] lr: [0.005625]\n",
      "18 240 recon: [0.00959272585215975, 0.0018798709133045625] lr: [0.005625]\n",
      "18 270 recon: [0.009208990896112433, 0.0022227931761076296] lr: [0.005625]\n",
      "18 300 recon: [0.008975195130746107, 0.001864575724514698] lr: [0.005625]\n",
      "18 330 recon: [0.00851262537171087, 0.002265816382238451] lr: [0.005625]\n",
      "18 360 recon: [0.008889264142419086, 0.002006169248511775] lr: [0.005625]\n",
      "18 390 recon: [0.013176620369877639, 0.006237467187615724] lr: [0.005625]\n",
      "19 0 recon: [0.008767885202194646, 0.001969309060767087] lr: [0.005625]\n",
      "19 30 recon: [0.008553946787003806, 0.001953627500302649] lr: [0.005625]\n",
      "19 60 recon: [0.009223870544565655, 0.0019483216763842269] lr: [0.005625]\n",
      "19 90 recon: [0.008931792899218877, 0.0019133972581415924] lr: [0.005625]\n",
      "19 120 recon: [0.010365587531097679, 0.0021559735329912647] lr: [0.005625]\n",
      "19 150 recon: [0.009279106625160497, 0.0019806012120657567] lr: [0.005625]\n",
      "19 180 recon: [0.008508548209616698, 0.0017774470131730672] lr: [0.005625]\n",
      "19 210 recon: [0.00919913949003415, 0.0017180024596414466] lr: [0.005625]\n",
      "19 240 recon: [0.009603303189417453, 0.0017801853020857753] lr: [0.005625]\n",
      "19 270 recon: [0.009255251964193842, 0.002092011834583072] lr: [0.005625]\n",
      "19 300 recon: [0.009008259179392814, 0.0017393413660938227] lr: [0.005625]\n",
      "19 330 recon: [0.008640975167039993, 0.0020576396914754993] lr: [0.00421875]\n",
      "19 360 recon: [0.008926345140385147, 0.0018788423001176264] lr: [0.00421875]\n",
      "19 390 recon: [0.012076521826449907, 0.005047690680300366] lr: [0.00421875]\n",
      "20 0 recon: [0.008776745510341, 0.0019038749295753005] lr: [0.00421875]\n",
      "20 30 recon: [0.008522732483193267, 0.001972499023020977] lr: [0.00421875]\n",
      "20 60 recon: [0.009165544311780457, 0.002023227086123561] lr: [0.00421875]\n",
      "20 90 recon: [0.00885913362925351, 0.0020078523937447244] lr: [0.00421875]\n",
      "20 120 recon: [0.01022805954146429, 0.0023155000299176737] lr: [0.00421875]\n",
      "20 150 recon: [0.009168105669201955, 0.002147074301296543] lr: [0.00421875]\n",
      "20 180 recon: [0.008402674979644644, 0.001945490989025099] lr: [0.00421875]\n",
      "20 210 recon: [0.009088490817343682, 0.0018757113163589973] lr: [0.00421875]\n",
      "20 240 recon: [0.009497432943912951, 0.0019363121710977292] lr: [0.00421875]\n",
      "20 270 recon: [0.009135346183624798, 0.0022603607327414924] lr: [0.00421875]\n",
      "20 300 recon: [0.008907435741097173, 0.0018681942526512644] lr: [0.00421875]\n",
      "20 330 recon: [0.008541186827696693, 0.002166551174702865] lr: [0.00421875]\n",
      "20 360 recon: [0.008844265578233151, 0.0019733386000050563] lr: [0.00421875]\n",
      "20 390 recon: [0.009524634494291931, 0.003138282229595952] lr: [0.00421875]\n",
      "21 0 recon: [0.008701393866356285, 0.0020015742816475238] lr: [0.00421875]\n",
      "21 30 recon: [0.008444760600934208, 0.0020866957391878736] lr: [0.00421875]\n",
      "21 60 recon: [0.009078020558083709, 0.002139663704790349] lr: [0.00421875]\n",
      "21 90 recon: [0.008762476284660394, 0.002140193906840706] lr: [0.00421875]\n",
      "21 120 recon: [0.010088350797559296, 0.0024750022204714566] lr: [0.00421875]\n",
      "21 150 recon: [0.009058770761137046, 0.0022865466924513493] lr: [0.00421875]\n",
      "21 180 recon: [0.008316611786532565, 0.002065229569477589] lr: [0.00421875]\n",
      "21 210 recon: [0.008987893463218913, 0.002001173810677355] lr: [0.00421875]\n",
      "21 240 recon: [0.009407016385945198, 0.0020649103762813456] lr: [0.00421875]\n",
      "21 270 recon: [0.009030144647310213, 0.002419314042885035] lr: [0.00421875]\n",
      "21 300 recon: [0.008815277181830476, 0.002005583549521752] lr: [0.00421875]\n",
      "21 330 recon: [0.008418871796289978, 0.0023321307415706603] lr: [0.00421875]\n",
      "21 360 recon: [0.008754947967148563, 0.0021201983935806154] lr: [0.00421875]\n",
      "21 390 recon: [0.009332890549538057, 0.0033700549733126097] lr: [0.00421875]\n",
      "22 0 recon: [0.008622529343322612, 0.002092405243122335] lr: [0.00421875]\n",
      "22 30 recon: [0.008379310559808473, 0.0021293056383335424] lr: [0.00421875]\n",
      "22 60 recon: [0.009006041774043303, 0.0021535426302342993] lr: [0.00421875]\n",
      "22 90 recon: [0.00869676268865854, 0.0021544276413995194] lr: [0.00421875]\n",
      "22 120 recon: [0.009986259974660834, 0.002462402690155435] lr: [0.00421875]\n",
      "22 150 recon: [0.008988825587169812, 0.0022602590321792564] lr: [0.00421875]\n",
      "22 180 recon: [0.008265206948252002, 0.00201506147483624] lr: [0.00421875]\n",
      "22 210 recon: [0.008918349400896076, 0.0019646665400807955] lr: [0.00421875]\n",
      "22 240 recon: [0.00934654234314052, 0.002026947881541373] lr: [0.00421875]\n",
      "22 270 recon: [0.008968082701359072, 0.0023841603277754025] lr: [0.00421875]\n",
      "22 300 recon: [0.008753818057209425, 0.001990679377770957] lr: [0.00421875]\n",
      "22 330 recon: [0.008348273880157223, 0.0023471609587584034] lr: [0.00421875]\n",
      "22 360 recon: [0.008697432802094032, 0.002135570138814995] lr: [0.00421875]\n",
      "22 390 recon: [0.009128687324207522, 0.0032280713430922103] lr: [0.00421875]\n",
      "23 0 recon: [0.008562414962294509, 0.0021274377180093345] lr: [0.00421875]\n",
      "23 30 recon: [0.008322587629136012, 0.002166407707006625] lr: [0.00421875]\n",
      "23 60 recon: [0.008932884821651983, 0.0022164360565216697] lr: [0.00421875]\n",
      "23 90 recon: [0.008621803618116286, 0.0022362248430897536] lr: [0.00421875]\n",
      "23 120 recon: [0.00986556605630359, 0.0025594755828372948] lr: [0.00421875]\n",
      "23 150 recon: [0.008903351417165827, 0.002359022194286371] lr: [0.00421875]\n",
      "23 180 recon: [0.008191632269513914, 0.002103368972379029] lr: [0.00421875]\n",
      "23 210 recon: [0.00883494345779309, 0.002054464834996888] lr: [0.00421875]\n",
      "23 240 recon: [0.009271000352987, 0.0021135979026142004] lr: [0.00421875]\n",
      "23 270 recon: [0.008891898128794562, 0.002472974964344117] lr: [0.00421875]\n",
      "23 300 recon: [0.008684370506236513, 0.002067679515582486] lr: [0.00421875]\n",
      "23 330 recon: [0.008267053635702522, 0.00244408298695206] lr: [0.00421875]\n",
      "23 360 recon: [0.008641109890739638, 0.0021959331192362573] lr: [0.00421875]\n",
      "23 390 recon: [0.009014039638488106, 0.003302502831028369] lr: [0.00421875]\n",
      "24 0 recon: [0.008506967773303805, 0.00217690843377487] lr: [0.00421875]\n",
      "24 30 recon: [0.00827269544779597, 0.002197687577091784] lr: [0.00421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 60 recon: [0.00887424815900264, 0.002244461714777596] lr: [0.00421875]\n",
      "24 90 recon: [0.008565994233326449, 0.002260351377687996] lr: [0.00421875]\n",
      "24 120 recon: [0.009768605522460906, 0.002569373566632375] lr: [0.00421875]\n",
      "24 150 recon: [0.00884975276472306, 0.0023606676785168476] lr: [0.00421875]\n",
      "24 180 recon: [0.008149394293304564, 0.002087435579174767] lr: [0.00421875]\n",
      "24 210 recon: [0.008779130231031027, 0.002048497759423174] lr: [0.00421875]\n",
      "24 240 recon: [0.009220423158907382, 0.0021072077671190187] lr: [0.00421875]\n",
      "24 270 recon: [0.008848291245625056, 0.002458616778651414] lr: [0.00421875]\n",
      "24 300 recon: [0.008638144641664626, 0.0020651352149834833] lr: [0.00421875]\n",
      "24 330 recon: [0.008217384317974948, 0.0024629454862340303] lr: [0.00421875]\n",
      "24 360 recon: [0.008603577166406487, 0.002196092466252661] lr: [0.00421875]\n",
      "24 390 recon: [0.008950790251787862, 0.003272502810926918] lr: [0.00421875]\n",
      "25 0 recon: [0.008465254171747982, 0.002186348029501398] lr: [0.00421875]\n",
      "25 30 recon: [0.008233489204092385, 0.0022018295398028155] lr: [0.00421875]\n",
      "25 60 recon: [0.008823452498679673, 0.0022610531004120973] lr: [0.00421875]\n",
      "25 90 recon: [0.008513873606724887, 0.002284640831074312] lr: [0.00421875]\n",
      "25 120 recon: [0.009669459232881355, 0.0025993654444104062] lr: [0.00421875]\n",
      "25 150 recon: [0.008793275207646957, 0.002392926691748255] lr: [0.00421875]\n",
      "25 180 recon: [0.008101712930840594, 0.0021139297503731365] lr: [0.00421875]\n",
      "25 210 recon: [0.008719507223647005, 0.00208267339743693] lr: [0.00421875]\n",
      "25 240 recon: [0.009162697166402596, 0.0021437803182404523] lr: [0.00421875]\n",
      "25 270 recon: [0.008795990051565573, 0.002492022978643916] lr: [0.00421875]\n",
      "25 300 recon: [0.008588323044577623, 0.002094576896350863] lr: [0.00421875]\n",
      "25 330 recon: [0.008164358534362396, 0.0025057502748534483] lr: [0.00421875]\n",
      "25 360 recon: [0.008562594683657266, 0.0022206543492548467] lr: [0.00421875]\n",
      "25 390 recon: [0.008873238400040766, 0.0033285168260896855] lr: [0.00421875]\n",
      "26 0 recon: [0.00842349725473582, 0.0022070775524001716] lr: [0.00421875]\n",
      "26 30 recon: [0.008194736448393105, 0.0022160730801401595] lr: [0.00421875]\n",
      "26 60 recon: [0.008776007665717803, 0.0022784933019822087] lr: [0.00421875]\n",
      "26 90 recon: [0.008466768060539476, 0.002299947701298014] lr: [0.00421875]\n",
      "26 120 recon: [0.009576047774164684, 0.002617298220374824] lr: [0.00421875]\n",
      "26 150 recon: [0.008745313911898355, 0.002405630372525033] lr: [0.00421875]\n",
      "26 180 recon: [0.008062905256551614, 0.0021171070428061822] lr: [0.00421875]\n",
      "26 210 recon: [0.008668890513466818, 0.0020930131420691194] lr: [0.00421875]\n",
      "26 240 recon: [0.009112829927757766, 0.002154939966777462] lr: [0.00421875]\n",
      "26 270 recon: [0.008753834680700245, 0.002496636668351987] lr: [0.00421875]\n",
      "26 300 recon: [0.008546648957918785, 0.002100957181271609] lr: [0.00421875]\n",
      "26 330 recon: [0.008121782085295492, 0.0025195136005812424] lr: [0.00421875]\n",
      "26 360 recon: [0.008527291792311764, 0.002227857503566449] lr: [0.00421875]\n",
      "26 390 recon: [0.008842900654816604, 0.0033247320315709906] lr: [0.00421875]\n",
      "27 0 recon: [0.00838581308703283, 0.0022188328962477106] lr: [0.00421875]\n",
      "27 30 recon: [0.008158650724253765, 0.002228479264387776] lr: [0.00421875]\n",
      "27 60 recon: [0.008730994983815892, 0.0022973429362450714] lr: [0.00421875]\n",
      "27 90 recon: [0.008421665000956908, 0.0023178532882348166] lr: [0.00421875]\n",
      "27 120 recon: [0.009482278941247951, 0.0026490008422109506] lr: [0.00421875]\n",
      "27 150 recon: [0.008696748047651307, 0.0024308083593915742] lr: [0.00421875]\n",
      "27 180 recon: [0.00802181630568794, 0.0021374240376328553] lr: [0.00421875]\n",
      "27 210 recon: [0.008617480912162127, 0.002119190081857569] lr: [0.00421875]\n",
      "27 240 recon: [0.009060901787895615, 0.002181731824450244] lr: [0.00421875]\n",
      "27 270 recon: [0.008709136820611923, 0.0025182869617584613] lr: [0.00421875]\n",
      "27 300 recon: [0.008504351026818327, 0.0021201107753030615] lr: [0.00421875]\n",
      "27 330 recon: [0.0080797233233933, 0.002538529125687373] lr: [0.00421875]\n",
      "27 360 recon: [0.00849163178727569, 0.0022419410634493815] lr: [0.00421875]\n",
      "27 390 recon: [0.008824904115242052, 0.0034405660347712527] lr: [0.00421875]\n",
      "28 0 recon: [0.008350266011111704, 0.002229158482402829] lr: [0.00421875]\n",
      "28 30 recon: [0.008125834828338264, 0.002235564553821358] lr: [0.00421875]\n",
      "28 60 recon: [0.008691175563568989, 0.0023057952729074347] lr: [0.00421875]\n",
      "28 90 recon: [0.008382947180473548, 0.002321723110254246] lr: [0.00421875]\n",
      "28 120 recon: [0.00939681819269491, 0.0026661552224371923] lr: [0.00421875]\n",
      "28 150 recon: [0.008655605257130522, 0.0024374873589766656] lr: [0.00421875]\n",
      "28 180 recon: [0.007987416328850234, 0.0021389646785934502] lr: [0.00421875]\n",
      "28 210 recon: [0.008572845728538295, 0.00212810698196011] lr: [0.00421875]\n",
      "28 240 recon: [0.009014797952732597, 0.0021909881324489165] lr: [0.00421875]\n",
      "28 270 recon: [0.008671326292351436, 0.002521332555286942] lr: [0.00421875]\n",
      "28 300 recon: [0.008467061954773893, 0.002125810431183428] lr: [0.00421875]\n",
      "28 330 recon: [0.008043735366035618, 0.002541735554069149] lr: [0.00421875]\n",
      "28 360 recon: [0.008459047534576257, 0.0022476301011711054] lr: [0.00421875]\n",
      "28 390 recon: [0.008951810363558434, 0.003530492787732118] lr: [0.00421875]\n",
      "29 0 recon: [0.008316595601414118, 0.0022381819896040212] lr: [0.00421875]\n",
      "29 30 recon: [0.008093714305829357, 0.0022466140075217264] lr: [0.00421875]\n",
      "29 60 recon: [0.008651669904015013, 0.002322147220024032] lr: [0.00421875]\n",
      "29 90 recon: [0.008345242506536805, 0.0023334265923334622] lr: [0.00421875]\n",
      "29 120 recon: [0.0093130074017679, 0.002697581384394093] lr: [0.00421875]\n",
      "29 150 recon: [0.008613450004504213, 0.0024553018987809832] lr: [0.00421875]\n",
      "29 180 recon: [0.007951119934982721, 0.0021544377730099286] lr: [0.00421875]\n",
      "29 210 recon: [0.008528761398069972, 0.0021467985217961953] lr: [0.00421875]\n",
      "29 240 recon: [0.008968512283401816, 0.002208991559811775] lr: [0.00421875]\n",
      "29 270 recon: [0.00863310323496426, 0.0025325182845895764] lr: [0.00421875]\n",
      "29 300 recon: [0.008430674278839012, 0.0021366347841411414] lr: [0.00421875]\n",
      "29 330 recon: [0.00801071121432934, 0.002542306935225695] lr: [0.00421875]\n",
      "29 360 recon: [0.008427963053439746, 0.0022528180496717877] lr: [0.00421875]\n",
      "29 390 recon: [0.009253138568754935, 0.003923327816352497] lr: [0.00421875]\n",
      "30 0 recon: [0.008287743890603013, 0.002236043341447223] lr: [0.00421875]\n",
      "30 30 recon: [0.00806883679936035, 0.002239410163034473] lr: [0.00421875]\n",
      "30 60 recon: [0.008622369857787436, 0.002312511753940634] lr: [0.00421875]\n",
      "30 90 recon: [0.008319174761928703, 0.0023164220083829548] lr: [0.00421875]\n",
      "30 120 recon: [0.009247817955713543, 0.0026948667885824183] lr: [0.00421875]\n",
      "30 150 recon: [0.008584840379787762, 0.0024386325927945617] lr: [0.00421875]\n",
      "30 180 recon: [0.007927105675197646, 0.0021373819117555446] lr: [0.00421875]\n",
      "30 210 recon: [0.00849667920844103, 0.0021358069144720615] lr: [0.00421875]\n",
      "30 240 recon: [0.008932728840904897, 0.002199698548321768] lr: [0.00421875]\n",
      "30 270 recon: [0.008606072435213986, 0.0025165243545831445] lr: [0.00421875]\n",
      "30 300 recon: [0.008402935181475116, 0.002126693939414249] lr: [0.00421875]\n",
      "30 330 recon: [0.007988121811084738, 0.0025198118428780623] lr: [0.00421875]\n",
      "30 360 recon: [0.008402229457302457, 0.0022459428018338098] lr: [0.00421875]\n",
      "30 390 recon: [0.009862680862467051, 0.004338102511680467] lr: [0.00421875]\n",
      "31 0 recon: [0.00826217107628048, 0.0022327699191916632] lr: [0.00421875]\n",
      "31 30 recon: [0.008044827083318372, 0.002241007415731368] lr: [0.00421875]\n",
      "31 60 recon: [0.008593290811836584, 0.0023175167922514415] lr: [0.00421875]\n",
      "31 90 recon: [0.00829416512736234, 0.002313252697587797] lr: [0.00421875]\n",
      "31 120 recon: [0.009188591412996034, 0.0027111660090538593] lr: [0.00421875]\n",
      "31 150 recon: [0.0085561138325115, 0.002438501962599443] lr: [0.00421875]\n",
      "31 180 recon: [0.007902065509647492, 0.00214079513940127] lr: [0.00421875]\n",
      "31 210 recon: [0.008467815549221344, 0.0021358022303161004] lr: [0.00421875]\n",
      "31 240 recon: [0.008900005925195726, 0.0021995391524303057] lr: [0.00421875]\n",
      "31 270 recon: [0.008582088414462157, 0.0025081864780195856] lr: [0.00421875]\n",
      "31 300 recon: [0.008380171893083358, 0.0021186972290681053] lr: [0.00421875]\n",
      "31 330 recon: [0.007975892525230262, 0.0024865099627749718] lr: [0.00421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 360 recon: [0.008382633411598908, 0.0022321980435597373] lr: [0.00421875]\n",
      "31 390 recon: [0.010237470579090508, 0.004810495850297865] lr: [0.00421875]\n",
      "32 0 recon: [0.008247629562261398, 0.002208457386348197] lr: [0.00421875]\n",
      "32 30 recon: [0.008034529471790295, 0.002213570742001266] lr: [0.00421875]\n",
      "32 60 recon: [0.0085821397066534, 0.002282563544138559] lr: [0.00421875]\n",
      "32 90 recon: [0.00828699543190989, 0.002272246388771357] lr: [0.00421875]\n",
      "32 120 recon: [0.009157568723331002, 0.0026810732238102364] lr: [0.00421875]\n",
      "32 150 recon: [0.008546176886356853, 0.0023998606393880527] lr: [0.00421875]\n",
      "32 180 recon: [0.007893801912840354, 0.0021083259911232914] lr: [0.00421875]\n",
      "32 210 recon: [0.008453626060713043, 0.002107753145334019] lr: [0.00421875]\n",
      "32 240 recon: [0.008880065461802356, 0.0021757029792932744] lr: [0.00421875]\n",
      "32 270 recon: [0.00856990440431228, 0.0024815157313157364] lr: [0.00421875]\n",
      "32 300 recon: [0.008366518630206867, 0.002097828481088084] lr: [0.00421875]\n",
      "32 330 recon: [0.007974661357350749, 0.002445596027916319] lr: [0.00421875]\n",
      "32 360 recon: [0.008368253405608556, 0.0022164227203973785] lr: [0.00421875]\n",
      "32 390 recon: [0.010164686241705025, 0.004611345001237889] lr: [0.00421875]\n",
      "33 0 recon: [0.008229316185571723, 0.002209061037133539] lr: [0.00421875]\n",
      "33 30 recon: [0.008012350943532531, 0.0022318427245018916] lr: [0.00421875]\n",
      "33 60 recon: [0.008553757527178008, 0.002310607136481313] lr: [0.00421875]\n",
      "33 90 recon: [0.008259256981241879, 0.002301398612705844] lr: [0.00421875]\n",
      "33 120 recon: [0.009102510364030088, 0.002732683321301944] lr: [0.00421875]\n",
      "33 150 recon: [0.008510204444968927, 0.0024399669323513107] lr: [0.00421875]\n",
      "33 180 recon: [0.007861797229175316, 0.0021513080055575056] lr: [0.00421875]\n",
      "33 210 recon: [0.008419933452838263, 0.0021436371297286856] lr: [0.00421875]\n",
      "33 240 recon: [0.008843224010147015, 0.0022099252553048603] lr: [0.00421875]\n",
      "33 270 recon: [0.00853743267540795, 0.0025138160337074993] lr: [0.00421875]\n",
      "33 300 recon: [0.008338363677212704, 0.0021230110862559895] lr: [0.00421875]\n",
      "33 330 recon: [0.007956068094853755, 0.0024529366418716814] lr: [0.00421875]\n",
      "33 360 recon: [0.008344333969661133, 0.0022314900999848976] lr: [0.00421875]\n",
      "33 390 recon: [0.009663042691357121, 0.00435934617454303] lr: [0.00421875]\n",
      "34 0 recon: [0.008209572398417547, 0.002212204992322378] lr: [0.00421875]\n",
      "34 30 recon: [0.00799510040580812, 0.0022298236257361176] lr: [0.00421875]\n",
      "34 60 recon: [0.008534737034918746, 0.002300388082075331] lr: [0.00421875]\n",
      "34 90 recon: [0.008240800366241804, 0.0022947040025477587] lr: [0.00421875]\n",
      "34 120 recon: [0.009060034500013966, 0.0027347392160023292] lr: [0.00421875]\n",
      "34 150 recon: [0.008486107665886882, 0.0024333831340088478] lr: [0.00421875]\n",
      "34 180 recon: [0.007842051784260609, 0.0021440219139133012] lr: [0.00421875]\n",
      "34 210 recon: [0.008392274162772854, 0.0021478298657910413] lr: [0.00421875]\n",
      "34 240 recon: [0.008811309923267433, 0.0022177774658425327] lr: [0.00421875]\n",
      "34 270 recon: [0.008508182203952486, 0.0025264252852786667] lr: [0.00421875]\n",
      "34 300 recon: [0.008309007435812555, 0.0021409264108347577] lr: [0.00421875]\n",
      "34 330 recon: [0.007927587994920224, 0.0024751238508065035] lr: [0.00421875]\n",
      "34 360 recon: [0.00831501980744089, 0.002256839994996788] lr: [0.00421875]\n",
      "34 390 recon: [0.009336123396681646, 0.004118768446803141] lr: [0.00421875]\n",
      "35 0 recon: [0.008176975101623558, 0.00224898667240498] lr: [0.00421875]\n",
      "35 30 recon: [0.007962352001464747, 0.0022716675356677847] lr: [0.00421875]\n",
      "35 60 recon: [0.008495514520406844, 0.002350400343967466] lr: [0.00421875]\n",
      "35 90 recon: [0.008202833925487195, 0.0023469456028972313] lr: [0.00421875]\n",
      "35 120 recon: [0.008993464936639434, 0.0028015185804885047] lr: [0.00421875]\n",
      "35 150 recon: [0.008442467156270754, 0.0024851159822736] lr: [0.00421875]\n",
      "35 180 recon: [0.007805642223157581, 0.00218928345470166] lr: [0.00421875]\n",
      "35 210 recon: [0.008353566882663217, 0.0021883008453680223] lr: [0.00421875]\n",
      "35 240 recon: [0.008771525792180396, 0.002252433680935983] lr: [0.00421875]\n",
      "35 270 recon: [0.008473364046944543, 0.0025548034287568937] lr: [0.00421875]\n",
      "35 300 recon: [0.00827742852168827, 0.0021649718770014033] lr: [0.00421875]\n",
      "35 330 recon: [0.007897672692577148, 0.0024978880482019795] lr: [0.00421875]\n",
      "35 360 recon: [0.008288893444195016, 0.0022702807507112015] lr: [0.00421875]\n",
      "35 390 recon: [0.009199480773854947, 0.004060815118033434] lr: [0.00421875]\n",
      "36 0 recon: [0.008152795681281525, 0.0022549457291262116] lr: [0.00421875]\n",
      "36 30 recon: [0.007942327961907594, 0.0022680309179507153] lr: [0.00421875]\n",
      "36 60 recon: [0.008472411281453854, 0.002343835804282568] lr: [0.00421875]\n",
      "36 90 recon: [0.008181185935016088, 0.0023448557312932567] lr: [0.00421875]\n",
      "36 120 recon: [0.008946625282515374, 0.002807993092717328] lr: [0.00421875]\n",
      "36 150 recon: [0.008416509054357995, 0.0024795779813850853] lr: [0.00421875]\n",
      "36 180 recon: [0.007784778662929238, 0.0021808073274739285] lr: [0.00421875]\n",
      "36 210 recon: [0.008325574378923242, 0.0021926850557473575] lr: [0.00421875]\n",
      "36 240 recon: [0.008739321577101888, 0.002262046525042592] lr: [0.00421875]\n",
      "36 270 recon: [0.008444212609178279, 0.0025666241856121914] lr: [0.00421875]\n",
      "36 300 recon: [0.008247769828917964, 0.00218272041193649] lr: [0.00421875]\n",
      "36 330 recon: [0.00786553760336694, 0.002526716322626693] lr: [0.00421875]\n",
      "36 360 recon: [0.008260329903517223, 0.002293222085116398] lr: [0.00421875]\n",
      "36 390 recon: [0.009149718983864612, 0.00411722795911174] lr: [0.00421875]\n",
      "37 0 recon: [0.008123206373485773, 0.002280919133210568] lr: [0.00421875]\n",
      "37 30 recon: [0.007914746720035372, 0.00229314980340291] lr: [0.00421875]\n",
      "37 60 recon: [0.008440118347257525, 0.002374420480566946] lr: [0.00421875]\n",
      "37 90 recon: [0.008152206643398581, 0.0023722660601435564] lr: [0.00421875]\n",
      "37 120 recon: [0.008893170444843635, 0.0028459782813876466] lr: [0.00421875]\n",
      "37 150 recon: [0.008383661904728742, 0.0025027416829767227] lr: [0.00421875]\n",
      "37 180 recon: [0.007758004750643862, 0.002199761600576966] lr: [0.00421875]\n",
      "37 210 recon: [0.008297467709894745, 0.002206656056320571] lr: [0.00421875]\n",
      "37 240 recon: [0.008709975143883594, 0.002270430974083147] lr: [0.00421875]\n",
      "37 270 recon: [0.008421385506184013, 0.0025655373275716474] lr: [0.00421875]\n",
      "37 300 recon: [0.008225670908050079, 0.0021795669958319442] lr: [0.00421875]\n",
      "37 330 recon: [0.007846125680787174, 0.002523137852912249] lr: [0.00421875]\n",
      "37 360 recon: [0.00824247465167359, 0.0022839245532799337] lr: [0.00421875]\n",
      "37 390 recon: [0.009228637324898177, 0.004149065963338358] lr: [0.00421875]\n",
      "38 0 recon: [0.008105097074202467, 0.002271183543698177] lr: [0.00421875]\n",
      "38 30 recon: [0.007899223513002132, 0.0022814080362798207] lr: [0.00421875]\n",
      "38 60 recon: [0.008421195859162374, 0.002364029751950668] lr: [0.00421875]\n",
      "38 90 recon: [0.008134464688962777, 0.002365986889213449] lr: [0.00421875]\n",
      "38 120 recon: [0.008853446803576545, 0.002852415328970763] lr: [0.00421875]\n",
      "38 150 recon: [0.008359709965125669, 0.002500155032461983] lr: [0.00421875]\n",
      "38 180 recon: [0.007738408409101213, 0.0021975480045558072] lr: [0.00421875]\n",
      "38 210 recon: [0.008272411359655988, 0.002214191482874233] lr: [0.00421875]\n",
      "38 240 recon: [0.008680613318059057, 0.002284013950963531] lr: [0.00421875]\n",
      "38 270 recon: [0.008393840654549171, 0.002583313967022426] lr: [0.00421875]\n",
      "38 300 recon: [0.008198428761050182, 0.0021989361965558383] lr: [0.00421875]\n",
      "38 330 recon: [0.00781918868943037, 0.0025459769741419144] lr: [0.00421875]\n",
      "38 360 recon: [0.008217522001924826, 0.002304282202974936] lr: [0.00421875]\n",
      "38 390 recon: [0.009287445942729749, 0.004322903533240496] lr: [0.00421875]\n",
      "39 0 recon: [0.008081338695940504, 0.002286446852743338] lr: [0.00421875]\n",
      "39 30 recon: [0.007878481712030243, 0.002293691910296902] lr: [0.00421875]\n",
      "39 60 recon: [0.008398553537659443, 0.00237517456383133] lr: [0.00421875]\n",
      "39 90 recon: [0.008116033574400393, 0.0023697708188850173] lr: [0.00421875]\n",
      "39 120 recon: [0.008817044556934177, 0.0028630694381581437] lr: [0.00421875]\n",
      "39 150 recon: [0.008338148145145826, 0.0025003068131078656] lr: [0.00421875]\n",
      "39 180 recon: [0.007721757893358051, 0.002196001145985177] lr: [0.00421875]\n",
      "39 210 recon: [0.00825419704059404, 0.002209071844520533] lr: [0.00421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 240 recon: [0.008660823850006053, 0.0022746407974913413] lr: [0.00421875]\n",
      "39 270 recon: [0.008380808285093194, 0.0025650532945497018] lr: [0.00421875]\n",
      "39 300 recon: [0.008183395677385248, 0.002183189021824688] lr: [0.00421875]\n",
      "39 330 recon: [0.007808985329339746, 0.0025258518417996915] lr: [0.00421875]\n",
      "39 360 recon: [0.008204707510328663, 0.0022890798101507077] lr: [0.00421875]\n",
      "39 390 recon: [0.009389489293919497, 0.0043208288025763765] lr: [0.00421875]\n",
      "40 0 recon: [0.008065975084742834, 0.0022784414099456954] lr: [0.00421875]\n",
      "40 30 recon: [0.007863661855767567, 0.0022900464816141023] lr: [0.00421875]\n",
      "40 60 recon: [0.008380007795082661, 0.0023760573106490035] lr: [0.00421875]\n",
      "40 90 recon: [0.00809867461752167, 0.002372981255633659] lr: [0.00421875]\n",
      "40 120 recon: [0.008780307432486905, 0.002881175748427339] lr: [0.00421875]\n",
      "40 150 recon: [0.008312906759901465, 0.0025126544828302346] lr: [0.00421875]\n",
      "40 180 recon: [0.007700975081303649, 0.0022084984653625893] lr: [0.00421875]\n",
      "40 210 recon: [0.008230158738282353, 0.002225517380556051] lr: [0.00421875]\n",
      "40 240 recon: [0.008633179086403856, 0.002295660382163303] lr: [0.00421875]\n",
      "40 270 recon: [0.008354572827213635, 0.002589753660900913] lr: [0.00421875]\n",
      "40 300 recon: [0.008158675694865733, 0.002204093201579262] lr: [0.00421875]\n",
      "40 330 recon: [0.0077879779757368, 0.0025412256033101725] lr: [0.00421875]\n",
      "40 360 recon: [0.0081846394509503, 0.0023033515153853884] lr: [0.00421875]\n",
      "40 390 recon: [0.009310703547172621, 0.004365854983582374] lr: [0.00421875]\n",
      "41 0 recon: [0.008048151973763138, 0.0022840010094219362] lr: [0.00421875]\n",
      "41 30 recon: [0.007848846926135281, 0.0022918072695375597] lr: [0.00421875]\n",
      "41 60 recon: [0.008363976251842545, 0.0023749855867774648] lr: [0.00421875]\n",
      "41 90 recon: [0.00808541036107883, 0.0023681725615233374] lr: [0.00421875]\n",
      "41 120 recon: [0.008751975978862129, 0.002881635482046975] lr: [0.00421875]\n",
      "41 150 recon: [0.008295652789755659, 0.002506330676253984] lr: [0.00421875]\n",
      "41 180 recon: [0.0076873854636730484, 0.002202648595006217] lr: [0.00421875]\n",
      "41 210 recon: [0.00821375544782363, 0.0022208236965105613] lr: [0.00421875]\n",
      "41 240 recon: [0.008614537091161226, 0.0022892865059832056] lr: [0.00421875]\n",
      "41 270 recon: [0.008340812672606081, 0.0025788694585261326] lr: [0.00421875]\n",
      "41 300 recon: [0.008141579694222101, 0.0021997591198666534] lr: [0.00421875]\n",
      "41 330 recon: [0.0077742566298328744, 0.0025365808779364346] lr: [0.00421875]\n",
      "41 360 recon: [0.008168361649237694, 0.0023054604688230963] lr: [0.00421875]\n",
      "41 390 recon: [0.009194472161751104, 0.00427597233686102] lr: [0.00421875]\n",
      "42 0 recon: [0.00802835960918568, 0.002296169218965148] lr: [0.00421875]\n",
      "42 30 recon: [0.007828995865301896, 0.0023086013767282154] lr: [0.00421875]\n",
      "42 60 recon: [0.008340700577193702, 0.0023961274539942424] lr: [0.00421875]\n",
      "42 90 recon: [0.008063970017063377, 0.002388460713665953] lr: [0.00421875]\n",
      "42 120 recon: [0.008712125093045201, 0.0029146042428906727] lr: [0.00421875]\n",
      "42 150 recon: [0.008267321186322188, 0.0025321116308386496] lr: [0.00421875]\n",
      "42 180 recon: [0.00766488688809112, 0.0022241046824566873] lr: [0.00421875]\n",
      "42 210 recon: [0.008189530919623478, 0.0022419693589546315] lr: [0.00421875]\n",
      "42 240 recon: [0.008587821068714127, 0.0023115661825556313] lr: [0.00421875]\n",
      "42 270 recon: [0.008316383004771975, 0.002601424524940313] lr: [0.00421875]\n",
      "42 300 recon: [0.00811885255157326, 0.00221606733441704] lr: [0.00421875]\n",
      "42 330 recon: [0.00775627419753946, 0.002545957505132072] lr: [0.00421875]\n",
      "42 360 recon: [0.008151896935197828, 0.0023107574933580823] lr: [0.00421875]\n",
      "42 390 recon: [0.009091920605333837, 0.004177267036143032] lr: [0.00421875]\n",
      "43 0 recon: [0.008013342973423366, 0.0022944611292309318] lr: [0.00421875]\n",
      "43 30 recon: [0.007816465031009861, 0.0023031838924467926] lr: [0.00421875]\n",
      "43 60 recon: [0.008325969385282794, 0.0023908219488253976] lr: [0.00421875]\n",
      "43 90 recon: [0.008049773681831508, 0.0023864585534150782] lr: [0.00421875]\n",
      "43 120 recon: [0.00868219315253178, 0.0029195478740138745] lr: [0.00421875]\n",
      "43 150 recon: [0.008247933911413327, 0.002531122064365189] lr: [0.00421875]\n",
      "43 180 recon: [0.0076484064209091564, 0.0022256407944582918] lr: [0.00421875]\n",
      "43 210 recon: [0.008169597469589092, 0.0022487088310706184] lr: [0.00421875]\n",
      "43 240 recon: [0.008565137145598813, 0.0023189580838576377] lr: [0.00421875]\n",
      "43 270 recon: [0.008296639885445817, 0.0026080297020472103] lr: [0.00421875]\n",
      "43 300 recon: [0.008096080482630188, 0.0022301411357000763] lr: [0.00421875]\n",
      "43 330 recon: [0.007733959326959289, 0.0025658746164964772] lr: [0.00421875]\n",
      "43 360 recon: [0.008130388505489873, 0.0023316749027069627] lr: [0.00421875]\n",
      "43 390 recon: [0.008978397127331708, 0.004240075907860564] lr: [0.00421875]\n",
      "44 0 recon: [0.007990105389799005, 0.002319660113134764] lr: [0.00421875]\n",
      "44 30 recon: [0.007795153719148523, 0.0023260081386187632] lr: [0.00421875]\n",
      "44 60 recon: [0.008303283829563227, 0.002412572857936406] lr: [0.00421875]\n",
      "44 90 recon: [0.008030700194344133, 0.002401596868110983] lr: [0.00421875]\n",
      "44 120 recon: [0.008647582153179402, 0.00294132949420562] lr: [0.00421875]\n",
      "44 150 recon: [0.008225499304965451, 0.0025430700672197633] lr: [0.00421875]\n",
      "44 180 recon: [0.007632319366577268, 0.002229876955070723] lr: [0.00421875]\n",
      "44 210 recon: [0.008152166926433996, 0.002252163735743596] lr: [0.00421875]\n",
      "44 240 recon: [0.008545485971768504, 0.0023215765976275097] lr: [0.00421875]\n",
      "44 270 recon: [0.00828105848412564, 0.002607252531616761] lr: [0.00421875]\n",
      "44 300 recon: [0.008080019139008162, 0.0022263836873818344] lr: [0.00421875]\n",
      "44 330 recon: [0.007722879816279387, 0.0025565191887114455] lr: [0.00421875]\n",
      "44 360 recon: [0.008119604412227498, 0.0023204670715516705] lr: [0.00421875]\n",
      "44 390 recon: [0.009050124258537793, 0.00415431150365506] lr: [0.00421875]\n",
      "45 0 recon: [0.007978648393423944, 0.0023086584016150107] lr: [0.00421875]\n",
      "45 30 recon: [0.007784127192298708, 0.002317291911140929] lr: [0.00421875]\n",
      "45 60 recon: [0.008288418104024612, 0.0024110294743055457] lr: [0.00421875]\n",
      "45 90 recon: [0.008015240427619183, 0.002407095983830834] lr: [0.00421875]\n",
      "45 120 recon: [0.008615777739616024, 0.0029581306319325733] lr: [0.00421875]\n",
      "45 150 recon: [0.008203285842266653, 0.002556368344105114] lr: [0.00421875]\n",
      "45 180 recon: [0.007612203064152101, 0.0022487173245458094] lr: [0.00421875]\n",
      "45 210 recon: [0.008130180883957555, 0.0022731020886393566] lr: [0.00421875]\n",
      "45 240 recon: [0.008520719619840028, 0.002342733811548571] lr: [0.00421875]\n",
      "45 270 recon: [0.008258611663245095, 0.0026276733655690634] lr: [0.00421875]\n",
      "45 300 recon: [0.008056585084116833, 0.002248794472143061] lr: [0.00421875]\n",
      "45 330 recon: [0.007700634706009546, 0.0025806811147285015] lr: [0.00421875]\n",
      "45 360 recon: [0.008099581065891938, 0.002342959259114209] lr: [0.00421875]\n",
      "45 390 recon: [0.009029911382283142, 0.00432766056374337] lr: [0.00421875]\n",
      "46 0 recon: [0.007960134369024686, 0.002326077639780582] lr: [0.00421875]\n",
      "46 30 recon: [0.007769740985605401, 0.002324276684116142] lr: [0.00421875]\n",
      "46 60 recon: [0.008275712073119454, 0.0024086682251332975] lr: [0.00421875]\n",
      "46 90 recon: [0.00800714997060044, 0.002394909393490911] lr: [0.00421875]\n",
      "46 120 recon: [0.008597087855346826, 0.002946701786610167] lr: [0.00421875]\n",
      "46 150 recon: [0.008194784837810104, 0.0025366426376684467] lr: [0.00421875]\n",
      "46 180 recon: [0.0076088557350427735, 0.0022218424767220125] lr: [0.00421875]\n",
      "46 210 recon: [0.008123483140134252, 0.002250769378662519] lr: [0.00421875]\n",
      "46 240 recon: [0.00850999967752477, 0.0023230783055075053] lr: [0.00421875]\n",
      "46 270 recon: [0.008251646948952274, 0.0026077232387318435] lr: [0.00421875]\n",
      "46 300 recon: [0.008046085042713348, 0.002233280664126028] lr: [0.00421875]\n",
      "46 330 recon: [0.007694046507803018, 0.002563188989437814] lr: [0.00421875]\n",
      "46 360 recon: [0.008091263358924504, 0.0023305724280971093] lr: [0.00421875]\n",
      "46 390 recon: [0.009112239868818416, 0.004291440538862915] lr: [0.00421875]\n",
      "47 0 recon: [0.007948941274552134, 0.0023232693516569603] lr: [0.00421875]\n",
      "47 30 recon: [0.007755224656465773, 0.0023334524143116655] lr: [0.00421875]\n",
      "47 60 recon: [0.008255877422257085, 0.0024316278038335605] lr: [0.00421875]\n",
      "47 90 recon: [0.007987281965905998, 0.0024229204786516364] lr: [0.00421875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 120 recon: [0.00856072335724399, 0.0029884160401372115] lr: [0.00421875]\n",
      "47 150 recon: [0.008167575971088713, 0.0025770259127511] lr: [0.00421875]\n",
      "47 180 recon: [0.007583980820272096, 0.002268273513791824] lr: [0.00421875]\n",
      "47 210 recon: [0.008100088596741346, 0.002288364723073645] lr: [0.00421875]\n",
      "47 240 recon: [0.008485411431501638, 0.0023534831124202805] lr: [0.00421875]\n",
      "47 270 recon: [0.008231429919000936, 0.002630338621781104] lr: [0.00421875]\n",
      "47 300 recon: [0.00802739572044126, 0.0022495674197912066] lr: [0.00421875]\n",
      "47 330 recon: [0.007680812898744038, 0.0025698525390223303] lr: [0.00421875]\n",
      "47 360 recon: [0.008079754841554208, 0.002336965631705273] lr: [0.00421875]\n",
      "47 390 recon: [0.009117314803600245, 0.0043726611158651195] lr: [0.00421875]\n",
      "48 0 recon: [0.007941587261438177, 0.002319978265063999] lr: [0.00421875]\n",
      "48 30 recon: [0.007752984847825033, 0.002312309199170985] lr: [0.00421875]\n",
      "48 60 recon: [0.0082566582228058, 0.0023957505127427626] lr: [0.00421875]\n",
      "48 90 recon: [0.007990716393116036, 0.002383631164890113] lr: [0.00421875]\n",
      "48 120 recon: [0.008556336204283164, 0.002949384571578414] lr: [0.00421875]\n",
      "48 150 recon: [0.008170281877754862, 0.002534450636132506] lr: [0.00421875]\n",
      "48 180 recon: [0.007589916610975445, 0.002221803384163002] lr: [0.00421875]\n",
      "48 210 recon: [0.008098280204444922, 0.0022581575040537026] lr: [0.00421875]\n",
      "48 240 recon: [0.008475464990702057, 0.0023362906029427343] lr: [0.00421875]\n",
      "48 270 recon: [0.008221141244226971, 0.002624842988775875] lr: [0.00421875]\n",
      "48 300 recon: [0.008012663775369763, 0.0022540862637397637] lr: [0.00421875]\n",
      "48 330 recon: [0.007666197464465858, 0.002581305446938055] lr: [0.00421875]\n",
      "48 360 recon: [0.008065645376699635, 0.002355030996874586] lr: [0.00421875]\n",
      "48 390 recon: [0.009130804025385367, 0.004393533172780497] lr: [0.00421875]\n",
      "49 0 recon: [0.007926231826186599, 0.0023472436858062535] lr: [0.00421875]\n",
      "49 30 recon: [0.00773112752980966, 0.0023539182106682983] lr: [0.00421875]\n",
      "49 60 recon: [0.008229552250485972, 0.0024512883510773194] lr: [0.00421875]\n",
      "49 90 recon: [0.00796672285407493, 0.0024340300219052886] lr: [0.00421875]\n",
      "49 120 recon: [0.00851917603135136, 0.003006876743184333] lr: [0.00421875]\n",
      "49 150 recon: [0.00814380286367848, 0.0025892933859523017] lr: [0.00421875]\n",
      "49 180 recon: [0.007567168630481289, 0.002280222128108576] lr: [0.00421875]\n",
      "49 210 recon: [0.008080971798803025, 0.0022930693885587577] lr: [0.00421875]\n",
      "49 240 recon: [0.008460049107274974, 0.0023493011401300415] lr: [0.00421875]\n",
      "49 270 recon: [0.008216331025837291, 0.0026144162582135287] lr: [0.00421875]\n",
      "49 300 recon: [0.008008162633289153, 0.0022369479579906746] lr: [0.00421875]\n",
      "49 330 recon: [0.007672711901803503, 0.0025456025714879183] lr: [0.00421875]\n",
      "49 360 recon: [0.008071018704572826, 0.002327403238397244] lr: [0.00421875]\n",
      "49 390 recon: [0.00917436992301358, 0.004404942073462186] lr: [0.00421875]\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LowRankCodes(nn.Module):\n",
    "    '''\n",
    "    ranks: array of rank for each codebook matrix\n",
    "    '''\n",
    "    def __init__(self, ranks):\n",
    "        super(LowRankCodes, self).__init__()\n",
    "        self.As = []\n",
    "        for rank in ranks:\n",
    "            A = nn.Parameter(1e-2*torch.randn(rank,264).float().cuda())\n",
    "            self.As.append(A)\n",
    "        self.As = nn.ParameterList(self.As)\n",
    "\n",
    "    def forward(self):\n",
    "        book = []\n",
    "        for A in self.As:\n",
    "            AA = A.T@A\n",
    "            book.append(AA)\n",
    "        return torch.stack(book)\n",
    "    \n",
    "class LowRankWeights(nn.Module):\n",
    "    '''\n",
    "    For a single modality!\n",
    "    \n",
    "    nsubs: number of subjects\n",
    "    ncodes: number of pages in the codebook\n",
    "    nt: number of timepoints\n",
    "    '''\n",
    "    def __init__(self, nsubs, nmods, ncodes, nt):\n",
    "        super(LowRankWeights, self).__init__()\n",
    "        self.w = nn.Parameter(1e-2*torch.rand(nsubs, ncodes, nt).float().cuda())\n",
    "\n",
    "    def forward(self, sub, book):\n",
    "        w = self.w[sub]\n",
    "        return torch.einsum('pt,pab->abt', w, book)\n",
    "    \n",
    "def get_recon_loss(x, xhat):\n",
    "    return mseLoss(xhat, x)\n",
    "\n",
    "def get_smooth_loss_fc(xhat):\n",
    "    before = xhat[:,:,:-1]\n",
    "    after = xhat[:,:,1:]\n",
    "    return torch.mean((before-after)**2)\n",
    "\n",
    "def get_sub_fc(subts):\n",
    "    return torch.einsum('at,bt->abt',subts,subts)\n",
    "    \n",
    "# Timeseries\n",
    "x = torch.from_numpy(ts[0]).float().cuda()\n",
    "    \n",
    "# Parameters\n",
    "ntrain = 400\n",
    "nbatch = 30\n",
    "smooth_mult = 0.1\n",
    "nEpochs = 50\n",
    "pPeriod = 40\n",
    "\n",
    "mseLoss = nn.MSELoss()\n",
    "    \n",
    "# Codebook and weights\n",
    "lrc = LowRankCodes(100*[1])\n",
    "ncodes = len(lrc.As)\n",
    "\n",
    "lrw = LowRankWeights(ntrain, 1, ncodes, x.shape[-1])\n",
    "\n",
    "# Optimizers\n",
    "optim = torch.optim.Adam(itertools.chain(lrc.parameters(), lrw.parameters()), lr=1e-2, weight_decay=0)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=int(ntrain/nbatch)+5, factor=0.75, eps=1e-7)\n",
    "    \n",
    "for epoch in range(nEpochs):\n",
    "    suborder = np.arange(ntrain)\n",
    "#     np.random.shuffle(suborder)\n",
    "    for bstart in range(0,ntrain,nbatch):\n",
    "        bend = bstart+nbatch\n",
    "        if bend > ntrain:\n",
    "            bend = ntrain\n",
    "        optim.zero_grad()\n",
    "        book = lrc()\n",
    "        recon_loss = 0\n",
    "        smooth_loss_fc = 0\n",
    "        for subidx in range(bstart, bend):\n",
    "            sub = suborder[subidx]\n",
    "            xsub = get_sub_fc(x[sub])\n",
    "            xhat = lrw(sub, book)\n",
    "            recon_loss += get_recon_loss(xsub, xhat)\n",
    "            smooth_loss_fc += smooth_mult*get_smooth_loss_fc(xhat)\n",
    "        recon_loss /= (bend-bstart)\n",
    "        smooth_loss_fc /= (bend-bstart)\n",
    "        totloss = recon_loss+smooth_loss_fc\n",
    "        totloss.backward()\n",
    "        optim.step()\n",
    "        sched.step(totloss)\n",
    "        if bstart % nbatch == 0:\n",
    "            print(f'{epoch} {bstart} recon: {[float(ls)**0.5 for ls in [recon_loss, smooth_loss_fc]]} '\n",
    "                  f'lr: {sched._last_lr}')\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee21fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 0.0072065494023263454\n",
      "Finished 100 0.008164320141077042\n",
      "Finished 200 0.005845096427947283\n",
      "Finished 300 0.0074473656713962555\n",
      "Finished 400 0.007260077632963657\n",
      "Finished 500 0.006784871686249971\n",
      "Finished 600 0.00850341934710741\n",
      "Finished 700 0.007079832721501589\n",
      "Finished 800 0.007483322639018297\n",
      "torch.Size([847, 200, 124])\n"
     ]
    }
   ],
   "source": [
    "# Fast weight estimation for all subjects\n",
    "\n",
    "book = lrc()\n",
    "\n",
    "A = book.reshape(book.shape[0], -1).permute(1,0)\n",
    "AA = A.T@A\n",
    "codes = []\n",
    "\n",
    "for sub in range(x.shape[0]):\n",
    "    B = get_sub_fc(x[sub]).reshape(-1, x.shape[-1])\n",
    "    AB = A.T@B\n",
    "    C,_,_,_ = torch.linalg.lstsq(AA+0.1*torch.eye(AA.shape[0]).float().cuda(),AB)\n",
    "    codes.append(torch.from_numpy(C.detach().cpu().numpy()))\n",
    "    if sub % 100 == 0:\n",
    "        loss = mseLoss(A@C,B)**0.5\n",
    "        print(f'Finished {sub} {loss}')\n",
    "    \n",
    "codes = torch.stack(codes)\n",
    "print(codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ad9f9fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [61], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m reconfc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(reconfc, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     15\u001b[0m A \u001b[38;5;241m=\u001b[39m book\u001b[38;5;241m.\u001b[39mreshape(book\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m reconfc2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;129;43m@codes\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msub\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m264\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m264\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean((statfc\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m124\u001b[39m\u001b[38;5;241m*\u001b[39mdynfc)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Reconstruct static FC from dynamic FC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sub = 398\n",
    "\n",
    "dynfc = get_sub_fc(x[sub])\n",
    "dynfc = torch.mean(dynfc, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "statfc = np.corrcoef(ts[0][sub])\n",
    "\n",
    "reconfc = lrw(sub, book)\n",
    "reconfc = torch.mean(reconfc, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "A = book.reshape(book.shape[0], -1).permute(1,0)\n",
    "reconfc2 = torch.mean((A.cpu()@codes[sub]), dim=1).reshape(264,264).numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(10,3))\n",
    "\n",
    "print(np.mean((statfc-124*dynfc)**2)**0.5)\n",
    "print(np.mean((statfc-124*reconfc)**2)**0.5)\n",
    "print(np.mean((statfc-124*reconfc2)**2)**0.5)\n",
    "\n",
    "ax[0].imshow(dynfc)\n",
    "ax[1].imshow(statfc)\n",
    "ax[2].imshow(reconfc)\n",
    "ax[3].imshow(reconfc2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f07099ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.303897857666016, 36.489013671875, 33.918373107910156, 33.12736892700195, 32.28167724609375, 31.161489486694336, 29.461423873901367, 30.928251266479492, 31.118194580078125, 26.9007511138916]\n"
     ]
    }
   ],
   "source": [
    "ntrain = 30\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = torch.mean(codescuda, dim=-1) #ps.reshape(ps.shape[0],-1)\n",
    "    xps = torch.cat([xps, torch.ones(xps.shape[0], 1).float().cuda()], dim=1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    w, _, _, _ = torch.linalg.lstsq(xtr.T@xtr + 0.01*torch.eye(201).float().cuda(), xtr.T@ytr)\n",
    "\n",
    "#     print(torch.mean((ytr-xtr@w)**2)**0.5)\n",
    "    losses.append(float(torch.mean((yt-xt@w)**2)**0.5))\n",
    "    \n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed23ada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.07823944091797, 36.521366119384766, 33.62803268432617, 33.55487060546875, 32.20626449584961, 31.09649085998535, 29.927452087402344, 31.040786743164062, 31.461437225341797, 27.856002807617188]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, x, dp=0.1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = torch.nn.Conv2d(1,10,(x.shape[-2],4)).float().cuda()\n",
    "        self.ap1 = torch.nn.AvgPool2d((1,x.shape[-1]-3))\n",
    "        self.lin1 = torch.nn.Linear(10,1).float().cuda()\n",
    "        self.dp = nn.Dropout(p=dp)\n",
    "        \n",
    "    def forward(self, ts):\n",
    "        ts = self.dp(ts)\n",
    "        y = F.relu(self.cnn1(ts))\n",
    "        y = self.ap1(y)\n",
    "        z = y.reshape(y.shape[0], -1).squeeze()\n",
    "        y = self.lin1(z)\n",
    "        return z, y.squeeze()\n",
    "    \n",
    "nEpochs = 1000\n",
    "pPeriod = 200\n",
    "\n",
    "ntrain = 30\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = codescuda.unsqueeze(1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    cnn = CNN(xtr, dp=0)\n",
    "\n",
    "    optim = torch.optim.Adam(cnn.parameters(), lr=1e-1, weight_decay=1e-1)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        z, yhat1 = cnn(xtr)\n",
    "        loss = mseLoss(yhat1, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sched.step(loss)\n",
    "#         if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "#             print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "#     print('Complete')\n",
    "\n",
    "    cnn.eval()\n",
    "    z, yhat1 = cnn(xt)\n",
    "    loss = mseLoss(yhat1, yt)**0.5\n",
    "    losses.append(float(loss))\n",
    "    \n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09cb8144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../LatentSimilarity')\n",
    "\n",
    "from latsim import LatSim\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddf7cd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.11385726928711, 39.22460174560547, 37.47481918334961, 35.456817626953125, 34.131099700927734, 33.35258102416992, 31.382802963256836, 30.60487937927246, 30.524438858032227, 31.71627426147461]\n"
     ]
    }
   ],
   "source": [
    "ntrain = 800\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = codescuda.unsqueeze(1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    mseLoss = nn.MSELoss()\n",
    "\n",
    "    nEpochs = 500\n",
    "    pPeriod = 100\n",
    "\n",
    "    cnn = CNN(xtr, dp=0.1)\n",
    "    sim = LatSim(1, torch.zeros(1,1,10), dp=0, edp=0.1, wInit=1e-4, dim=20, temp=1)\n",
    "\n",
    "    optim = torch.optim.Adam(itertools.chain(cnn.parameters(), sim.parameters()), lr=1e-1, weight_decay=1e-2)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        z, yhat1 = cnn(xtr)\n",
    "        yhat2 = sim(z.unsqueeze(1), [ytr])[0][0]\n",
    "        loss = mseLoss(yhat2, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sched.step(loss)\n",
    "    #     if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "    #         print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "    # print('Complete')\n",
    "\n",
    "    cnn.eval()\n",
    "    sim.eval()\n",
    "    z, yhat1 = cnn(xps)\n",
    "    yhat2 = sim(z.unsqueeze(1), [y_t])[0][0][ntrain:]\n",
    "    loss = mseLoss(yhat2, yt)**0.5\n",
    "    losses.append(float(loss))\n",
    "    \n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea2c4bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.33172607421875, 39.20526123046875, 38.03037643432617, 35.90704345703125, 34.469017028808594, 34.209110260009766, 32.38001251220703, 32.26662826538086, 32.01296615600586, 32.053043365478516]\n"
     ]
    }
   ],
   "source": [
    "ntrain = 700\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = torch.mean(codescuda, dim=-1).unsqueeze(1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    mseLoss = nn.MSELoss()\n",
    "\n",
    "    nEpochs = 500\n",
    "    pPeriod = 100\n",
    "\n",
    "    sim = LatSim(1, torch.zeros(1,1,ncodes), dp=0.1, edp=0.1, wInit=1e-4, dim=2, temp=1)\n",
    "\n",
    "    optim = torch.optim.Adam(sim.parameters(), lr=1e-1, weight_decay=1e-2)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        yhat = sim(xtr, [ytr])[0][0]\n",
    "        loss = mseLoss(yhat, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sched.step(loss)\n",
    "#         if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "#             print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "#     print('Complete')\n",
    "\n",
    "    sim.eval()\n",
    "    yhat = sim(xps, [y_t])[0][0][ntrain:]\n",
    "    loss = mseLoss(yhat, yt)**0.5\n",
    "    losses.append(float(loss))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9cfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
