{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "338118a7",
   "metadata": {},
   "source": [
    "# Fast kSVD test using Ariel5's orthogonal mp pytorch implementation\n",
    "\n",
    "https://github.com/Ariel5/omp-parallel-gpu-python<br>\n",
    "https://github.com/nel215/ksvd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae302e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'wrat', 'missingage', 'missingsex', 'missingwrat', 'failedqc']\n",
      "['emoid', 'nback', 'rest']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Using newly preprocessed subjects\n",
    "\n",
    "import pickle\n",
    "\n",
    "metadictname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_agesexwrat.pkl'\n",
    "alltsname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_PowerTS_float2.pkl'\n",
    "\n",
    "with open(metadictname, 'rb') as f:\n",
    "    metadict = pickle.load(f)\n",
    "\n",
    "with open(alltsname, 'rb') as f:\n",
    "    allts = pickle.load(f)\n",
    "    \n",
    "print(list(metadict.keys()))\n",
    "print(list(allts.keys()))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e101ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'wrat', 'missingage', 'missingsex', 'missingwrat', 'failedqc']\n",
      "['emoid', 'nback', 'rest']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Using newly preprocessed subjects\n",
    "\n",
    "import pickle\n",
    "\n",
    "metadictname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_agesexwrat.pkl'\n",
    "alltsname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_PowerTS_float2.pkl'\n",
    "\n",
    "with open(metadictname, 'rb') as f:\n",
    "    metadict = pickle.load(f)\n",
    "\n",
    "with open(alltsname, 'rb') as f:\n",
    "    allts = pickle.load(f)\n",
    "    \n",
    "print(list(metadict.keys()))\n",
    "print(list(allts.keys()))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7052b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n",
      "(847, 264, 124)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get subjects that have all tasks and paras specified\n",
    "Functions for creating independent and response variables\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_subs(allts, metadict, tasks, paras):\n",
    "    # Get subs for all paras\n",
    "    for i,para in enumerate(paras):\n",
    "        tmpset = set([int(sub[4:]) for sub in allts[para].keys()])\n",
    "        if i == 0:\n",
    "            paraset = tmpset\n",
    "        else:\n",
    "            paraset = paraset.intersection(tmpset)\n",
    "    # Get subs for all tasks\n",
    "    for i,task in enumerate(tasks):\n",
    "        tmpset = set([sub for sub in metadict[task].keys()])\n",
    "        if i == 0:\n",
    "            taskset = tmpset\n",
    "        else:\n",
    "            taskset = paraset.intersection(tmpset)\n",
    "    # Remove QC failures\n",
    "    allsubs = taskset.intersection(paraset)\n",
    "    for badsub in metadict['failedqc']:\n",
    "        try:\n",
    "            allsubs.remove(int(badsub[4:]))\n",
    "        except:\n",
    "            pass\n",
    "    return allsubs\n",
    "\n",
    "def get_X(allts, paras, subs):\n",
    "    X = []\n",
    "    for para in paras:\n",
    "        pX = [allts[para][f'sub-{sub}'] for sub in subs]\n",
    "        pX = np.stack(pX)\n",
    "        X.append(pX)\n",
    "    return X\n",
    "\n",
    "def get_y(metadict, tasks, subs):\n",
    "    y = []\n",
    "    for task in tasks:\n",
    "        if task == 'age' or task == 'wrat':\n",
    "            var = [metadict[task][sub] for sub in subs]\n",
    "            var = np.array(var)\n",
    "            y.append(var)\n",
    "        if task == 'sex':\n",
    "            maleness = [metadict[task][sub] == 'M' for sub in subs]\n",
    "            maleness = np.array(maleness)\n",
    "            sex = np.stack([maleness, 1-maleness], axis=1)\n",
    "            y.append(sex)\n",
    "    return y\n",
    "\n",
    "subs = get_subs(allts, metadict, ['age'], ['rest', 'nback', 'emoid'])\n",
    "print(len(subs))\n",
    "\n",
    "X = get_X(allts, ['rest', 'nback', 'emoid'], subs)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77dfa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 34716)\n"
     ]
    }
   ],
   "source": [
    "# TS to condensed FC\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = [cutoff[0] / nyq, cutoff[1] / nyq]\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_bandpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "tr = 1.83\n",
    "\n",
    "def filter_design_ts(X):\n",
    "    Xs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        nX = butter_bandpass_filter(X[i], [0.01, 0.2], 1/tr)\n",
    "        Xs.append(nX)\n",
    "    return np.stack(Xs)\n",
    "\n",
    "def ts_to_flat_fc(X):\n",
    "    p = np.corrcoef(X)\n",
    "    a,b = np.triu_indices(p[0].shape[0], 1)\n",
    "    p = p[a,b]\n",
    "    return p\n",
    "\n",
    "p = [np.stack([ts_to_flat_fc(ts) for ts in filter_design_ts(Xp)]) for Xp in X]\n",
    "print(p[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74090fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import orthogonal_mp_gram\n",
    "import torch\n",
    "\n",
    "class ApproximateKSVD(object):\n",
    "    def __init__(self, n_components, max_iter=10, tol=1e-6,\n",
    "                 transform_n_nonzero_coefs=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_components:\n",
    "            Number of dictionary elements\n",
    "\n",
    "        max_iter:\n",
    "            Maximum number of iterations\n",
    "\n",
    "        tol:\n",
    "            tolerance for error\n",
    "\n",
    "        transform_n_nonzero_coefs:\n",
    "            Number of nonzero coefficients to target\n",
    "        \"\"\"\n",
    "        self.components_ = None\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.n_components = n_components\n",
    "        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n",
    "\n",
    "    def _update_dict(self, X, D, gamma):\n",
    "        for j in range(self.n_components):\n",
    "            I = gamma[:, j] > 0\n",
    "            if np.sum(I) == 0:\n",
    "                continue\n",
    "\n",
    "            D[j, :] = 0\n",
    "            g = gamma[I, j].T\n",
    "            r = X[I, :] - gamma[I, :].dot(D)\n",
    "            d = r.T.dot(g)\n",
    "            d /= np.linalg.norm(d)\n",
    "            g = r.dot(d)\n",
    "            D[j, :] = d\n",
    "            gamma[I, j] = g.T\n",
    "        return D, gamma\n",
    "\n",
    "    def _initialize(self, X):\n",
    "        if min(X.shape) < self.n_components:\n",
    "            D = np.random.randn(self.n_components, X.shape[1])\n",
    "        else:\n",
    "            X = torch.from_numpy(X).float().cuda()\n",
    "            u, s, vt = torch.linalg.svd(X, full_matrices=False)\n",
    "            u, s, vt = [mat.detach().cpu().numpy() for mat in [u, s, vt]]\n",
    "#           #sp.sparse.linalg.svds(X, k=self.n_components)\n",
    "            D = np.dot(np.diag(s), vt)[:self.n_components,:]\n",
    "        D /= np.linalg.norm(D, axis=1)[:, np.newaxis]\n",
    "        return D\n",
    "\n",
    "    def _transform(self, D, X):\n",
    "        gram = D.dot(D.T)\n",
    "        Xy = D.dot(X.T)\n",
    "\n",
    "        n_nonzero_coefs = self.transform_n_nonzero_coefs\n",
    "        if n_nonzero_coefs is None:\n",
    "            n_nonzero_coefs = int(0.1 * X.shape[1])\n",
    "\n",
    "        return orthogonal_mp_gram(\n",
    "            gram, Xy, n_nonzero_coefs=n_nonzero_coefs).T\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: shape = [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        D = self._initialize(X)\n",
    "        for i in range(self.max_iter):\n",
    "            print(f'Start iter {i}')\n",
    "            gamma = self._transform(D, X)\n",
    "            e = np.linalg.norm(X - gamma.dot(D))\n",
    "            if e < self.tol:\n",
    "                break\n",
    "            D, gamma = self._update_dict(X, D, gamma)\n",
    "\n",
    "        self.components_ = D\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._transform(self.components_, X)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc03e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start iter 0\n",
      "397.67435693740845 seconds\n",
      "(847, 800)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ncodes = 800\n",
    "nnzero = 100\n",
    "ntrain = max(ncodes, 400)\n",
    "\n",
    "idcs = np.arange(p[0].shape[0])\n",
    "np.random.shuffle(idcs)\n",
    "\n",
    "t0 = time.time()\n",
    "ksvd = ApproximateKSVD(n_components=ncodes, transform_n_nonzero_coefs=nnzero, max_iter=1)\n",
    "ksvd.fit(p[0][idcs[0:ntrain]])\n",
    "z = ksvd.transform(p[0])\n",
    "t1 = time.time()\n",
    "print(f'{t1-t0} seconds')\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56ef6249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48.3423, device='cuda:0')\n",
      "tensor(44.0789, device='cuda:0')\n",
      "tensor(38.8934, device='cuda:0')\n",
      "tensor(35.2361, device='cuda:0')\n",
      "tensor(34.5684, device='cuda:0')\n",
      "tensor(34.1900, device='cuda:0')\n",
      "tensor(34.1446, device='cuda:0')\n",
      "tensor(31.8684, device='cuda:0')\n",
      "tensor(31.6421, device='cuda:0')\n",
      "tensor(29.8326, device='cuda:0')\n",
      "Finished 0\n",
      "tensor(45.3498, device='cuda:0')\n",
      "tensor(41.4417, device='cuda:0')\n",
      "tensor(38.2623, device='cuda:0')\n",
      "tensor(35.8105, device='cuda:0')\n",
      "tensor(33.4743, device='cuda:0')\n",
      "tensor(32.7844, device='cuda:0')\n",
      "tensor(33.2585, device='cuda:0')\n",
      "tensor(32.3238, device='cuda:0')\n",
      "tensor(33.2109, device='cuda:0')\n",
      "tensor(31.4636, device='cuda:0')\n",
      "Finished 1\n",
      "tensor(49.3059, device='cuda:0')\n",
      "tensor(44.8776, device='cuda:0')\n",
      "tensor(37.0280, device='cuda:0')\n",
      "tensor(36.3713, device='cuda:0')\n",
      "tensor(34.9822, device='cuda:0')\n",
      "tensor(34.8250, device='cuda:0')\n",
      "tensor(34.4912, device='cuda:0')\n",
      "tensor(33.1836, device='cuda:0')\n",
      "tensor(32.3107, device='cuda:0')\n",
      "tensor(30.2710, device='cuda:0')\n",
      "Finished 2\n",
      "tensor(42.8598, device='cuda:0')\n",
      "tensor(40.9977, device='cuda:0')\n",
      "tensor(36.8013, device='cuda:0')\n",
      "tensor(34.8123, device='cuda:0')\n",
      "tensor(34.4454, device='cuda:0')\n",
      "tensor(34.4532, device='cuda:0')\n",
      "tensor(34.2981, device='cuda:0')\n",
      "tensor(34.3255, device='cuda:0')\n",
      "tensor(35.2747, device='cuda:0')\n",
      "tensor(33.6449, device='cuda:0')\n",
      "Finished 3\n",
      "tensor(52.8666, device='cuda:0')\n",
      "tensor(45.0830, device='cuda:0')\n",
      "tensor(38.3305, device='cuda:0')\n",
      "tensor(36.3652, device='cuda:0')\n",
      "tensor(34.9846, device='cuda:0')\n",
      "tensor(35.3246, device='cuda:0')\n",
      "tensor(34.6239, device='cuda:0')\n",
      "tensor(35.2647, device='cuda:0')\n",
      "tensor(36.2915, device='cuda:0')\n",
      "tensor(38.6391, device='cuda:0')\n",
      "Finished 4\n",
      "tensor(43.2045, device='cuda:0')\n",
      "tensor(39.6826, device='cuda:0')\n",
      "tensor(37.3732, device='cuda:0')\n",
      "tensor(34.9675, device='cuda:0')\n",
      "tensor(34.4525, device='cuda:0')\n",
      "tensor(33.6765, device='cuda:0')\n",
      "tensor(34.1286, device='cuda:0')\n",
      "tensor(33.6102, device='cuda:0')\n",
      "tensor(32.8472, device='cuda:0')\n",
      "tensor(34.1911, device='cuda:0')\n",
      "Finished 5\n",
      "tensor(43.7736, device='cuda:0')\n",
      "tensor(40.9037, device='cuda:0')\n",
      "tensor(38.8958, device='cuda:0')\n",
      "tensor(35.3281, device='cuda:0')\n",
      "tensor(34.0839, device='cuda:0')\n",
      "tensor(32.9744, device='cuda:0')\n",
      "tensor(33.2671, device='cuda:0')\n",
      "tensor(34.0094, device='cuda:0')\n",
      "tensor(32.4899, device='cuda:0')\n",
      "tensor(31.3164, device='cuda:0')\n",
      "Finished 6\n",
      "tensor(43.5833, device='cuda:0')\n",
      "tensor(41.3577, device='cuda:0')\n",
      "tensor(39.1889, device='cuda:0')\n",
      "tensor(37.9513, device='cuda:0')\n",
      "tensor(34.8253, device='cuda:0')\n",
      "tensor(34.6197, device='cuda:0')\n",
      "tensor(33.8201, device='cuda:0')\n",
      "tensor(33.5759, device='cuda:0')\n",
      "tensor(31.3064, device='cuda:0')\n",
      "tensor(31.2764, device='cuda:0')\n",
      "Finished 7\n",
      "tensor(45.0739, device='cuda:0')\n",
      "tensor(43.3218, device='cuda:0')\n",
      "tensor(38.3327, device='cuda:0')\n",
      "tensor(36.2179, device='cuda:0')\n",
      "tensor(34.7880, device='cuda:0')\n",
      "tensor(33.4892, device='cuda:0')\n",
      "tensor(31.4869, device='cuda:0')\n",
      "tensor(31.2185, device='cuda:0')\n",
      "tensor(30.3262, device='cuda:0')\n",
      "tensor(29.5415, device='cuda:0')\n",
      "Finished 8\n",
      "tensor(45.3376, device='cuda:0')\n",
      "tensor(37.8661, device='cuda:0')\n",
      "tensor(35.8090, device='cuda:0')\n",
      "tensor(35.3848, device='cuda:0')\n",
      "tensor(35.6828, device='cuda:0')\n",
      "tensor(34.0520, device='cuda:0')\n",
      "tensor(33.6967, device='cuda:0')\n",
      "tensor(33.6279, device='cuda:0')\n",
      "tensor(30.7939, device='cuda:0')\n",
      "tensor(27.9686, device='cuda:0')\n",
      "Finished 9\n",
      "[45.96972237 41.96107063 37.89153137 35.84450531 34.62874603 34.0388813\n",
      " 33.72157383 33.30080643 32.64934387 31.81450977]\n",
      "[3.06184617 2.21876603 1.03730859 0.8837653  0.55899346 0.77094137\n",
      " 0.86653166 1.14208891 1.79749194 2.87232242]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "nreps = 10\n",
    "trainsizes = [30,50,100,200,300,400,500,600,700,800]\n",
    "res = np.zeros((nreps,len(trainsizes)))\n",
    "l2 = 1e3\n",
    "\n",
    "for rep in range(nreps):\n",
    "    losses = []\n",
    "\n",
    "    idcs = np.arange(z.shape[0])\n",
    "    np.random.shuffle(idcs)\n",
    "\n",
    "    for ntrain in trainsizes:\n",
    "        xps = torch.from_numpy(np.asarray(z)).float().cuda()\n",
    "        xps = torch.cat([xps, torch.ones(xps.shape[0], 1).float().cuda()], dim=1)\n",
    "        xtr = xps[idcs[:ntrain]]\n",
    "        xt = xps[idcs[ntrain:]]\n",
    "\n",
    "        y = get_y(metadict, ['age'], subs)[0]\n",
    "        y_t = torch.from_numpy(y).float().cuda()\n",
    "        ytr = y_t[idcs[:ntrain]]\n",
    "        yt = y_t[idcs[ntrain:]]\n",
    "\n",
    "        # REDUCE THIS TO GET GOOD RESULTS WITH SPARSITY 0.01->0.001 or 0.0001\n",
    "        w, _, _, _ = torch.linalg.lstsq(xtr.T@xtr + l2*torch.eye(ncodes+1).float().cuda(), xtr.T@ytr)\n",
    "#         w, _, _, _ = torch.linalg.lstsq(xtr, ytr)\n",
    "\n",
    "        print(torch.mean((yt-xt@w)**2)**0.5)\n",
    "        losses.append(float(torch.mean((yt-xt@w)**2)**0.5))\n",
    "            \n",
    "    print(f'Finished {rep}')\n",
    "    res[rep,:] = losses\n",
    "    \n",
    "print(np.mean(res, axis=0))\n",
    "print(np.std(res, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d7a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.99235534667969\n",
      "39.626373291015625\n",
      "42.756378173828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m mlp \u001b[38;5;241m=\u001b[39m MLP(ncodes)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 1e-3 good for age 1e-2 good for wrat\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m loss \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mpredict(xt, yt)\n\u001b[1;32m     65\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(loss))\n",
      "Cell \u001b[0;32mIn [11], line 21\u001b[0m, in \u001b[0;36mMLP.train\u001b[0;34m(self, xtr, ytr, nepochs, lr, l1, l2, pperiod, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(xtr)\n\u001b[0;32m---> 21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmseLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43myhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     22\u001b[0m l1loss \u001b[38;5;241m=\u001b[39m l1\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mabs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1\u001b[38;5;241m.\u001b[39mweight))\n\u001b[1;32m     23\u001b[0m (loss\u001b[38;5;241m+\u001b[39ml1loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/torch/nn/modules/loss.py:530\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/torch/nn/functional.py:3280\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m   3279\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[0;32m-> 3280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "mseLoss = nn.MSELoss()\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, ncodes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Linear(ncodes, 40).float().cuda()\n",
    "        self.l2 = nn.Linear(40,1).float().cuda()\n",
    "        \n",
    "    def train(self, xtr, ytr, nepochs=1000, lr=1e-1, l1=1e-1, l2=1e-4, pperiod=100, verbose=False):\n",
    "        optim = torch.optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "        sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.75, eps=1e-7)\n",
    "        mseLoss = nn.MSELoss()\n",
    "        \n",
    "        for epoch in range(nepochs):\n",
    "            optim.zero_grad()\n",
    "            yhat = self(xtr)\n",
    "            loss = mseLoss(yhat, ytr)**0.5\n",
    "            l1loss = l1*torch.sum(torch.abs(self.l1.weight))\n",
    "            (loss+l1loss).backward()\n",
    "            optim.step()\n",
    "            sched.step(loss)\n",
    "            if verbose:\n",
    "                if epoch % pperiod == 0 or epoch == nepochs-1:\n",
    "                    print(f'{epoch} {[float(l) for l in [loss, l1loss]]} {sched._last_lr}')\n",
    "                    \n",
    "    def predict(self, xt, yt):\n",
    "        with torch.no_grad():\n",
    "            return mseLoss(self(xt), yt)**0.5\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x).squeeze()\n",
    "        return x\n",
    "    \n",
    "nreps = 10\n",
    "trainsizes = [30,50,100,200,300,400,500,600,700,800]\n",
    "res = np.zeros((nreps,len(trainsizes)))\n",
    "\n",
    "for rep in range(nreps):\n",
    "\n",
    "    idcs = np.arange(z.shape[0])\n",
    "    np.random.shuffle(idcs)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for ntrain in trainsizes:\n",
    "        xps = torch.from_numpy(np.asarray(z)).float().cuda()\n",
    "        xtr = xps[idcs[:ntrain]]\n",
    "        xt = xps[idcs[ntrain:]]\n",
    "\n",
    "        y = get_y(metadict, ['age'], subs)[0]\n",
    "        y_t = torch.from_numpy(y).float().cuda()\n",
    "        ytr = y_t[idcs[:ntrain]]\n",
    "        yt = y_t[idcs[ntrain:]]\n",
    "\n",
    "        mlp = MLP(ncodes)\n",
    "        # 1e-3 good for age 1e-2 good for wrat\n",
    "        mlp.train(xtr, ytr, lr=1e-2, nepochs=1000, l1=1e0, l2=1e-3)\n",
    "        loss = mlp.predict(xt, yt)\n",
    "\n",
    "        losses.append(float(loss))\n",
    "        print(float(loss))\n",
    "\n",
    "    res[rep,:] = losses\n",
    "    print(f'Finished {rep}')\n",
    "\n",
    "    print(np.mean(res, axis=0))\n",
    "    print(np.std(res, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68daca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
