{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87783615",
   "metadata": {},
   "source": [
    "# Try to train on PNC age data and predict fibromyalgia data age\n",
    "Will LatSim learn any relevant features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1022343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FC-slim', 'subjNum2IdxMap', 'subjIdx2NumMap', 'groupsNormalDiagMap']\n"
     ]
    }
   ],
   "source": [
    "# Get the fibromyalgia fc data\n",
    "\n",
    "import pickle\n",
    "\n",
    "fibrotsname = '/home/anton/Documents/Tulane/Research/ImageNomeR/data/fmri-FC-slim.pkl'\n",
    "\n",
    "with open(fibrotsname, 'rb') as f:\n",
    "    fibrodict = pickle.load(f)\n",
    "    \n",
    "print(list(fibrodict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7b2896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66,)\n",
      "(66, 34716)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "csvname = '/home/anton/Documents/Tulane/Hackathon/Clinical_fm_66_.csv'\n",
    "\n",
    "csv = pandas.read_csv(csvname)\n",
    "fibroage = []\n",
    "fibrofc = []\n",
    "\n",
    "for i in fibrodict['subjIdx2NumMap'].keys():\n",
    "    rid = int(fibrodict['subjIdx2NumMap'][i])\n",
    "    age = csv.loc[csv['rid'] == rid]['1_age']\n",
    "    if len(age) > 0:\n",
    "        fibroage.append(int(age))\n",
    "        fibrofc.append(fibrodict['FC-slim'][i])\n",
    "        \n",
    "fibroage = np.stack(fibroage)\n",
    "fibrofc = np.stack(fibrofc)\n",
    "\n",
    "print(fibroage.shape)\n",
    "print(fibrofc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "98f4507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5609, device='cuda:0')\n",
      "tensor(3.6682, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "ntrain = 60\n",
    "\n",
    "pca = PCA(n_components=10).fit(fibrofc)\n",
    "fb = pca.transform(fibrofc)\n",
    "\n",
    "x = torch.from_numpy(np.concatenate([fb, np.ones((fb.shape[0], 1))], axis=1)).float().cuda()\n",
    "xtr = x[:ntrain]\n",
    "xt = x[ntrain:]\n",
    "\n",
    "y = torch.from_numpy(fibroage).float().cuda()\n",
    "ytr = y[:ntrain]\n",
    "yt = y[ntrain:]\n",
    "\n",
    "w, _, _, _ = torch.linalg.lstsq(xtr.T@xtr+0.0001*torch.eye(11).float().cuda(), xtr.T@ytr)\n",
    "\n",
    "print(torch.mean((yt-torch.mean(ytr))**2)**0.5)\n",
    "print(torch.mean((yt-xt@w)**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "09cb8144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../LatentSimilarity')\n",
    "\n",
    "from latsim import LatSim\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "03f351bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8076, device='cuda:0')\n",
      "5.7591047286987305\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "ntrain = 20\n",
    "\n",
    "x = torch.from_numpy(fibrofc).unsqueeze(1).float().cuda()\n",
    "xtr = x[:ntrain]\n",
    "xt = x[ntrain:]\n",
    "\n",
    "y = torch.from_numpy(fibroage).float().cuda()\n",
    "ytr = y[:ntrain]\n",
    "yt = y[ntrain:]\n",
    "\n",
    "# mseLoss = nn.MSELoss()\n",
    "\n",
    "# nEpochs = 1000\n",
    "# pPeriod = 100\n",
    "\n",
    "# sim = LatSim(1, x, dp=0.5, edp=0.1, wInit=1e-4, dim=10, temp=1)\n",
    "\n",
    "# optim = torch.optim.Adam(sim.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "# sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "# for epoch in range(nEpochs):\n",
    "#     optim.zero_grad()\n",
    "#     yhat = sim(xtr, [ytr])[0][0]\n",
    "#     loss = mseLoss(yhat, ytr)\n",
    "#     loss.backward()\n",
    "#     optim.step()\n",
    "#     sched.step(loss)\n",
    "#     if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "#         print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "# print('Complete')\n",
    "\n",
    "sim.eval()\n",
    "yhat = sim(x, [y])[0][0][ntrain:]\n",
    "loss = mseLoss(yhat, yt)**0.5\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f4cd3b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'wrat', 'missingage', 'missingsex', 'missingwrat', 'failedqc']\n",
      "['emoid', 'nback', 'rest']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Using newly preprocessed subjects\n",
    "\n",
    "import pickle\n",
    "\n",
    "metadictname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_agesexwrat.pkl'\n",
    "alltsname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_PowerTS_float2.pkl'\n",
    "\n",
    "with open(metadictname, 'rb') as f:\n",
    "    metadict = pickle.load(f)\n",
    "\n",
    "with open(alltsname, 'rb') as f:\n",
    "    allts = pickle.load(f)\n",
    "    \n",
    "print(list(metadict.keys()))\n",
    "print(list(allts.keys()))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8d995126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n",
      "(847, 264, 124)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get subjects that have all tasks and paras specified\n",
    "Functions for creating independent and response variables\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_subs(allts, metadict, tasks, paras):\n",
    "    # Get subs for all paras\n",
    "    for i,para in enumerate(paras):\n",
    "        tmpset = set([int(sub[4:]) for sub in allts[para].keys()])\n",
    "        if i == 0:\n",
    "            paraset = tmpset\n",
    "        else:\n",
    "            paraset = paraset.intersection(tmpset)\n",
    "    # Get subs for all tasks\n",
    "    for i,task in enumerate(tasks):\n",
    "        tmpset = set([sub for sub in metadict[task].keys()])\n",
    "        if i == 0:\n",
    "            taskset = tmpset\n",
    "        else:\n",
    "            taskset = paraset.intersection(tmpset)\n",
    "    # Remove QC failures\n",
    "    allsubs = taskset.intersection(paraset)\n",
    "    for badsub in metadict['failedqc']:\n",
    "        try:\n",
    "            allsubs.remove(int(badsub[4:]))\n",
    "        except:\n",
    "            pass\n",
    "    return allsubs\n",
    "\n",
    "def get_X(allts, paras, subs):\n",
    "    X = []\n",
    "    for para in paras:\n",
    "        pX = [allts[para][f'sub-{sub}'] for sub in subs]\n",
    "        pX = np.stack(pX)\n",
    "        X.append(pX)\n",
    "    return X\n",
    "\n",
    "def get_y(metadict, tasks, subs):\n",
    "    y = []\n",
    "    for task in tasks:\n",
    "        if task == 'age' or task == 'wrat':\n",
    "            var = [metadict[task][sub] for sub in subs]\n",
    "            var = np.array(var)\n",
    "            y.append(var)\n",
    "        if task == 'sex':\n",
    "            maleness = [metadict[task][sub] == 'M' for sub in subs]\n",
    "            maleness = np.array(maleness)\n",
    "            sex = np.stack([maleness, 1-maleness], axis=1)\n",
    "            y.append(sex)\n",
    "    return y\n",
    "\n",
    "subs = get_subs(allts, metadict, ['age'], ['rest', 'nback', 'emoid'])\n",
    "print(len(subs))\n",
    "\n",
    "X = get_X(allts, ['rest', 'nback', 'emoid'], subs)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "807e832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847, 34716)\n"
     ]
    }
   ],
   "source": [
    "# TS to condensed FC\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = [cutoff[0] / nyq, cutoff[1] / nyq]\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_bandpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "tr = 1.83\n",
    "\n",
    "def filter_design_ts(X):\n",
    "    Xs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        nX = butter_bandpass_filter(X[i], [0.01, 0.2], 1/tr)\n",
    "        Xs.append(nX)\n",
    "    return np.stack(Xs)\n",
    "\n",
    "def ts_to_flat_fc(X):\n",
    "    p = np.corrcoef(X)\n",
    "    a,b = np.triu_indices(p[0].shape[0], 1)\n",
    "    p = p[a,b]\n",
    "    return p\n",
    "\n",
    "p = [np.stack([ts_to_flat_fc(ts) for ts in filter_design_ts(Xp)]) for Xp in X]\n",
    "print(p[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9ab4b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 recon: 35.21892166137695 [0.0001]\n",
      "100 recon: 6.035109996795654 [8.1e-05]\n",
      "200 recon: 4.178535461425781 [3.874204890000002e-05]\n",
      "300 recon: 4.6053924560546875 [1.5009463529699922e-05]\n",
      "400 recon: 3.9806344509124756 [7.1789798769185315e-06]\n",
      "500 recon: 5.758667945861816 [2.7812838944369375e-06]\n",
      "600 recon: 6.326016902923584 [1.0775263664305828e-06]\n",
      "700 recon: 4.762712001800537 [9.697737297875246e-07]\n",
      "800 recon: 3.31640887260437 [9.697737297875246e-07]\n",
      "900 recon: 4.184307098388672 [9.697737297875246e-07]\n",
      "999 recon: 4.126438617706299 [9.697737297875246e-07]\n",
      "Complete\n",
      "38.15674591064453\n"
     ]
    }
   ],
   "source": [
    "ntrain = 50\n",
    "\n",
    "x = torch.from_numpy(p[0]).unsqueeze(1).float().cuda()\n",
    "xtr = x[:ntrain]\n",
    "xt = x[ntrain:]\n",
    "\n",
    "y = get_y(metadict, ['age'], subs)[0]\n",
    "y_t = torch.from_numpy(y).float().cuda()\n",
    "ytr = y_t[:ntrain]\n",
    "yt = y_t[ntrain:]\n",
    "\n",
    "mseLoss = nn.MSELoss()\n",
    "\n",
    "nEpochs = 1000\n",
    "pPeriod = 100\n",
    "\n",
    "sim = LatSim(1, x, dp=0.3, edp=0.1, wInit=1e-4, dim=1, temp=1)\n",
    "\n",
    "optim = torch.optim.Adam(sim.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "for epoch in range(nEpochs):\n",
    "    optim.zero_grad()\n",
    "    yhat = sim(xtr, [ytr])[0][0]\n",
    "    loss = mseLoss(yhat, ytr)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    sched.step(loss)\n",
    "    if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "        print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "print('Complete')\n",
    "\n",
    "sim.eval()\n",
    "yhat = sim(x, [y_t])[0][0][ntrain:]\n",
    "loss = mseLoss(yhat, yt)**0.5\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d7893693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 recon: [0.006931878057287242, 5.054098581481911e-06] lr: [0.01]\n",
      "0 30 recon: [0.007252615866164383, 5.069046498124369e-06] lr: [0.01]\n",
      "0 60 recon: [0.007207318799926511, 5.0734193671780404e-06] lr: [0.01]\n",
      "0 90 recon: [0.007554061423944718, 5.0869478431888015e-06] lr: [0.01]\n",
      "0 120 recon: [0.008664171841262957, 5.099513035209801e-06] lr: [0.01]\n",
      "0 150 recon: [0.007751345164208635, 5.11643584323018e-06] lr: [0.01]\n",
      "0 180 recon: [0.00735320598659946, 5.132490740223583e-06] lr: [0.01]\n",
      "0 210 recon: [0.007052520547498541, 5.151676294822728e-06] lr: [0.01]\n",
      "0 240 recon: [0.008216108307432206, 5.1674755116092385e-06] lr: [0.01]\n",
      "0 270 recon: [0.007459870688218595, 5.1904628279662914e-06] lr: [0.01]\n",
      "0 300 recon: [0.006873753959932207, 5.213338638126864e-06] lr: [0.01]\n",
      "0 330 recon: [0.007477348171786484, 5.234373735559109e-06] lr: [0.01]\n",
      "0 360 recon: [0.007769009351238047, 5.2642294895775884e-06] lr: [0.01]\n",
      "0 390 recon: [0.008794059177484395, 5.292160037638664e-06] lr: [0.01]\n",
      "1 0 recon: [0.0069309561520436, 5.328354546941792e-06] lr: [0.01]\n",
      "1 30 recon: [0.007251505720051467, 5.36906357662838e-06] lr: [0.01]\n",
      "1 60 recon: [0.0072061002020575235, 5.401837283688857e-06] lr: [0.01]\n",
      "1 90 recon: [0.007552720792450269, 5.447232732555282e-06] lr: [0.01]\n",
      "1 120 recon: [0.008662809198665057, 5.498123378145573e-06] lr: [0.01]\n",
      "1 150 recon: [0.007749484261596972, 5.55914238260339e-06] lr: [0.01]\n",
      "1 180 recon: [0.007350989926886515, 5.626189587531755e-06] lr: [0.01]\n",
      "1 210 recon: [0.00705012380116778, 5.70761524243966e-06] lr: [0.01]\n",
      "1 240 recon: [0.00821357916657056, 5.7865358225136985e-06] lr: [0.01]\n",
      "1 270 recon: [0.007456732338876951, 5.892335955284441e-06] lr: [0.01]\n",
      "1 300 recon: [0.006870217616991543, 6.007688993590881e-06] lr: [0.01]\n",
      "1 330 recon: [0.007473505274154711, 6.129389838913707e-06] lr: [0.01]\n",
      "1 360 recon: [0.007765376614972941, 6.283069581416883e-06] lr: [0.01]\n",
      "1 390 recon: [0.008789919275008594, 6.445644716868947e-06] lr: [0.01]\n",
      "2 0 recon: [0.006925434750774704, 6.638076636152149e-06] lr: [0.01]\n",
      "2 30 recon: [0.007244867884819679, 6.872697195271433e-06] lr: [0.01]\n",
      "2 60 recon: [0.007198887122978394, 7.106816570338765e-06] lr: [0.01]\n",
      "2 90 recon: [0.007544840283916121, 7.394697958185201e-06] lr: [0.01]\n",
      "2 120 recon: [0.008654778901543127, 7.745734099463537e-06] lr: [0.01]\n",
      "2 150 recon: [0.007738581646298577, 8.11815335348289e-06] lr: [0.01]\n",
      "2 180 recon: [0.007338142075252449, 8.58278144251859e-06] lr: [0.01]\n",
      "2 210 recon: [0.007036399631914376, 9.157850916148206e-06] lr: [0.01]\n",
      "2 240 recon: [0.008198951027547774, 9.661446484284877e-06] lr: [0.01]\n",
      "2 270 recon: [0.00743892302413731, 1.04411606837994e-05] lr: [0.01]\n",
      "2 300 recon: [0.0068505147178636126, 1.1176015559889371e-05] lr: [0.01]\n",
      "2 330 recon: [0.007452067982027254, 1.1980064454296342e-05] lr: [0.01]\n",
      "2 360 recon: [0.007745302230528338, 1.3025974410918902e-05] lr: [0.01]\n",
      "2 390 recon: [0.008764155929908072, 1.5660239576795515e-05] lr: [0.01]\n",
      "3 0 recon: [0.0068959471691318955, 1.5352883573600524e-05] lr: [0.01]\n",
      "3 30 recon: [0.007209152870743141, 1.7052063746002263e-05] lr: [0.01]\n",
      "3 60 recon: [0.007160944027251213, 1.8466322252272327e-05] lr: [0.01]\n",
      "3 90 recon: [0.007504043308000021, 2.05211429431157e-05] lr: [0.01]\n",
      "3 120 recon: [0.00861212622578947, 2.3215456795793937e-05] lr: [0.01]\n",
      "3 150 recon: [0.007681790439866767, 2.5482324314437004e-05] lr: [0.01]\n",
      "3 180 recon: [0.007273539405238458, 2.8620886300291493e-05] lr: [0.01]\n",
      "3 210 recon: [0.006970026068795076, 3.202901217760393e-05] lr: [0.01]\n",
      "3 240 recon: [0.00812354359761326, 3.676098043881146e-05] lr: [0.01]\n",
      "3 270 recon: [0.007353521381239139, 4.204259710435449e-05] lr: [0.01]\n",
      "3 300 recon: [0.006763426247578573, 4.550360105848743e-05] lr: [0.01]\n",
      "3 330 recon: [0.007354214459815449, 5.294112473874078e-05] lr: [0.01]\n",
      "3 360 recon: [0.007655399349607611, 6.282806335979507e-05] lr: [0.01]\n",
      "3 390 recon: [0.008600654811768525, 0.00015230903066340456] lr: [0.01]\n",
      "4 0 recon: [0.006780702453678978, 7.931184725172594e-05] lr: [0.01]\n",
      "4 30 recon: [0.007060186162465945, 0.00010095322371772987] lr: [0.01]\n",
      "4 60 recon: [0.007015183673196221, 0.00010934659717662337] lr: [0.01]\n",
      "4 90 recon: [0.007356064328323651, 0.00013383192040404194] lr: [0.01]\n",
      "4 120 recon: [0.008432474806781321, 0.0001697267823324024] lr: [0.01]\n",
      "4 150 recon: [0.007454146378779863, 0.00019027197444309584] lr: [0.01]\n",
      "4 180 recon: [0.0070450182933055145, 0.00021782490317888458] lr: [0.01]\n",
      "4 210 recon: [0.006759463796528917, 0.00024559480358628976] lr: [0.01]\n",
      "4 240 recon: [0.007816008435677414, 0.0003103470819615824] lr: [0.01]\n",
      "4 270 recon: [0.007063591347785159, 0.00036969476170611854] lr: [0.01]\n",
      "4 300 recon: [0.006539170587073921, 0.00038190182040998845] lr: [0.01]\n",
      "4 330 recon: [0.007041764799820966, 0.00046220955900796616] lr: [0.01]\n",
      "4 360 recon: [0.007358308524115285, 0.0005519649373879742] lr: [0.01]\n",
      "4 390 recon: [0.007956391369960574, 0.001377612960667267] lr: [0.01]\n",
      "5 0 recon: [0.006481362621210376, 0.0006713576566233856] lr: [0.01]\n",
      "5 30 recon: [0.006592756826209324, 0.0008538155798645393] lr: [0.01]\n",
      "5 60 recon: [0.006589155528903222, 0.0008845463916237238] lr: [0.01]\n",
      "5 90 recon: [0.006957907947860961, 0.001000348672326137] lr: [0.01]\n",
      "5 120 recon: [0.00784173771326995, 0.0011430929482517146] lr: [0.01]\n",
      "5 150 recon: [0.006749380535581765, 0.0012435498954746205] lr: [0.01]\n",
      "5 180 recon: [0.0064112811305647895, 0.0013231897349915956] lr: [0.01]\n",
      "5 210 recon: [0.006143098864633721, 0.0014093716580779658] lr: [0.01]\n",
      "5 240 recon: [0.006929579495374003, 0.0015358678376980275] lr: [0.01]\n",
      "5 270 recon: [0.0062689698312747705, 0.0017424198719709308] lr: [0.01]\n",
      "5 300 recon: [0.005911980236375567, 0.0016565690725543446] lr: [0.01]\n",
      "5 330 recon: [0.006245941247268935, 0.001756786713648919] lr: [0.01]\n",
      "5 360 recon: [0.006567343138730919, 0.0018070059157112898] lr: [0.01]\n",
      "5 390 recon: [0.008057171179179269, 0.002319049660683103] lr: [0.01]\n",
      "6 0 recon: [0.005847516266019922, 0.001726268927585368] lr: [0.01]\n",
      "6 30 recon: [0.005894898476325759, 0.0018671047725278122] lr: [0.01]\n",
      "6 60 recon: [0.0060475408311828766, 0.001656012887405] lr: [0.01]\n",
      "6 90 recon: [0.006563962343467027, 0.001531336159934093] lr: [0.01]\n",
      "6 120 recon: [0.007422161881022094, 0.0015710225700899883] lr: [0.01]\n",
      "6 150 recon: [0.006403272188108925, 0.001507096775472796] lr: [0.01]\n",
      "6 180 recon: [0.006234886956156886, 0.0013395524474749299] lr: [0.01]\n",
      "6 210 recon: [0.006095865939492077, 0.0011676392120903622] lr: [0.01]\n",
      "6 240 recon: [0.006827345039605263, 0.0013617920764328747] lr: [0.01]\n",
      "6 270 recon: [0.006382394094856576, 0.0013762908612402977] lr: [0.01]\n",
      "6 300 recon: [0.006109212958089084, 0.0012281014372425613] lr: [0.01]\n",
      "6 330 recon: [0.006423896961489947, 0.0013097753739343262] lr: [0.01]\n",
      "6 360 recon: [0.006717645329858468, 0.0014487447625141485] lr: [0.01]\n",
      "6 390 recon: [0.00930630874192133, 0.005925629406911529] lr: [0.01]\n",
      "7 0 recon: [0.006057596925653619, 0.0011248443023658629] lr: [0.01]\n",
      "7 30 recon: [0.006102611057485117, 0.0012477979769654052] lr: [0.01]\n",
      "7 60 recon: [0.006206293518387816, 0.0010791396426389262] lr: [0.01]\n",
      "7 90 recon: [0.0066639960742753005, 0.001108536304627518] lr: [0.01]\n",
      "7 120 recon: [0.007497907563351449, 0.0012958736497988934] lr: [0.01]\n",
      "7 150 recon: [0.006483641372987515, 0.0012802881899993451] lr: [0.0075]\n",
      "7 180 recon: [0.006263893789811064, 0.0012405574155502986] lr: [0.0075]\n",
      "7 210 recon: [0.006065403140467833, 0.0011907780071334004] lr: [0.0075]\n",
      "7 240 recon: [0.006842816246822128, 0.001340540470616343] lr: [0.0075]\n",
      "7 270 recon: [0.0063206592599593095, 0.0014166711596809252] lr: [0.0075]\n",
      "7 300 recon: [0.005983671253442567, 0.0013202734022293976] lr: [0.0075]\n",
      "7 330 recon: [0.0063710515168811585, 0.0013598828116631158] lr: [0.0075]\n",
      "7 360 recon: [0.0066939190350250415, 0.0014569738105891996] lr: [0.0075]\n",
      "7 390 recon: [0.00893627296361341, 0.0057220458984375] lr: [0.0075]\n",
      "8 0 recon: [0.006028798355838588, 0.0011243638695602064] lr: [0.0075]\n",
      "8 30 recon: [0.00614168599521137, 0.0011534416361834974] lr: [0.0075]\n",
      "8 60 recon: [0.006255972674792649, 0.000983758625872271] lr: [0.0075]\n",
      "8 90 recon: [0.006715792683276485, 0.0009835767117073032] lr: [0.0075]\n",
      "8 120 recon: [0.007572184161508598, 0.0011461069507354548] lr: [0.0075]\n",
      "8 150 recon: [0.006558902165704814, 0.0011169931041246613] lr: [0.0075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 180 recon: [0.0063175406305075186, 0.001073335870150546] lr: [0.0075]\n",
      "8 210 recon: [0.006104630428071503, 0.0010289049841461437] lr: [0.0075]\n",
      "8 240 recon: [0.00688838133533527, 0.0011988295465278148] lr: [0.0075]\n",
      "8 270 recon: [0.006348056562803892, 0.001242223260301122] lr: [0.0075]\n",
      "8 300 recon: [0.005993623281862925, 0.001127199220128288] lr: [0.005625]\n",
      "8 330 recon: [0.0063765902583937245, 0.0011995162146295985] lr: [0.005625]\n",
      "8 360 recon: [0.006702081132045309, 0.001268890108924891] lr: [0.005625]\n",
      "8 390 recon: [0.007684926351586409, 0.001958847858425072] lr: [0.005625]\n",
      "9 0 recon: [0.005979666031678252, 0.0011609843078501667] lr: [0.005625]\n",
      "9 30 recon: [0.006021822249210598, 0.0013645024181509957] lr: [0.005625]\n",
      "9 60 recon: [0.006115107257893097, 0.0012721469812405197] lr: [0.005625]\n",
      "9 90 recon: [0.006564391030374997, 0.0013385813607832565] lr: [0.005625]\n",
      "9 120 recon: [0.00732597737259428, 0.0016051579663726172] lr: [0.005625]\n",
      "9 150 recon: [0.006279757604782522, 0.0016074274668818618] lr: [0.005625]\n",
      "9 180 recon: [0.006073511104381395, 0.0015576865071870497] lr: [0.005625]\n",
      "9 210 recon: [0.005890772067012486, 0.001487665526424081] lr: [0.005625]\n",
      "9 240 recon: [0.006510497567051669, 0.0017578265370447586] lr: [0.005625]\n",
      "9 270 recon: [0.006083139441537033, 0.0017717221976445898] lr: [0.005625]\n",
      "9 300 recon: [0.005803102181399365, 0.0015487654749387393] lr: [0.005625]\n",
      "9 330 recon: [0.006136995817112736, 0.0016607737143463064] lr: [0.005625]\n",
      "9 360 recon: [0.006453621698392644, 0.0017479144266509315] lr: [0.005625]\n",
      "9 390 recon: [0.007307967644228019, 0.0025028824962636644] lr: [0.005625]\n",
      "10 0 recon: [0.005824705150343161, 0.00155701008673545] lr: [0.005625]\n",
      "10 30 recon: [0.005844992006778593, 0.0018240456119523183] lr: [0.005625]\n",
      "10 60 recon: [0.005998734562373134, 0.0016613896189542478] lr: [0.005625]\n",
      "10 90 recon: [0.006474893515254629, 0.0016894037694583112] lr: [0.005625]\n",
      "10 120 recon: [0.007197181607436002, 0.001967304140644593] lr: [0.005625]\n",
      "10 150 recon: [0.0061811934205035935, 0.0018871229201278881] lr: [0.005625]\n",
      "10 180 recon: [0.006013785850738588, 0.0017426466541255676] lr: [0.005625]\n",
      "10 210 recon: [0.005853196452896002, 0.0015684875373972891] lr: [0.005625]\n",
      "10 240 recon: [0.006430265466600656, 0.001846821770177286] lr: [0.005625]\n",
      "10 270 recon: [0.006059082240310562, 0.0017585222340683845] lr: [0.005625]\n",
      "10 300 recon: [0.005794768111739801, 0.001467039869824697] lr: [0.005625]\n",
      "10 330 recon: [0.006130227704329079, 0.0015732299568642393] lr: [0.005625]\n",
      "10 360 recon: [0.006452697427700752, 0.0016447288010036077] lr: [0.005625]\n",
      "10 390 recon: [0.007305252333371838, 0.0020908411696160195] lr: [0.005625]\n",
      "11 0 recon: [0.0058401202442186296, 0.0014015395969584018] lr: [0.005625]\n",
      "11 30 recon: [0.005868981788373469, 0.0016517051362553924] lr: [0.005625]\n",
      "11 60 recon: [0.006014959924411198, 0.0014920024376591276] lr: [0.005625]\n",
      "11 90 recon: [0.006487842659624666, 0.0015115751452996482] lr: [0.005625]\n",
      "11 120 recon: [0.007214773052252059, 0.0018087591209132725] lr: [0.005625]\n",
      "11 150 recon: [0.006199637147078887, 0.0017219811213697118] lr: [0.005625]\n",
      "11 180 recon: [0.006031475497527533, 0.001585553031488883] lr: [0.005625]\n",
      "11 210 recon: [0.005867567395008146, 0.0014097960529358907] lr: [0.005625]\n",
      "11 240 recon: [0.00643878778327523, 0.0017443342624706946] lr: [0.005625]\n",
      "11 270 recon: [0.0060770761513000765, 0.0016423815423184328] lr: [0.005625]\n",
      "11 300 recon: [0.005806944448149528, 0.0013784866594596461] lr: [0.005625]\n",
      "11 330 recon: [0.006133099622520021, 0.001519408215171316] lr: [0.005625]\n",
      "11 360 recon: [0.006443417222610918, 0.0016252084310380813] lr: [0.005625]\n",
      "11 390 recon: [0.007274515914258372, 0.001969220271098821] lr: [0.005625]\n",
      "12 0 recon: [0.005832987091361985, 0.0013962492247775794] lr: [0.005625]\n",
      "12 30 recon: [0.005857082566695832, 0.0016592624492127884] lr: [0.005625]\n",
      "12 60 recon: [0.006004634919895334, 0.0015009397707039902] lr: [0.005625]\n",
      "12 90 recon: [0.006473486466813731, 0.001526777852022887] lr: [0.005625]\n",
      "12 120 recon: [0.007185701760042398, 0.0018627037382448087] lr: [0.005625]\n",
      "12 150 recon: [0.006175353068131459, 0.0017630024616200036] lr: [0.005625]\n",
      "12 180 recon: [0.006011595569562236, 0.0016216042067542945] lr: [0.005625]\n",
      "12 210 recon: [0.005847892649127902, 0.0014350716702883385] lr: [0.005625]\n",
      "12 240 recon: [0.006388223410494471, 0.0018227397730405798] lr: [0.005625]\n",
      "12 270 recon: [0.006053335921978028, 0.0016929398037029964] lr: [0.005625]\n",
      "12 300 recon: [0.00578754669079072, 0.0014233271277374524] lr: [0.005625]\n",
      "12 330 recon: [0.006104003171521747, 0.0015799924944692456] lr: [0.005625]\n",
      "12 360 recon: [0.006404041976562652, 0.0017010499136525718] lr: [0.005625]\n",
      "12 390 recon: [0.0072141850841882585, 0.0020712171625310726] lr: [0.005625]\n",
      "13 0 recon: [0.00581172289587775, 0.0014423609156272567] lr: [0.005625]\n",
      "13 30 recon: [0.005833665315382858, 0.0017000073951729034] lr: [0.005625]\n",
      "13 60 recon: [0.005988345132113447, 0.0015244516761035703] lr: [0.005625]\n",
      "13 90 recon: [0.006454753813030551, 0.00154340071522247] lr: [0.005625]\n",
      "13 120 recon: [0.007161226740708404, 0.0018936164767196961] lr: [0.005625]\n",
      "13 150 recon: [0.0061568974561828915, 0.0017721197985162563] lr: [0.005625]\n",
      "13 180 recon: [0.005997133603621596, 0.00162186141127361] lr: [0.005625]\n",
      "13 210 recon: [0.005828857421875, 0.0014301095238870246] lr: [0.005625]\n",
      "13 240 recon: [0.006361202997643674, 0.0018421759233690346] lr: [0.005625]\n",
      "13 270 recon: [0.006041529729973396, 0.001685531875628151] lr: [0.005625]\n",
      "13 300 recon: [0.00577805383634173, 0.001418849937381387] lr: [0.005625]\n",
      "13 330 recon: [0.006089285414674904, 0.0015787540398976493] lr: [0.005625]\n",
      "13 360 recon: [0.00638413663876843, 0.0017070762271985788] lr: [0.005625]\n",
      "13 390 recon: [0.007181576670309249, 0.002070248915522757] lr: [0.005625]\n",
      "14 0 recon: [0.005800402111429466, 0.0014335865506858601] lr: [0.005625]\n",
      "14 30 recon: [0.005821355515830115, 0.0016835723652673972] lr: [0.005625]\n",
      "14 60 recon: [0.005977539324717585, 0.0015058777917417686] lr: [0.005625]\n",
      "14 90 recon: [0.006437425682850666, 0.0015279006974675028] lr: [0.005625]\n",
      "14 120 recon: [0.007141766355272799, 0.0018913179503548595] lr: [0.005625]\n",
      "14 150 recon: [0.006139641186264074, 0.0017622720846048358] lr: [0.005625]\n",
      "14 180 recon: [0.005980923444987007, 0.0016133175537226061] lr: [0.005625]\n",
      "14 210 recon: [0.0058032444865041225, 0.0014278163157393168] lr: [0.005625]\n",
      "14 240 recon: [0.006332657705267744, 0.0018630575143209426] lr: [0.005625]\n",
      "14 270 recon: [0.006024031760709805, 0.0016865726241223704] lr: [0.005625]\n",
      "14 300 recon: [0.005763938140955938, 0.0014250414694341933] lr: [0.005625]\n",
      "14 330 recon: [0.006067199550651877, 0.001592314282183521] lr: [0.005625]\n",
      "14 360 recon: [0.0063553643536588, 0.0017313098991259517] lr: [0.005625]\n",
      "14 390 recon: [0.007129398746984325, 0.0021093925300050198] lr: [0.005625]\n",
      "15 0 recon: [0.005780897445395954, 0.0014459460001958783] lr: [0.005625]\n",
      "15 30 recon: [0.005797226071049291, 0.0016955402062488498] lr: [0.005625]\n",
      "15 60 recon: [0.005956691615983504, 0.0015155482763092366] lr: [0.005625]\n",
      "15 90 recon: [0.00640818105663748, 0.0015428060174374008] lr: [0.005625]\n",
      "15 120 recon: [0.007110136758130591, 0.0019191753174762022] lr: [0.005625]\n",
      "15 150 recon: [0.006110350536941843, 0.0017819652142233185] lr: [0.005625]\n",
      "15 180 recon: [0.005953931661635636, 0.0016298567500089177] lr: [0.005625]\n",
      "15 210 recon: [0.005766579264465266, 0.001448583649209286] lr: [0.005625]\n",
      "15 240 recon: [0.006296073187276645, 0.0019030683890370755] lr: [0.005625]\n",
      "15 270 recon: [0.005998613876075436, 0.0017039141843996162] lr: [0.005625]\n",
      "15 300 recon: [0.005745297555963032, 0.0014416107485750985] lr: [0.005625]\n",
      "15 330 recon: [0.006039578711587529, 0.0016141937230552538] lr: [0.005625]\n",
      "15 360 recon: [0.006322133121657539, 0.0017614742836766857] lr: [0.005625]\n",
      "15 390 recon: [0.007067478000995548, 0.0021533320909740785] lr: [0.005625]\n",
      "16 0 recon: [0.005758243824724748, 0.0014600661126109998] lr: [0.005625]\n",
      "16 30 recon: [0.005769129004625923, 0.0017091568605410578] lr: [0.005625]\n",
      "16 60 recon: [0.005932332292533183, 0.0015262986887237436] lr: [0.005625]\n",
      "16 90 recon: [0.006374047509731391, 0.0015591260434647714] lr: [0.005625]\n",
      "16 120 recon: [0.007076206361278327, 0.001942079422137327] lr: [0.005625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 150 recon: [0.006078436407693872, 0.0017977248445774118] lr: [0.005625]\n",
      "16 180 recon: [0.005923675835906718, 0.0016423391786896222] lr: [0.005625]\n",
      "16 210 recon: [0.005726205585412582, 0.0014683156418460624] lr: [0.005625]\n",
      "16 240 recon: [0.00626102579513073, 0.001935080213770247] lr: [0.005625]\n",
      "16 270 recon: [0.005971420594670839, 0.0017161511089124164] lr: [0.005625]\n",
      "16 300 recon: [0.005726296117943105, 0.0014537068008675016] lr: [0.005625]\n",
      "16 330 recon: [0.006010742535637598, 0.0016313823636154954] lr: [0.005625]\n",
      "16 360 recon: [0.006288715587697204, 0.0017874854481689825] lr: [0.005625]\n",
      "16 390 recon: [0.0069997376863523714, 0.0021932454634922497] lr: [0.005625]\n",
      "17 0 recon: [0.005734021053731914, 0.0014732830662646515] lr: [0.005625]\n",
      "17 30 recon: [0.005738584459398825, 0.001723714223578123] lr: [0.005625]\n",
      "17 60 recon: [0.005905063884786953, 0.0015397096942823256] lr: [0.005625]\n",
      "17 90 recon: [0.006335833777624959, 0.001580832909965298] lr: [0.005625]\n",
      "17 120 recon: [0.007039443720521864, 0.0019670311305504465] lr: [0.005625]\n",
      "17 150 recon: [0.006042572584317063, 0.001817366540331104] lr: [0.005625]\n",
      "17 180 recon: [0.005888400728908802, 0.0016597328167579305] lr: [0.005625]\n",
      "17 210 recon: [0.005682931728126093, 0.0014953884692794368] lr: [0.005625]\n",
      "17 240 recon: [0.006223473412524656, 0.001970622426271731] lr: [0.005625]\n",
      "17 270 recon: [0.005940107448799488, 0.0017343667399000247] lr: [0.005625]\n",
      "17 300 recon: [0.005705393082900183, 0.001470236039328597] lr: [0.005625]\n",
      "17 330 recon: [0.005979184470306558, 0.0016538302714714298] lr: [0.005625]\n",
      "17 360 recon: [0.006253495486867604, 0.0018189190129109518] lr: [0.005625]\n",
      "17 390 recon: [0.006923160323632993, 0.0022440764213651388] lr: [0.005625]\n",
      "18 0 recon: [0.005707532596854656, 0.001491726196192618] lr: [0.005625]\n",
      "18 30 recon: [0.0057051826582847085, 0.001744480378510898] lr: [0.005625]\n",
      "18 60 recon: [0.005874851458096299, 0.0015590873969608396] lr: [0.005625]\n",
      "18 90 recon: [0.006294755337438044, 0.0016093723855403184] lr: [0.005625]\n",
      "18 120 recon: [0.007000542443133047, 0.0019951896932635647] lr: [0.005625]\n",
      "18 150 recon: [0.0060035460875547345, 0.0018406575813660671] lr: [0.005625]\n",
      "18 180 recon: [0.005848963497642721, 0.0016812050223337593] lr: [0.005625]\n",
      "18 210 recon: [0.005639793821933855, 0.0015261330243938871] lr: [0.005625]\n",
      "18 240 recon: [0.006184294333091178, 0.0020063054752430063] lr: [0.005625]\n",
      "18 270 recon: [0.0059061779564080555, 0.0017545659148861773] lr: [0.005625]\n",
      "18 300 recon: [0.005683724829548506, 0.0014865481576021545] lr: [0.005625]\n",
      "18 330 recon: [0.005946893730793548, 0.0016763704522141543] lr: [0.005625]\n",
      "18 360 recon: [0.006218919503939638, 0.001848977630782927] lr: [0.005625]\n",
      "18 390 recon: [0.006843648493268621, 0.0022939606359808585] lr: [0.005625]\n",
      "19 0 recon: [0.00568053542856403, 0.0015096940045904248] lr: [0.005625]\n",
      "19 30 recon: [0.005671491778468431, 0.0017647266510340842] lr: [0.005625]\n",
      "19 60 recon: [0.005843640599431594, 0.0015788059586007213] lr: [0.005625]\n",
      "19 90 recon: [0.006253295361235882, 0.0016384295450460478] lr: [0.005625]\n",
      "19 120 recon: [0.006961438155342193, 0.0020208489281240537] lr: [0.005625]\n",
      "19 150 recon: [0.005963372398569068, 0.00186319944526527] lr: [0.005625]\n",
      "19 180 recon: [0.005807222288762203, 0.001703614847754671] lr: [0.005625]\n",
      "19 210 recon: [0.005598722611349583, 0.0015562790967813011] lr: [0.005625]\n",
      "19 240 recon: [0.0061441611899936315, 0.0020395730522961885] lr: [0.005625]\n",
      "19 270 recon: [0.005870702592413894, 0.001775212611176696] lr: [0.005625]\n",
      "19 300 recon: [0.005661352615110016, 0.0015015775492379772] lr: [0.005625]\n",
      "19 330 recon: [0.005914371030514067, 0.0016983610215766639] lr: [0.005625]\n",
      "19 360 recon: [0.006185085787543576, 0.0018767912572618798] lr: [0.005625]\n",
      "19 390 recon: [0.006764788585541422, 0.0023405025256121544] lr: [0.005625]\n",
      "20 0 recon: [0.005653088223558371, 0.0015278561268948366] lr: [0.005625]\n",
      "20 30 recon: [0.005637688936275839, 0.0017851520380571] lr: [0.005625]\n",
      "20 60 recon: [0.005811684085452132, 0.0015998480738881355] lr: [0.005625]\n",
      "20 90 recon: [0.006211775943462427, 0.0016684322977294597] lr: [0.005625]\n",
      "20 120 recon: [0.0069216875106806386, 0.002045525479186068] lr: [0.005625]\n",
      "20 150 recon: [0.005922450188518773, 0.001886559680093361] lr: [0.005625]\n",
      "20 180 recon: [0.00576407699492657, 0.0017282360739738969] lr: [0.005625]\n",
      "20 210 recon: [0.005559466165070997, 0.0015862972638071462] lr: [0.005625]\n",
      "20 240 recon: [0.006102785722481216, 0.0020716088127132573] lr: [0.005625]\n",
      "20 270 recon: [0.005834229038834883, 0.0017974913499655967] lr: [0.005625]\n",
      "20 300 recon: [0.0056378102506415085, 0.0015167597129817098] lr: [0.005625]\n",
      "20 330 recon: [0.005881511081057625, 0.0017206950811068937] lr: [0.005625]\n",
      "20 360 recon: [0.0061514645896321475, 0.001903005303920854] lr: [0.005625]\n",
      "20 390 recon: [0.006689890671868225, 0.0023810357264802623] lr: [0.005625]\n",
      "21 0 recon: [0.005625204766167442, 0.001546914053244498] lr: [0.005625]\n",
      "21 30 recon: [0.005603963292244689, 0.0018059039471573746] lr: [0.005625]\n",
      "21 60 recon: [0.005779472196331439, 0.0016220386055917247] lr: [0.005625]\n",
      "21 90 recon: [0.0061705522901402835, 0.0016989924081246097] lr: [0.005625]\n",
      "21 120 recon: [0.006881167227270942, 0.002069149453455569] lr: [0.005625]\n",
      "21 150 recon: [0.005881713341769001, 0.0019101444853179808] lr: [0.005625]\n",
      "21 180 recon: [0.0057209360317879675, 0.001753918170780585] lr: [0.005625]\n",
      "21 210 recon: [0.005521818434253881, 0.0016154950171906673] lr: [0.005625]\n",
      "21 240 recon: [0.006060839707562177, 0.002101418272500473] lr: [0.005625]\n",
      "21 270 recon: [0.005797878673685087, 0.0018202585090466624] lr: [0.005625]\n",
      "21 300 recon: [0.005613134862401908, 0.001532179371695235] lr: [0.005625]\n",
      "21 330 recon: [0.00584848454810253, 0.0017428326378294975] lr: [0.005625]\n",
      "21 360 recon: [0.006117924728758537, 0.0019274079991612862] lr: [0.005625]\n",
      "21 390 recon: [0.006620698063555484, 0.002413188107111705] lr: [0.005625]\n",
      "22 0 recon: [0.005597090432652403, 0.0015667248036637734] lr: [0.005625]\n",
      "22 30 recon: [0.005570565401009276, 0.0018265892006726454] lr: [0.005625]\n",
      "22 60 recon: [0.005747489626766967, 0.001644627741629475] lr: [0.005625]\n",
      "22 90 recon: [0.006129974296277474, 0.0017297857295536794] lr: [0.005625]\n",
      "22 120 recon: [0.006839702997493431, 0.0020919998790217536] lr: [0.005625]\n",
      "22 150 recon: [0.005841731227239178, 0.0019335759700295746] lr: [0.005625]\n",
      "22 180 recon: [0.005678662505828927, 0.0017798510150978798] lr: [0.005625]\n",
      "22 210 recon: [0.005485547931851412, 0.001643679195116108] lr: [0.005625]\n",
      "22 240 recon: [0.006018852205314073, 0.002128895445263637] lr: [0.005625]\n",
      "22 270 recon: [0.005762308250189916, 0.001842834410495117] lr: [0.005625]\n",
      "22 300 recon: [0.0055873758989561885, 0.0015482160892940225] lr: [0.005625]\n",
      "22 330 recon: [0.005815259503489609, 0.0017648333947005263] lr: [0.005625]\n",
      "22 360 recon: [0.006084344976719653, 0.0019504973684623121] lr: [0.005625]\n",
      "22 390 recon: [0.006555946256423929, 0.00243868191529534] lr: [0.005625]\n",
      "23 0 recon: [0.00556884919065783, 0.0015872427853220385] lr: [0.005625]\n",
      "23 30 recon: [0.005537556049644541, 0.0018472208697695948] lr: [0.005625]\n",
      "23 60 recon: [0.005715967446622058, 0.0016670244782130677] lr: [0.005625]\n",
      "23 90 recon: [0.0060903568279168626, 0.0017605252147162226] lr: [0.005625]\n",
      "23 120 recon: [0.006797160869768446, 0.002114518772854343] lr: [0.005625]\n",
      "23 150 recon: [0.005802779944608307, 0.0019565477545716936] lr: [0.005625]\n",
      "23 180 recon: [0.005637674094445499, 0.0018054163113371603] lr: [0.005625]\n",
      "23 210 recon: [0.005450588709655429, 0.001670483139009925] lr: [0.005625]\n",
      "23 240 recon: [0.005977359478320688, 0.0021538521721486048] lr: [0.005625]\n",
      "23 270 recon: [0.005727875600864419, 0.0018644535936776755] lr: [0.005625]\n",
      "23 300 recon: [0.0055606910211971824, 0.0015646980312547984] lr: [0.005625]\n",
      "23 330 recon: [0.005781894816321372, 0.0017863936486036851] lr: [0.005625]\n",
      "23 360 recon: [0.006050887304434632, 0.001972162976858372] lr: [0.005625]\n",
      "23 390 recon: [0.0064932711344544225, 0.0024604146786154353] lr: [0.005625]\n",
      "24 0 recon: [0.005540662621245761, 0.0016077721482163911] lr: [0.005625]\n",
      "24 30 recon: [0.005505117847481704, 0.0018673652390948268] lr: [0.005625]\n",
      "24 60 recon: [0.005685026261842124, 0.001688415199665767] lr: [0.005625]\n",
      "24 90 recon: [0.006052048469989314, 0.0017904145706691503] lr: [0.005625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 120 recon: [0.006753641137264057, 0.0021367687585971086] lr: [0.005625]\n",
      "24 150 recon: [0.005765080746531402, 0.0019785637209801883] lr: [0.005625]\n",
      "24 180 recon: [0.005598179037891949, 0.001830037773395406] lr: [0.005625]\n",
      "24 210 recon: [0.005416908734143648, 0.0016955455032309666] lr: [0.005625]\n",
      "24 240 recon: [0.005936782482400056, 0.002176130575187403] lr: [0.005625]\n",
      "24 270 recon: [0.005694658860482435, 0.0018846946905670104] lr: [0.005625]\n",
      "24 300 recon: [0.005533192742021038, 0.0015814386124890483] lr: [0.005625]\n",
      "24 330 recon: [0.005748420647747028, 0.0018073155542533597] lr: [0.005625]\n",
      "24 360 recon: [0.006017730277445322, 0.0019923221990216515] lr: [0.005625]\n",
      "24 390 recon: [0.00643039417542301, 0.002482981787311057] lr: [0.005625]\n",
      "25 0 recon: [0.005512627419540638, 0.0016277332118157283] lr: [0.005625]\n",
      "25 30 recon: [0.005473403189695718, 0.00188676823347349] lr: [0.005625]\n",
      "25 60 recon: [0.005654595832773937, 0.0017085005509587397] lr: [0.005625]\n",
      "25 90 recon: [0.0060152508366555415, 0.0018188600721751546] lr: [0.005625]\n",
      "25 120 recon: [0.006709373660988601, 0.002158976375791927] lr: [0.005625]\n",
      "25 150 recon: [0.005728758054070956, 0.001999382582645367] lr: [0.005625]\n",
      "25 180 recon: [0.005560238274620427, 0.0018534278203245372] lr: [0.005625]\n",
      "25 210 recon: [0.005384402962389657, 0.001718874938838136] lr: [0.005625]\n",
      "25 240 recon: [0.005897389653486958, 0.0021959027809046712] lr: [0.005625]\n",
      "25 270 recon: [0.005662580167170696, 0.0019036156960742512] lr: [0.005625]\n",
      "25 300 recon: [0.005504991626402104, 0.001598448198873027] lr: [0.005625]\n",
      "25 330 recon: [0.005714869449423899, 0.0018275860128307325] lr: [0.005625]\n",
      "25 360 recon: [0.005985026601175283, 0.0020110571956773325] lr: [0.005625]\n",
      "25 390 recon: [0.0063676516309433325, 0.002514864578234469] lr: [0.005625]\n",
      "26 0 recon: [0.005484819033953748, 0.0016467547613424908] lr: [0.005625]\n",
      "26 30 recon: [0.00544262926653229, 0.0019051606622699114] lr: [0.005625]\n",
      "26 60 recon: [0.005624633676137459, 0.0017272458368579047] lr: [0.005625]\n",
      "26 90 recon: [0.005980161546135981, 0.0018452920950560727] lr: [0.005625]\n",
      "26 120 recon: [0.0066648779424294275, 0.0021810336668797096] lr: [0.005625]\n",
      "26 150 recon: [0.0056940228592328454, 0.0020185880459500107] lr: [0.005625]\n",
      "26 180 recon: [0.005523983113349966, 0.0018751016626474602] lr: [0.005625]\n",
      "26 210 recon: [0.005353104168252247, 0.001740303163513178] lr: [0.005625]\n",
      "26 240 recon: [0.005859561261554422, 0.0022131972276496765] lr: [0.005625]\n",
      "26 270 recon: [0.005631698373446841, 0.0019211403986949631] lr: [0.005625]\n",
      "26 300 recon: [0.005476394859498328, 0.0016155551847771646] lr: [0.005625]\n",
      "26 330 recon: [0.005681440282470632, 0.001847101407451227] lr: [0.005625]\n",
      "26 360 recon: [0.005952993059002496, 0.0020283590054890714] lr: [0.005625]\n",
      "26 390 recon: [0.006317404727585244, 0.0026174212302619683] lr: [0.005625]\n",
      "27 0 recon: [0.005457596902436644, 0.0016639993582971292] lr: [0.005625]\n",
      "27 30 recon: [0.005413646477547944, 0.0019207483719299897] lr: [0.005625]\n",
      "27 60 recon: [0.005595870618306508, 0.0017428871049218074] lr: [0.005625]\n",
      "27 90 recon: [0.0059478103591016135, 0.0018668183269474425] lr: [0.005625]\n",
      "27 120 recon: [0.006622100202548942, 0.0021991960296017803] lr: [0.005625]\n",
      "27 150 recon: [0.005662376825066487, 0.0020325611059672055] lr: [0.005625]\n",
      "27 180 recon: [0.005490876754754174, 0.0018912966713483634] lr: [0.005625]\n",
      "27 210 recon: [0.005324152830068986, 0.0017567621872724766] lr: [0.005625]\n",
      "27 240 recon: [0.0058253768445353125, 0.002223928734994646] lr: [0.005625]\n",
      "27 270 recon: [0.005603337123510155, 0.001934110999838432] lr: [0.005625]\n",
      "27 300 recon: [0.0054487046818896875, 0.0016301587510314144] lr: [0.005625]\n",
      "27 330 recon: [0.005649534775298232, 0.0018629592058541139] lr: [0.005625]\n",
      "27 360 recon: [0.005922911179620668, 0.002041321440045198] lr: [0.005625]\n",
      "27 390 recon: [0.006393025471781264, 0.003217819247730103] lr: [0.005625]\n",
      "28 0 recon: [0.005433711547362258, 0.0016723753244991413] lr: [0.005625]\n",
      "28 30 recon: [0.005392383078139085, 0.0019193438995370768] lr: [0.005625]\n",
      "28 60 recon: [0.005574673992814871, 0.0017389758233546685] lr: [0.005625]\n",
      "28 90 recon: [0.005926369771870245, 0.0018612733023397991] lr: [0.005625]\n",
      "28 120 recon: [0.006593730982736365, 0.002183770295779409] lr: [0.005625]\n",
      "28 150 recon: [0.005646431083041756, 0.0020121394708544223] lr: [0.005625]\n",
      "28 180 recon: [0.005473934065013533, 0.0018715948967198493] lr: [0.005625]\n",
      "28 210 recon: [0.005308005604748938, 0.0017415490700200657] lr: [0.005625]\n",
      "28 240 recon: [0.005811179839347545, 0.002192891609364393] lr: [0.005625]\n",
      "28 270 recon: [0.005589374765042224, 0.0019143005874068546] lr: [0.005625]\n",
      "28 300 recon: [0.00543047831001709, 0.0016215576546156879] lr: [0.005625]\n",
      "28 330 recon: [0.005629538762736997, 0.0018507276871321636] lr: [0.005625]\n",
      "28 360 recon: [0.005904731809511855, 0.0020254192519257056] lr: [0.005625]\n",
      "28 390 recon: [0.007145554993139248, 0.005604160639376842] lr: [0.005625]\n",
      "29 0 recon: [0.005430376648907341, 0.0016316783689468227] lr: [0.005625]\n",
      "29 30 recon: [0.005415296157995376, 0.0018287334157771977] lr: [0.005625]\n",
      "29 60 recon: [0.005602100486284662, 0.001632676294412655] lr: [0.005625]\n",
      "29 90 recon: [0.0059675516337561255, 0.0017227256107804907] lr: [0.005625]\n",
      "29 120 recon: [0.0066610605859594735, 0.001990398036161946] lr: [0.005625]\n",
      "29 150 recon: [0.005732464524147817, 0.0018173196854247024] lr: [0.005625]\n",
      "29 180 recon: [0.005560193783083121, 0.001675784883604273] lr: [0.005625]\n",
      "29 210 recon: [0.005379583411715203, 0.0015672550796245975] lr: [0.005625]\n",
      "29 240 recon: [0.005936490176152085, 0.0019425641792922249] lr: [0.005625]\n",
      "29 270 recon: [0.005675456798984757, 0.0017196700254523641] lr: [0.005625]\n",
      "29 300 recon: [0.005485690019182468, 0.00147495930797359] lr: [0.005625]\n",
      "29 330 recon: [0.0057018885013032415, 0.0016732948990527733] lr: [0.005625]\n",
      "29 360 recon: [0.005976937381005822, 0.0018381697036135602] lr: [0.00421875]\n",
      "29 390 recon: [0.008297896497504209, 0.007870242350696938] lr: [0.00421875]\n",
      "30 0 recon: [0.005485062121224054, 0.001502564352816863] lr: [0.00421875]\n",
      "30 30 recon: [0.005504301159097298, 0.0016700043626539977] lr: [0.00421875]\n",
      "30 60 recon: [0.005681697367887705, 0.001488075079225176] lr: [0.00421875]\n",
      "30 90 recon: [0.006058503710462311, 0.0015562847216532814] lr: [0.00421875]\n",
      "30 120 recon: [0.006794396429734704, 0.0017760418157665796] lr: [0.00421875]\n",
      "30 150 recon: [0.005878357512149473, 0.0016186714059987825] lr: [0.00421875]\n",
      "30 180 recon: [0.005704278062867978, 0.0014794796316201064] lr: [0.00421875]\n",
      "30 210 recon: [0.005506439360411586, 0.0013872291138555747] lr: [0.00421875]\n",
      "30 240 recon: [0.006155051570242402, 0.0016743452229791456] lr: [0.00421875]\n",
      "30 270 recon: [0.005831766713177354, 0.0015004337927754965] lr: [0.00421875]\n",
      "30 300 recon: [0.005604796452363257, 0.0012869946644323694] lr: [0.00421875]\n",
      "30 330 recon: [0.005864339950202279, 0.00143943056540534] lr: [0.00421875]\n",
      "30 360 recon: [0.006147059740646889, 0.0015720038930103002] lr: [0.00421875]\n",
      "30 390 recon: [0.006771748201628583, 0.0030277297195472263] lr: [0.00421875]\n",
      "31 0 recon: [0.005565599515872034, 0.0013748326688331485] lr: [0.00421875]\n",
      "31 30 recon: [0.005548553230233816, 0.001616541543346093] lr: [0.00421875]\n",
      "31 60 recon: [0.005670968010299743, 0.0015181693877830294] lr: [0.00421875]\n",
      "31 90 recon: [0.006010514656140634, 0.0016497474149197188] lr: [0.0031640625]\n",
      "31 120 recon: [0.006680364628035898, 0.001969988648310953] lr: [0.0031640625]\n",
      "31 150 recon: [0.005722051938371649, 0.0018606720544709614] lr: [0.0031640625]\n",
      "31 180 recon: [0.005541769532108626, 0.0017381102946142056] lr: [0.0031640625]\n",
      "31 210 recon: [0.005342375418166183, 0.0016558096681600011] lr: [0.0031640625]\n",
      "31 240 recon: [0.005894989195236667, 0.0020403274163044494] lr: [0.0031640625]\n",
      "31 270 recon: [0.00561431139896606, 0.0018603964736079617] lr: [0.0031640625]\n",
      "31 300 recon: [0.005434395084336621, 0.0016026863626258166] lr: [0.0031640625]\n",
      "31 330 recon: [0.005650153248770556, 0.0017915027774978527] lr: [0.0031640625]\n",
      "31 360 recon: [0.005924353810004194, 0.001953695351799851] lr: [0.0031640625]\n",
      "31 390 recon: [0.006360965940232646, 0.0031919205832242484] lr: [0.0031640625]\n",
      "32 0 recon: [0.005408500700127319, 0.0016840556552147798] lr: [0.0031640625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 30 recon: [0.00535872560049258, 0.001966565122741463] lr: [0.0031640625]\n",
      "32 60 recon: [0.005529060563662075, 0.0018149452686372948] lr: [0.0031640625]\n",
      "32 90 recon: [0.0058782881975445326, 0.0019330424388819079] lr: [0.0031640625]\n",
      "32 120 recon: [0.006520206788098053, 0.0022893883074986327] lr: [0.0031640625]\n",
      "32 150 recon: [0.005582627637878769, 0.0021377011328761087] lr: [0.0031640625]\n",
      "32 180 recon: [0.005422491192758186, 0.00197427018720755] lr: [0.0031640625]\n",
      "32 210 recon: [0.0052524130503095725, 0.0018460715939364767] lr: [0.0031640625]\n",
      "32 240 recon: [0.00576940267598134, 0.0022684801007854766] lr: [0.0031640625]\n",
      "32 270 recon: [0.0055301464433308994, 0.002033628918263333] lr: [0.0031640625]\n",
      "32 300 recon: [0.005378597339213998, 0.0017241163676615288] lr: [0.0031640625]\n",
      "32 330 recon: [0.005583860443726537, 0.0019178267795809452] lr: [0.0031640625]\n",
      "32 360 recon: [0.0058603413227090685, 0.0020717086892226276] lr: [0.0031640625]\n",
      "32 390 recon: [0.006113292492987194, 0.0026875546486029534] lr: [0.0031640625]\n",
      "33 0 recon: [0.005377047189724766, 0.0017351893874212345] lr: [0.0031640625]\n",
      "33 30 recon: [0.005327104539126531, 0.002007383629449314] lr: [0.0031640625]\n",
      "33 60 recon: [0.005507587497645717, 0.0018303973662189192] lr: [0.0031640625]\n",
      "33 90 recon: [0.005854743875751837, 0.0019431953763083838] lr: [0.0031640625]\n",
      "33 120 recon: [0.006491327550397856, 0.002292501545782262] lr: [0.0031640625]\n",
      "33 150 recon: [0.005568349087722205, 0.002118885348613032] lr: [0.0031640625]\n",
      "33 180 recon: [0.005406259164292501, 0.001955001412123632] lr: [0.0031640625]\n",
      "33 210 recon: [0.005243818792498618, 0.0018137625671583674] lr: [0.0031640625]\n",
      "33 240 recon: [0.005758762181945277, 0.002239189318216284] lr: [0.0031640625]\n",
      "33 270 recon: [0.005528794406720895, 0.001984834542145596] lr: [0.0031640625]\n",
      "33 300 recon: [0.005378029995077287, 0.001676564533955018] lr: [0.0031640625]\n",
      "33 330 recon: [0.005578348823389157, 0.001881727996315932] lr: [0.0031640625]\n",
      "33 360 recon: [0.005856052961965656, 0.0020385018843749386] lr: [0.0031640625]\n",
      "33 390 recon: [0.0060875062790584685, 0.002622361345301832] lr: [0.0031640625]\n",
      "34 0 recon: [0.005376832203537236, 0.0016941792722452143] lr: [0.0031640625]\n",
      "34 30 recon: [0.005330936553726775, 0.00195513992478807] lr: [0.0031640625]\n",
      "34 60 recon: [0.005507497663548109, 0.001782564182158491] lr: [0.0031640625]\n",
      "34 90 recon: [0.005849805607314364, 0.0019058200552312713] lr: [0.0031640625]\n",
      "34 120 recon: [0.006481438396058466, 0.0022503198939174776] lr: [0.0031640625]\n",
      "34 150 recon: [0.0055672876492590595, 0.002074584603730463] lr: [0.0031640625]\n",
      "34 180 recon: [0.00539908107397263, 0.001925489110018595] lr: [0.0031640625]\n",
      "34 210 recon: [0.005237686832655878, 0.0017896900446655395] lr: [0.0031640625]\n",
      "34 240 recon: [0.005748855726516722, 0.002220716089804604] lr: [0.0031640625]\n",
      "34 270 recon: [0.005522753244960389, 0.001962687345769657] lr: [0.0031640625]\n",
      "34 300 recon: [0.005369916598602348, 0.0016618906472431365] lr: [0.0031640625]\n",
      "34 330 recon: [0.005564739240149062, 0.0018801201783340093] lr: [0.0031640625]\n",
      "34 360 recon: [0.005840327364355442, 0.002044894456942891] lr: [0.0031640625]\n",
      "34 390 recon: [0.00603976664385611, 0.002628813762079854] lr: [0.0031640625]\n",
      "35 0 recon: [0.00536383146681945, 0.0017003544374682917] lr: [0.0031640625]\n",
      "35 30 recon: [0.0053171228685936316, 0.001959933441197439] lr: [0.0031640625]\n",
      "35 60 recon: [0.005492202356713171, 0.0017906961599096001] lr: [0.0031640625]\n",
      "35 90 recon: [0.005831000922564838, 0.0019221087004755537] lr: [0.0031640625]\n",
      "35 120 recon: [0.006453256966942195, 0.0022696248591774397] lr: [0.0031640625]\n",
      "35 150 recon: [0.005547803429394944, 0.0020895471093218113] lr: [0.0031640625]\n",
      "35 180 recon: [0.005377403225835074, 0.0019455172266413198] lr: [0.0031640625]\n",
      "35 210 recon: [0.005218702620706396, 0.0018114515835593095] lr: [0.0031640625]\n",
      "35 240 recon: [0.005721800480983791, 0.002250469833174727] lr: [0.0031640625]\n",
      "35 270 recon: [0.005502195847480176, 0.0019860697532113466] lr: [0.0031640625]\n",
      "35 300 recon: [0.005350952966463086, 0.0016839946270871175] lr: [0.0031640625]\n",
      "35 330 recon: [0.0055419116550005495, 0.0019091512387418652] lr: [0.0031640625]\n",
      "35 360 recon: [0.00581611994138915, 0.002077411772230993] lr: [0.0031640625]\n",
      "35 390 recon: [0.005994020230293603, 0.0026720662667792834] lr: [0.0031640625]\n",
      "36 0 recon: [0.005345710091933473, 0.0017248530807177352] lr: [0.0031640625]\n",
      "36 30 recon: [0.005297606662778933, 0.0019829346466433717] lr: [0.0031640625]\n",
      "36 60 recon: [0.005473481287260506, 0.0018121923147994359] lr: [0.0031640625]\n",
      "36 90 recon: [0.0058107729049404555, 0.001946385614792177] lr: [0.0031640625]\n",
      "36 120 recon: [0.0064243406575796155, 0.0022947130193812114] lr: [0.0031640625]\n",
      "36 150 recon: [0.005528078779095213, 0.0021083693446075965] lr: [0.0031640625]\n",
      "36 180 recon: [0.00535743912150993, 0.0019647316957975697] lr: [0.0031640625]\n",
      "36 210 recon: [0.005201851505214956, 0.0018299334043290403] lr: [0.0031640625]\n",
      "36 240 recon: [0.0056991513314779505, 0.0022718753152643273] lr: [0.0031640625]\n",
      "36 270 recon: [0.005485276181652743, 0.0020018484870383776] lr: [0.0031640625]\n",
      "36 300 recon: [0.005335130299091381, 0.00169847146757766] lr: [0.0031640625]\n",
      "36 330 recon: [0.005524206861005026, 0.0019262728656888309] lr: [0.0031640625]\n",
      "36 360 recon: [0.005798291218704324, 0.0020946363828299886] lr: [0.0031640625]\n",
      "36 390 recon: [0.005966317926603736, 0.002684638173758226] lr: [0.0031640625]\n",
      "37 0 recon: [0.005332429325938669, 0.0017365799169909485] lr: [0.0031640625]\n",
      "37 30 recon: [0.005283925993125562, 0.001992212750186327] lr: [0.0031640625]\n",
      "37 60 recon: [0.005459654277574821, 0.0018210779402594553] lr: [0.0031640625]\n",
      "37 90 recon: [0.005795628453303981, 0.001957392547218833] lr: [0.0031640625]\n",
      "37 120 recon: [0.006401257517651369, 0.002305541733546184] lr: [0.0031640625]\n",
      "37 150 recon: [0.005513771958936375, 0.00211495949137205] lr: [0.0031640625]\n",
      "37 180 recon: [0.005342560297377892, 0.0019726964738729516] lr: [0.0031640625]\n",
      "37 210 recon: [0.005189402646922335, 0.0018376437361252778] lr: [0.0031640625]\n",
      "37 240 recon: [0.005681937474521115, 0.0022813432539238966] lr: [0.0031640625]\n",
      "37 270 recon: [0.005472433690122794, 0.0020082261715433586] lr: [0.0031640625]\n",
      "37 300 recon: [0.005322190038664879, 0.0017057703520855822] lr: [0.0031640625]\n",
      "37 330 recon: [0.005509766846641536, 0.0019358106965178482] lr: [0.0031640625]\n",
      "37 360 recon: [0.0057836704658348215, 0.0021044727056109365] lr: [0.0031640625]\n",
      "37 390 recon: [0.0059426112016492845, 0.002693613222245252] lr: [0.0031640625]\n",
      "38 0 recon: [0.005320981728269756, 0.0017442044943874484] lr: [0.0031640625]\n",
      "38 30 recon: [0.005271967343810153, 0.00199862345827468] lr: [0.0031640625]\n",
      "38 60 recon: [0.005447128400588546, 0.001827963191167268] lr: [0.0031640625]\n",
      "38 90 recon: [0.005781709198801662, 0.0019665086995169665] lr: [0.0031640625]\n",
      "38 120 recon: [0.006378677168063393, 0.002316351530386307] lr: [0.0031640625]\n",
      "38 150 recon: [0.005500071209648392, 0.0021220699003899352] lr: [0.0031640625]\n",
      "38 180 recon: [0.005328319142129975, 0.0019811425364529237] lr: [0.0031640625]\n",
      "38 210 recon: [0.005177598254189116, 0.0018454072389247403] lr: [0.0031640625]\n",
      "38 240 recon: [0.005664930117889046, 0.0022920810769677526] lr: [0.0031640625]\n",
      "38 270 recon: [0.005459548828460882, 0.0020163638710020914] lr: [0.0031640625]\n",
      "38 300 recon: [0.005309159138291129, 0.0017147381788077346] lr: [0.0031640625]\n",
      "38 330 recon: [0.0054953769359242415, 0.001946667710813099] lr: [0.0031640625]\n",
      "38 360 recon: [0.005768911760862529, 0.0021159148008838636] lr: [0.0031640625]\n",
      "38 390 recon: [0.0059179185264804255, 0.0027079086396571196] lr: [0.0031640625]\n",
      "39 0 recon: [0.005309379776777319, 0.0017534841553425056] lr: [0.0031640625]\n",
      "39 30 recon: [0.005259669570485337, 0.0020073629011755417] lr: [0.0031640625]\n",
      "39 60 recon: [0.005434422698494625, 0.001836860227519233] lr: [0.0031640625]\n",
      "39 90 recon: [0.005767782844428925, 0.001977000440946237] lr: [0.0031640625]\n",
      "39 120 recon: [0.006355572427275902, 0.002329550444528004] lr: [0.0031640625]\n",
      "39 150 recon: [0.005486319834579663, 0.002130924387446727] lr: [0.0031640625]\n",
      "39 180 recon: [0.005314288153956598, 0.001990691142307039] lr: [0.0031640625]\n",
      "39 210 recon: [0.005166117590470787, 0.0018536894113844234] lr: [0.0031640625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 240 recon: [0.005648372338453835, 0.002303206993152475] lr: [0.0031640625]\n",
      "39 270 recon: [0.0054469367182539445, 0.0020250012646129225] lr: [0.0031640625]\n",
      "39 300 recon: [0.005296409915912573, 0.001723928562618162] lr: [0.0031640625]\n",
      "39 330 recon: [0.005481642820098079, 0.001956825132158237] lr: [0.0031640625]\n",
      "39 360 recon: [0.005754876683545211, 0.002126402364538619] lr: [0.0031640625]\n",
      "39 390 recon: [0.005895241287737291, 0.002720001115645832] lr: [0.0031640625]\n",
      "40 0 recon: [0.005298398908124709, 0.0017618972973748564] lr: [0.0031640625]\n",
      "40 30 recon: [0.005248159618880473, 0.0020151688928839806] lr: [0.0031640625]\n",
      "40 60 recon: [0.005422400619768165, 0.0018449196919058703] lr: [0.0031640625]\n",
      "40 90 recon: [0.005754640252410625, 0.001986237351059202] lr: [0.0031640625]\n",
      "40 120 recon: [0.0063331683964983855, 0.0023416382914357506] lr: [0.0031640625]\n",
      "40 150 recon: [0.0054735595498724594, 0.002138411523959717] lr: [0.0031640625]\n",
      "40 180 recon: [0.005301280720606187, 0.001998841989159447] lr: [0.0031640625]\n",
      "40 210 recon: [0.005155511489590349, 0.001860622440707606] lr: [0.0031640625]\n",
      "40 240 recon: [0.005633158104801591, 0.0023122152903332044] lr: [0.0031640625]\n",
      "40 270 recon: [0.005435243528025033, 0.0020321426855411297] lr: [0.0031640625]\n",
      "40 300 recon: [0.005284374703425468, 0.0017318784665330451] lr: [0.0031640625]\n",
      "40 330 recon: [0.0054689324896136995, 0.0019650779222579054] lr: [0.0031640625]\n",
      "40 360 recon: [0.005741921555757374, 0.002134840163737784] lr: [0.0031640625]\n",
      "40 390 recon: [0.0058743758578463905, 0.0027299875551104746] lr: [0.0031640625]\n",
      "41 0 recon: [0.005288159427920285, 0.0017689661810214399] lr: [0.0031640625]\n",
      "41 30 recon: [0.005237528119319449, 0.002021628049481995] lr: [0.0031640625]\n",
      "41 60 recon: [0.005411069746395189, 0.0018519526511213264] lr: [0.0031640625]\n",
      "41 90 recon: [0.005742195256708057, 0.001994324656233102] lr: [0.0031640625]\n",
      "41 120 recon: [0.00631137195385744, 0.0023527851836349185] lr: [0.0031640625]\n",
      "41 150 recon: [0.005461552513056452, 0.002144921348002771] lr: [0.0031640625]\n",
      "41 180 recon: [0.005289017745405596, 0.0020061294667478814] lr: [0.0031640625]\n",
      "41 210 recon: [0.005145488948460742, 0.0018668650356777037] lr: [0.0031640625]\n",
      "41 240 recon: [0.005618834119156862, 0.0023200615693592308] lr: [0.0031640625]\n",
      "41 270 recon: [0.0054240818439651815, 0.0020386948387429663] lr: [0.0031640625]\n",
      "41 300 recon: [0.00527275084980047, 0.0017394041124860983] lr: [0.0031640625]\n",
      "41 330 recon: [0.005456815269842239, 0.001972543632735028] lr: [0.0031640625]\n",
      "41 360 recon: [0.005729574972155743, 0.002142433862280242] lr: [0.0031640625]\n",
      "41 390 recon: [0.005854448094810415, 0.0027395206482723777] lr: [0.0031640625]\n",
      "42 0 recon: [0.005278307262044136, 0.0017756666696239335] lr: [0.0031640625]\n",
      "42 30 recon: [0.005227327732838668, 0.002027783079623437] lr: [0.0031640625]\n",
      "42 60 recon: [0.005400100964256865, 0.0018588021918172818] lr: [0.0031640625]\n",
      "42 90 recon: [0.00573011814392098, 0.002002107664066187] lr: [0.0031640625]\n",
      "42 120 recon: [0.006289818388168074, 0.0023638881699453197] lr: [0.0031640625]\n",
      "42 150 recon: [0.005449926562062095, 0.002151246069799592] lr: [0.0031640625]\n",
      "42 180 recon: [0.0052771880027503125, 0.00201321461367354] lr: [0.0031640625]\n",
      "42 210 recon: [0.005135818038049539, 0.001872936053312365] lr: [0.0031640625]\n",
      "42 240 recon: [0.005605070034224204, 0.002327443683422919] lr: [0.0031640625]\n",
      "42 270 recon: [0.005413239901344728, 0.00204511171244003] lr: [0.0031640625]\n",
      "42 300 recon: [0.005261408325450598, 0.001746806875649791] lr: [0.0031640625]\n",
      "42 330 recon: [0.0054451113908240934, 0.0019796348167102143] lr: [0.0031640625]\n",
      "42 360 recon: [0.005717674492933568, 0.0021495519744291576] lr: [0.0031640625]\n",
      "42 390 recon: [0.005835489424709917, 0.0027483490716831266] lr: [0.0031640625]\n",
      "43 0 recon: [0.005268769666682438, 0.0017821241931754257] lr: [0.0031640625]\n",
      "43 30 recon: [0.005217493179286064, 0.0020336882868424587] lr: [0.0031640625]\n",
      "43 60 recon: [0.005389469483576423, 0.0018654382782491178] lr: [0.0031640625]\n",
      "43 90 recon: [0.005718387705955992, 0.0020095659233934425] lr: [0.0031640625]\n",
      "43 120 recon: [0.006268522102069505, 0.002374847913174678] lr: [0.0031640625]\n",
      "43 150 recon: [0.005438679960087286, 0.002157254623362633] lr: [0.0031640625]\n",
      "43 180 recon: [0.005265793894292888, 0.002019973717688498] lr: [0.0031640625]\n",
      "43 210 recon: [0.0051265156508176314, 0.0018786769217873272] lr: [0.0031640625]\n",
      "43 240 recon: [0.005591868683333612, 0.0023342561632138303] lr: [0.0031640625]\n",
      "43 270 recon: [0.005402760026581665, 0.002051186854089433] lr: [0.0031640625]\n",
      "43 300 recon: [0.005250387409610688, 0.0017538959377978033] lr: [0.0031640625]\n",
      "43 330 recon: [0.005433829883741876, 0.001986248111640049] lr: [0.0031640625]\n",
      "43 360 recon: [0.005706234066220765, 0.002156095022003218] lr: [0.0031640625]\n",
      "43 390 recon: [0.005817478054499538, 0.002756384899398419] lr: [0.0031640625]\n",
      "44 0 recon: [0.0052595715247249555, 0.0017882021575067481] lr: [0.0031640625]\n",
      "44 30 recon: [0.005208053599205423, 0.00203918316591883] lr: [0.0031640625]\n",
      "44 60 recon: [0.005379199791478722, 0.001871719902242813] lr: [0.0031640625]\n",
      "44 90 recon: [0.005707011498920329, 0.002016613290004482] lr: [0.0031640625]\n",
      "44 120 recon: [0.006247507272053388, 0.0023855524914274595] lr: [0.0031640625]\n",
      "44 150 recon: [0.005427807692475364, 0.0021628628110400313] lr: [0.0031640625]\n",
      "44 180 recon: [0.005254817830607162, 0.002026362690216842] lr: [0.0031640625]\n",
      "44 210 recon: [0.005117562114561359, 0.0018840574714937568] lr: [0.0031640625]\n",
      "44 240 recon: [0.00557917765782152, 0.0023405501273416063] lr: [0.0031640625]\n",
      "44 270 recon: [0.005392618020371913, 0.0020569152221349154] lr: [0.0031640625]\n",
      "44 300 recon: [0.005239664268470181, 0.001760682190815993] lr: [0.0031640625]\n",
      "44 330 recon: [0.005422919213532315, 0.0019924645077544103] lr: [0.0031640625]\n",
      "44 360 recon: [0.00569519322550301, 0.002162177699829875] lr: [0.0031640625]\n",
      "44 390 recon: [0.005800279180055303, 0.002763796707843323] lr: [0.0031640625]\n",
      "45 0 recon: [0.005250669930848407, 0.0017939712155157755] lr: [0.0031640625]\n",
      "45 30 recon: [0.005198947991683456, 0.0020443511059696495] lr: [0.0031640625]\n",
      "45 60 recon: [0.005369245857465178, 0.0018777204311709859] lr: [0.0031640625]\n",
      "45 90 recon: [0.005695937675608355, 0.00202335058982932] lr: [0.0031640625]\n",
      "45 120 recon: [0.0062267273786795144, 0.0023960994606477457] lr: [0.0031640625]\n",
      "45 150 recon: [0.005417236967156382, 0.0021681788205208923] lr: [0.0031640625]\n",
      "45 180 recon: [0.00524419254516139, 0.002032483357885561] lr: [0.0031640625]\n",
      "45 210 recon: [0.005108896778133336, 0.0018891774295246811] lr: [0.0031640625]\n",
      "45 240 recon: [0.00556690536423857, 0.0023464911885372574] lr: [0.0031640625]\n",
      "45 270 recon: [0.005382755134570801, 0.002062399151583651] lr: [0.0031640625]\n",
      "45 300 recon: [0.005229194295759557, 0.0017672519818662706] lr: [0.0031640625]\n",
      "45 330 recon: [0.00541231373443173, 0.00199840490349298] lr: [0.0031640625]\n",
      "45 360 recon: [0.005684483901266377, 0.0021679376095377675] lr: [0.0031640625]\n",
      "45 390 recon: [0.00578378431528166, 0.002770712930961832] lr: [0.0031640625]\n",
      "46 0 recon: [0.005242024408772948, 0.0017995061084526902] lr: [0.0031640625]\n",
      "46 30 recon: [0.005190125193595561, 0.002049267367436509] lr: [0.0031640625]\n",
      "46 60 recon: [0.005359571259491979, 0.001883492469733274] lr: [0.0031640625]\n",
      "46 90 recon: [0.005685130888282569, 0.0020298375911494896] lr: [0.0031640625]\n",
      "46 120 recon: [0.006206161041252621, 0.002406530292399708] lr: [0.0031640625]\n",
      "46 150 recon: [0.005406923463546646, 0.002173255748204864] lr: [0.0031640625]\n",
      "46 180 recon: [0.0052338795121047495, 0.002038375394549363] lr: [0.0031640625]\n",
      "46 210 recon: [0.005100485447472602, 0.0018940731822786278] lr: [0.0031640625]\n",
      "46 240 recon: [0.005554996946708178, 0.0023521525883582564] lr: [0.0031640625]\n",
      "46 270 recon: [0.005373144130949347, 0.0020676613711743345] lr: [0.0031640625]\n",
      "46 300 recon: [0.005218957406022374, 0.0017736220745660292] lr: [0.0031640625]\n",
      "46 330 recon: [0.005401983928491307, 0.002004105108931693] lr: [0.0031640625]\n",
      "46 360 recon: [0.005674074309924688, 0.002173422616319741] lr: [0.0031640625]\n",
      "46 390 recon: [0.005767929805277863, 0.00277717575162738] lr: [0.0031640625]\n",
      "47 0 recon: [0.0052336172856084825, 0.0018048202030684962] lr: [0.0031640625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 30 recon: [0.005181561198483601, 0.0020539454918932073] lr: [0.0031640625]\n",
      "47 60 recon: [0.005350161873496539, 0.0018890379318705606] lr: [0.0031640625]\n",
      "47 90 recon: [0.005674576635074906, 0.002036084503398613] lr: [0.0031640625]\n",
      "47 120 recon: [0.006185808625489587, 0.0024168374588236347] lr: [0.0031640625]\n",
      "47 150 recon: [0.0053968430408047035, 0.0021781067489080813] lr: [0.0031640625]\n",
      "47 180 recon: [0.005223857773213753, 0.0020440455605260964] lr: [0.0031640625]\n",
      "47 210 recon: [0.005092306877487322, 0.0018987537088603654] lr: [0.0031640625]\n",
      "47 240 recon: [0.005543422265016438, 0.002357568361221296] lr: [0.0031640625]\n",
      "47 270 recon: [0.0053637690681406095, 0.002072707847811097] lr: [0.0031640625]\n",
      "47 300 recon: [0.005208939433842628, 0.001779800170384108] lr: [0.0031640625]\n",
      "47 330 recon: [0.005391906415855743, 0.0020095864026546976] lr: [0.0031640625]\n",
      "47 360 recon: [0.005663937200401755, 0.00217866913237543] lr: [0.0031640625]\n",
      "47 390 recon: [0.005752642527272367, 0.002783259729230143] lr: [0.0031640625]\n",
      "48 0 recon: [0.0052254317847382345, 0.0018099302052979461] lr: [0.0031640625]\n",
      "48 30 recon: [0.0051732303931061345, 0.0020584077592932723] lr: [0.0031640625]\n",
      "48 60 recon: [0.00534099951837259, 0.0018943715901959127] lr: [0.0031640625]\n",
      "48 90 recon: [0.005664257059578665, 0.0020421122355362463] lr: [0.0031640625]\n",
      "48 120 recon: [0.006165668119543286, 0.002427027781788881] lr: [0.0031640625]\n",
      "48 150 recon: [0.005386970838445371, 0.0021827601002915756] lr: [0.0031640625]\n",
      "48 180 recon: [0.005214103715872027, 0.0020495126712545522] lr: [0.0031640625]\n",
      "48 210 recon: [0.005084338936860269, 0.0019032423999240707] lr: [0.0031640625]\n",
      "48 240 recon: [0.005532144286435277, 0.002362781094862743] lr: [0.0031640625]\n",
      "48 270 recon: [0.005354609614178592, 0.0020775610572954344] lr: [0.0031640625]\n",
      "48 300 recon: [0.005199123276823872, 0.00178580615094339] lr: [0.0031640625]\n",
      "48 330 recon: [0.005382057772774266, 0.002014873253777499] lr: [0.0031640625]\n",
      "48 360 recon: [0.005654047657752549, 0.0021837165693137537] lr: [0.0031640625]\n",
      "48 390 recon: [0.005737862344282158, 0.0027890190301252888] lr: [0.0031640625]\n",
      "49 0 recon: [0.00521744872841111, 0.00181486020252185] lr: [0.0031640625]\n",
      "49 30 recon: [0.005165109782301417, 0.00206268412083746] lr: [0.0031640625]\n",
      "49 60 recon: [0.005332066193108501, 0.001899513962199047] lr: [0.0031640625]\n",
      "49 90 recon: [0.0056541551093915576, 0.0020479442619539827] lr: [0.0031640625]\n",
      "49 120 recon: [0.006145740126915634, 0.002437111310260493] lr: [0.0031640625]\n",
      "49 150 recon: [0.005377285508190596, 0.0021872446119516084] lr: [0.0031640625]\n",
      "49 180 recon: [0.005204595953091093, 0.0020547949458733063] lr: [0.0031640625]\n",
      "49 210 recon: [0.005076561835358175, 0.0019075602175657618] lr: [0.0031640625]\n",
      "49 240 recon: [0.0055211374841305765, 0.002367821706618103] lr: [0.0031640625]\n",
      "49 270 recon: [0.005345648502551893, 0.00208223982256154] lr: [0.0031640625]\n",
      "49 300 recon: [0.005189493080293755, 0.0017916562780576574] lr: [0.0031640625]\n",
      "49 330 recon: [0.0053724199589465305, 0.002019982835245813] lr: [0.0031640625]\n",
      "49 360 recon: [0.0056443844247320235, 0.002188592485057997] lr: [0.0031640625]\n",
      "49 390 recon: [0.00572352930550007, 0.0027945267747423812] lr: [0.0031640625]\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LowRankCodes(nn.Module):\n",
    "    '''\n",
    "    ranks: array of rank for each codebook matrix\n",
    "    '''\n",
    "    def __init__(self, ranks):\n",
    "        super(LowRankCodes, self).__init__()\n",
    "        self.As = []\n",
    "        for rank in ranks:\n",
    "            A = nn.Parameter(1e-2*torch.randn(rank,264).float().cuda())\n",
    "            self.As.append(A)\n",
    "        self.As = nn.ParameterList(self.As)\n",
    "\n",
    "    def forward(self):\n",
    "        book = []\n",
    "        for A in self.As:\n",
    "            AA = A.T@A\n",
    "            book.append(AA)\n",
    "        return torch.stack(book)\n",
    "    \n",
    "class LowRankWeights(nn.Module):\n",
    "    '''\n",
    "    For a single modality!\n",
    "    \n",
    "    nsubs: number of subjects\n",
    "    ncodes: number of pages in the codebook\n",
    "    nt: number of timepoints\n",
    "    '''\n",
    "    def __init__(self, nsubs, nmods, ncodes, nt):\n",
    "        super(LowRankWeights, self).__init__()\n",
    "        self.w = nn.Parameter(1e-2*torch.rand(nsubs, ncodes, nt).float().cuda())\n",
    "\n",
    "    def forward(self, sub, book):\n",
    "        w = self.w[sub]\n",
    "        return torch.einsum('pt,pab->abt', w, book)\n",
    "    \n",
    "def get_recon_loss(x, xhat):\n",
    "    return mseLoss(xhat, x)\n",
    "\n",
    "def get_smooth_loss_fc(xhat):\n",
    "    before = xhat[:,:,:-1]\n",
    "    after = xhat[:,:,1:]\n",
    "    return torch.mean((before-after)**2)\n",
    "\n",
    "def get_sub_fc(subts):\n",
    "    return torch.einsum('at,bt->abt',subts,subts)\n",
    "    \n",
    "# Timeseries\n",
    "x = torch.from_numpy(ts[1]).float().cuda()\n",
    "    \n",
    "# Parameters\n",
    "ntrain = 400\n",
    "nbatch = 30\n",
    "smooth_mult = 0.5\n",
    "nEpochs = 50\n",
    "pPeriod = 40\n",
    "\n",
    "mseLoss = nn.MSELoss()\n",
    "    \n",
    "# Codebook and weights\n",
    "lrc = LowRankCodes(300*[1])\n",
    "ncodes = len(lrc.As)\n",
    "\n",
    "lrw = LowRankWeights(ntrain, 1, ncodes, x.shape[-1])\n",
    "\n",
    "# Optimizers\n",
    "optim = torch.optim.Adam(itertools.chain(lrc.parameters(), lrw.parameters()), lr=1e-2, weight_decay=0)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=int(ntrain/nbatch)+5, factor=0.75, eps=1e-7)\n",
    "    \n",
    "for epoch in range(nEpochs):\n",
    "    suborder = np.arange(ntrain)\n",
    "#     np.random.shuffle(suborder)\n",
    "    for bstart in range(0,ntrain,nbatch):\n",
    "        bend = bstart+nbatch\n",
    "        if bend > ntrain:\n",
    "            bend = ntrain\n",
    "        optim.zero_grad()\n",
    "        book = lrc()\n",
    "        recon_loss = 0\n",
    "        smooth_loss_fc = 0\n",
    "        for subidx in range(bstart, bend):\n",
    "            sub = suborder[subidx]\n",
    "            xsub = get_sub_fc(x[sub])\n",
    "            xhat = lrw(sub, book)\n",
    "            recon_loss += get_recon_loss(xsub, xhat)\n",
    "            smooth_loss_fc += smooth_mult*get_smooth_loss_fc(xhat)\n",
    "        recon_loss /= (bend-bstart)\n",
    "        smooth_loss_fc /= (bend-bstart)\n",
    "        totloss = recon_loss+smooth_loss_fc\n",
    "        totloss.backward()\n",
    "        optim.step()\n",
    "        sched.step(totloss)\n",
    "        if bstart % nbatch == 0:\n",
    "            print(f'{epoch} {bstart} recon: {[float(ls)**0.5 for ls in [recon_loss, smooth_loss_fc]]} '\n",
    "                  f'lr: {sched._last_lr}')\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ee21fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 0 0.004010740667581558\n",
      "Finished 100 0.004055102821439505\n",
      "Finished 200 0.0038849436677992344\n",
      "Finished 300 0.004113595932722092\n",
      "Finished 400 0.004754922818392515\n",
      "Finished 500 0.004039555322378874\n",
      "Finished 600 0.005404890514910221\n",
      "Finished 700 0.003230147063732147\n",
      "Finished 800 0.005620813928544521\n",
      "torch.Size([847, 300, 231])\n"
     ]
    }
   ],
   "source": [
    "# Fast weight estimation for all subjects\n",
    "\n",
    "book = lrc()\n",
    "\n",
    "A = book.reshape(book.shape[0], -1).permute(1,0)\n",
    "AA = A.T@A\n",
    "codes = []\n",
    "\n",
    "for sub in range(x.shape[0]):\n",
    "    B = get_sub_fc(x[sub]).reshape(-1, x.shape[-1])\n",
    "    AB = A.T@B\n",
    "    C,_,_,_ = torch.linalg.lstsq(AA+0.1*torch.eye(AA.shape[0]).float().cuda(),AB)\n",
    "    codes.append(torch.from_numpy(C.detach().cpu().numpy()))\n",
    "    if sub % 100 == 0:\n",
    "        loss = mseLoss(A@C,B)**0.5\n",
    "        print(f'Finished {sub} {loss}')\n",
    "    \n",
    "codes = torch.stack(codes)\n",
    "print(codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6ad9f9fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [256], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m reconfc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(reconfc, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     15\u001b[0m A \u001b[38;5;241m=\u001b[39m book\u001b[38;5;241m.\u001b[39mreshape(book\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m reconfc2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;129;43m@codes\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msub\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m264\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m264\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean((statfc\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m124\u001b[39m\u001b[38;5;241m*\u001b[39mdynfc)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# Reconstruct static FC from dynamic FC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sub = 398\n",
    "\n",
    "dynfc = get_sub_fc(x[sub])\n",
    "dynfc = torch.mean(dynfc, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "statfc = np.corrcoef(ts[0][sub])\n",
    "\n",
    "reconfc = lrw(sub, book)\n",
    "reconfc = torch.mean(reconfc, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "A = book.reshape(book.shape[0], -1).permute(1,0)\n",
    "reconfc2 = torch.mean((A.cpu()@codes[sub]), dim=1).reshape(264,264).numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(10,3))\n",
    "\n",
    "print(np.mean((statfc-124*dynfc)**2)**0.5)\n",
    "print(np.mean((statfc-124*reconfc)**2)**0.5)\n",
    "print(np.mean((statfc-124*reconfc2)**2)**0.5)\n",
    "\n",
    "ax[0].imshow(dynfc)\n",
    "ax[1].imshow(statfc)\n",
    "ax[2].imshow(reconfc)\n",
    "ax[3].imshow(reconfc2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f07099ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.5264892578125, 36.16930389404297, 35.08573913574219, 34.39638137817383, 34.270389556884766, 33.73544692993164, 31.58016586303711, 31.929637908935547, 31.736000061035156, 31.088274002075195]\n"
     ]
    }
   ],
   "source": [
    "ntrain = 30\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = torch.mean(codescuda, dim=-1) #ps.reshape(ps.shape[0],-1)\n",
    "    xps = torch.cat([xps, torch.ones(xps.shape[0], 1).float().cuda()], dim=1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    w, _, _, _ = torch.linalg.lstsq(xtr.T@xtr + 0.01*torch.eye(301).float().cuda(), xtr.T@ytr)\n",
    "\n",
    "#     print(torch.mean((ytr-xtr@w)**2)**0.5)\n",
    "    losses.append(float(torch.mean((yt-xt@w)**2)**0.5))\n",
    "    \n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ed23ada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.116512298583984, 36.63888931274414, 35.6799430847168, 34.733787536621094, 33.64529800415039, 33.227699279785156, 31.140424728393555, 31.789806365966797, 31.55638313293457, 30.451705932617188]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, x, dp=0.1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = torch.nn.Conv2d(1,10,(x.shape[-2],4)).float().cuda()\n",
    "        self.ap1 = torch.nn.AvgPool2d((1,x.shape[-1]-3))\n",
    "        self.lin1 = torch.nn.Linear(10,1).float().cuda()\n",
    "        self.dp = nn.Dropout(p=dp)\n",
    "        \n",
    "    def forward(self, ts):\n",
    "        ts = self.dp(ts)\n",
    "        y = F.relu(self.cnn1(ts))\n",
    "        y = self.ap1(y)\n",
    "        z = y.reshape(y.shape[0], -1).squeeze()\n",
    "        y = self.lin1(z)\n",
    "        return z, y.squeeze()\n",
    "    \n",
    "nEpochs = 1000\n",
    "pPeriod = 200\n",
    "\n",
    "ntrain = 30\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = codescuda.unsqueeze(1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    cnn = CNN(xtr, dp=0)\n",
    "\n",
    "    optim = torch.optim.Adam(cnn.parameters(), lr=1e-1, weight_decay=1e-1)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        z, yhat1 = cnn(xtr)\n",
    "        loss = mseLoss(yhat1, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sched.step(loss)\n",
    "#         if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "#             print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "#     print('Complete')\n",
    "\n",
    "    cnn.eval()\n",
    "    z, yhat1 = cnn(xt)\n",
    "    loss = mseLoss(yhat1, yt)**0.5\n",
    "    losses.append(float(loss))\n",
    "    \n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ddf7cd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.68341064453125, 36.79133605957031, 34.97216796875, 34.43770217895508, 33.28044891357422, 31.87364387512207, 30.97648048400879, 33.13452911376953, 30.899599075317383, 29.04654884338379]\n"
     ]
    }
   ],
   "source": [
    "ntrain = 800\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = codescuda.unsqueeze(1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    mseLoss = nn.MSELoss()\n",
    "\n",
    "    nEpochs = 500\n",
    "    pPeriod = 100\n",
    "\n",
    "    cnn = CNN(xtr, dp=0.1)\n",
    "    sim = LatSim(1, torch.zeros(1,1,10), dp=0, edp=0.1, wInit=1e-4, dim=20, temp=1)\n",
    "\n",
    "    optim = torch.optim.Adam(itertools.chain(cnn.parameters(), sim.parameters()), lr=1e-1, weight_decay=1e-2)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        z, yhat1 = cnn(xtr)\n",
    "        yhat2 = sim(z.unsqueeze(1), [ytr])[0][0]\n",
    "        loss = mseLoss(yhat2, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sched.step(loss)\n",
    "    #     if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "    #         print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "    # print('Complete')\n",
    "\n",
    "    cnn.eval()\n",
    "    sim.eval()\n",
    "    z, yhat1 = cnn(xps)\n",
    "    yhat2 = sim(z.unsqueeze(1), [y_t])[0][0][ntrain:]\n",
    "    loss = mseLoss(yhat2, yt)**0.5\n",
    "    losses.append(float(loss))\n",
    "    \n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ea2c4bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.64677429199219, 36.754432678222656, 35.20348358154297, 33.7934455871582, 33.08011245727539, 32.91068649291992, 30.93649673461914, 31.29697608947754, 31.2243709564209, 30.52267074584961]\n"
     ]
    }
   ],
   "source": [
    "ntrain = 700\n",
    "\n",
    "losses = []\n",
    "\n",
    "for ntrain in [30,50,100,200,300,400,500,600,700,800]:\n",
    "    codescuda = codes.float().cuda()\n",
    "    xps = torch.mean(codescuda, dim=-1).unsqueeze(1)\n",
    "    xtr = xps[:ntrain]\n",
    "    xt = xps[ntrain:]\n",
    "\n",
    "    y = get_y(metadict, ['age'], subs)[0]\n",
    "    y_t = torch.from_numpy(y).float().cuda()\n",
    "    ytr = y_t[:ntrain]\n",
    "    yt = y_t[ntrain:]\n",
    "\n",
    "    mseLoss = nn.MSELoss()\n",
    "\n",
    "    nEpochs = 500\n",
    "    pPeriod = 100\n",
    "\n",
    "    sim = LatSim(1, torch.zeros(1,1,ncodes), dp=0.1, edp=0.1, wInit=1e-4, dim=2, temp=1)\n",
    "\n",
    "    optim = torch.optim.Adam(sim.parameters(), lr=1e-1, weight_decay=1e-2)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        optim.zero_grad()\n",
    "        yhat = sim(xtr, [ytr])[0][0]\n",
    "        loss = mseLoss(yhat, ytr)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sched.step(loss)\n",
    "#         if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "#             print(f'{epoch} recon: {loss**0.5} {sched._last_lr}')\n",
    "\n",
    "#     print('Complete')\n",
    "\n",
    "    sim.eval()\n",
    "    yhat = sim(xps, [y_t])[0][0][ntrain:]\n",
    "    loss = mseLoss(yhat, yt)**0.5\n",
    "    losses.append(float(loss))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9cfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
