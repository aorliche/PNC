{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oX3vFL00HkNt",
    "outputId": "3db765b4-7743-4581-e445-f7b07c1fae8b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# It might be faster to construct codebook page by page, and update the weights periodically,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Rather than have the codebook and weights update in one big network\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# It might be faster to construct codebook page by page, and update the weights periodically,\n",
    "# Rather than have the codebook and weights update in one big network\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wf-6dMU0H6Wk",
    "outputId": "7e61f7a6-4ba6-40ab-db66-d6f699688d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'wrat', 'missingage', 'missingsex', 'missingwrat', 'failedqc']\n",
      "['emoid', 'nback', 'rest']\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Using newly preprocessed subjects\n",
    "\n",
    "import pickle\n",
    "\n",
    "# metadictname = '/content/drive/MyDrive/Tulane/Research/PNC/PNC_agesexwrat.pkl'\n",
    "# alltsname = '/content/drive/MyDrive/Tulane/Research/PNC/PNC_PowerTS_float2.pkl'\n",
    "metadictname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_agesexwrat.pkl'\n",
    "alltsname = '/home/anton/Documents/Tulane/Research/PNC_Good/PNC_PowerTS_float2.pkl'\n",
    "\n",
    "with open(metadictname, 'rb') as f:\n",
    "    metadict = pickle.load(f)\n",
    "\n",
    "with open(alltsname, 'rb') as f:\n",
    "    allts = pickle.load(f)\n",
    "    \n",
    "print(list(metadict.keys()))\n",
    "print(list(allts.keys()))\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjpa4d4wJmzB",
    "outputId": "f0114bbb-df19-4f63-daf1-bdb5cc81d8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n",
      "(847, 264, 124)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get subjects that have all tasks and paras specified\n",
    "Functions for creating independent and response variables\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_subs(allts, metadict, tasks, paras):\n",
    "    # Get subs for all paras\n",
    "    for i,para in enumerate(paras):\n",
    "        tmpset = set([int(sub[4:]) for sub in allts[para].keys()])\n",
    "        if i == 0:\n",
    "            paraset = tmpset\n",
    "        else:\n",
    "            paraset = paraset.intersection(tmpset)\n",
    "    # Get subs for all tasks\n",
    "    for i,task in enumerate(tasks):\n",
    "        tmpset = set([sub for sub in metadict[task].keys()])\n",
    "        if i == 0:\n",
    "            taskset = tmpset\n",
    "        else:\n",
    "            taskset = paraset.intersection(tmpset)\n",
    "    # Remove QC failures\n",
    "    allsubs = taskset.intersection(paraset)\n",
    "    for badsub in metadict['failedqc']:\n",
    "        try:\n",
    "            allsubs.remove(int(badsub[4:]))\n",
    "        except:\n",
    "            pass\n",
    "    return allsubs\n",
    "\n",
    "def get_X(allts, paras, subs):\n",
    "    X = []\n",
    "    for para in paras:\n",
    "        pX = [allts[para][f'sub-{sub}'] for sub in subs]\n",
    "        pX = np.stack(pX)\n",
    "        X.append(pX)\n",
    "    return X\n",
    "\n",
    "def get_y(metadict, tasks, subs):\n",
    "    y = []\n",
    "    for task in tasks:\n",
    "        if task == 'age' or task == 'wrat':\n",
    "            var = [metadict[task][sub] for sub in subs]\n",
    "            var = np.array(var)\n",
    "            y.append(var)\n",
    "        if task == 'sex':\n",
    "            maleness = [metadict[task][sub] == 'M' for sub in subs]\n",
    "            maleness = np.array(maleness)\n",
    "            sex = np.stack([maleness, 1-maleness], axis=1)\n",
    "            y.append(sex)\n",
    "    return y\n",
    "\n",
    "subs = get_subs(allts, metadict, ['age'], ['rest', 'nback', 'emoid'])\n",
    "print(len(subs))\n",
    "\n",
    "X = get_X(allts, ['rest', 'nback', 'emoid'], subs)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dl7s1WtYJnz-",
    "outputId": "995081e9-5ba2-4006-9189-79ce74ee01a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(264, 264)\n"
     ]
    }
   ],
   "source": [
    "# TS to condensed FC\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def butter_bandpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = [cutoff[0] / nyq, cutoff[1] / nyq]\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_bandpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "tr = 1.83\n",
    "N = X[0].shape[0]\n",
    "\n",
    "def filter_design_ts(X):\n",
    "    Xs = []\n",
    "    for i in range(X.shape[0]):\n",
    "        nX = butter_bandpass_filter(X[i], [tr/20*N, 0.8*N], 2*N)\n",
    "        Xs.append(nX)\n",
    "    return np.stack(Xs)\n",
    "\n",
    "def ts_to_flat_fc(X):\n",
    "    p = np.corrcoef(X)\n",
    "    a,b = np.triu_indices(p[0].shape[0], 1)\n",
    "    p = p[a,b]\n",
    "    return p\n",
    "\n",
    "p = [[np.corrcoef(ts) for ts in filter_design_ts(Xp)] for Xp in X]\n",
    "print(len(p))\n",
    "print(p[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Cgccp6PeXYn",
    "outputId": "518bd42b-c7dc-48a5-9870-a7036c4e1c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([847, 3, 264, 264])\n",
      "torch.Size([600, 3, 264, 264])\n",
      "torch.Size([247, 3, 264, 264])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mask(e):\n",
    "    return e - torch.diag(torch.diag(e.detach()))\n",
    "\n",
    "x = [[mask(torch.from_numpy(pp).float().cuda()) for pp in para] for para in p]\n",
    "x = torch.stack([torch.stack(para) for para in x], dim=1)\n",
    "xtr = x[:600]\n",
    "xt = x[600:]\n",
    "\n",
    "print(x.shape)\n",
    "print(xtr.shape)\n",
    "print(xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oe2rTfDAJtAW",
    "outputId": "c2e50b97-694e-47c9-9ebb-9d3bd4806c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.1620311588048935] page: 0 lr: [0.1, 0.1]\n",
      "100 [0.04182826727628708] page: 0 lr: [0.08100000000000002, 0.08100000000000002]\n",
      "200 [0.04182606562972069] page: 0 lr: [0.03138105960900001, 0.03138105960900001]\n",
      "300 [0.04182606562972069] page: 0 lr: [0.01215766545905694, 0.01215766545905694]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "class LowRankCodes(nn.Module):\n",
    "    def __init__(self, ranks):\n",
    "        super(LowRankCodes, self).__init__()\n",
    "        self.book = []\n",
    "        for rank in ranks:\n",
    "            self.book.append(nn.Parameter(1e-5*torch.randn(rank,264).float().cuda()))\n",
    "        self.book = nn.ParameterList(self.book)\n",
    "        self.page = 0\n",
    "\n",
    "    def turn_page(self):\n",
    "        if self.page < len(self.book)-1:\n",
    "            self.page += 1\n",
    "        \n",
    "    def is_finished(self):\n",
    "        return self.page == len(self.book)-1\n",
    "\n",
    "    def get_book(self):\n",
    "        book = []\n",
    "        for page in self.book:\n",
    "            book.append(mask(page.T@page))\n",
    "        return torch.stack(book)\n",
    "\n",
    "    def forward(self):\n",
    "        return mask(self.book[self.page].T@self.book[self.page])\n",
    "    \n",
    "class LowRankWeights(nn.Module):\n",
    "    def __init__(self, nsubs, nranks):\n",
    "        super(LowRankWeights, self).__init__()\n",
    "        self.w = nn.Parameter(torch.ones(nsubs, nranks).float().cuda())\n",
    "        \n",
    "    def forward(self, book, pagenum):\n",
    "        w = F.relu(self.w[:,:pagenum+1])\n",
    "        return torch.einsum('nr,rab->nab',w,book[:pagenum+1])\n",
    "    \n",
    "nEpochs = 30000\n",
    "pPeriod = 100\n",
    "nRanks = 100\n",
    "lr = 1e-1\n",
    "lr_thresh = 1e-2\n",
    "\n",
    "mseLoss = nn.MSELoss()\n",
    "    \n",
    "lrc = LowRankCodes(nRanks*[1])\n",
    "lrw = LowRankWeights(xtr.shape[0], nRanks)\n",
    "\n",
    "optim = torch.optim.Adam(\n",
    "    [\n",
    "        {'params': lrc.parameters(), 'lr': lr},\n",
    "        {'params': lrw.parameters(), 'lr': lr} \n",
    "    ],\n",
    "    weight_decay=0\n",
    ")\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=10, factor=0.9, eps=1e-7)\n",
    "\n",
    "def reset_lr(optim, lr):\n",
    "    for i, param_group in enumerate(optim.param_groups):\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "book = torch.zeros(nRanks,264,264).float().cuda()\n",
    "    \n",
    "for epoch in range(nEpochs):\n",
    "    optim.zero_grad()\n",
    "    book = book.detach()\n",
    "    book[lrc.page] = lrc()\n",
    "    loss = []\n",
    "    for ip in range(1):\n",
    "        scratch = lrw(book, lrc.page)\n",
    "        xloss = mseLoss(scratch, xtr[:,ip])\n",
    "        loss.append(xloss)\n",
    "    sum(loss).backward()\n",
    "    optim.step()\n",
    "    sched.step(xloss)\n",
    "    if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "        print(f'{epoch} {[float(ploss) for ploss in loss]} page: {lrc.page} lr: {sched._last_lr}')\n",
    "    if sched._last_lr[0] < lr_thresh:\n",
    "        # print('Turned')\n",
    "        lrc.turn_page()\n",
    "        reset_lr(optim, lr)\n",
    "    if lrc.is_finished():\n",
    "        print('Early finish')\n",
    "        break\n",
    "        \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVgWdNQPmEJu",
    "outputId": "81fdc862-1b9d-48d0-9038-45523de58993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40181, device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(lrw.w[:,:100] > 0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
